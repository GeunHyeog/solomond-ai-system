#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì¢…í•© ìƒí™© ë¶„ì„ ì‹œìŠ¤í…œ - ì‹¤ì œ ìƒí™©ì˜ ëª¨ë“  íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•© ë¶„ì„
"""
import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import tempfile
import shutil

# ìµœì í™” ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['OMP_NUM_THREADS'] = '4'
os.environ['MKL_NUM_THREADS'] = '4'

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

class ComprehensiveSituationAnalyzer:
    """ì¢…í•© ìƒí™© ë¶„ì„ê¸° - ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„"""
    
    def __init__(self):
        self.situation_data = {
            'metadata': {
                'analysis_time': datetime.now().isoformat(),
                'total_files': 0,
                'file_types': {},
                'timeline': []
            },
            'audio_analysis': [],
            'image_analysis': [],
            'video_analysis': [],
            'comprehensive_story': {},
            'situation_reconstruction': {},
            'recommendations': []
        }
        
        # ë¶„ì„ ì—”ì§„ë“¤
        self.engines_loaded = False
        
    def _load_engines(self):
        """ë¶„ì„ ì—”ì§„ë“¤ ì§€ì—° ë¡œë”©"""
        if self.engines_loaded:
            return
            
        try:
            print("ğŸ”„ ë¶„ì„ ì—”ì§„ ë¡œë”© ì¤‘...")
            
            # ìµœì í™”ëœ ëª¨ë¸ë“¤
            import whisper
            self.whisper_model = whisper.load_model("tiny", device="cpu")
            print("âœ… Whisper tiny ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            import easyocr
            self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False)
            print("âœ… EasyOCR ë¡œë“œ ì™„ë£Œ")
            
            # ê¸°ì¡´ ì†”ë¡œëª¬ë“œ ì—”ì§„ í™œìš©
            try:
                from core.real_analysis_engine import RealAnalysisEngine
                self.analysis_engine = RealAnalysisEngine()
                print("âœ… ì†”ë¡œëª¬ë“œ ë¶„ì„ ì—”ì§„ ì—°ê²° ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì†”ë¡œëª¬ë“œ ì—”ì§„ ì—°ê²° ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œ ì‚¬ìš©: {e}")
                self.analysis_engine = None
            
            self.engines_loaded = True
            
        except Exception as e:
            print(f"âŒ ì—”ì§„ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def discover_situation_files(self, user_files_path: str = "user_files"):
        """ìƒí™© íŒŒì¼ë“¤ ë°œê²¬ ë° ë¶„ë¥˜"""
        print("ğŸ“ ìƒí™© íŒŒì¼ íƒìƒ‰ ì¤‘...")
        
        files_by_type = {
            'audio': [],
            'image': [],
            'video': [],
            'document': []
        }
        
        user_path = Path(user_files_path)
        if not user_path.exists():
            print(f"âŒ {user_files_path} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return files_by_type
        
        # ì‹œê°„ìˆœ ì •ë ¬ì„ ìœ„í•œ íŒŒì¼ ìˆ˜ì§‘
        all_files = []
        
        for file_path in user_path.rglob("*"):
            if file_path.is_file() and file_path.name != "README.md":
                try:
                    stat = file_path.stat()
                    file_info = {
                        'path': file_path,
                        'name': file_path.name,
                        'size_mb': stat.st_size / 1024 / 1024,
                        'modified_time': stat.st_mtime,
                        'ext': file_path.suffix.lower()
                    }
                    all_files.append(file_info)
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ì •ë³´ ì½ê¸° ì‹¤íŒ¨: {file_path.name} - {e}")
        
        # ì‹œê°„ìˆœ ì •ë ¬ (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
        all_files.sort(key=lambda x: x['modified_time'])
        
        # íƒ€ì…ë³„ ë¶„ë¥˜
        for file_info in all_files:
            ext = file_info['ext']
            
            if ext in ['.m4a', '.wav', '.mp3', '.aac']:
                files_by_type['audio'].append(file_info)
            elif ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                files_by_type['image'].append(file_info)
            elif ext in ['.mov', '.mp4', '.avi', '.mkv']:
                files_by_type['video'].append(file_info)
            elif ext in ['.pdf', '.docx', '.txt']:
                files_by_type['document'].append(file_info)
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.situation_data['metadata']['total_files'] = len(all_files)
        self.situation_data['metadata']['file_types'] = {
            k: len(v) for k, v in files_by_type.items()
        }
        
        print(f"ğŸ“Š ë°œê²¬ëœ íŒŒì¼:")
        print(f"   ğŸµ ì˜¤ë””ì˜¤: {len(files_by_type['audio'])}ê°œ")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {len(files_by_type['image'])}ê°œ")
        print(f"   ğŸ¬ ë¹„ë””ì˜¤: {len(files_by_type['video'])}ê°œ")
        print(f"   ğŸ“„ ë¬¸ì„œ: {len(files_by_type['document'])}ê°œ")
        
        return files_by_type
    
    def analyze_audio_sequence(self, audio_files: List[Dict]):
        """ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ ìˆœì°¨ ë¶„ì„"""
        if not audio_files:
            return
            
        print("\\nğŸµ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ ë¶„ì„ ì¤‘...")
        
        for i, file_info in enumerate(audio_files):
            print(f"  ì²˜ë¦¬ ì¤‘: {file_info['name']} ({file_info['size_mb']:.1f}MB)")
            
            try:
                # í¬ê¸° ì œí•œ (ì„±ëŠ¥ ìµœì í™”)
                if file_info['size_mb'] > 50:
                    print(f"    âš ï¸ íŒŒì¼ í¬ê¸° ì´ˆê³¼, ìŠ¤í‚µ")
                    continue
                
                start_time = time.time()
                
                # Whisper STT
                result = self.whisper_model.transcribe(str(file_info['path']))
                
                analysis_result = {
                    'file_name': file_info['name'],
                    'file_path': str(file_info['path']),
                    'sequence_order': i + 1,
                    'file_size_mb': file_info['size_mb'],
                    'processing_time': time.time() - start_time,
                    'transcript': result.get('text', ''),
                    'language': result.get('language', 'unknown'),
                    'segments': result.get('segments', []),
                    'timestamp': datetime.fromtimestamp(file_info['modified_time']).isoformat()
                }
                
                self.situation_data['audio_analysis'].append(analysis_result)
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                text_preview = analysis_result['transcript'][:100]
                print(f"    âœ… ì™„ë£Œ ({analysis_result['processing_time']:.1f}ì´ˆ)")
                print(f"    ğŸ“ ë‚´ìš©: {text_preview}...")
                
            except Exception as e:
                print(f"    âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                self._handle_audio_error(file_info, str(e))
    
    def analyze_image_sequence(self, image_files: List[Dict]):
        """ì´ë¯¸ì§€ íŒŒì¼ë“¤ ìˆœì°¨ ë¶„ì„"""
        if not image_files:
            return
            
        print("\\nğŸ–¼ï¸ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ë¶„ì„ ì¤‘...")
        
        for i, file_info in enumerate(image_files):
            print(f"  ì²˜ë¦¬ ì¤‘: {file_info['name']} ({file_info['size_mb']:.1f}MB)")
            
            try:
                # í¬ê¸° ì œí•œ
                if file_info['size_mb'] > 20:
                    print(f"    âš ï¸ íŒŒì¼ í¬ê¸° ì´ˆê³¼, ìŠ¤í‚µ")
                    continue
                
                start_time = time.time()
                
                # OCR ë¶„ì„
                results = self.ocr_reader.readtext(str(file_info['path']))
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                extracted_texts = []
                for (bbox, text, confidence) in results:
                    if confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒ
                        extracted_texts.append({
                            'text': text,
                            'confidence': confidence,
                            'bbox': bbox
                        })
                
                analysis_result = {
                    'file_name': file_info['name'],
                    'file_path': str(file_info['path']),
                    'sequence_order': i + 1,
                    'file_size_mb': file_info['size_mb'],
                    'processing_time': time.time() - start_time,
                    'extracted_texts': extracted_texts,
                    'total_text_blocks': len(extracted_texts),
                    'timestamp': datetime.fromtimestamp(file_info['modified_time']).isoformat()
                }
                
                self.situation_data['image_analysis'].append(analysis_result)
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                text_preview = ' '.join([item['text'] for item in extracted_texts[:3]])[:100]
                print(f"    âœ… ì™„ë£Œ ({analysis_result['processing_time']:.1f}ì´ˆ)")
                print(f"    ğŸ“ í…ìŠ¤íŠ¸: {text_preview}...")
                
            except Exception as e:
                print(f"    âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                self._handle_image_error(file_info, str(e))
    
    def analyze_video_sequence(self, video_files: List[Dict]):
        """ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ë¶„ì„ (ê¸°ë³¸ì ì¸ ë©”íƒ€ë°ì´í„°)"""
        if not video_files:
            return
            
        print("\\nğŸ¬ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë¶„ì„ ì¤‘...")
        
        for i, file_info in enumerate(video_files):
            print(f"  ì²˜ë¦¬ ì¤‘: {file_info['name']} ({file_info['size_mb']:.1f}MB)")
            
            try:
                # ë¹„ë””ì˜¤ëŠ” ë©”íƒ€ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ì„±ëŠ¥ìƒ ì´ìœ )
                analysis_result = {
                    'file_name': file_info['name'],
                    'file_path': str(file_info['path']),
                    'sequence_order': i + 1,
                    'file_size_mb': file_info['size_mb'],
                    'processing_time': 0.1,
                    'analysis_type': 'metadata_only',
                    'timestamp': datetime.fromtimestamp(file_info['modified_time']).isoformat(),
                    'note': 'ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ëŠ” ë©”íƒ€ë°ì´í„°ë§Œ ìˆ˜ì§‘'
                }
                
                self.situation_data['video_analysis'].append(analysis_result)
                print(f"    âœ… ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                
            except Exception as e:
                print(f"    âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def reconstruct_situation_story(self):
        """ìƒí™© ì¬êµ¬ì„± ë° ìŠ¤í† ë¦¬ ìƒì„±"""
        print("\\nğŸ“– ìƒí™© ìŠ¤í† ë¦¬ ì¬êµ¬ì„± ì¤‘...")
        
        # ì‹œê°„ìˆœìœ¼ë¡œ ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì •ë ¬
        timeline_events = []
        
        # ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸
        for audio in self.situation_data['audio_analysis']:
            timeline_events.append({
                'timestamp': audio['timestamp'],
                'type': 'audio',
                'content': audio['transcript'],
                'file': audio['file_name'],
                'order': audio['sequence_order']
            })
        
        # ì´ë¯¸ì§€ ì´ë²¤íŠ¸
        for image in self.situation_data['image_analysis']:
            text_content = ' '.join([item['text'] for item in image['extracted_texts']])
            timeline_events.append({
                'timestamp': image['timestamp'],
                'type': 'image',
                'content': text_content,
                'file': image['file_name'],
                'order': image['sequence_order']
            })
        
        # ë¹„ë””ì˜¤ ì´ë²¤íŠ¸
        for video in self.situation_data['video_analysis']:
            timeline_events.append({
                'timestamp': video['timestamp'],
                'type': 'video',
                'content': f"ë¹„ë””ì˜¤ íŒŒì¼: {video['file_name']}",
                'file': video['file_name'],
                'order': video['sequence_order']
            })
        
        # ì‹œê°„ìˆœ ì •ë ¬
        timeline_events.sort(key=lambda x: x['timestamp'])
        
        # ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„±
        story_parts = []
        for event in timeline_events:
            if event['content'].strip():
                story_parts.append(f"[{event['type'].upper()}] {event['content']}")
        
        comprehensive_story = "\\n\\n".join(story_parts)
        
        # ìƒí™© ìš”ì•½ ìƒì„±
        audio_summary = self._summarize_audio_content()
        image_summary = self._summarize_image_content()
        
        situation_summary = {
            'timeline_events': timeline_events,
            'comprehensive_story': comprehensive_story,
            'audio_summary': audio_summary,
            'image_summary': image_summary,
            'total_duration': len(timeline_events),
            'key_insights': self._extract_key_insights(timeline_events)
        }
        
        self.situation_data['situation_reconstruction'] = situation_summary
        
        print(f"âœ… ìŠ¤í† ë¦¬ ì¬êµ¬ì„± ì™„ë£Œ: {len(timeline_events)}ê°œ ì´ë²¤íŠ¸")
        
    def _summarize_audio_content(self):
        """ì˜¤ë””ì˜¤ ë‚´ìš© ìš”ì•½"""
        all_transcripts = []
        for audio in self.situation_data['audio_analysis']:
            if audio['transcript'].strip():
                all_transcripts.append(audio['transcript'])
        
        if not all_transcripts:
            return "ì˜¤ë””ì˜¤ ë‚´ìš© ì—†ìŒ"
        
        # ê°„ë‹¨í•œ ìš”ì•½ (ì²« 200ì + ë§ˆì§€ë§‰ 100ì)
        combined = " ".join(all_transcripts)
        if len(combined) > 300:
            summary = combined[:200] + "..." + combined[-100:]
        else:
            summary = combined
        
        return summary
    
    def _summarize_image_content(self):
        """ì´ë¯¸ì§€ ë‚´ìš© ìš”ì•½"""
        all_texts = []
        for image in self.situation_data['image_analysis']:
            for text_item in image['extracted_texts']:
                all_texts.append(text_item['text'])
        
        if not all_texts:
            return "ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì—†ìŒ"
        
        # ì¤‘ë³µ ì œê±° ë° ìš”ì•½
        unique_texts = list(set(all_texts))
        combined = " ".join(unique_texts[:10])  # ì²˜ìŒ 10ê°œë§Œ
        
        return combined[:200] + "..." if len(combined) > 200 else combined
    
    def _extract_key_insights(self, timeline_events):
        """ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬
        type_counts = {}
        for event in timeline_events:
            type_counts[event['type']] = type_counts.get(event['type'], 0) + 1
        
        insights.append(f"íŒŒì¼ êµ¬ì„±: " + ", ".join([f"{k} {v}ê°œ" for k, v in type_counts.items()]))
        
        # ë‚´ìš© ê¸¸ì´ ë¶„ì„
        content_lengths = [len(event['content']) for event in timeline_events if event['content']]
        if content_lengths:
            avg_length = sum(content_lengths) / len(content_lengths)
            insights.append(f"í‰ê·  ë‚´ìš© ê¸¸ì´: {avg_length:.0f}ì")
        
        # ì‹œê°„ ë²”ìœ„
        if len(timeline_events) > 1:
            first_time = timeline_events[0]['timestamp']
            last_time = timeline_events[-1]['timestamp']
            insights.append(f"ì‹œê°„ ë²”ìœ„: {first_time} ~ {last_time}")
        
        return insights
    
    def _handle_audio_error(self, file_info, error_msg):
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ ìë™ ë³µêµ¬"""
        print(f"    ğŸ”§ ì˜¤ë””ì˜¤ ì˜¤ë¥˜ ìë™ ë³µêµ¬ ì‹œë„: {file_info['name']}")
        
        # ê°„ë‹¨í•œ ì˜¤ë¥˜ ì •ë³´ë§Œ ê¸°ë¡
        error_result = {
            'file_name': file_info['name'],
            'error': error_msg,
            'recovery_attempted': True,
            'timestamp': datetime.fromtimestamp(file_info['modified_time']).isoformat()
        }
        
        self.situation_data['audio_analysis'].append(error_result)
    
    def _handle_image_error(self, file_info, error_msg):
        """ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ ìë™ ë³µêµ¬"""
        print(f"    ğŸ”§ ì´ë¯¸ì§€ ì˜¤ë¥˜ ìë™ ë³µêµ¬ ì‹œë„: {file_info['name']}")
        
        # ê°„ë‹¨í•œ ì˜¤ë¥˜ ì •ë³´ë§Œ ê¸°ë¡
        error_result = {
            'file_name': file_info['name'],
            'error': error_msg,
            'recovery_attempted': True,
            'timestamp': datetime.fromtimestamp(file_info['modified_time']).isoformat()
        }
        
        self.situation_data['image_analysis'].append(error_result)
    
    def save_comprehensive_analysis(self):
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"comprehensive_situation_analysis_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.situation_data, f, ensure_ascii=False, indent=2)
        
        print(f"\\nğŸ’¾ ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥: {filename}")
        return filename
    
    def print_situation_summary(self):
        """ìƒí™© ìš”ì•½ ì¶œë ¥"""
        print("\\n" + "="*60)
        print("ğŸ“‹ ìƒí™© ë¶„ì„ ìš”ì•½")
        print("="*60)
        
        # ë©”íƒ€ë°ì´í„°
        meta = self.situation_data['metadata']
        print(f"ğŸ“Š ì´ íŒŒì¼ ìˆ˜: {meta['total_files']}ê°œ")
        
        for file_type, count in meta['file_types'].items():
            if count > 0:
                print(f"   {file_type}: {count}ê°œ")
        
        # ì˜¤ë””ì˜¤ ìš”ì•½
        if self.situation_data['audio_analysis']:
            print(f"\\nğŸµ ì˜¤ë””ì˜¤ ë¶„ì„:")
            audio_summary = self.situation_data['situation_reconstruction'].get('audio_summary', '')
            print(f"   {audio_summary[:150]}...")
        
        # ì´ë¯¸ì§€ ìš”ì•½
        if self.situation_data['image_analysis']:
            print(f"\\nğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„:")
            image_summary = self.situation_data['situation_reconstruction'].get('image_summary', '')
            print(f"   {image_summary[:150]}...")
        
        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
        insights = self.situation_data['situation_reconstruction'].get('key_insights', [])
        if insights:
            print(f"\\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
            for insight in insights:
                print(f"   â€¢ {insight}")
        
        print("="*60)
    
    def analyze_comprehensive_situation(self, user_files_path: str = "user_files"):
        """ì¢…í•© ìƒí™© ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ¯ ì¢…í•© ìƒí™© ë¶„ì„ ì‹œì‘")
        print("="*50)
        
        try:
            # 1. ì—”ì§„ ë¡œë”©
            self._load_engines()
            
            # 2. íŒŒì¼ ë°œê²¬
            files_by_type = self.discover_situation_files(user_files_path)
            
            # 3. ìˆœì°¨ ë¶„ì„
            self.analyze_audio_sequence(files_by_type['audio'])
            self.analyze_image_sequence(files_by_type['image'])
            self.analyze_video_sequence(files_by_type['video'])
            
            # 4. ìƒí™© ì¬êµ¬ì„±
            self.reconstruct_situation_story()
            
            # 5. ê²°ê³¼ ì €ì¥
            self.save_comprehensive_analysis()
            
            # 6. ìš”ì•½ ì¶œë ¥
            self.print_situation_summary()
            
            print("\\nâœ… ì¢…í•© ìƒí™© ë¶„ì„ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"\\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ğŸ”§ ìë™ ë³µêµ¬ ì‹œë„ ì¤‘...")
            
            # ê¸°ë³¸ì ì¸ ì˜¤ë¥˜ ë³µêµ¬
            try:
                self.save_comprehensive_analysis()
                print("ğŸ’¾ ë¶€ë¶„ ê²°ê³¼ë¼ë„ ì €ì¥ ì™„ë£Œ")
            except:
                print("âŒ ì €ì¥ë„ ì‹¤íŒ¨")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = ComprehensiveSituationAnalyzer()
    analyzer.analyze_comprehensive_situation()

if __name__ == "__main__":
    main()