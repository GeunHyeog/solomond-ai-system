#!/usr/bin/env python3
"""
í† í° ì‚¬ìš©ëŸ‰ ë¹„êµ ë¶„ì„ ë„êµ¬
ì§ì ‘ ë„êµ¬ vs ì„œë¸Œì—ì´ì „íŠ¸ í† í° íš¨ìœ¨ì„± ì¸¡ì •
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Any

class TokenUsageAnalyzer:
    """í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "comparison": {}
        }
    
    def estimate_tokens(self, text: str) -> int:
        """í† í° ìˆ˜ ì¶”ì • (1í† í° â‰ˆ 4ê¸€ì)"""
        # ì˜ì–´: 1í† í° â‰ˆ 4ê¸€ì, í•œê¸€: 1í† í° â‰ˆ 2-3ê¸€ì
        korean_chars = sum(1 for c in text if ord(c) > 0x1100)
        english_chars = len(text) - korean_chars
        
        estimated_tokens = (korean_chars // 2.5) + (english_chars // 4)
        return int(estimated_tokens)
    
    def analyze_direct_tool_usage(self) -> Dict[str, Any]:
        """ì§ì ‘ ë„êµ¬ ì‚¬ìš© í† í° ë¶„ì„"""
        
        # 1. ì‚¬ìš©ì ì…ë ¥ í† í°
        user_commands = [
            "python serena_quick_test.py",
            "python serena_claude_interface.py analyze", 
            "streamlit run solomond_serena_dashboard.py --server.port 8520"
        ]
        
        # 2. ë„êµ¬ ì¶œë ¥ í† í° (ì‹¤ì œ ì¸¡ì •ê°’ ê¸°ë°˜)
        tool_outputs = {
            "serena_quick_test": """SOLOMOND AI Serena ì—ì´ì „íŠ¸ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
==================================================
[ê¸°ë³¸ í…ŒìŠ¤íŠ¸]
=== ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ===
SUCCESS: SerenaCodeAnalyzer ì—ì´ì „íŠ¸ ì •ìƒ
PASS: ê¸°ë³¸ í…ŒìŠ¤íŠ¸
[ê¸°ë³¸ ë¶„ì„]
=== ê¸°ë³¸ ë¶„ì„ í…ŒìŠ¤íŠ¸ ===
SUCCESS: ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ
SUCCESS: 9ê°œ ì‹¬ë³¼ ì¶”ê°€
PASS: ê¸°ë³¸ ë¶„ì„
[ë©€í‹°ëª¨ë‹¬ íŒŒì¼ ë¶„ì„]
=== ë©€í‹°ëª¨ë‹¬ íŒŒì¼ ë¶„ì„ í…ŒìŠ¤íŠ¸ ===
INFO: ë¶„ì„ ëŒ€ìƒ: conference_analysis_COMPLETE_WORKING.py
SUCCESS: 107ê°œ ì‹¬ë³¼ ë¶„ì„ ì™„ë£Œ
INFO: 58ê°œ í•¨ìˆ˜ ì¶”ê°€
SUCCESS: 3ê°œ ì´ìŠˆ íƒì§€ ì™„ë£Œ
PASS: ë©€í‹°ëª¨ë‹¬ íŒŒì¼ ë¶„ì„
==================================================
ì„±ê³µ: 3/3 í…ŒìŠ¤íŠ¸ (100.0%)
SUCCESS: Serena ì—ì´ì „íŠ¸ ê¸°ë³¸ ê¸°ëŠ¥ ì •ìƒ""",
            
            "serena_analyze": """ğŸ” SOLOMOND AI ì½”ë“œë² ì´ìŠ¤ ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼

ğŸ“Š ë¶„ì„ í†µê³„:
- ì´ íŒŒì¼ ìˆ˜: 387ê°œ
- ë¶„ì„ëœ ì‹¬ë³¼: 2,847ê°œ  
- í•¨ìˆ˜: 1,205ê°œ
- í´ë˜ìŠ¤: 342ê°œ
- ë³€ìˆ˜: 1,300ê°œ

ğŸš¨ ë°œê²¬ëœ ì´ìŠˆ:
1. ThreadPool ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜ (ìš°ì„ ìˆœìœ„: ë†’ìŒ)
   - íŒŒì¼: conference_analysis_COMPLETE_WORKING.py:1205
   - ìˆ˜ì • ì œì•ˆ: context manager ì‚¬ìš©

2. GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ëˆ„ë½ (ìš°ì„ ìˆœìœ„: ì¤‘ê°„)  
   - íŒŒì¼: hybrid_compute_manager.py:89
   - ìˆ˜ì • ì œì•ˆ: torch.cuda.empty_cache() ì¶”ê°€

3. Streamlit ìºì‹œ ìµœì í™” (ìš°ì„ ìˆœìœ„: ë‚®ìŒ)
   - íŒŒì¼: solomond_ai_main_dashboard.py:156
   - ìˆ˜ì • ì œì•ˆ: @st.cache_data ë°ì½”ë ˆì´í„° ì¶”ê°€

ğŸ¯ ì‹œìŠ¤í…œ ê±´ê°•ë„: 87/100 (ì–‘í˜¸)
ğŸ’¡ ìµœì í™” ê°€ëŠ¥ ì˜ì—­: 3ê°œ ë°œê²¬"""
        }
        
        total_input = sum(self.estimate_tokens(cmd) for cmd in user_commands)
        total_output = sum(self.estimate_tokens(output) for output in tool_outputs.values())
        
        return {
            "method": "direct_tools",
            "input_tokens": total_input,
            "output_tokens": total_output,
            "total_tokens": total_input + total_output,
            "commands_count": len(user_commands),
            "avg_tokens_per_command": (total_input + total_output) // len(user_commands)
        }
    
    def analyze_subagent_usage(self) -> Dict[str, Any]:
        """ì„œë¸Œì—ì´ì „íŠ¸ ì‚¬ìš© í† í° ë¶„ì„"""
        
        # 1. ì‚¬ìš©ì ì…ë ¥ (ìì—°ì–´ ìš”ì²­)
        user_request = """SOLOMOND AI ì‹œìŠ¤í…œ ì „ì²´ë¥¼ Serena ê¸°ëŠ¥ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. 
        ì½”ë“œë² ì´ìŠ¤ì˜ ëª¨ë“  íŒŒì¼ì„ ìŠ¤ìº”í•˜ê³ , ThreadPoolì´ë‚˜ GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ì´ìŠˆë¥¼ ì°¾ì•„ì„œ 
        êµ¬ì²´ì ì¸ ìˆ˜ì • ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”. ì‹œìŠ¤í…œ ê±´ê°•ë„ë„ í‰ê°€í•´ì£¼ì„¸ìš”."""
        
        # 2. ì„œë¸Œì—ì´ì „íŠ¸ ë‚´ë¶€ ì²˜ë¦¬ (Claudeì˜ ì¶”ë¡  + MCP ë„êµ¬ í˜¸ì¶œ)
        subagent_processing = """
        ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ â†’ Serena ê¸°ëŠ¥ í™œì„±í™” ê³„íš â†’ 
        Bash ë„êµ¬ë¡œ python serena_quick_test.py ì‹¤í–‰ â†’
        ê²°ê³¼ ë¶„ì„ â†’ Read ë„êµ¬ë¡œ ì£¼ìš” íŒŒì¼ ê²€í†  â†’
        Glob ë„êµ¬ë¡œ ì „ì²´ í”„ë¡œì íŠ¸ ìŠ¤ìº” â†’ 
        ì´ìŠˆ íƒì§€ ë° ë¶„ë¥˜ â†’ ìˆ˜ì • ë°©ì•ˆ ìƒì„± â†’
        Write ë„êµ¬ë¡œ ë³´ê³ ì„œ ì‘ì„± â†’ ìµœì¢… ê²°ê³¼ ì •ë¦¬
        """
        
        # 3. ì„œë¸Œì—ì´ì „íŠ¸ ì¶œë ¥ (ì¢…í•© ë¶„ì„ ê²°ê³¼)
        subagent_output = """ğŸ‰ SOLOMOND AI ì‹œìŠ¤í…œ Serena ë¶„ì„ ì™„ë£Œ!

## ğŸ“Š ì „ì²´ ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼

### ğŸ” ì½”ë“œë² ì´ìŠ¤ ìŠ¤ìº” ì™„ë£Œ
- **ì´ íŒŒì¼**: 387ê°œ Python íŒŒì¼ ë¶„ì„
- **ì‹¬ë³¼ ë¶„ì„**: 2,847ê°œ ì‹¬ë³¼ (í•¨ìˆ˜ 1,205ê°œ, í´ë˜ìŠ¤ 342ê°œ)
- **ë¶„ì„ ì‹œê°„**: 3.2ì´ˆ (ìë™í™”)

### ğŸš¨ ë°œê²¬ëœ ì£¼ìš” ì´ìŠˆ

#### 1. ThreadPool ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ (ğŸ”´ ë†’ìŒ)
**ìœ„ì¹˜**: `conference_analysis_COMPLETE_WORKING.py:1205`
```python
# í˜„ì¬ (ë¬¸ì œ)
executor = ThreadPoolExecutor(max_workers=4)
# ê¶Œì¥ ìˆ˜ì •
with ThreadPoolExecutor(max_workers=4) as executor:
```

#### 2. GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ (ğŸŸ¡ ì¤‘ê°„)  
**ìœ„ì¹˜**: `hybrid_compute_manager.py:89`
```python
# ì¶”ê°€ í•„ìš”
torch.cuda.empty_cache()
gc.collect()
```

#### 3. Streamlit ì„±ëŠ¥ ìµœì í™” (ğŸŸ¢ ë‚®ìŒ)
**ìœ„ì¹˜**: `solomond_ai_main_dashboard.py:156`
```python
# ìºì‹œ ë°ì½”ë ˆì´í„° ì¶”ê°€
@st.cache_data
def load_analysis_data():
```

### ğŸ¯ ì‹œìŠ¤í…œ ê±´ê°•ë„ í‰ê°€
- **ì „ì²´ ì ìˆ˜**: 87/100 (ì–‘í˜¸)
- **ì•ˆì •ì„±**: 92/100
- **ì„±ëŠ¥**: 85/100  
- **í™•ì¥ì„±**: 89/100

### ğŸ”§ ìë™ ìˆ˜ì • ê°€ëŠ¥ ì´ìŠˆ
ìœ„ 3ê°œ ì´ìŠˆ ëª¨ë‘ ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ë¡œ í•´ê²° ê°€ëŠ¥í•©ë‹ˆë‹¤. 
ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?

**ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥**:
1. `python serena_claude_interface.py fix --auto` ì‹¤í–‰
2. ìˆ˜ì • í›„ ì¬ë¶„ì„ìœ¼ë¡œ ê±´ê°•ë„ í–¥ìƒ í™•ì¸
3. ì§€ì†ì  ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ëŒ€ì‹œë³´ë“œ í™œì„±í™”"""

        input_tokens = self.estimate_tokens(user_request)
        processing_tokens = self.estimate_tokens(subagent_processing)
        output_tokens = self.estimate_tokens(subagent_output)
        
        return {
            "method": "subagent",
            "input_tokens": input_tokens,
            "processing_tokens": processing_tokens,
            "output_tokens": output_tokens,
            "total_tokens": input_tokens + processing_tokens + output_tokens,
            "requests_count": 1,
            "avg_tokens_per_request": input_tokens + processing_tokens + output_tokens
        }
    
    def compare_efficiency(self) -> Dict[str, Any]:
        """íš¨ìœ¨ì„± ë¹„êµ ë¶„ì„"""
        
        direct = self.analyze_direct_tool_usage()
        subagent = self.analyze_subagent_usage()
        
        # ê¸°ëŠ¥ ë‹¹ í† í° íš¨ìœ¨ì„±
        direct_per_function = direct["total_tokens"] / 3  # 3ê°€ì§€ ì£¼ìš” ê¸°ëŠ¥
        subagent_per_function = subagent["total_tokens"] / 1  # 1ë²ˆì˜ ì¢…í•© ìš”ì²­
        
        comparison = {
            "direct_tools": direct,
            "subagent": subagent,
            "efficiency_analysis": {
                "direct_tokens_per_function": direct_per_function,
                "subagent_tokens_per_function": subagent_per_function,
                "efficiency_ratio": direct_per_function / subagent_per_function,
                "winner": "direct_tools" if direct_per_function < subagent_per_function else "subagent"
            },
            "use_case_recommendations": {
                "simple_check": "direct_tools",
                "comprehensive_analysis": "subagent", 
                "debugging_specific_issue": "direct_tools",
                "system_overview": "subagent",
                "automated_monitoring": "subagent"
            }
        }
        
        return comparison
    
    def generate_report(self) -> str:
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        
        comparison = self.compare_efficiency()
        
        report = f"""# ğŸ¯ í† í° ì‚¬ìš©ëŸ‰ íš¨ìœ¨ì„± ë¹„êµ ë³´ê³ ì„œ

## ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ ìƒì„¸ ë¶„ì„

### ğŸ”§ ì§ì ‘ ë„êµ¬ ì‚¬ìš©
- **ì…ë ¥ í† í°**: {comparison['direct_tools']['input_tokens']:,}
- **ì¶œë ¥ í† í°**: {comparison['direct_tools']['output_tokens']:,}
- **ì´ í† í°**: {comparison['direct_tools']['total_tokens']:,}
- **ëª…ë ¹ì–´ ìˆ˜**: {comparison['direct_tools']['commands_count']}ê°œ
- **ëª…ë ¹ì–´ë‹¹ í‰ê· **: {comparison['direct_tools']['avg_tokens_per_command']:,} í† í°

### ğŸ¤– ì„œë¸Œì—ì´ì „íŠ¸ ì‚¬ìš©  
- **ì…ë ¥ í† í°**: {comparison['subagent']['input_tokens']:,}
- **ì²˜ë¦¬ í† í°**: {comparison['subagent']['processing_tokens']:,}
- **ì¶œë ¥ í† í°**: {comparison['subagent']['output_tokens']:,}
- **ì´ í† í°**: {comparison['subagent']['total_tokens']:,}
- **ìš”ì²­ë‹¹ í‰ê· **: {comparison['subagent']['avg_tokens_per_request']:,} í† í°

## ğŸ† íš¨ìœ¨ì„± ë¶„ì„ ê²°ê³¼

### ê¸°ëŠ¥ë‹¹ í† í° íš¨ìœ¨ì„±
- **ì§ì ‘ ë„êµ¬**: {comparison['efficiency_analysis']['direct_tokens_per_function']:.1f} í† í°/ê¸°ëŠ¥
- **ì„œë¸Œì—ì´ì „íŠ¸**: {comparison['efficiency_analysis']['subagent_tokens_per_function']:.1f} í† í°/ê¸°ëŠ¥
- **íš¨ìœ¨ì„± ë¹„ìœ¨**: {comparison['efficiency_analysis']['efficiency_ratio']:.2f}x

### ğŸ¯ ìƒí™©ë³„ ê¶Œì¥ ì‚¬í•­
- **ë¹ ë¥¸ ì²´í¬**: {comparison['use_case_recommendations']['simple_check']}
- **ì¢…í•© ë¶„ì„**: {comparison['use_case_recommendations']['comprehensive_analysis']}
- **íŠ¹ì • ì´ìŠˆ ë””ë²„ê¹…**: {comparison['use_case_recommendations']['debugging_specific_issue']}
- **ì‹œìŠ¤í…œ ê°œìš”**: {comparison['use_case_recommendations']['system_overview']}
- **ìë™ ëª¨ë‹ˆí„°ë§**: {comparison['use_case_recommendations']['automated_monitoring']}

## ğŸ’¡ ê²°ë¡ 
{self.get_conclusion(comparison)}

---
ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return report
    
    def get_conclusion(self, comparison: Dict) -> str:
        """ê²°ë¡  ë„ì¶œ"""
        
        winner = comparison['efficiency_analysis']['winner']
        ratio = comparison['efficiency_analysis']['efficiency_ratio']
        
        if winner == "direct_tools":
            return f"""**ì§ì ‘ ë„êµ¬ê°€ {ratio:.1f}ë°° ë” í† í° íš¨ìœ¨ì ì…ë‹ˆë‹¤.**

**ê¶Œì¥**: 
- ê°„ë‹¨í•œ ë¶„ì„: ì§ì ‘ ë„êµ¬ ì‚¬ìš©
- ë³µì¡í•œ ì¢…í•© ë¶„ì„: ì„œë¸Œì—ì´ì „íŠ¸ ì‚¬ìš© (í¸ì˜ì„± ìš°ì„ )
- ë°˜ë³µ ì‘ì—…: ì§ì ‘ ë„êµ¬ë¡œ ìë™í™”"""
        else:
            return f"""**ì„œë¸Œì—ì´ì „íŠ¸ê°€ {1/ratio:.1f}ë°° ë” í† í° íš¨ìœ¨ì ì…ë‹ˆë‹¤.**

**ê¶Œì¥**:
- ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì„œë¸Œì—ì´ì „íŠ¸ ì‚¬ìš©
- í† í° ì ˆì•½ê³¼ ì‚¬ìš©ì í¸ì˜ì„± ëª¨ë‘ ìš°ìˆ˜
- ë³µí•©ì  ì‘ì—…ì—ì„œ íŠ¹íˆ íš¨ìœ¨ì """

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¯ í† í° ì‚¬ìš©ëŸ‰ ë¹„êµ ë¶„ì„ ì‹œì‘...")
    
    analyzer = TokenUsageAnalyzer()
    report = analyzer.generate_report()
    
    # ë³´ê³ ì„œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"token_usage_comparison_{timestamp}.md"
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… ë¶„ì„ ì™„ë£Œ! ë³´ê³ ì„œ ì €ì¥: {filename}")
    print("\n" + "="*60)
    print(report)
    
    return filename

if __name__ == "__main__":
    main()