#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
âš™ï¸ SOLOMOND AI ë¦¬ì†ŒìŠ¤ ì„¤ì • ë„êµ¬
Resource Configurator - ì‚¬ìš©ìê°€ CPU/GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì‰½ê²Œ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ë„êµ¬

í•µì‹¬ ê¸°ëŠ¥:
1. GPU/CPU ì‚¬ìš© ëª¨ë“œ ì„ íƒ
2. ì‹¤ì‹œê°„ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ê¶Œì¥ì‚¬í•­
4. ì„¤ì • ìë™ ì €ì¥ ë° ë¡œë“œ
"""

import streamlit as st
import os
import json
import time
import subprocess
from pathlib import Path
from typing import Dict, Any, List
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta

# í•˜ì´ë¸Œë¦¬ë“œ ì»´í“¨íŒ… ë§¤ë‹ˆì € ì„í¬íŠ¸
try:
    from hybrid_compute_manager import HybridComputeManager, ComputeMode, TaskType
    HYBRID_MANAGER_AVAILABLE = True
except ImportError:
    HYBRID_MANAGER_AVAILABLE = False

class ResourceConfigurator:
    """ë¦¬ì†ŒìŠ¤ ì„¤ì • ê´€ë¦¬ì"""
    
    def __init__(self):
        self.config_file = Path("resource_config.json")
        self.load_config()
        
        if HYBRID_MANAGER_AVAILABLE:
            self.compute_manager = HybridComputeManager()
        else:
            self.compute_manager = None
    
    def load_config(self):
        """ì„¤ì • ë¡œë“œ"""
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
            except Exception:
                self.config = self.get_default_config()
        else:
            self.config = self.get_default_config()
    
    def get_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            "compute_mode": "auto",
            "whisper_device": "auto",
            "ocr_device": "auto", 
            "ollama_gpu": False,
            "memory_optimization": True,
            "auto_cleanup": True,
            "performance_monitoring": True,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
    
    def save_config(self):
        """ì„¤ì • ì €ì¥"""
        self.config["updated_at"] = datetime.now().isoformat()
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def apply_settings(self):
        """ì„¤ì • ì ìš©"""
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        if self.config["compute_mode"] == "cpu_only":
            os.environ["CUDA_VISIBLE_DEVICES"] = ""
        elif self.config["compute_mode"] == "gpu_only":
            if "CUDA_VISIBLE_DEVICES" in os.environ:
                del os.environ["CUDA_VISIBLE_DEVICES"]
        
        # Ollama GPU ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ)
        if self.config["ollama_gpu"]:
            os.environ["OLLAMA_GPU"] = "1"
        else:
            os.environ["OLLAMA_GPU"] = "0"
    
    def get_resource_status(self) -> Dict[str, Any]:
        """ë¦¬ì†ŒìŠ¤ ìƒíƒœ ë°˜í™˜"""
        if self.compute_manager:
            return self.compute_manager.get_resource_status()
        
        # í´ë°±: psutilë¡œ ê¸°ë³¸ ì •ë³´ë§Œ
        import psutil
        memory = psutil.virtual_memory()
        return {
            "cpu": {
                "device_type": "cpu",
                "total_memory_gb": memory.total / (1024**3),
                "available_memory_gb": memory.available / (1024**3),
                "usage_percent": memory.percent
            }
        }

def render_resource_configurator():
    """ë¦¬ì†ŒìŠ¤ ì„¤ì • UI ë Œë”ë§"""
    st.set_page_config(
        page_title="SOLOMOND AI ë¦¬ì†ŒìŠ¤ ì„¤ì •",
        page_icon="âš™ï¸",
        layout="wide"
    )
    
    st.title("âš™ï¸ SOLOMOND AI ë¦¬ì†ŒìŠ¤ ì„¤ì •")
    st.markdown("**CPU/GPU ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì„¸ìš”**")
    
    # ì„¤ì • ê´€ë¦¬ì ì´ˆê¸°í™”
    configurator = ResourceConfigurator()
    
    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    # ë¦¬ì†ŒìŠ¤ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    resource_status = configurator.get_resource_status()
    
    with col1:
        cpu_status = resource_status.get("cpu", {})
        cpu_usage = cpu_status.get("usage_percent", 0)
        st.metric(
            "CPU ì‚¬ìš©ë¥ ",
            f"{cpu_usage:.1f}%",
            delta=None,
            delta_color="inverse" if cpu_usage > 80 else "normal"
        )
    
    with col2:
        cpu_memory = cpu_status.get("available_memory_gb", 0)
        st.metric(
            "ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬",
            f"{cpu_memory:.1f}GB"
        )
    
    with col3:
        gpu_available = "gpu" in resource_status
        st.metric(
            "GPU ìƒíƒœ",
            "ì‚¬ìš© ê°€ëŠ¥" if gpu_available else "ë¯¸ì‚¬ìš©"
        )
    
    with col4:
        if gpu_available:
            gpu_memory = resource_status["gpu"].get("available_memory_gb", 0)
            st.metric("GPU ë©”ëª¨ë¦¬", f"{gpu_memory:.1f}GB")
        else:
            st.metric("Ollama ëª¨ë“œ", "CPU")
    
    # ì„¤ì • íƒ­
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ ê¸°ë³¸ ì„¤ì •", "ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§", "ğŸ”§ ê³ ê¸‰ ì„¤ì •", "ğŸ’¡ ê¶Œì¥ì‚¬í•­"])
    
    with tab1:
        st.header("ğŸ¯ ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ì„¤ì •")
        
        # ì»´í“¨íŒ… ëª¨ë“œ ì„ íƒ
        col1, col2 = st.columns(2)
        
        with col1:
            current_mode = configurator.config.get("compute_mode", "auto")
            mode_options = {
                "auto": "ğŸ¤– ìë™ ì„ íƒ (ê¶Œì¥)",
                "gpu_preferred": "ğŸš€ GPU ìš°ì„  ì‚¬ìš©",
                "cpu_preferred": "ğŸ–¥ï¸ CPU ìš°ì„  ì‚¬ìš©", 
                "gpu_only": "ğŸ’ª GPU ì „ìš©",
                "cpu_only": "âš¡ CPU ì „ìš©"
            }
            
            selected_mode = st.selectbox(
                "ì»´í“¨íŒ… ëª¨ë“œ",
                options=list(mode_options.keys()),
                format_func=lambda x: mode_options[x],
                index=list(mode_options.keys()).index(current_mode),
                help="ì‹œìŠ¤í…œì´ CPUì™€ GPUë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€ ê²°ì •í•©ë‹ˆë‹¤"
            )
            
            if selected_mode != current_mode:
                configurator.config["compute_mode"] = selected_mode
                configurator.save_config()
                st.success("ì»´í“¨íŒ… ëª¨ë“œê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        with col2:
            # Ollama GPU ì„¤ì •
            ollama_gpu = st.checkbox(
                "Ollama GPU ê°€ì† ì‚¬ìš©",
                value=configurator.config.get("ollama_gpu", False),
                help="Ollama AI ëª¨ë¸ì—ì„œ GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ (ì¬ì‹œì‘ í•„ìš”)"
            )
            
            if ollama_gpu != configurator.config.get("ollama_gpu", False):
                configurator.config["ollama_gpu"] = ollama_gpu
                configurator.save_config()
                st.warning("Ollama ì„œë¹„ìŠ¤ ì¬ì‹œì‘ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ê°œë³„ ë„êµ¬ ì„¤ì •
        st.subheader("ê°œë³„ ë„êµ¬ ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            whisper_device = st.selectbox(
                "Whisper STT",
                ["auto", "cpu", "gpu"],
                index=["auto", "cpu", "gpu"].index(configurator.config.get("whisper_device", "auto")),
                help="ìŒì„± ì¸ì‹ì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤"
            )
            configurator.config["whisper_device"] = whisper_device
        
        with col2:
            ocr_device = st.selectbox(
                "EasyOCR",
                ["auto", "cpu", "gpu"],
                index=["auto", "cpu", "gpu"].index(configurator.config.get("ocr_device", "auto")),
                help="ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤"
            )
            configurator.config["ocr_device"] = ocr_device
        
        with col3:
            st.info("ì„¤ì •ì€ ìë™ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤")
    
    with tab2:
        st.header("ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        
        # ì‹¤ì‹œê°„ ì°¨íŠ¸
        if st.button("ğŸ”„ ë¦¬ì†ŒìŠ¤ ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
            st.rerun()
        
        # CPU/GPU ì‚¬ìš©ë¥  ì°¨íŠ¸
        fig = go.Figure()
        
        devices = []
        usage_values = []
        memory_values = []
        
        for device_name, status in resource_status.items():
            devices.append(device_name.upper())
            usage_values.append(status.get("usage_percent", 0))
            memory_gb = status.get("total_memory_gb", 0) - status.get("available_memory_gb", 0)
            memory_values.append(memory_gb)
        
        # ì‚¬ìš©ë¥  ì°¨íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            fig_usage = px.bar(
                x=devices,
                y=usage_values,
                title="ë””ë°”ì´ìŠ¤ ì‚¬ìš©ë¥ ",
                labels={"x": "ë””ë°”ì´ìŠ¤", "y": "ì‚¬ìš©ë¥  (%)"},
                color=usage_values,
                color_continuous_scale="RdYlGn_r"
            )
            fig_usage.update_layout(showlegend=False)
            st.plotly_chart(fig_usage, use_container_width=True)
        
        with col2:
            fig_memory = px.bar(
                x=devices,
                y=memory_values,
                title="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰",
                labels={"x": "ë””ë°”ì´ìŠ¤", "y": "ì‚¬ìš©ëŸ‰ (GB)"},
                color=memory_values,
                color_continuous_scale="Blues"
            )
            fig_memory.update_layout(showlegend=False)
            st.plotly_chart(fig_memory, use_container_width=True)
    
    with tab3:
        st.header("ğŸ”§ ê³ ê¸‰ ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            memory_opt = st.checkbox(
                "ìë™ ë©”ëª¨ë¦¬ ìµœì í™”",
                value=configurator.config.get("memory_optimization", True),
                help="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìë™ìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤"
            )
            configurator.config["memory_optimization"] = memory_opt
            
            auto_cleanup = st.checkbox(
                "ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬",
                value=configurator.config.get("auto_cleanup", True),
                help="ì‘ì—… ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"
            )
            configurator.config["auto_cleanup"] = auto_cleanup
        
        with col2:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            perf_monitoring = st.checkbox(
                "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
                value=configurator.config.get("performance_monitoring", True),
                help="ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤"
            )
            configurator.config["performance_monitoring"] = perf_monitoring
        
        # í™˜ê²½ë³€ìˆ˜ ìƒíƒœ í‘œì‹œ
        st.subheader("í™˜ê²½ë³€ìˆ˜ ìƒíƒœ")
        env_vars = {
            "CUDA_VISIBLE_DEVICES": os.environ.get("CUDA_VISIBLE_DEVICES", "ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "OLLAMA_GPU": os.environ.get("OLLAMA_GPU", "ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "PYTHONIOENCODING": os.environ.get("PYTHONIOENCODING", "ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        }
        
        for var, value in env_vars.items():
            st.code(f"{var}={value}")
    
    with tab4:
        st.header("ğŸ’¡ ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­")
        
        if configurator.compute_manager:
            recommendations = configurator.compute_manager.get_performance_recommendation()
            
            if recommendations["general"]:
                st.subheader("ğŸ” ì¼ë°˜ ê¶Œì¥ì‚¬í•­")
                for rec in recommendations["general"]:
                    st.info(rec)
            
            st.subheader("ğŸ¯ ëª¨ë“œë³„ ê¶Œì¥ì‚¬í•­")
            for scenario, recommendation in recommendations["mode"].items():
                st.success(f"**{scenario}**: {recommendation}")
        
        # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (ì‹œë®¬ë ˆì´ì…˜)
        st.subheader("âš¡ ì˜ˆìƒ ì„±ëŠ¥ ë¹„êµ")
        
        benchmark_data = {
            "ì‘ì—… ìœ í˜•": ["STT (5ë¶„ ìŒì„±)", "OCR (10ì¥)", "LLM ì¶”ë¡ ", "ë¹„ë””ì˜¤ ì²˜ë¦¬"],
            "CPU ëª¨ë“œ": ["45ì´ˆ", "30ì´ˆ", "12ì´ˆ", "180ì´ˆ"],
            "GPU ëª¨ë“œ": ["15ì´ˆ", "8ì´ˆ", "3ì´ˆ", "45ì´ˆ"],
            "ê¶Œì¥ ëª¨ë“œ": ["GPU", "GPU", "GPU", "GPU"]
        }
        
        df_benchmark = st.dataframe(benchmark_data)
    
    # ì„¤ì • ì ìš© ë²„íŠ¼
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("ğŸ’¾ ì„¤ì • ì €ì¥", type="primary"):
            configurator.save_config()
            configurator.apply_settings()
            st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    with col2:
        if st.button("ğŸ”„ ê¸°ë³¸ê°’ ë³µì›"):
            configurator.config = configurator.get_default_config()
            configurator.save_config()
            st.info("ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤")
            st.rerun()
    
    with col3:
        if st.button("ğŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"):
            with st.spinner("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."):
                time.sleep(2)  # ì‹œë®¬ë ˆì´ì…˜
                st.balloons()
                st.success("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! í˜„ì¬ ì„¤ì •ì´ ìµœì ì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    render_resource_configurator()