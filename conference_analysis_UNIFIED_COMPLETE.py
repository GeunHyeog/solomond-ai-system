#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
[ëª©í‘œ] ì™„ì „ í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ - SOLOMOND AI v7.1
Complete Unified Conference Analysis System

8501ê³¼ 8650ì˜ ëª¨ë“  ì¥ì ì„ í†µí•©í•œ ì™„ì „í•œ ì‹œìŠ¤í…œ:
[ì™„ë£Œ] ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ (EasyOCR, Whisper STT)
[ì™„ë£Œ] Supabase í´ë¼ìš°ë“œ ë°ì´í„°ë² ì´ìŠ¤ ì§€ì›  
[ì™„ë£Œ] í™€ë¦¬ìŠ¤í‹± ë¶„ì„ (ì˜ë¯¸ì  ì—°ê²°, ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§)
[ì™„ë£Œ] ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ í†µí•©
[ì™„ë£Œ] í—ˆìœ„ì •ë³´ ì™„ì „ ì°¨ë‹¨

í•µì‹¬ ì›ì¹™:
- ëª¨ë“  ê¸°ëŠ¥ì´ ì‹¤ì œë¡œ ì‘ë™í•´ì•¼ í•¨
- í—ˆìœ„ ìƒíƒœ í‘œì‹œ ì ˆëŒ€ ê¸ˆì§€
- ì‹¤ì œ ë¶„ì„ ê²°ê³¼ë§Œ ì œê³µ
"""

import streamlit as st
import os
import tempfile
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import traceback
import re
from collections import Counter
import json
import uuid
import hashlib
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np

# [ë³´ì•ˆ] Unicode ì•ˆì „ì„± ì‹œìŠ¤í…œ ìµœìš°ì„  ë¡œë“œ
try:
    from core.unicode_safety_system import (
        safe_text, safe_error, safe_format,
        safe_st_error, safe_st_warning, safe_st_info, safe_st_success,
        unicode_manager
    )
    UNICODE_SAFETY_AVAILABLE = True
except ImportError:
    # í´ë°± ì•ˆì „ í•¨ìˆ˜ë“¤
    def safe_text(text, fallback="[í…ìŠ¤íŠ¸ í‘œì‹œ ë¶ˆê°€]"):
        try:
            return str(text).encode('utf-8', errors='replace').decode('utf-8')
        except:
            return fallback
    
    def safe_error(error, context=""):
        return safe_text(str(error))
    
    def safe_st_error(text):
        return st.error(safe_text(text))
    
    def safe_st_warning(text):
        return st.warning(safe_text(text))
    
    def safe_st_info(text):
        return st.info(safe_text(text))
    
    def safe_st_success(text):
        return st.success(safe_text(text))
    
    UNICODE_SAFETY_AVAILABLE = False

# í–¥ìƒëœ íŒŒì¼ í•¸ë“¤ëŸ¬
try:
    from core.enhanced_file_handler import enhanced_handler, get_enhanced_file_upload
    ENHANCED_FILE_HANDLER_AVAILABLE = True
except ImportError:
    ENHANCED_FILE_HANDLER_AVAILABLE = False
    def get_enhanced_file_upload():
        return []

# ì‹¤ì œ ë¶„ì„ ì—”ì§„ë“¤
try:
    import easyocr
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

try:
    import whisper
    # [ë³´ì•ˆ] ì•ˆì „í•œ ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œ ì„í¬íŠ¸
    from defensive_model_loader import safe_whisper_load, enable_defensive_mode
    enable_defensive_mode()  # ì „ì—­ ì•ˆì „ ëª¨ë“œ í™œì„±í™”
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    safe_whisper_load = None

# [ì„±ëŠ¥ìµœì í™”] ìƒˆë¡œìš´ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œë“¤
try:
    from enhanced_modules.performance_monitor import get_performance_monitor, OperationTracker
    from enhanced_modules.memory_optimizer import get_memory_optimizer, memory_context, optimize_memory
    from enhanced_modules.parallel_optimizer import ParallelOptimizer, create_task_profile
    PERFORMANCE_OPTIMIZATION_AVAILABLE = True
except ImportError:
    PERFORMANCE_OPTIMIZATION_AVAILABLE = False
    # í´ë°± ë”ë¯¸ í•¨ìˆ˜ë“¤
    def get_performance_monitor():
        return None
    def get_memory_optimizer():
        return None
    def memory_context():
        return None
    class OperationTracker:
        def __init__(self, *args, **kwargs):
            pass
        def __enter__(self):
            return self
        def __exit__(self, *args):
            pass

# ë”ë¯¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì (í´ë°±ìš©)
class DummyContext:
    def __enter__(self):
        return self
    def __exit__(self, *args):
        pass

# ë™ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œ
try:
    from dynamic_resource_manager import (
        get_resource_manager, get_optimal_ocr_settings, 
        get_optimal_whisper_settings, log_performance
    )
    DYNAMIC_RESOURCE_AVAILABLE = True
except ImportError:
    DYNAMIC_RESOURCE_AVAILABLE = False

# Enhanced OCR í†µí•© ì‹œìŠ¤í…œ
try:
    from enhanced_modules.integration_controller import IntegrationController
    from enhanced_modules.enhanced_ocr_engine import EnhancedOCREngine
    ENHANCED_OCR_AVAILABLE = True
except ImportError:
    ENHANCED_OCR_AVAILABLE = False

# ë…¸ì´ì¦ˆ ê°ì†Œ ì‹œìŠ¤í…œ
try:
    from enhanced_modules.noise_reduction_engine import NoiseReductionEngine
    NOISE_REDUCTION_AVAILABLE = True
except ImportError:
    NOISE_REDUCTION_AVAILABLE = False

# í™”ì êµ¬ë¶„ ì‹œìŠ¤í…œ
try:
    from enhanced_modules.speaker_diarization_engine import SpeakerDiarizationEngine
    SPEAKER_DIARIZATION_AVAILABLE = True
except ImportError:
    SPEAKER_DIARIZATION_AVAILABLE = False

# ë©€í‹°ëª¨ë‹¬ ìœµí•© ì‹œìŠ¤í…œ
try:
    from enhanced_modules.multimodal_fusion_engine import MultimodalFusionEngine
    MULTIMODAL_FUSION_AVAILABLE = True
except ImportError:
    MULTIMODAL_FUSION_AVAILABLE = False
    
# í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹œìŠ¤í…œ
try:
    from holistic_conference_analyzer_supabase import HolisticConferenceAnalyzerSupabase
    from semantic_connection_engine import SemanticConnectionEngine
    from conference_story_generator import ConferenceStoryGenerator
    from actionable_insights_extractor import ActionableInsightsExtractor
    HOLISTIC_AVAILABLE = True
except ImportError:
    HOLISTIC_AVAILABLE = False

# [ì‹œì‘] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ (v4.0 ê³ ê¸‰ ì—”ì§„)
try:
    from core.multimodal_pipeline import MultimodalPipeline, MultimodalResult
    from core.crossmodal_fusion import CrossModalFusionLayer, FusionResult
    from core.comprehensive_message_extractor import ComprehensiveMessageExtractor
    from core.insight_generator import InsightGenerator, InsightItem
    MULTIMODAL_AVAILABLE = True
    safe_st_info("[ì‹œì‘] ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ì—”ì§„ ë¡œë“œ ì™„ë£Œ!")
except ImportError as e:
    MULTIMODAL_AVAILABLE = False
    safe_st_warning(f"[ì£¼ì˜] ë©€í‹°ëª¨ë‹¬ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {safe_error(e)}")

# ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ
try:
    from dual_brain_integration import DualBrainSystem
    DUAL_BRAIN_AVAILABLE = True
except ImportError:
    DUAL_BRAIN_AVAILABLE = False

# ë°ì´í„°ë² ì´ìŠ¤ ì–´ëŒ‘í„°
try:
    from database_adapter import DatabaseFactory
    DATABASE_ADAPTER_AVAILABLE = True
except ImportError:
    DATABASE_ADAPTER_AVAILABLE = False

# Ollama AI ì¸í„°í˜ì´ìŠ¤
try:
    from shared.ollama_interface import OllamaInterface
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False

# ìœ íŠœë¸Œ ë‹¤ìš´ë¡œë”
try:
    import yt_dlp
    YOUTUBE_AVAILABLE = True
except ImportError:
    YOUTUBE_AVAILABLE = False

class UnifiedConferenceAnalyzer:
    """ì™„ì „ í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self, conference_name: str = "unified_conference"):
        self.conference_name = conference_name
        self.session_id = str(uuid.uuid4())[:8]
        
        # ì‚¬ì „ ì •ë³´ ì €ì¥
        self.conference_info = {
            "conference_name": "",
            "conference_date": "",
            "location": "",
            "industry_field": "",
            "interest_keywords": []
        }
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.analysis_results = {
            "session_id": self.session_id,
            "conference_name": conference_name,
            "conference_info": self.conference_info,
            "timestamp": datetime.now().isoformat(),
            "processed_files": [],
            "analysis_data": {},
            "holistic_results": {},
            "dual_brain_results": {}
        }
        
        # ì‹¤ì œ ì—”ì§„ë“¤ ì´ˆê¸°í™”
        self._initialize_engines()
        
        # ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.user_files_dir = Path("user_files")
        self.user_files_dir.mkdir(exist_ok=True)
    
    def _initialize_engines(self):
        """ì‹¤ì œ ë¶„ì„ ì—”ì§„ë“¤ ì´ˆê¸°í™” - ë™ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì ìš©"""
        # ë™ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™”
        if DYNAMIC_RESOURCE_AVAILABLE:
            self.resource_manager = get_resource_manager()
            resource_status = self.resource_manager.get_current_status()
            st.info(f"[ë¦¬ì†ŒìŠ¤] GPU: {resource_status.gpu_available}, ì¶”ì²œ ëª¨ë“œ: {resource_status.recommendation}")
        else:
            self.resource_manager = None
        
        # Enhanced OCR ì—”ì§„ ì´ˆê¸°í™” (ìš°ì„  ì‹œë„)
        self.enhanced_ocr_engine = None
        self.use_enhanced_ocr = False
        
        if ENHANCED_OCR_AVAILABLE:
            try:
                self.integration_controller = IntegrationController()
                self.enhanced_ocr_engine = EnhancedOCREngine()
                self.use_enhanced_ocr = True
                st.success("[ì™„ë£Œ] Enhanced OCR ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ (PPT ì´ë¯¸ì§€ íŠ¹í™”)")
                st.info(f"[Enhanced OCR] {len(self.enhanced_ocr_engine.ocr_instances)}ê°œ ì—”ì§„ í†µí•©")
            except Exception as e:
                st.warning(f"[í´ë°±] Enhanced OCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_enhanced_ocr = False
        
        # ê¸°ë³¸ OCR ì—”ì§„ - ë™ì  ìµœì í™” ì ìš© (í´ë°± ë˜ëŠ” ê¸°ë³¸)
        self.ocr_engine = None
        if OCR_AVAILABLE:
            try:
                if DYNAMIC_RESOURCE_AVAILABLE:
                    ocr_config = get_optimal_ocr_settings()
                    use_gpu = ocr_config.get('gpu', False)
                    st.info(f"[OCR ìµœì í™”] {ocr_config.get('reason', 'GPU/CPU ìë™ ì„ íƒ')}")
                else:
                    use_gpu = False
                
                self.ocr_engine = easyocr.Reader(['ko', 'en'], gpu=use_gpu)
                if self.use_enhanced_ocr:
                    st.info("[ë°±ì—…] ê¸°ë³¸ EasyOCR ì—”ì§„ë„ ì¤€ë¹„ ì™„ë£Œ (í´ë°±ìš©)")
                else:
                    st.success("[ì™„ë£Œ] EasyOCR ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                st.warning(f"[ì£¼ì˜] EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Whisper ì—”ì§„ - ë™ì  ìµœì í™” ì ìš©
        self.whisper_model = None
        if WHISPER_AVAILABLE:
            try:
                if DYNAMIC_RESOURCE_AVAILABLE:
                    whisper_config = get_optimal_whisper_settings()
                    model_size = whisper_config.get('model_size', 'base')
                    device = whisper_config.get('device', 'cpu')
                    st.info(f"[Whisper ìµœì í™”] ëª¨ë¸: {model_size}, ë””ë°”ì´ìŠ¤: {device}")
                    st.info(f"[Whisper ì´ìœ ] {whisper_config.get('reason', 'GPU/CPU ìë™ ì„ íƒ')}")
                else:
                    model_size = 'base'
                    device = 'cpu'
                
                # [ë³´ì•ˆ] ì•ˆì „í•œ ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ meta tensor ë¬¸ì œ ì™„ì „ í•´ê²°
                self.whisper_model = safe_whisper_load(model_size)
                st.success(f"[ì™„ë£Œ] Whisper STT ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ ({model_size}, {device})")
            except Exception as e:
                st.warning(f"[ì£¼ì˜] Whisper ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # CPU í´ë°± ì‹œë„
                try:
                    self.whisper_model = safe_whisper_load("base")
                    st.info("[í´ë°±] Whisper ê¸°ë³¸ ëª¨ë“œë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ë…¸ì´ì¦ˆ ê°ì†Œ ì—”ì§„ ì´ˆê¸°í™”
        self.noise_reducer = None
        if NOISE_REDUCTION_AVAILABLE:
            try:
                self.noise_reducer = NoiseReductionEngine()
                st.success("[ì™„ë£Œ] ë…¸ì´ì¦ˆ ê°ì†Œ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
                formats = self.noise_reducer.get_supported_formats()
                st.info(f"[ë…¸ì´ì¦ˆ ê°ì†Œ] ì˜¤ë””ì˜¤: {len(formats['audio'])}ê°œ, ì´ë¯¸ì§€: {len(formats['image'])}ê°œ í˜•ì‹ ì§€ì›")
            except Exception as e:
                st.warning(f"[ì„ íƒ] ë…¸ì´ì¦ˆ ê°ì†Œ ì—”ì§„ ë¹„í™œì„±í™”: {e}")
        
        # í™”ì êµ¬ë¶„ ì—”ì§„ ì´ˆê¸°í™”
        self.speaker_diarization = None
        if SPEAKER_DIARIZATION_AVAILABLE:
            try:
                self.speaker_diarization = SpeakerDiarizationEngine()
                st.success("[ì™„ë£Œ] í™”ì êµ¬ë¶„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
                st.info("[í™”ì êµ¬ë¶„] Whisper ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ê³ ì •ë°€ í™”ì ë¶„ë¦¬ ì§€ì›")
            except Exception as e:
                st.warning(f"[ì„ íƒ] í™”ì êµ¬ë¶„ ì—”ì§„ ë¹„í™œì„±í™”: {e}")
        
        # ë©€í‹°ëª¨ë‹¬ ìœµí•© ì—”ì§„ ì´ˆê¸°í™”
        self.multimodal_fusion = None
        if MULTIMODAL_FUSION_AVAILABLE:
            try:
                self.multimodal_fusion = MultimodalFusionEngine()
                st.success("[ì™„ë£Œ] ë©€í‹°ëª¨ë‹¬ ìœµí•© ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
                st.info("[ë©€í‹°ëª¨ë‹¬ ìœµí•©] ì´ë¯¸ì§€-ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ ì§€ì›")
            except Exception as e:
                st.warning(f"[ì„ íƒ] ë©€í‹°ëª¨ë‹¬ ìœµí•© ì—”ì§„ ë¹„í™œì„±í™”: {e}")
        
        # [ì„±ëŠ¥ìµœì í™”] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.performance_monitor = None
        self.memory_optimizer = None
        self.parallel_optimizer = None
        if PERFORMANCE_OPTIMIZATION_AVAILABLE:
            try:
                self.performance_monitor = get_performance_monitor()
                self.memory_optimizer = get_memory_optimizer()
                self.parallel_optimizer = ParallelOptimizer()
                
                # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
                if self.performance_monitor:
                    self.performance_monitor.start_monitoring()
                if self.memory_optimizer:
                    self.memory_optimizer.start_monitoring()
                
                st.success("[ì™„ë£Œ] ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                st.info("[ì„±ëŠ¥ ìµœì í™”] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ë©”ëª¨ë¦¬ ê´€ë¦¬, ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” í™œì„±í™”")
            except Exception as e:
                st.warning(f"[ì„ íƒ] ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ë¹„í™œì„±í™”: {e}")
        
        # í™€ë¦¬ìŠ¤í‹± ë¶„ì„ê¸°
        self.holistic_analyzer = None
        if HOLISTIC_AVAILABLE:
            try:
                self.holistic_analyzer = HolisticConferenceAnalyzerSupabase(self.conference_name, "auto")
                st.success("[ì™„ë£Œ] í™€ë¦¬ìŠ¤í‹± ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                st.warning(f"[ì£¼ì˜] í™€ë¦¬ìŠ¤í‹± ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ
        self.dual_brain = None
        if DUAL_BRAIN_AVAILABLE:
            try:
                self.dual_brain = DualBrainSystem()
                st.success("[ì™„ë£Œ] ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                st.warning(f"[ì£¼ì˜] ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ë°ì´í„°ë² ì´ìŠ¤
        self.database = None
        if DATABASE_ADAPTER_AVAILABLE:
            try:
                self.database = DatabaseFactory.create_database("auto", self.conference_name)
                # í…Œì´ë¸” ìƒì„± ì‹œë„
                if self.database.create_fragments_table():
                    st.success("[ì™„ë£Œ] ë°ì´í„°ë² ì´ìŠ¤ ì–´ëŒ‘í„° ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    st.warning("[ì£¼ì˜] ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
            except Exception as e:
                st.warning(f"[ì£¼ì˜] ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Ollama AI ì¸í„°í˜ì´ìŠ¤
        self.ollama = None
        if OLLAMA_AVAILABLE:
            try:
                self.ollama = OllamaInterface()
                if self.ollama.health_check():
                    available_models = self.ollama.available_models
                    st.success(f"[ì™„ë£Œ] Ollama AI ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ ({len(available_models)}ê°œ ëª¨ë¸)")
                    st.info(f"[AI] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(available_models[:3])}...")
                else:
                    st.warning("[ì£¼ì˜] Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨ - ollama serve ì‹¤í–‰ í•„ìš”")
                    self.ollama = None
            except Exception as e:
                st.warning(f"[ì£¼ì˜] Ollama ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.ollama = None
        
        # [ì‹œì‘] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (v4.0 ê³ ê¸‰ ì—”ì§„)
        self.multimodal_pipeline = None
        self.fusion_engine = None
        self.message_extractor = None
        self.insight_generator = None
        
        if MULTIMODAL_AVAILABLE:
            try:
                self.multimodal_pipeline = MultimodalPipeline()
                self.fusion_engine = CrossModalFusionLayer()
                self.message_extractor = ComprehensiveMessageExtractor()
                self.insight_generator = InsightGenerator()
                st.success("[ì‹œì‘] ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ!")
                st.info("[íŒ] í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•©, ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„± ê¸°ëŠ¥ í™œì„±í™”ë¨")
            except Exception as e:
                st.warning(f"[ì£¼ì˜] ë©€í‹°ëª¨ë‹¬ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.multimodal_pipeline = None
    
    def update_conference_info(self, info: Dict[str, Any]):
        """ì‚¬ì „ ì •ë³´ ì—…ë°ì´íŠ¸"""
        self.conference_info.update(info)
        self.analysis_results["conference_info"] = self.conference_info
    
    def check_system_status(self) -> Dict[str, Any]:
        """ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (í—ˆìœ„ì •ë³´ ì—†ìŒ)"""
        status = {
            "ocr_available": self.ocr_engine is not None,
            "whisper_available": self.whisper_model is not None,
            "holistic_available": self.holistic_analyzer is not None,
            "dual_brain_available": self.dual_brain is not None,
            "database_available": self.database is not None and self._check_database_working(),
            "ollama_available": self.ollama is not None and self.ollama.health_check(),
            "multimodal_available": self.multimodal_pipeline is not None,
            "fusion_available": self.fusion_engine is not None,
            "overall_ready": False
        }
        
        # ì „ì²´ ì¤€ë¹„ ìƒíƒœ ê³„ì‚°
        ready_count = sum([
            status["ocr_available"],
            status["whisper_available"], 
            status["holistic_available"],
            status["database_available"],
            status["ollama_available"],
            status["multimodal_available"]
        ])
        
        status["overall_ready"] = ready_count >= 5  # ìµœì†Œ 5ê°œ ì‹œìŠ¤í…œ í•„ìš” (ë©€í‹°ëª¨ë‹¬ í¬í•¨)
        status["ready_systems"] = ready_count
        status["total_systems"] = 5
        
        return status
    
    def _check_database_working(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì‹¤ì œ ì‘ë™ í™•ì¸"""
        if not self.database:
            return False
        try:
            # í…Œì´ë¸” ìƒì„± ì‹œë„
            self.database.create_fragments_table()
            # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì‘ë™ í™•ì¸
            count = self.database.get_fragment_count()
            return True
        except Exception:
            return False
    
    def process_uploaded_files(self, uploaded_files: List, skip_errors: bool = True) -> Dict[str, Any]:
        """ì‹¤ì œ ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ì²˜ë¦¬ - [ì‹œì‘] v4.0 ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ í†µí•©"""
        if not uploaded_files:
            return {"error": "ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        # [ì‹œì‘] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ê°€ëŠ¥ì‹œ ê³ ê¸‰ ì²˜ë¦¬
        if self.multimodal_pipeline is not None:
            return self._process_with_multimodal_pipeline(uploaded_files, skip_errors)
        else:
            # ê¸°ì¡´ ë°©ì‹ ìœ ì§€ (í˜¸í™˜ì„±)
            st.info("[ì •ë³´] ê¸°ì¡´ ë¶„ì„ ë°©ì‹ ì‚¬ìš© (ë©€í‹°ëª¨ë‹¬ ì—”ì§„ ë¹„í™œì„±)")
            return self._process_with_legacy_method(uploaded_files, skip_errors)
    
    def _process_with_multimodal_pipeline(self, uploaded_files: List, skip_errors: bool = True) -> Dict[str, Any]:
        """[ì‹œì‘] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ì„ í™œìš©í•œ ê³ ê¸‰ ë¶„ì„"""
        st.success("[ì‹œì‘] ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ëª¨ë“œ í™œì„±í™”!")
        st.info("[íŒ] í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•©, ì‹œê°„ ë™ê¸°í™”, ìƒí™© í†µí•© ë¶„ì„ ìˆ˜í–‰")
        
        results = {
            "processed_count": 0,
            "successful_count": 0,
            "failed_files": [],
            "analysis_fragments": [],
            "multimodal_insights": [],  # ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸
            "cross_modal_correlations": []  # í¬ë¡œìŠ¤ëª¨ë‹¬ ìƒê´€ê´€ê³„
        }
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # [ì²˜ë¦¬ì¤‘] ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹¤í–‰ (async ì²˜ë¦¬ë¥¼ syncë¡œ wrapping)
        try:
            import asyncio
            
            # íŒŒì¼ë“¤ì„ Path ê°ì²´ë¡œ ë³€í™˜
            file_paths = []
            for i, uploaded_file in enumerate(uploaded_files):
                try:
                    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                        tmp_file.write(uploaded_file.read())
                        file_paths.append(Path(tmp_file.name))
                except Exception as e:
                    st.warning(f"[ì£¼ì˜] íŒŒì¼ ì¤€ë¹„ ì‹¤íŒ¨: {uploaded_file.name} - {e}")
                    if not skip_errors:
                        return {"error": f"íŒŒì¼ ì¤€ë¹„ ì‹¤íŒ¨: {e}"}
            
            status_text.text("[ì‹œì‘] ë©€í‹°ëª¨ë‹¬ AI ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
            
            # ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                multimodal_results = loop.run_until_complete(
                    self.multimodal_pipeline.process_multimodal_batch(file_paths)
                )
                loop.close()
            except Exception as e:
                st.error(f"ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
                return self._process_with_legacy_method(uploaded_files, skip_errors)
            
            status_text.text("ğŸ”€ í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•© ë¶„ì„ ì¤‘...")
            progress_bar.progress(0.7)
            
            # ğŸ”€ í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•© ì‹¤í–‰ (ë©€í‹°ëª¨ë‹¬ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ)
            if multimodal_results and self.fusion_engine:
                try:
                    # MultimodalResultë¥¼ EncodedResultë¡œ ë³€í™˜
                    encoded_results = self._convert_to_encoded_results(multimodal_results)
                    if encoded_results:
                        fusion_result = self.fusion_engine.fuse_multimodal_encodings(encoded_results)
                        results["cross_modal_correlations"] = fusion_result.cross_modal_correlations if hasattr(fusion_result, 'cross_modal_correlations') else []
                except Exception as e:
                    st.warning(f"í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•© ì‹¤íŒ¨: {e}")
            
            # ê²°ê³¼ ë³€í™˜
            for mm_result in multimodal_results:
                fragment = {
                    'fragment_id': f'{self.conference_name}_{self.session_id}_{hashlib.md5(str(mm_result.file_path).encode()).hexdigest()[:8]}',
                    'file_source': Path(mm_result.file_path).name,
                    'file_type': mm_result.file_type,
                    'timestamp': datetime.now().isoformat(),
                    'content': mm_result.content,
                    'confidence': mm_result.confidence,
                    'processing_time': mm_result.processing_time,
                    'metadata': mm_result.metadata
                }
                
                results["analysis_fragments"].append(fragment)
                results["successful_count"] += 1
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                if self.database:
                    try:
                        self.database.insert_fragment(fragment)
                    except Exception as e:
                        st.warning(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")
            
            results["processed_count"] = len(uploaded_files)
            
            progress_bar.progress(1.0)
            status_text.text(f"[ì™„ë£Œ] ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì™„ë£Œ! ({results['successful_count']}/{results['processed_count']} ì„±ê³µ)")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for file_path in file_paths:
                try:
                    os.unlink(file_path)
                except:
                    pass
                    
            return results
            
        except Exception as e:
            st.error(f"[ì‹¤íŒ¨] ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            if not skip_errors:
                return {"error": f"ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹¤íŒ¨: {e}"}
            else:
                st.info("[ì²˜ë¦¬ì¤‘] ê¸°ì¡´ ë¶„ì„ ë°©ì‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
                return self._process_with_legacy_method(uploaded_files, skip_errors)
    
    def _process_with_legacy_method(self, uploaded_files: List, skip_errors: bool = True) -> Dict[str, Any]:
        """ê¸°ì¡´ ë°©ì‹ì˜ íŒŒì¼ ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€)"""
        results = {
            "processed_count": 0,
            "successful_count": 0,
            "failed_files": [],
            "analysis_fragments": []
        }
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = (i + 1) / len(uploaded_files)
                progress_bar.progress(progress)
                status_text.text(f"ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name
                
                # íŒŒì¼ íƒ€ì…ë³„ ì‹¤ì œ ì²˜ë¦¬
                file_ext = Path(uploaded_file.name).suffix.lower()
                
                if file_ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                    fragment = self._process_image_file(tmp_path, uploaded_file.name)
                elif file_ext in ['.wav', '.mp3', '.m4a', '.flac']:
                    fragment = self._process_audio_file(tmp_path, uploaded_file.name)
                elif file_ext in ['.mp4', '.avi', '.mov']:
                    fragment = self._process_video_file(tmp_path, uploaded_file.name)
                elif file_ext == '.txt':
                    # TXT íŒŒì¼ì˜ ê²½ìš° URL ë°°ì¹˜ ì²˜ë¦¬
                    st.info(f"[ë¬¸ì„œ] TXT íŒŒì¼ ê°ì§€: {uploaded_file.name} - URL ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
                    
                    # ì„ì‹œ íŒŒì¼ì„ ë‹¤ì‹œ ìƒì„±í•˜ì—¬ process_text_file_urlsì— ì „ë‹¬
                    uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    batch_results = self.process_text_file_urls(uploaded_file)
                    
                    if batch_results and "error" not in batch_results[0]:
                        # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë¶„ì„ ê²°ê³¼ì— ì¶”ê°€
                        results["analysis_fragments"].extend(batch_results)
                        results["successful_count"] += len(batch_results)
                        st.success(f"[ì™„ë£Œ] {uploaded_file.name}ì—ì„œ {len(batch_results)}ê°œ URL ì²˜ë¦¬ ì™„ë£Œ!")
                    else:
                        error_msg = batch_results[0]["error"] if batch_results else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                        results["failed_files"].append({
                            "filename": uploaded_file.name,
                            "error": error_msg
                        })
                    
                    # TXT íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ, continueë¡œ ì¼ë°˜ ì²˜ë¦¬ ìŠ¤í‚µ
                    results["processed_count"] += 1
                    continue
                else:
                    fragment = {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}"}
                
                # ì •ë¦¬
                os.unlink(tmp_path)
                
                if "error" not in fragment:
                    results["analysis_fragments"].append(fragment)
                    results["successful_count"] += 1
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    if self.database:
                        self.database.insert_fragment(fragment)
                else:
                    results["failed_files"].append({
                        "filename": uploaded_file.name,
                        "error": fragment["error"]
                    })
                
                results["processed_count"] += 1
                
            except Exception as e:
                if not skip_errors:
                    # ì—ëŸ¬ ë°œìƒì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
                    return {"error": f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
                
                results["failed_files"].append({
                    "filename": uploaded_file.name,
                    "error": str(e)
                })
                results["processed_count"] += 1
        
        # ì§„í–‰ë¥  ì™„ë£Œ
        progress_bar.progress(1.0)
        status_text.text("[ì™„ë£Œ] ê¸°ì¡´ ë°©ì‹ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ë©€í‹°ëª¨ë‹¬ ìœµí•© ë¶„ì„ ìˆ˜í–‰
        if self.multimodal_fusion and len(results["analysis_fragments"]) >= 2:
            try:
                st.info("[ë©€í‹°ëª¨ë‹¬ ìœµí•©] ëª¨ë‹¬ë¦¬í‹° ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ ì‹œì‘...")
                
                fusion_result = self.multimodal_fusion.fuse_modalities(results["analysis_fragments"])
                
                if fusion_result.success:
                    results["multimodal_fusion"] = {
                        'correlations_found': len(fusion_result.correlations),
                        'unified_narrative': fusion_result.unified_narrative,
                        'key_insights': fusion_result.key_insights,
                        'modal_summary': fusion_result.modal_summary,
                        'confidence_score': fusion_result.confidence_score,
                        'processing_time': fusion_result.processing_time
                    }
                    
                    st.success(f"[ì™„ë£Œ] ë©€í‹°ëª¨ë‹¬ ìœµí•© ë¶„ì„ ì™„ë£Œ ({len(fusion_result.correlations)}ê°œ ìƒê´€ê´€ê³„ ë°œê²¬)")
                    
                    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
                    if fusion_result.key_insights:
                        st.info("[ì£¼ìš” ì¸ì‚¬ì´íŠ¸]")
                        for insight in fusion_result.key_insights[:3]:
                            st.info(f"â€¢ {insight}")
                    
                    # í†µí•© ë‚´ëŸ¬í‹°ë¸Œ í‘œì‹œ
                    if fusion_result.unified_narrative:
                        with st.expander("ğŸ”— í†µí•© ë¶„ì„ ê²°ê³¼", expanded=True):
                            st.markdown(fusion_result.unified_narrative)
                    
                else:
                    st.warning(f"[ë©€í‹°ëª¨ë‹¬ ìœµí•©] ë¶„ì„ ì‹¤íŒ¨: {fusion_result.error_message}")
                    results["multimodal_fusion"] = None
                    
            except Exception as e:
                st.warning(f"[ì„ íƒ] ë©€í‹°ëª¨ë‹¬ ìœµí•© ì‹¤íŒ¨: {e}")
                results["multimodal_fusion"] = None
        else:
            st.info("[ì •ë³´] ë©€í‹°ëª¨ë‹¬ ìœµí•©ì„ ìœ„í•´ì„œëŠ” 2ê°œ ì´ìƒì˜ ë‹¤ë¥¸ ìœ í˜• íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            results["multimodal_fusion"] = None
        
        # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
        self.analysis_results["processed_files"] = results["analysis_fragments"]
        self.analysis_results["multimodal_fusion"] = results.get("multimodal_fusion")
        
        return results
    
    def _process_image_file(self, file_path: str, filename: str) -> Dict[str, Any]:
        """ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ OCR ì²˜ë¦¬ - Enhanced OCR ìš°ì„ , ê¸°ë³¸ OCR í´ë°± + ì„±ëŠ¥ ìµœì í™”"""
        if not self.ocr_engine and not self.use_enhanced_ocr:
            return {"error": "OCR ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        # [ì„±ëŠ¥ìµœì í™”] íŒŒì¼ í¬ê¸° ê³„ì‚° ë° ì„±ëŠ¥ ì¶”ì  ì‹œì‘
        file_size_mb = Path(file_path).stat().st_size / (1024 * 1024)
        
        # [ì„±ëŠ¥ìµœì í™”] ì‘ì—… ì¶”ì  ì‹œì‘
        operation_tracker = None
        if PERFORMANCE_OPTIMIZATION_AVAILABLE and self.performance_monitor:
            operation_tracker = OperationTracker(f"OCR_processing_{filename}", file_size_mb)
        
        # [ë©”ëª¨ë¦¬ìµœì í™”] ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
        memory_ctx = None
        if PERFORMANCE_OPTIMIZATION_AVAILABLE and self.memory_optimizer:
            memory_ctx = memory_context(auto_optimize=file_size_mb > 10)  # 10MB ì´ìƒì‹œ ìë™ ìµœì í™”
        
        start_time = time.time()
        resource_used = 'cpu'  # ê¸°ë³¸ê°’
        ocr_engine_used = 'basic'  # ì¶”ì ìš©
        
        try:
            # [ì„±ëŠ¥ìµœì í™”] ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ìë“¤ ì‹œì‘
            with (operation_tracker or DummyContext()), (memory_ctx or DummyContext()):
                
                # ë…¸ì´ì¦ˆ ê°ì†Œ ì „ì²˜ë¦¬ (ì„ íƒì )
                processed_file_path = file_path
                noise_reduction_applied = False
            
            if self.noise_reducer and file_size_mb > 1.0:  # 1MB ì´ìƒ ì´ë¯¸ì§€ë§Œ
                try:
                    # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì²˜ë¦¬ëœ íŒŒì¼ ì €ì¥
                    temp_dir = Path(tempfile.gettempdir()) / "solomond_noise_reduction"
                    temp_dir.mkdir(exist_ok=True)
                    temp_file = temp_dir / f"enhanced_{Path(filename).name}"
                    
                    noise_result = self.noise_reducer.process_file(file_path, 'image', str(temp_file))
                    if noise_result.success and noise_result.improvement_score > 0.1:
                        processed_file_path = noise_result.processed_file_path
                        noise_reduction_applied = True
                        st.info(f"[ë…¸ì´ì¦ˆ ê°ì†Œ] {filename} í’ˆì§ˆ {noise_result.improvement_score:.2f} í–¥ìƒ")
                except Exception as noise_error:
                    st.warning(f"[ì„ íƒ] ë…¸ì´ì¦ˆ ê°ì†Œ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {noise_error}")
            
            # ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸ ë° ìµœì í™” ì ìš©
            if DYNAMIC_RESOURCE_AVAILABLE and self.resource_manager:
                current_status = self.resource_manager.get_current_status()
                resource_used = 'gpu' if current_status.gpu_available else 'cpu'
            
            # Enhanced OCR ìš°ì„  ì‹œë„ (ë…¸ì´ì¦ˆ ê°ì†Œëœ íŒŒì¼ ì‚¬ìš©)
            if self.use_enhanced_ocr and self.enhanced_ocr_engine:
                try:
                    enhanced_result = self.enhanced_ocr_engine.extract_text(processed_file_path)
                    
                    if enhanced_result and not enhanced_result.error_message:
                        ocr_engine_used = 'enhanced'
                        full_text = enhanced_result.extracted_text
                        avg_confidence = enhanced_result.confidence
                        
                        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ í† í°í™”)
                        keywords = self._extract_keywords(full_text)
                        
                        processing_time = time.time() - start_time
                        
                        # ì„±ëŠ¥ ë¡œê¹…
                        if DYNAMIC_RESOURCE_AVAILABLE:
                            log_performance(f"EnhancedOCR_{filename}", processing_time, True, resource_used)
                        
                        fragment = {
                            'fragment_id': f'{self.conference_name}_{self.session_id}_{hashlib.md5(filename.encode()).hexdigest()[:8]}',
                            'file_source': filename,
                            'file_type': 'image',
                            'timestamp': datetime.now().isoformat(),
                            'speaker': None,  # ì´ë¯¸ì§€ëŠ” í™”ì ì—†ìŒ
                            'content': full_text,
                            'confidence': float(avg_confidence),
                            'keywords': keywords,
                            'processing_time': processing_time,
                            'file_size_mb': file_size_mb,
                            'resource_used': resource_used,
                            'ocr_engine': 'enhanced',
                            'engine_results': len(enhanced_result.individual_results) if enhanced_result.individual_results else 1,
                            'best_engine': enhanced_result.best_result.get('engine', 'unknown') if hasattr(enhanced_result, 'best_result') else 'enhanced',
                            'noise_reduction_applied': noise_reduction_applied
                        }
                        
                        return fragment
                    else:
                        # Enhanced OCR ì‹¤íŒ¨, ê¸°ë³¸ OCRë¡œ í´ë°±
                        st.warning(f"[í´ë°±] Enhanced OCR ì‹¤íŒ¨, ê¸°ë³¸ OCR ì‚¬ìš©: {filename}")
                        
                except Exception as enhanced_error:
                    st.warning(f"[í´ë°±] Enhanced OCR ì˜¤ë¥˜: {enhanced_error}")
            
            # ê¸°ë³¸ EasyOCR ì²˜ë¦¬ (í´ë°± ë˜ëŠ” ê¸°ë³¸)
            if not self.ocr_engine:
                return {"error": "ê¸°ë³¸ OCR ì—”ì§„ë„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            ocr_results = self.ocr_engine.readtext(processed_file_path)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì‹ ë¢°ë„ ê³„ì‚°
            extracted_texts = []
            confidences = []
            
            for (bbox, text, confidence) in ocr_results:
                if confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒë§Œ
                    extracted_texts.append(text.strip())
                    confidences.append(confidence)
            
            if not extracted_texts:
                return {"error": "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            full_text = " ".join(extracted_texts)
            avg_confidence = np.mean(confidences)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ í† í°í™”)
            keywords = self._extract_keywords(full_text)
            
            processing_time = time.time() - start_time
            
            # ì„±ëŠ¥ ë¡œê¹…
            if DYNAMIC_RESOURCE_AVAILABLE:
                log_performance(f"BasicOCR_{filename}", processing_time, True, resource_used)
            
            fragment = {
                'fragment_id': f'{self.conference_name}_{self.session_id}_{hashlib.md5(filename.encode()).hexdigest()[:8]}',
                'file_source': filename,
                'file_type': 'image',
                'timestamp': datetime.now().isoformat(),
                'speaker': None,  # ì´ë¯¸ì§€ëŠ” í™”ì ì—†ìŒ
                'content': full_text,
                'confidence': float(avg_confidence),
                'keywords': keywords,
                'processing_time': processing_time,
                'file_size_mb': file_size_mb,
                'resource_used': resource_used,
                'ocr_engine': 'basic',
                'raw_ocr_results': len(ocr_results),
                'noise_reduction_applied': noise_reduction_applied
            }
            
            return fragment
            
        except Exception as e:
            processing_time = time.time() - start_time
            if DYNAMIC_RESOURCE_AVAILABLE:
                log_performance(f"OCR_{filename}", processing_time, False, resource_used)
            return {"error": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"}
    
    def _process_audio_file(self, file_path: str, filename: str) -> Dict[str, Any]:
        """ì‹¤ì œ ìŒì„± íŒŒì¼ Whisper STT ì²˜ë¦¬ - ë™ì  ìµœì í™” ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        if not self.whisper_model:
            return {"error": "Whisper ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        start_time = time.time()
        resource_used = 'cpu'  # ê¸°ë³¸ê°’
        
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸ (ë™ì  ìµœì í™” ì°¸ê³ ìš©)
            file_size_mb = Path(file_path).stat().st_size / (1024 * 1024)
            
            # ë…¸ì´ì¦ˆ ê°ì†Œ ì „ì²˜ë¦¬ (ì„ íƒì )
            processed_file_path = file_path
            noise_reduction_applied = False
            
            if self.noise_reducer and file_size_mb > 0.5:  # 0.5MB ì´ìƒ ì˜¤ë””ì˜¤ë§Œ
                try:
                    # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì²˜ë¦¬ëœ íŒŒì¼ ì €ì¥
                    temp_dir = Path(tempfile.gettempdir()) / "solomond_noise_reduction"
                    temp_dir.mkdir(exist_ok=True)
                    temp_file = temp_dir / f"enhanced_{Path(filename).stem}.wav"
                    
                    noise_result = self.noise_reducer.process_file(file_path, 'audio', str(temp_file))
                    if noise_result.success and noise_result.improvement_score > 0.1:
                        processed_file_path = noise_result.processed_file_path
                        noise_reduction_applied = True
                        st.info(f"[ë…¸ì´ì¦ˆ ê°ì†Œ] {filename} ìŒì§ˆ {noise_result.improvement_score:.2f} í–¥ìƒ")
                        st.info(f"[ì ìš© ë°©ë²•] {', '.join(noise_result.methods_applied)}")
                except Exception as noise_error:
                    st.warning(f"[ì„ íƒ] ì˜¤ë””ì˜¤ ë…¸ì´ì¦ˆ ê°ì†Œ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {noise_error}")
            
            # ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸ ë° ìµœì í™” ì ìš©
            if DYNAMIC_RESOURCE_AVAILABLE and self.resource_manager:
                current_status = self.resource_manager.get_current_status()
                resource_used = 'gpu' if current_status.gpu_available and current_status.gpu_memory_free > 3.0 else 'cpu'
            
            # Whisperë¡œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ (ìµœì í™”ëœ ì„¤ì • ì ìš©)
            transcribe_options = {'language': 'ko'}
            if DYNAMIC_RESOURCE_AVAILABLE:
                whisper_config = get_optimal_whisper_settings(file_size_mb)
                if whisper_config.get('fp16', False):
                    transcribe_options['fp16'] = True
                if 'temperature' in whisper_config:
                    transcribe_options['temperature'] = whisper_config['temperature']
            
            result = self.whisper_model.transcribe(processed_file_path, **transcribe_options)
            
            if not result["text"].strip():
                return {"error": "ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            text = result["text"].strip()
            
            # ê³ ê¸‰ í™”ì ë¶„ë¦¬ (í™”ì êµ¬ë¶„ ì—”ì§„ ì‚¬ìš©)
            segments = result.get("segments", [])
            enhanced_segments = []
            num_speakers = 1
            speaker_profiles = {}
            
            if self.speaker_diarization and segments:
                try:
                    # Whisper ì„¸ê·¸ë¨¼íŠ¸ì— í™”ì ì •ë³´ ì¶”ê°€
                    enhanced_segments = self.speaker_diarization.enhance_whisper_segments(
                        segments, processed_file_path
                    )
                    
                    # í™”ì ìˆ˜ ê³„ì‚°
                    unique_speakers = set(seg.get('speaker', 'speaker_00') for seg in enhanced_segments)
                    num_speakers = len(unique_speakers)
                    
                    if num_speakers > 1:
                        st.info(f"[í™”ì êµ¬ë¶„] {num_speakers}ëª…ì˜ í™”ì ê°ì§€ë¨")
                        # ê° í™”ìë³„ ë°œì–¸ ì‹œê°„ í‘œì‹œ
                        speaker_times = {}
                        for seg in enhanced_segments:
                            speaker_id = seg.get('speaker', 'speaker_00')
                            duration = seg.get('end', 0) - seg.get('start', 0)
                            speaker_times[speaker_id] = speaker_times.get(speaker_id, 0) + duration
                        
                        for speaker_id, duration in speaker_times.items():
                            st.info(f"  - {speaker_id}: {duration:.1f}ì´ˆ ë°œì–¸")
                    
                    # ë©”ì¸ í™”ì ê²°ì • (ê°€ì¥ ë§ì´ ë°œì–¸í•œ í™”ì)
                    if enhanced_segments:
                        speaker_durations = {}
                        for seg in enhanced_segments:
                            speaker_id = seg.get('speaker', 'speaker_00')
                            duration = seg.get('end', 0) - seg.get('start', 0)
                            speaker_durations[speaker_id] = speaker_durations.get(speaker_id, 0) + duration
                        
                        main_speaker = max(speaker_durations.keys(), key=lambda k: speaker_durations[k])
                        speaker = main_speaker
                    else:
                        speaker = f"í™”ì_{hashlib.md5(filename.encode()).hexdigest()[:4]}"
                        
                except Exception as diarization_error:
                    st.warning(f"[í´ë°±] í™”ì êµ¬ë¶„ ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {diarization_error}")
                    enhanced_segments = segments
                    if segments:
                        main_segment = max(segments, key=lambda s: len(s.get("text", "")))
                        speaker = f"í™”ì_{hashlib.md5(filename.encode()).hexdigest()[:4]}"
                    else:
                        speaker = None
            else:
                # ê¸°ë³¸ í™”ì ë¶„ë¦¬ (í´ë°±)
                enhanced_segments = segments
                if segments:
                    main_segment = max(segments, key=lambda s: len(s.get("text", "")))
                    speaker = f"í™”ì_{hashlib.md5(filename.encode()).hexdigest()[:4]}"
                else:
                    speaker = None
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(text)
            
            processing_time = time.time() - start_time
            
            # ì„±ëŠ¥ ë¡œê¹…
            if DYNAMIC_RESOURCE_AVAILABLE:
                log_performance(f"Whisper_{filename}", processing_time, True, resource_used)
            
            fragment = {
                'fragment_id': f'{self.conference_name}_{self.session_id}_{hashlib.md5(filename.encode()).hexdigest()[:8]}',
                'file_source': filename,
                'file_type': 'audio',
                'timestamp': datetime.now().isoformat(),
                'speaker': speaker,
                'content': text,
                'confidence': 0.85,  # WhisperëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ ì •í™•ë„
                'keywords': keywords,
                'duration': result.get("duration", 0),
                'segments_count': len(segments),
                'processing_time': processing_time,
                'file_size_mb': file_size_mb,
                'resource_used': resource_used,
                'noise_reduction_applied': noise_reduction_applied,
                'num_speakers': num_speakers,
                'enhanced_segments': enhanced_segments if enhanced_segments != segments else None
            }
            
            return fragment
            
        except Exception as e:
            processing_time = time.time() - start_time
            if DYNAMIC_RESOURCE_AVAILABLE:
                log_performance(f"Whisper_{filename}", processing_time, False, resource_used)
            return {"error": f"ìŒì„± ì²˜ë¦¬ ì‹¤íŒ¨: {e}"}
    
    def _process_video_file(self, file_path: str, filename: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ í›„ STT)"""
        if not self.whisper_model:
            return {"error": "Whisper ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # Whisperë¡œ ë¹„ë””ì˜¤ì˜ ìŒì„± ì§ì ‘ ì²˜ë¦¬
            result = self.whisper_model.transcribe(file_path, language='ko')
            
            if not result["text"].strip():
                return {"error": "ë¹„ë””ì˜¤ì—ì„œ ìŒì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            text = result["text"].strip()
            
            # í™”ì ì¶”ì •
            segments = result.get("segments", [])
            speaker = f"í™”ì_{hashlib.md5(filename.encode()).hexdigest()[:4]}" if segments else None
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(text)
            
            fragment = {
                'fragment_id': f'{self.conference_name}_{self.session_id}_{hashlib.md5(filename.encode()).hexdigest()[:8]}',
                'file_source': filename,
                'file_type': 'video',
                'timestamp': datetime.now().isoformat(),
                'speaker': speaker,
                'content': text,
                'confidence': 0.85,
                'keywords': keywords,
                'duration': result.get("duration", 0),
                'segments_count': len(segments)
            }
            
            return fragment
            
        except Exception as e:
            return {"error": f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"}
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ë§Œ ì¶”ì¶œ
        words = re.findall(r'[ê°€-í£a-zA-Z]{2,}', text)
        
        # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        word_freq = Counter(words)
        keywords = [word for word, count in word_freq.most_common(10) if count >= 1]
        
        return keywords
    
    def run_holistic_analysis(self) -> Dict[str, Any]:
        """í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤í–‰"""
        if not self.holistic_analyzer:
            return {"error": "í™€ë¦¬ìŠ¤í‹± ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if self.database:
                self.database.create_fragments_table()
                fragment_count = self.database.get_fragment_count(self.conference_name)
                
                if fragment_count == 0:
                    return {"error": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”."}
            
            # í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤í–‰
            result = self.holistic_analyzer.analyze_conference_holistically()
            
            if "error" in result:
                return result
            
            # ì˜ë¯¸ì  ì—°ê²° ë¶„ì„
            semantic_engine = SemanticConnectionEngine(self.conference_name)
            semantic_result = semantic_engine.analyze_semantic_connections()
            
            # Ollama AI ê¸°ë°˜ ì‹¬í™” ë¶„ì„
            ollama_insights = self._generate_ai_insights(result)
            
            # ê²°ê³¼ í†µí•©
            combined_result = {
                "holistic_analysis": result,
                "semantic_connections": semantic_result,
                "ai_insights": ollama_insights,
                "analysis_timestamp": datetime.now().isoformat(),
                "database_type": type(self.database).__name__ if self.database else "None"
            }
            
            # ì„¸ì…˜ì— ì €ì¥
            self.analysis_results["holistic_results"] = combined_result
            
            return combined_result
            
        except Exception as e:
            return {"error": f"í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤íŒ¨: {e}"}
    
    def _generate_ai_insights(self, holistic_result: Dict[str, Any]) -> List[str]:
        """[ì‹œì‘] v4.0 ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ì„ í™œìš©í•œ ê³ ê¸‰ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        if not self.ollama:
            return ["AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (Ollama ë¹„í™œì„±)"]
        
        try:
            # [ì²˜ë¦¬ì¤‘] ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•©
            processed_files = self.analysis_results.get("processed_files", [])
            multimodal_context = self._build_multimodal_context(processed_files)
            
            # [ëª©í‘œ] í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (v4.0 ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ í™œìš©)
            enhanced_analysis_summary = f"""
ğŸ­ **ë©€í‹°ëª¨ë‹¬ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë°ì´í„°**:

[í†µê³„] **ê¸°ë³¸ í†µê³„**:
- ì²˜ë¦¬ëœ íŒŒì¼: {len(processed_files)}ê°œ 
- ì´ ë¶„ì„ ì¡°ê°: {holistic_result.get('total_fragments', 0)}ê°œ
- ë°œê²¬ëœ ê°œì²´: {holistic_result.get('total_entities', 0)}ê°œ  
- ì£¼ì œ í´ëŸ¬ìŠ¤í„°: {holistic_result.get('total_topics', 0)}ê°œ

[ë””ìì¸] **ë©€í‹°ëª¨ë‹¬ ë¶„í¬**:
{multimodal_context['modal_distribution']}

ğŸ”— **í¬ë¡œìŠ¤ëª¨ë‹¬ ì—°ê²°ì„±**:
{multimodal_context['cross_modal_connections']}

ğŸ“ **í•µì‹¬ ì½˜í…ì¸  ìƒ˜í”Œ**:
{multimodal_context['content_samples']}

[ê²€ìƒ‰] **í™€ë¦¬ìŠ¤í‹± ì¸ì‚¬ì´íŠ¸**:
{', '.join(holistic_result.get('key_insights', ['ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ']))}

[ëª©í‘œ] **ì»¨í¼ëŸ°ìŠ¤ ë©”íƒ€ì •ë³´**:
- ì´ë²¤íŠ¸ëª…: {self.conference_info.get('conference_name', 'N/A')}
- ì—…ê³„ ë¶„ì•¼: {self.conference_info.get('industry_field', 'N/A')}  
- ê´€ì‹¬ í‚¤ì›Œë“œ: {', '.join(self.conference_info.get('interest_keywords', []))}
"""
            
            # [AI] ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ë¡œ AI ë¶„ì„ ì‹¤í–‰
            ai_response = self.ollama.analyze_conference(enhanced_analysis_summary)
            
            if ai_response and not ai_response.startswith("AI ëª¨ë¸ ì˜¤ë¥˜"):
                # [ëª©í‘œ] êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹± (v4.0 í¬ë§·)
                structured_insights = self._parse_structured_ai_response(ai_response)
                return structured_insights
            else:
                return [f"AI ë¶„ì„ ì‹¤íŒ¨: {ai_response}"]
                
        except Exception as e:
            return [f"AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}"]
    
    def _build_multimodal_context(self, processed_files):
        """ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• - Task 3 ì‹œê°„ ê¸°ë°˜ íŒŒì¼ ê·¸ë£¹í•‘ í¬í•¨"""
        try:
            # ëª¨ë‹¬ë³„ ë¶„í¬ ë¶„ì„
            modal_stats = {'image': 0, 'audio': 0, 'text': 0, 'video': 0}
            content_samples = []
            cross_modal_connections = []
            
            for file_info in processed_files:
                file_type = self._detect_file_type(file_info.get('filename', ''))
                content = file_info.get('content', '').strip()
                
                if file_type in modal_stats:
                    modal_stats[file_type] += 1
                    
                # ì»¨í…ì¸  ìƒ˜í”Œ ìˆ˜ì§‘ (ê° ëª¨ë‹¬ë³„ ëŒ€í‘œ ìƒ˜í”Œ)
                if content and len(content_samples) < 6:  # ìµœëŒ€ 6ê°œ ìƒ˜í”Œ
                    content_samples.append(f"[{file_type.upper()}] {content[:150]}...")
            
            # ëª¨ë‹¬ ë¶„í¬ ë¬¸ìì—´ ìƒì„±
            modal_distribution = []
            for modal, count in modal_stats.items():
                if count > 0:
                    emoji = {'image': '[ì´ë¯¸ì§€]', 'audio': '[ìŒì•…]', 'text': '[ë¬¸ì„œ]', 'video': '[ë¹„ë””ì˜¤]'}
                    modal_distribution.append(f"{emoji.get(modal, '[í´ë”]')} {modal}: {count}ê°œ")
            
            # ì‹œê°„ ê¸°ë°˜ íŒŒì¼ ê·¸ë£¹í•‘ (Task 3 êµ¬í˜„)
            time_groups = self._group_files_by_time(processed_files)
            if len(time_groups) > 1:
                cross_modal_connections.append(f"ğŸ“… {len(time_groups)}ê°œ ì‹œê°„ëŒ€ ì„¸ì…˜ìœ¼ë¡œ ê·¸ë£¹í™”ë¨")
                for i, group in enumerate(time_groups[:3]):
                    cross_modal_connections.append(
                        f"  ì„¸ì…˜ {i+1}: {group['file_count']}ê°œ íŒŒì¼, {group.get('duration', 0):.1f}ë¶„"
                    )
            
            # í¬ë¡œìŠ¤ ëª¨ë‹¬ ìƒê´€ê´€ê³„ ì¶”ê°€
            if len([m for m in modal_stats.values() if m > 0]) >= 2:
                cross_modal_connections.append("ğŸ”— ì—¬ëŸ¬ ëª¨ë‹¬ ê°„ ë°ì´í„° ìƒê´€ê´€ê³„ ë¶„ì„ ê°€ëŠ¥")
            
            return {
                'modal_distribution': '\n'.join(modal_distribution) if modal_distribution else "ë°ì´í„° ì—†ìŒ",
                'cross_modal_connections': '\n'.join(cross_modal_connections) if cross_modal_connections else "ë‹¨ì¼ ëª¨ë‹¬ ë°ì´í„°",
                'content_samples': '\n'.join(content_samples) if content_samples else "ì»¨í…ì¸  ìƒ˜í”Œ ì—†ìŒ",
                'total_modalities': len([m for m in modal_stats.values() if m > 0]),
                'time_groups': time_groups
            }
            
        except Exception as e:
            return {
                'modal_distribution': f"ë¶„ì„ ì˜¤ë¥˜: {e}",
                'cross_modal_connections': "ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨",
                'content_samples': "ìƒ˜í”Œ ì¶”ì¶œ ì‹¤íŒ¨",
                'total_modalities': 0,
                'time_groups': []
            }
    
    def _group_files_by_time(self, processed_files):
        """ì‹œê°„ ê¸°ë°˜ íŒŒì¼ ê·¸ë£¹í•‘ - Task 3 êµ¬í˜„"""
        try:
            import os
            from datetime import datetime, timedelta
            
            time_groups = []
            files_with_time = []
            
            # íŒŒì¼ë³„ ì‹œê°„ ì •ë³´ ìˆ˜ì§‘
            for file_info in processed_files:
                filename = file_info.get('filename', '')
                if filename:
                    try:
                        if os.path.exists(filename):
                            mtime = os.path.getmtime(filename)
                            files_with_time.append({
                                'file_info': file_info,
                                'timestamp': datetime.fromtimestamp(mtime),
                                'filename': filename
                            })
                    except (OSError, ValueError):
                        # íŒŒì¼ ì ‘ê·¼ ë¶ˆê°€ì‹œ í˜„ì¬ ì‹œê°„ ì‚¬ìš©
                        files_with_time.append({
                            'file_info': file_info,
                            'timestamp': datetime.now(),
                            'filename': filename
                        })
            
            if not files_with_time:
                return []
            
            # ì‹œê°„ ìˆœ ì •ë ¬
            files_with_time.sort(key=lambda x: x['timestamp'])
            
            # 30ë¶„ ê°„ê²©ìœ¼ë¡œ ê·¸ë£¹í•‘ (ì»¨í¼ëŸ°ìŠ¤ ì„¸ì…˜ë³„ ë¶„ë¥˜)
            current_group = []
            current_group_start = None
            
            for file_data in files_with_time:
                file_time = file_data['timestamp']
                
                if not current_group_start:
                    current_group_start = file_time
                    current_group = [file_data]
                elif file_time - current_group_start <= timedelta(minutes=30):
                    current_group.append(file_data)
                else:
                    # í˜„ì¬ ê·¸ë£¹ ì €ì¥
                    if current_group:
                        duration_minutes = (current_group[-1]['timestamp'] - current_group[0]['timestamp']).total_seconds() / 60
                        time_groups.append({
                            'start_time': current_group[0]['timestamp'],
                            'end_time': current_group[-1]['timestamp'],
                            'duration': round(max(duration_minutes, 0), 1),
                            'file_count': len(current_group),
                            'files': current_group
                        })
                    
                    # ìƒˆ ê·¸ë£¹ ì‹œì‘
                    current_group_start = file_time
                    current_group = [file_data]
            
            # ë§ˆì§€ë§‰ ê·¸ë£¹ ì €ì¥
            if current_group:
                duration_minutes = (current_group[-1]['timestamp'] - current_group[0]['timestamp']).total_seconds() / 60
                time_groups.append({
                    'start_time': current_group[0]['timestamp'],
                    'end_time': current_group[-1]['timestamp'],
                    'duration': round(max(duration_minutes, 0), 1),
                    'file_count': len(current_group),
                    'files': current_group
                })
            
            return time_groups
            
        except Exception as e:
            st.error(f"ì‹œê°„ ê¸°ë°˜ ê·¸ë£¹í•‘ ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_structured_ai_response(self, ai_response):
        """êµ¬ì¡°í™”ëœ AI ì‘ë‹µ íŒŒì‹± - v4.0 ë©€í‹°ëª¨ë‹¬ ì¸ì‚¬ì´íŠ¸ êµ¬ì¡°í™”"""
        try:
            import re
            
            # ê¸°ë³¸ êµ¬ì¡°í™”ëœ ì‘ë‹µ í…œí”Œë¦¿
            structured_insights = []
            
            # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì„¹ì…˜ë³„ ë‚´ìš© ì¶”ì¶œ
            sections = {
                '[ê²€ìƒ‰] í•µì‹¬ ì‹œê·¸ë„': r'[ê²€ìƒ‰]\s*\*\*í•µì‹¬ ì‹œê·¸ë„[^*]*\*\*[^[ëª©í‘œ][ì‹œì‘][íŒ][ì£¼ì˜]]*',
                '[íŒ] ìƒí™© í†µí•©': r'[íŒ]\s*\*\*[^*]*ìƒí™©[^*]*\*\*[^[ê²€ìƒ‰][ì‹œì‘][ëª©í‘œ][ì£¼ì˜]]*',
                '[ëª©í‘œ] ì—…ê³„ ì¸ì‚¬ì´íŠ¸': r'[ëª©í‘œ]\s*\*\*[^*]*ì¸ì‚¬ì´íŠ¸[^*]*\*\*[^[ê²€ìƒ‰][íŒ][ì‹œì‘][ì£¼ì˜]]*',
                '[ì‹œì‘] ì‹¤í–‰ ì œì•ˆ': r'[ì‹œì‘]\s*\*\*[^*]*ì œì•ˆ[^*]*\*\*[^[ê²€ìƒ‰][íŒ][ëª©í‘œ][ì£¼ì˜]]*',
                '[ì£¼ì˜] ì£¼ì˜ì‚¬í•­': r'[ì£¼ì˜]\s*\*\*[^*]*ì£¼ì˜ì‚¬í•­[^*]*\*\*[^[ê²€ìƒ‰][íŒ][ëª©í‘œ][ì‹œì‘]]*'
            }
            
            parsed_sections = {}
            
            for section_name, pattern in sections.items():
                match = re.search(pattern, ai_response, re.DOTALL | re.IGNORECASE)
                if match:
                    content = match.group(0)
                    # ë¶ˆë¦¿ í¬ì¸íŠ¸ ë˜ëŠ” ì¤„ë°”ê¿ˆ ê¸°ë°˜ìœ¼ë¡œ ë‚´ìš© ì¶”ì¶œ
                    lines = [line.strip() for line in content.split('\n') if line.strip() and not line.strip().startswith('**')]
                    # ì„¹ì…˜ í—¤ë” ì œê±°
                    clean_lines = []
                    for line in lines:
                        if not re.match(r'^[ê²€ìƒ‰]|[íŒ]|[ëª©í‘œ]|[ì‹œì‘]|[ì£¼ì˜]', line.strip()):
                            clean_lines.append(line.strip('- â€¢').strip())
                    
                    if clean_lines:
                        parsed_sections[section_name] = clean_lines[:3]  # ìµœëŒ€ 3ê°œì”©
            
            # êµ¬ì¡°í™”ëœ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            if '[ê²€ìƒ‰] í•µì‹¬ ì‹œê·¸ë„' in parsed_sections:
                for insight in parsed_sections['[ê²€ìƒ‰] í•µì‹¬ ì‹œê·¸ë„']:
                    if insight:
                        structured_insights.append(f"[ê²€ìƒ‰] í•µì‹¬ ë°œê²¬: {insight}")
            
            if '[íŒ] ìƒí™© í†µí•©' in parsed_sections:
                for insight in parsed_sections['[íŒ] ìƒí™© í†µí•©']:
                    if insight:
                        structured_insights.append(f"[íŒ] í†µí•© ë¶„ì„: {insight}")
            
            if '[ëª©í‘œ] ì—…ê³„ ì¸ì‚¬ì´íŠ¸' in parsed_sections:
                for insight in parsed_sections['[ëª©í‘œ] ì—…ê³„ ì¸ì‚¬ì´íŠ¸']:
                    if insight:
                        structured_insights.append(f"[ëª©í‘œ] ì—…ê³„ ì‹œì‚¬ì : {insight}")
            
            if '[ì‹œì‘] ì‹¤í–‰ ì œì•ˆ' in parsed_sections:
                for insight in parsed_sections['[ì‹œì‘] ì‹¤í–‰ ì œì•ˆ']:
                    if insight:
                        structured_insights.append(f"[ì‹œì‘] ì•¡ì…˜ ì•„ì´í…œ: {insight}")
            
            if '[ì£¼ì˜] ì£¼ì˜ì‚¬í•­' in parsed_sections:
                for insight in parsed_sections['[ì£¼ì˜] ì£¼ì˜ì‚¬í•­']:
                    if insight:
                        structured_insights.append(f"[ì£¼ì˜] ì£¼ì˜ì‚¬í•­: {insight}")
            
            # ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ì‘ë‹µì—ì„œ ì¶”ì¶œ ì‹œë„
            if not structured_insights:
                # ê°„ë‹¨í•œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                sentences = [s.strip() for s in ai_response.split('.') if s.strip() and len(s.strip()) > 20]
                for sentence in sentences[:5]:  # ìµœëŒ€ 5ê°œ ë¬¸ì¥
                    structured_insights.append(f"[íŒ] AI ë¶„ì„: {sentence}.")
            
            # ìµœì†Œ 1ê°œ ì¸ì‚¬ì´íŠ¸ ë³´ì¥
            if not structured_insights:
                structured_insights = [
                    "[ê²€ìƒ‰] ë©€í‹°ëª¨ë‹¬ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                    "[íŒ] ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì—ì„œ ì£¼ìš” ì½˜í…ì¸ ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤",
                    "[ì‹œì‘] ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤"
                ]
            
            return structured_insights
            
        except Exception as e:
            return [
                f"[ì£¼ì˜] ì¸ì‚¬ì´íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {str(e)}",
                "[ê²€ìƒ‰] ì›ë³¸ AI ì‘ë‹µ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
                f"[íŒ] Raw Response: {ai_response[:200]}..."
            ]
    
    def _normalize_embedding_dimension(self, embedding, target_dim=768):
        """ì„ë² ë”© ì°¨ì›ì„ ëª©í‘œ ì°¨ì›ìœ¼ë¡œ ì •ê·œí™”"""
        try:
            import numpy as np
            
            if embedding is None:
                return np.random.rand(target_dim).astype(np.float32)
            
            current_dim = embedding.shape[0] if len(embedding.shape) > 0 else len(embedding)
            
            if current_dim == target_dim:
                return embedding.astype(np.float32)
            elif current_dim < target_dim:
                # íŒ¨ë”©ìœ¼ë¡œ í™•ì¥
                padding_size = target_dim - current_dim
                return np.concatenate([
                    embedding.astype(np.float32), 
                    np.zeros(padding_size, dtype=np.float32)
                ])
            else:
                # ì²˜ìŒ target_dim ì°¨ì›ë§Œ ì‚¬ìš©
                return embedding[:target_dim].astype(np.float32)
                
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒì‹œ ëœë¤ ì„ë² ë”© ë°˜í™˜
            import numpy as np
            return np.random.rand(target_dim).astype(np.float32)
    
    def _convert_to_encoded_results(self, multimodal_results):
        """MultimodalResultë¥¼ EncodedResultë¡œ ë³€í™˜"""
        try:
            encoded_results = []
            
            for mm_result in multimodal_results:
                # ì„ë² ë”©ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë³€í™˜
                if hasattr(mm_result, 'embeddings') and mm_result.embeddings is not None:
                    try:
                        # ì‹¤ì œ multimodal_encoderì˜ EncodedResult ì‚¬ìš©
                        from core.multimodal_encoder import EncodedResult
                        import numpy as np
                        
                        # ì„ë² ë”© ì°¨ì› ì •ê·œí™”
                        normalized_embedding = self._normalize_embedding_dimension(mm_result.embeddings)
                        
                        encoded_result = EncodedResult(
                            file_path=mm_result.file_path,
                            modality=mm_result.file_type,
                            encoding=normalized_embedding,
                            confidence=mm_result.confidence,
                            metadata=mm_result.metadata or {},
                            processing_time=mm_result.processing_time if hasattr(mm_result, 'processing_time') else 0.0,
                            raw_content=mm_result.content if hasattr(mm_result, 'content') else ""
                        )
                        encoded_results.append(encoded_result)
                    except ImportError:
                        # í´ë°±: crossmodal_fusionì˜ EncodedResult ì‚¬ìš©
                        from core.crossmodal_fusion import EncodedResult
                        import numpy as np
                        
                        # ì„ë² ë”© ì°¨ì› ì •ê·œí™” (í´ë°±)
                        normalized_embedding = self._normalize_embedding_dimension(mm_result.embeddings)
                        
                        encoded_result = EncodedResult(
                            file_path=mm_result.file_path,
                            modality=mm_result.file_type,
                            encoding=normalized_embedding,
                            confidence=mm_result.confidence,
                            metadata=mm_result.metadata or {}
                        )
                        encoded_results.append(encoded_result)
                else:
                    # ì„ë² ë”©ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ê°’ìœ¼ë¡œ ìƒì„±
                    try:
                        from core.multimodal_encoder import EncodedResult
                        import numpy as np
                        
                        # 768ì°¨ì› ì •ê·œí™” ì„ë² ë”© ìƒì„±
                        dummy_embedding = self._normalize_embedding_dimension(None)
                        
                        encoded_result = EncodedResult(
                            file_path=mm_result.file_path,
                            modality=mm_result.file_type,
                            encoding=dummy_embedding,
                            confidence=mm_result.confidence,
                            metadata=mm_result.metadata or {},
                            processing_time=mm_result.processing_time if hasattr(mm_result, 'processing_time') else 0.0,
                            raw_content=mm_result.content if hasattr(mm_result, 'content') else ""
                        )
                        encoded_results.append(encoded_result)
                    except ImportError:
                        # í´ë°±: crossmodal_fusionì˜ EncodedResult ì‚¬ìš©
                        from core.crossmodal_fusion import EncodedResult
                        import numpy as np
                        
                        dummy_embedding = self._normalize_embedding_dimension(None)
                        
                        encoded_result = EncodedResult(
                            file_path=mm_result.file_path,
                            modality=mm_result.file_type,
                            encoding=dummy_embedding,
                            confidence=mm_result.confidence,
                            metadata=mm_result.metadata or {}
                        )
                        encoded_results.append(encoded_result)
            
            return encoded_results
            
        except Exception as e:
            st.error(f"ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return []
    
    def _detect_file_type(self, filename):
        """íŒŒì¼ í™•ì¥ì ê¸°ë°˜ íƒ€ì… ê°ì§€"""
        if not filename:
            return 'unknown'
            
        ext = Path(filename).suffix.lower()
        
        if ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']:
            return 'image'
        elif ext in ['.wav', '.mp3', '.m4a', '.ogg', '.flac']:
            return 'audio'
        elif ext in ['.txt', '.md', '.pdf', '.docx', '.doc']:
            return 'text'
        elif ext in ['.mov', '.mp4', '.avi', '.mkv', '.webm']:
            return 'video'
        else:
            return 'unknown'
    
    def _create_sample_data(self):
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ìš©)"""
        if not self.database:
            return False
            
        try:
            # í…Œì´ë¸” ìƒì„±
            self.database.create_fragments_table()
            
            # ìƒ˜í”Œ ì¡°ê°ë“¤ ìƒì„±
            sample_fragments = [
                {
                    'fragment_id': f'{self.conference_name}_sample_001',
                    'file_source': 'sample_conference_audio.wav',
                    'file_type': 'audio',
                    'timestamp': datetime.now().isoformat(),
                    'speaker': 'í™”ì_001',
                    'content': 'ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ì£¼ì–¼ë¦¬ ì—…ê³„ì˜ ìµœì‹  íŠ¸ë Œë“œì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ìµœê·¼ ì§€ì†ê°€ëŠ¥ì„±ì´ ì¤‘ìš”í•œ í™”ë‘ê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤.',
                    'confidence': 0.92,
                    'keywords': ['ì£¼ì–¼ë¦¬', 'íŠ¸ë Œë“œ', 'ì§€ì†ê°€ëŠ¥ì„±', 'ì—…ê³„', 'í™”ë‘']
                },
                {
                    'fragment_id': f'{self.conference_name}_sample_002',
                    'file_source': 'sample_presentation.jpg',
                    'file_type': 'image',
                    'timestamp': datetime.now().isoformat(),
                    'speaker': None,
                    'content': '2025ë…„ ì£¼ì–¼ë¦¬ ì‹œì¥ ì „ë§: ë””ì§€í„¸ ë³€í˜ê³¼ ê°œì¸í™” íŠ¸ë Œë“œ',
                    'confidence': 0.87,
                    'keywords': ['2025ë…„', 'ì£¼ì–¼ë¦¬', 'ì‹œì¥', 'ë””ì§€í„¸', 'ê°œì¸í™”']
                },
                {
                    'fragment_id': f'{self.conference_name}_sample_003',
                    'file_source': 'sample_discussion.wav',
                    'file_type': 'audio',
                    'timestamp': datetime.now().isoformat(),
                    'speaker': 'í™”ì_002',
                    'content': 'ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ í™œìš©í•œ ë§ì¶¤í˜• ì£¼ì–¼ë¦¬ ë””ìì¸ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê³ ê°ì˜ ì„ í˜¸ë„ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ ì œí’ˆì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
                    'confidence': 0.89,
                    'keywords': ['ì¸ê³µì§€ëŠ¥', 'ë§ì¶¤í˜•', 'ë””ìì¸', 'ê³ ê°', 'ê°œì¸í™”']
                }
            ]
            
            # ë°°ì¹˜ ì‚½ì…
            success = self.database.insert_fragments_batch(sample_fragments)
            
            if success:
                # ë¶„ì„ ê²°ê³¼ì—ë„ ì¶”ê°€
                self.analysis_results["processed_files"] = sample_fragments
                return True
            return False
            
        except Exception as e:
            st.error(f"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def download_video_from_url(self, url: str) -> Optional[Dict[str, Any]]:
        """ë‹¤ì–‘í•œ í”Œë«í¼ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ"""
        if not YOUTUBE_AVAILABLE:
            st.error("[ì‹¤íŒ¨] yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install yt-dlpë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return None
        
        try:
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            temp_dir = tempfile.mkdtemp()
            
            # yt-dlp ì˜µì…˜ ì„¤ì • (ë‹¤ì–‘í•œ í”Œë«í¼ ì§€ì›)
            ydl_opts = {
                'format': 'best[height<=720]/best/worstvideo+bestaudio/worst',  # Brightcove í˜¸í™˜ì„± ê°œì„ 
                'outtmpl': os.path.join(temp_dir, '%(title)s.%(ext)s'),
                'quiet': True,
                'no_warnings': True,
                'extractaudio': False,
                'writesubtitles': False,
                'writeautomaticsub': False,
                'ignoreerrors': True,  # í¬ë§· ì—ëŸ¬ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                info = ydl.extract_info(url, download=False)
                title = info.get('title', 'unknown')
                duration = info.get('duration', 0)
                platform = info.get('extractor', 'unknown')
                uploader = info.get('uploader', 'unknown')
                
                # ë„ˆë¬´ ê¸´ ë¹„ë””ì˜¤ëŠ” ì œí•œ (30ë¶„)
                if duration and duration > 1800:
                    st.warning(f"[ì£¼ì˜] ë¹„ë””ì˜¤ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({duration//60}ë¶„). 30ë¶„ ì´í•˜ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                    return None
                
                # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
                st.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {title} ({platform})")
                ydl.download([url])
                
                # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì°¾ê¸°
                for file in os.listdir(temp_dir):
                    if file.endswith(('.mp4', '.webm', '.mkv', '.flv', '.avi')):
                        downloaded_path = os.path.join(temp_dir, file)
                        st.success(f"[ì™„ë£Œ] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {title}")
                        
                        return {
                            'path': downloaded_path,
                            'title': title,
                            'platform': platform,
                            'uploader': uploader,
                            'duration': duration,
                            'url': url
                        }
            
            return None
            
        except Exception as e:
            st.error(f"[ì‹¤íŒ¨] ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def process_video_url(self, url: str) -> Dict[str, Any]:
        """ë‹¤ì–‘í•œ í”Œë«í¼ ë¹„ë””ì˜¤ URL ì²˜ë¦¬"""
        # URL ê¸°ë³¸ ê²€ì¦
        if not url.startswith(('http://', 'https://')):
            return {"error": "ìœ íš¨í•œ URLì´ ì•„ë‹™ë‹ˆë‹¤."}
        
        # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        download_info = self.download_video_from_url(url)
        if not download_info:
            return {"error": "ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
        
        try:
            # ë‹¤ìš´ë¡œë“œëœ ë¹„ë””ì˜¤ë¥¼ ì¼ë°˜ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì²˜ë¦¬
            result = self._process_video_file(download_info['path'], download_info['title'])
            
            # ì›ë³¸ URL ë° í”Œë«í¼ ì •ë³´ ì¶”ê°€
            if "error" not in result:
                result["original_url"] = download_info['url']
                result["platform"] = download_info['platform']
                result["uploader"] = download_info['uploader']
                result["source_type"] = "web_video"
                result["video_duration"] = download_info['duration']
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.unlink(download_info['path'])
            os.rmdir(os.path.dirname(download_info['path']))
            
            return result
            
        except Exception as e:
            return {"error": f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"}
    
    def process_text_file_urls(self, uploaded_file) -> List[Dict[str, Any]]:
        """TXT íŒŒì¼ì—ì„œ URL ì¶”ì¶œ ë° ë°°ì¹˜ ì²˜ë¦¬"""
        try:
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            content = uploaded_file.read().decode('utf-8')
            
            # URL íŒ¨í„´ ì°¾ê¸°
            url_pattern = r'https?://[^\s\n\r]+'
            urls = re.findall(url_pattern, content)
            
            if not urls:
                return [{"error": "í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ìœ íš¨í•œ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}]
            
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, url in enumerate(urls):
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = (i + 1) / len(urls)
                progress_bar.progress(progress)
                status_text.text(f"URL ì²˜ë¦¬ ì¤‘: {i+1}/{len(urls)} - {url[:50]}...")
                
                # URL ì²˜ë¦¬
                result = self.process_video_url(url.strip())
                
                if "error" not in result:
                    result["batch_index"] = i + 1
                    result["total_batch"] = len(urls)
                    results.append(result)
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    if self.database:
                        self.database.insert_fragment(result)
                else:
                    st.warning(f"[ì£¼ì˜] URL ì²˜ë¦¬ ì‹¤íŒ¨: {url[:50]}... - {result['error']}")
                
                # ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ ë°©ì§€
                time.sleep(1)
            
            progress_bar.progress(1.0)
            status_text.text(f"[ì™„ë£Œ] ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}/{len(urls)}ê°œ ì„±ê³µ")
            
            return results
            
        except Exception as e:
            return [{"error": f"í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"}]
    
    def trigger_dual_brain_system(self) -> Dict[str, Any]:
        """ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ íŠ¸ë¦¬ê±°"""
        if not self.dual_brain:
            return {"error": "ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            if not self.analysis_results.get("holistic_results"):
                return {"error": "ë¨¼ì € í™€ë¦¬ìŠ¤í‹± ë¶„ì„ì„ ì™„ë£Œí•˜ì„¸ìš”."}
            
            # ë“€ì–¼ ë¸Œë ˆì¸ ë¶„ì„ ì‹¤í–‰
            dual_brain_result = self.dual_brain.analyze_and_integrate(
                self.analysis_results["holistic_results"]
            )
            
            # ì„¸ì…˜ì— ì €ì¥
            self.analysis_results["dual_brain_results"] = dual_brain_result
            
            return dual_brain_result
            
        except Exception as e:
            return {"error": f"ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì‹¤íŒ¨: {e}"}
    
    def generate_comprehensive_report(self) -> str:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not self.analysis_results["processed_files"]:
            return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report_parts = []
        
        # í—¤ë”
        report_parts.append(f"# {self.conference_name} ì™„ì „ í†µí•© ë¶„ì„ ë³´ê³ ì„œ")
        report_parts.append(f"**ìƒì„± ì¼ì‹œ:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_parts.append(f"**ì„¸ì…˜ ID:** {self.session_id}")
        report_parts.append("")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        status = self.check_system_status()
        report_parts.append("## [ì„¤ì •] ì‹œìŠ¤í…œ ìƒíƒœ")
        report_parts.append(f"- **ì „ì²´ ì¤€ë¹„ë„:** {status['ready_systems']}/{status['total_systems']} ({'ì™„ë£Œ' if status['overall_ready'] else 'ë¶€ë¶„ì™„ë£Œ'})")
        report_parts.append(f"- **OCR ì—”ì§„:** {'[ì™„ë£Œ] ì •ìƒ' if status['ocr_available'] else '[ì‹¤íŒ¨] ë¹„í™œì„±'}")
        report_parts.append(f"- **Whisper STT:** {'[ì™„ë£Œ] ì •ìƒ' if status['whisper_available'] else '[ì‹¤íŒ¨] ë¹„í™œì„±'}")
        report_parts.append(f"- **í™€ë¦¬ìŠ¤í‹± ë¶„ì„:** {'[ì™„ë£Œ] ì •ìƒ' if status['holistic_available'] else '[ì‹¤íŒ¨] ë¹„í™œì„±'}")
        report_parts.append(f"- **ë°ì´í„°ë² ì´ìŠ¤:** {'[ì™„ë£Œ] ì •ìƒ' if status['database_available'] else '[ì‹¤íŒ¨] ë¹„í™œì„±'}")
        report_parts.append(f"- **Ollama AI:** {'[ì™„ë£Œ] ì •ìƒ' if status['ollama_available'] else '[ì‹¤íŒ¨] ë¹„í™œì„±'}")
        if status['ollama_available'] and self.ollama:
            report_parts.append(f"  - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(self.ollama.available_models)}ê°œ")
        report_parts.append("")
        
        # íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼
        processed_files = self.analysis_results["processed_files"]
        report_parts.append("## [í´ë”] íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼")
        report_parts.append(f"- **ì²˜ë¦¬ëœ íŒŒì¼:** {len(processed_files)}ê°œ")
        
        file_types = Counter([f['file_type'] for f in processed_files])
        for file_type, count in file_types.items():
            type_name = {"image": "ì´ë¯¸ì§€", "audio": "ìŒì„±", "video": "ë¹„ë””ì˜¤"}.get(file_type, file_type)
            report_parts.append(f"  - {type_name}: {count}ê°œ")
        
        # í‰ê·  ì‹ ë¢°ë„
        if processed_files:
            avg_confidence = np.mean([f['confidence'] for f in processed_files])
            report_parts.append(f"- **í‰ê·  ì‹ ë¢°ë„:** {avg_confidence:.1%}")
        
        report_parts.append("")
        
        # í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ê²°ê³¼
        if self.analysis_results.get("holistic_results"):
            holistic = self.analysis_results["holistic_results"]["holistic_analysis"]
            report_parts.append("## ğŸ§  í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ê²°ê³¼")
            report_parts.append(f"- **ì´ ì¡°ê° ìˆ˜:** {holistic.get('total_fragments', 0)}ê°œ")
            report_parts.append(f"- **ë°œê²¬ëœ ê°œì²´:** {holistic.get('total_entities', 0)}ê°œ")
            report_parts.append(f"- **ì£¼ìš” ì£¼ì œ:** {holistic.get('total_topics', 0)}ê°œ")
            
            # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
            key_insights = holistic.get('key_insights', [])
            if key_insights:
                report_parts.append("### [íŒ] í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
                for insight in key_insights:
                    report_parts.append(f"- {insight}")
            
            # AI ì¸ì‚¬ì´íŠ¸
            ai_insights = self.analysis_results["holistic_results"].get("ai_insights", [])
            if ai_insights and not ai_insights[0].startswith("AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"):
                report_parts.append("### [AI] AI ì‹¬í™” ë¶„ì„")
                for insight in ai_insights:
                    if not insight.startswith("AI"):  # ì—ëŸ¬ ë©”ì‹œì§€ ì œì™¸
                        report_parts.append(f"- {insight}")
            
            report_parts.append("")
        
        # ë“€ì–¼ ë¸Œë ˆì¸ ê²°ê³¼
        if self.analysis_results.get("dual_brain_results"):
            report_parts.append("## ğŸ§ ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ë¶„ì„")
            dual_brain = self.analysis_results["dual_brain_results"]
            report_parts.append("### AI ì¸ì‚¬ì´íŠ¸")
            if dual_brain.get("ai_insights"):
                for insight in dual_brain["ai_insights"][:3]:  # ìƒìœ„ 3ê°œ
                    report_parts.append(f"- {insight}")
            report_parts.append("")
        
        # ê²°ë¡ 
        report_parts.append("## ğŸ“‹ ê²°ë¡ ")
        report_parts.append("ë³¸ í†µí•© ë¶„ì„ì„ í†µí•´ ì»¨í¼ëŸ°ìŠ¤ì˜ ì „ì²´ì ì¸ ë‚´ìš©ê³¼ í•µì‹¬ ì‚¬ì•ˆë“¤ì´ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        report_parts.append("ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬ë¶€í„° ê³ ê¸‰ ì˜ë¯¸ ë¶„ì„ê¹Œì§€ ì „ ê³¼ì •ì´ ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
        report_parts.append("")
        report_parts.append("---")
        report_parts.append("*ë³¸ ë³´ê³ ì„œëŠ” SOLOMOND AI ì™„ì „ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ v7.1ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
        
        return "\n".join(report_parts)

def main():
    st.set_page_config(
        page_title="ì™„ì „ í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ",
        page_icon="[ëª©í‘œ]",
        layout="wide"
    )
    
    # ğŸ”¥ ë©”ëª¨ë¦¬ ì•ˆì „ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ (MemoryError ë°©ì§€)
    os.environ['STREAMLIT_SERVER_MAX_UPLOAD_SIZE'] = '5120'  # 5GB
    os.environ['STREAMLIT_SERVER_MAX_MESSAGE_SIZE'] = '5120'  # 5GB  
    os.environ['STREAMLIT_SERVER_ENABLE_CORS'] = 'false'
    os.environ['STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION'] = 'false'
    
    # Tornado ë©”ëª¨ë¦¬ ìµœì í™” (ì¤‘ìš”!)
    os.environ['STREAMLIT_SERVER_MAX_REQUEST_SIZE'] = '5368709120'  # 5GB in bytes
    os.environ['STREAMLIT_TORNADO_MAX_BUFFER_SIZE'] = '268435456'  # 256MB buffer
    
    # [ì‹œì‘] GPU í™œì„±í™” ì„¤ì • (5-15ë°° ì„±ëŠ¥ í–¥ìƒ)
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # GTX 1050 Ti ì‚¬ìš©
    
    # GPU ë©”ëª¨ë¦¬ ìµœì í™”
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()  # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        st.success(f"GPU í™œì„±í™”: {torch.cuda.get_device_name(0)}")
    else:
        st.warning("GPU ì‚¬ìš© ë¶ˆê°€, CPU ëª¨ë“œë¡œ ì§„í–‰")
    
    st.title("[ëª©í‘œ] ì™„ì „ í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("**SOLOMOND AI v7.4 - 1000+ í”Œë«í¼ ë©€í‹°ë¯¸ë””ì–´ ë¶„ì„**")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    if OLLAMA_AVAILABLE and YOUTUBE_AVAILABLE:
        st.info("[ì‹œì‘] **ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”**: Ollama AI 5ê°œ ëª¨ë¸ + 1000+ ì›¹ í”Œë«í¼ + TXT ë°°ì¹˜ ì²˜ë¦¬")
    elif OLLAMA_AVAILABLE:
        st.info("[AI] **AI ë¶„ì„ í™œì„±í™”**: Ollama 5ê°œ ëª¨ë¸ í™œì„± | [ì£¼ì˜] ì›¹ ë™ì˜ìƒ ë¶„ì„ ë¹„í™œì„±")
    elif YOUTUBE_AVAILABLE:
        st.info("[ë¹„ë””ì˜¤] **ì›¹ ë¶„ì„ í™œì„±í™”**: 1000+ í”Œë«í¼ ì§€ì› | [ì£¼ì˜] AI ê³ ê¸‰ ë¶„ì„ ë¹„í™œì„±")
    else:
        st.warning("[ì£¼ì˜] ê¸°ë³¸ ë¶„ì„ë§Œ ì§€ì› - AI ëª¨ë¸ê³¼ ì›¹ ë¶„ì„ ë¹„í™œì„±")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    conference_name = st.sidebar.text_input("ì»¨í¼ëŸ°ìŠ¤ ì´ë¦„", "unified_conference_2025")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    if 'analyzer' not in st.session_state:
        with st.spinner("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            st.session_state.analyzer = UnifiedConferenceAnalyzer(conference_name)
    
    analyzer = st.session_state.analyzer
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    status = analyzer.check_system_status()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    st.sidebar.markdown("### [ì„¤ì •] ì‹œìŠ¤í…œ ìƒíƒœ")
    if status["overall_ready"]:
        st.sidebar.success(f"[ì™„ë£Œ] ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ ({status['ready_systems']}/{status['total_systems']})")
    else:
        st.sidebar.warning(f"[ì£¼ì˜] ë¶€ë¶„ ì¤€ë¹„ ({status['ready_systems']}/{status['total_systems']})")
    
    st.sidebar.markdown(f"**OCR:** {'[ì™„ë£Œ]' if status['ocr_available'] else '[ì‹¤íŒ¨]'}")
    st.sidebar.markdown(f"**Whisper:** {'[ì™„ë£Œ]' if status['whisper_available'] else '[ì‹¤íŒ¨]'}")
    st.sidebar.markdown(f"**í™€ë¦¬ìŠ¤í‹±:** {'[ì™„ë£Œ]' if status['holistic_available'] else '[ì‹¤íŒ¨]'}")
    st.sidebar.markdown(f"**ë°ì´í„°ë² ì´ìŠ¤:** {'[ì™„ë£Œ]' if status['database_available'] else '[ì‹¤íŒ¨]'}")
    st.sidebar.markdown(f"**Ollama AI:** {'[ì™„ë£Œ]' if status['ollama_available'] else '[ì‹¤íŒ¨]'}")
    
    if status['ollama_available'] and analyzer.ollama:
        st.sidebar.markdown("### [AI] Ollama ëª¨ë¸")
        for model in analyzer.ollama.available_models:
            model_info = f"**{model}**"
            if "gpt-oss:20b" in model:
                model_info += " (13GB, ìµœì‹  GPT)"
            elif "qwen3:8b" in model:
                model_info += " (5.2GB, Qwen3)"
            elif "gemma3:27b" in model:
                model_info += " (17GB, ëŒ€í˜• ëª¨ë¸)"
            elif "qwen2.5:7b" in model:
                model_info += " (4.7GB, ì¶”ì²œ)"
            elif "gemma3:4b" in model:
                model_info += " (3.3GB, ê²½ëŸ‰)"
            st.sidebar.markdown(f"- {model_info}")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœê°€ Xì¸ ê²½ìš° ìƒ˜í”Œ ë°ì´í„° ì œê³µ
    if not status["database_available"]:
        st.error("[ì‹¤íŒ¨] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        if st.button("[ì„¤ì •] ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸", type="secondary"):
            with st.spinner("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
                analyzer._create_sample_data()
            st.rerun()
    
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    tab0, tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ì‚¬ì „ì •ë³´", "[í´ë”] íŒŒì¼/URL ì²˜ë¦¬", "ğŸ§  í™€ë¦¬ìŠ¤í‹± ë¶„ì„", "ğŸ§ ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸", "ğŸ“‹ ì¢…í•© ë³´ê³ ì„œ"])
    
    with tab0:
        st.markdown("## ğŸ“‹ ì»¨í¼ëŸ°ìŠ¤ ì‚¬ì „ì •ë³´")
        st.markdown("**ë¶„ì„ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ë°°ê²½ ì •ë³´ ì…ë ¥**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            conference_name_input = st.text_input("[ëª©í‘œ] ì»¨í¼ëŸ°ìŠ¤ëª…", "")
            conference_date = st.date_input("ğŸ“… ë‚ ì§œ", datetime.now().date())
            location = st.text_input("ğŸ“ ì¥ì†Œ", "")
        
        with col2:
            industry_options = ["ì£¼ì–¼ë¦¬", "íŒ¨ì…˜", "ê¸°ìˆ ", "ì˜ë£Œ", "êµìœ¡", "ê¸ˆìœµ", "ê¸°íƒ€"]
            industry_field = st.selectbox("ğŸ¢ ì—…ê³„ë¶„ì•¼", industry_options)
            interest_keywords = st.text_area("ğŸ”‘ ê´€ì‹¬ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", 
                                           placeholder="ì˜ˆ: íŠ¸ë Œë“œ, í˜ì‹ , ì§€ì†ê°€ëŠ¥ì„±, AI")
        
        if st.button("ğŸ’¾ ì‚¬ì „ì •ë³´ ì €ì¥", type="primary"):
            keywords_list = [k.strip() for k in interest_keywords.split(",") if k.strip()]
            
            analyzer.update_conference_info({
                "conference_name": conference_name_input,
                "conference_date": conference_date.isoformat(),
                "location": location,
                "industry_field": industry_field,
                "interest_keywords": keywords_list
            })
            
            st.success("[ì™„ë£Œ] ì‚¬ì „ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        # ì €ì¥ëœ ì •ë³´ í‘œì‹œ
        if analyzer.conference_info["conference_name"]:
            st.markdown("### ğŸ’¾ ì €ì¥ëœ ì •ë³´")
            st.info(f"""
            **ì»¨í¼ëŸ°ìŠ¤:** {analyzer.conference_info['conference_name']}  
            **ë‚ ì§œ:** {analyzer.conference_info['conference_date']}  
            **ì¥ì†Œ:** {analyzer.conference_info['location']}  
            **ì—…ê³„:** {analyzer.conference_info['industry_field']}  
            **í‚¤ì›Œë“œ:** {', '.join(analyzer.conference_info['interest_keywords'])}
            """)
    
    with tab1:
        st.markdown("## [í´ë”] íŒŒì¼ ì—…ë¡œë“œ ë° URL ë¶„ì„")
        
        # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        st.markdown("### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ ë° ë¡œì»¬ íŒŒì¼")
        st.markdown("**ì§€ì› í˜•ì‹:** ì´ë¯¸ì§€ (JPG, PNG), ìŒì„± (WAV, MP3, M4A), ë¹„ë””ì˜¤ (MP4, MOV), í…ìŠ¤íŠ¸ (TXT)")
        
        # í–¥ìƒëœ íŒŒì¼ ì—…ë¡œë“œ ì‹œìŠ¤í…œ ì‚¬ìš©
        if ENHANCED_FILE_HANDLER_AVAILABLE:
            uploaded_files = get_enhanced_file_upload()
        else:
            st.warning("í–¥ìƒëœ íŒŒì¼ í•¸ë“¤ëŸ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì—…ë¡œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            uploaded_files = st.file_uploader(
                "ë¶„ì„í•  íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
                accept_multiple_files=True,
                type=['jpg', 'jpeg', 'png', 'bmp', 'wav', 'mp3', 'm4a', 'flac', 'mp4', 'avi', 'mov', 'txt']
            )
            
            # ì´ˆëŒ€ìš©ëŸ‰ íŒŒì¼ í¬ê¸° ì•ˆë‚´
            if uploaded_files:
                total_size = sum(file.size for file in uploaded_files) / (1024*1024)  # MB
                if total_size > 3000:  # 3GB ì´ìƒ
                    st.success(f"[ì‹œì‘] ì´ˆëŒ€ìš©ëŸ‰ íŒŒì¼: {total_size:.1f}MB ({total_size/1024:.2f}GB) - GPU ê°€ì†ìœ¼ë¡œ ì•ˆì • ì²˜ë¦¬")
                elif total_size > 1000:  # 1GB ì´ìƒ
                    st.info(f"[í´ë”] ëŒ€ìš©ëŸ‰ íŒŒì¼: {total_size:.1f}MB ({total_size/1024:.2f}GB)")
                elif total_size > 100:  # 100MB ì´ìƒ
                    st.info(f"[í´ë”] ì—…ë¡œë“œëœ íŒŒì¼: {total_size:.1f}MB")
                
                # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´
                with st.expander("[í†µê³„] ì—…ë¡œë“œëœ íŒŒì¼ ìƒì„¸ ì •ë³´"):
                    for file in uploaded_files:
                        file_size_mb = file.size / (1024*1024)
                        file_type = "[ì´ë¯¸ì§€]" if file.type.startswith('image') else "[ìŒì•…]" if file.type.startswith('audio') else "[ë¹„ë””ì˜¤]" if file.type.startswith('video') else "[ë¬¸ì„œ]"
                        st.write(f"{file_type} **{file.name}** - {file_size_mb:.1f}MB ({file.type})")
            
            st.info(f"ì„ íƒëœ íŒŒì¼: {len(uploaded_files)}ê°œ")
            
        # Local file system section
        # ğŸ—‚ï¸ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ (3GB+ IMG_0032.MOV ë“±)
        st.markdown("**[íŒ] ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬**: 3GB+ íŒŒì¼ì€ user_files í´ë”ì— ë³µì‚¬ í›„ ì—¬ê¸°ì„œ ì„ íƒí•˜ì„¸ìš”")
        st.markdown("**ğŸ“ íŒŒì¼ ê²½ë¡œ**: `C:/Users/PC_58410/solomond-ai-system/user_files/`")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë¡œì»¬ íŒŒì¼ ìŠ¤ìº”
        local_files = []
        if analyzer.user_files_dir.exists():
            for folder in analyzer.user_files_dir.iterdir():
                if folder.is_dir():
                    for file_path in folder.rglob("*"):
                        if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.wav', '.mp3', '.m4a', '.flac', '.mp4', '.avi', '.mov', '.txt']:
                            file_size = file_path.stat().st_size
                            local_files.append({
                                'path': file_path,
                                'name': file_path.name,
                                'folder': folder.name,
                                'size_mb': file_size / (1024*1024),
                                'type': file_path.suffix.lower()
                            })
        
        if local_files:
            st.success(f"[í´ë”] {len(local_files)}ê°œ ë¡œì»¬ íŒŒì¼ ë°œê²¬")
            
            # í´ë”ë³„ ê·¸ë£¹í™”
            folders = {}
            for file_info in local_files:
                folder_name = file_info['folder']
                if folder_name not in folders:
                    folders[folder_name] = []
                folders[folder_name].append(file_info)
            
            # í´ë” ì„ íƒ
            selected_folder = st.selectbox(
                "ğŸ“‚ ë¶„ì„í•  í´ë” ì„ íƒ",
                list(folders.keys()),
                help="3GB+ IMG_0032.MOVê°€ í¬í•¨ëœ JGA2025_D1 í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            if selected_folder:
                    folder_files = folders[selected_folder]
                    
                    # ëŒ€ìš©ëŸ‰ íŒŒì¼ ìš°ì„  í‘œì‹œ
                    large_files = [f for f in folder_files if f['size_mb'] > 1000]  # 1GB+
                    if large_files:
                        st.info(f"[ì‹œì‘] ëŒ€ìš©ëŸ‰ íŒŒì¼ {len(large_files)}ê°œ ë°œê²¬ (MemoryError ë°©ì§€ ì™„ë²½ ì§€ì›)")
                        
                        for file_info in large_files:
                            file_type = "[ì´ë¯¸ì§€]" if file_info['type'] in ['.jpg', '.jpeg', '.png'] else "[ìŒì•…]" if file_info['type'] in ['.wav', '.mp3', '.m4a'] else "[ë¹„ë””ì˜¤]" if file_info['type'] in ['.mp4', '.mov', '.avi'] else "[ë¬¸ì„œ]"
                            st.markdown(f"â€¢ {file_type} **{file_info['name']}** - {file_info['size_mb']:.1f}MB ({file_info['size_mb']/1024:.2f}GB)")
                    
                    # ì „ì²´ ë¶„ì„ ë²„íŠ¼
                    if st.button(f"[ì‹œì‘] {selected_folder} í´ë” ì „ì²´ ë¶„ì„ ì‹œì‘", type="primary", key="local_files_analyze"):
                        # ë¡œì»¬ íŒŒì¼ì„ uploaded_files í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        uploaded_files = []
                        for file_info in folder_files:
                            # ì„ì‹œ íŒŒì¼ ê°ì²´ ìƒì„± (streamlit í˜¸í™˜)
                            class LocalFileWrapper:
                                def __init__(self, file_path, file_name, file_size):
                                    self.name = file_name
                                    self.size = file_size
                                    self._file_path = file_path
                                    self.type = self._get_mime_type(file_path.suffix.lower())
                                
                                def _get_mime_type(self, ext):
                                    mime_map = {
                                        '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png',
                                        '.wav': 'audio/wav', '.mp3': 'audio/mpeg', '.m4a': 'audio/mp4',
                                        '.mp4': 'video/mp4', '.mov': 'video/quicktime', '.avi': 'video/avi',
                                        '.txt': 'text/plain'
                                    }
                                    return mime_map.get(ext, 'application/octet-stream')
                                
                                def read(self):
                                    with open(self._file_path, 'rb') as f:
                                        return f.read()
                            
                            wrapped_file = LocalFileWrapper(file_info['path'], file_info['name'], int(file_info['size_mb'] * 1024 * 1024))
                            uploaded_files.append(wrapped_file)
                        
                        st.success(f"[ì™„ë£Œ] ë¡œì»¬ íŒŒì¼ {len(uploaded_files)}ê°œ ì¤€ë¹„ ì™„ë£Œ (3GB+ IMG_0032.MOV í¬í•¨)")
                        st.info("[í´ë”] ë¡œì»¬ íŒŒì¼ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë¶„ì„ ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!")
            else:
                st.warning("ğŸ“‚ user_files í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                st.markdown("**í•´ê²° ë°©ë²•**: 3GB+ IMG_0032.MOV íŒŒì¼ì„ ë‹¤ìŒ ê²½ë¡œì— ë³µì‚¬í•˜ì„¸ìš”:")
                st.code("C:/Users/PC_58410/solomond-ai-system/user_files/JGA2025_D1/IMG_0032.MOV")
        
        # ì„ íƒëœ íŒŒì¼ ìˆ˜ í‘œì‹œ (ë‘ íƒ­ í†µí•©)
        if uploaded_files:
            st.info(f"[ì™„ë£Œ] ì´ ì„ íƒëœ íŒŒì¼: {len(uploaded_files)}ê°œ")
        
        # ì›¹ ë™ì˜ìƒ URL ì„¹ì…˜
        st.markdown("### [ë¹„ë””ì˜¤] ì›¹ ë™ì˜ìƒ ë¶„ì„")
        if YOUTUBE_AVAILABLE:
            st.markdown("**ì§€ì› í”Œë«í¼:** YouTube, Vimeo, Dailymotion, Facebook, Instagram, TikTok, Twitch ë“± 1000+ ì‚¬ì´íŠ¸")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                video_url = st.text_input(
                    "ë™ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš”",
                    placeholder="https://www.youtube.com/watch?v=... ë˜ëŠ” ë‹¤ë¥¸ í”Œë«í¼ URL",
                    help="ìµœëŒ€ 30ë¶„ ê¸¸ì´ì˜ ë™ì˜ìƒë§Œ ì§€ì›ë©ë‹ˆë‹¤."
                )
            
            with col2:
                st.markdown("<br>", unsafe_allow_html=True)  # ê³µê°„ ì¡°ì •
                if video_url and st.button("[ë¹„ë””ì˜¤] ë™ì˜ìƒ ë¶„ì„", type="secondary"):
                    with st.spinner("ì›¹ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ ì¤‘..."):
                        video_result = analyzer.process_video_url(video_url)
                    
                    if "error" not in video_result:
                        st.success(f"[ì™„ë£Œ] ë™ì˜ìƒ ë¶„ì„ ì™„ë£Œ!")
                        
                        # ê²°ê³¼ í‘œì‹œ
                        with st.expander(f"[ë¹„ë””ì˜¤] {video_result.get('file_source', 'Web Video')}"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown(f"**í”Œë«í¼:** {video_result.get('platform', 'N/A')}")
                                st.markdown(f"**ì—…ë¡œë”:** {video_result.get('uploader', 'N/A')}")
                                st.markdown(f"**ì›ë³¸ URL:** [{video_result.get('original_url', 'N/A')[:50]}...]({video_result.get('original_url', '#')})")
                            
                            with col2:
                                st.markdown(f"**ì‹ ë¢°ë„:** {video_result['confidence']:.1%}")
                                if video_result.get('video_duration'):
                                    st.markdown(f"**ê¸¸ì´:** {video_result['video_duration']:.1f}ì´ˆ")
                                st.markdown(f"**í‚¤ì›Œë“œ:** {', '.join(video_result['keywords'][:5])}")
                            
                            st.markdown("**ì¶”ì¶œëœ ë‚´ìš©:**")
                            st.markdown(f"> {video_result['content'][:300]}{'...' if len(video_result['content']) > 300 else ''}")
                        
                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        if analyzer.database:
                            analyzer.database.insert_fragment(video_result)
                            analyzer.analysis_results["processed_files"].append(video_result)
                    else:
                        st.error(f"[ì‹¤íŒ¨] ë™ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {video_result['error']}")
        else:
            st.warning("[ì£¼ì˜] ì›¹ ë™ì˜ìƒ ë¶„ì„ ë¹„í™œì„± - yt-dlp ì„¤ì¹˜ í•„ìš”")
            st.code("pip install yt-dlp", language="bash")
        
        if uploaded_files:
            st.info(f"ì„ íƒëœ íŒŒì¼: {len(uploaded_files)}ê°œ")
            
            # ì²˜ë¦¬ ì˜µì…˜
            col1, col2 = st.columns([3, 1])
            with col1:
                process_mode = st.selectbox(
                    "ì²˜ë¦¬ ëª¨ë“œ",
                    ["[ì‹œì‘] ê³ ì† ëª¨ë“œ (ê¶Œì¥)", "[ë³´ì•ˆ] ì•ˆì „ ëª¨ë“œ (ëŒ€ìš©ëŸ‰)", "âš¡ í„°ë³´ ëª¨ë“œ (ì†Œìš©ëŸ‰)"],
                    help="ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì•ˆì „ ëª¨ë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
                )
            
            with col2:
                st.markdown("<br>", unsafe_allow_html=True)
                skip_errors = st.checkbox("ì˜¤ë¥˜ ê±´ë„ˆë›°ê¸°", value=True, help="íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê³„ì† ì§„í–‰")
            
            if st.button("[ì‹œì‘] íŒŒì¼ ì²˜ë¦¬ ì‹œì‘", type="primary"):
                # ì²˜ë¦¬ ëª¨ë“œì— ë”°ë¥¸ ì„¤ì •
                if "ì•ˆì „" in process_mode:
                    st.info("[ë³´ì•ˆ] ì•ˆì „ ëª¨ë“œ: ëŒ€ìš©ëŸ‰ íŒŒì¼ ìµœì í™” ì²˜ë¦¬")
                elif "í„°ë³´" in process_mode:
                    st.info("âš¡ í„°ë³´ ëª¨ë“œ: ê³ ì† ë³‘ë ¬ ì²˜ë¦¬")
                else:
                    st.info("[ì‹œì‘] ê³ ì† ëª¨ë“œ: ê· í˜•ì¡íŒ ì²˜ë¦¬")
                
                with st.spinner("ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬ ì¤‘... (ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤)"):
                    result = analyzer.process_uploaded_files(uploaded_files, skip_errors=skip_errors)
                
                if "error" not in result:
                    st.success(f"[ì™„ë£Œ] íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {result['successful_count']}/{result['processed_count']}ê°œ ì„±ê³µ")
                    
                    if result['failed_files']:
                        st.warning("ì¼ë¶€ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨:")
                        for failed in result['failed_files']:
                            st.error(f"- {failed['filename']}: {failed['error']}")
                    
                    # ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ
                    if result['analysis_fragments']:
                        st.markdown("### [í†µê³„] ì²˜ë¦¬ëœ ì¡°ê°ë“¤")
                        
                        for fragment in result['analysis_fragments']:
                            with st.expander(f"[ë¬¸ì„œ] {fragment['file_source']} ({fragment['file_type']})"):
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.markdown(f"**ì‹ ë¢°ë„:** {fragment['confidence']:.1%}")
                                    keywords = fragment.get('keywords', [])
                                    if keywords:
                                        st.markdown(f"**í‚¤ì›Œë“œ:** {', '.join(keywords[:5])}")
                                    else:
                                        st.markdown("**í‚¤ì›Œë“œ:** ì¶”ì¶œ ì¤‘...")
                                
                                with col2:
                                    if fragment.get('speaker'):
                                        st.markdown(f"**í™”ì:** {fragment['speaker']}")
                                    if fragment.get('duration'):
                                        st.markdown(f"**ê¸¸ì´:** {fragment['duration']:.1f}ì´ˆ")
                                
                                st.markdown("**ì¶”ì¶œëœ ë‚´ìš©:**")
                                st.markdown(f"> {fragment['content'][:200]}{'...' if len(fragment['content']) > 200 else ''}")
                else:
                    st.error(f"[ì‹¤íŒ¨] íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
    
    with tab2:
        st.markdown("## ğŸ§  í™€ë¦¬ìŠ¤í‹± ë¶„ì„")
        st.markdown("**ì˜ë¯¸ì  ì—°ê²°, ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§, ì „ì²´ ìŠ¤í† ë¦¬ ìƒì„±**")
        
        if st.button("[ê²€ìƒ‰] í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤í–‰", type="primary"):
            with st.spinner("í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ìˆ˜í–‰ ì¤‘..."):
                holistic_result = analyzer.run_holistic_analysis()
            
            if "error" not in holistic_result:
                st.success("[ì™„ë£Œ] í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì™„ë£Œ!")
                
                # ê²°ê³¼ í‘œì‹œ
                holistic = holistic_result["holistic_analysis"]
                semantic = holistic_result["semantic_connections"]
                ai_insights = holistic_result.get("ai_insights", [])
                
                # ë©”íŠ¸ë¦­
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ì´ ì¡°ê°", holistic.get("total_fragments", 0))
                
                with col2:
                    st.metric("ë°œê²¬ëœ ê°œì²´", holistic.get("total_entities", 0))
                
                with col3:
                    st.metric("ì£¼ìš” ì£¼ì œ", holistic.get("total_topics", 0))
                
                with col4:
                    if "error" not in semantic:
                        st.metric("ì˜ë¯¸ì  ì—°ê²°", semantic.get("semantic_connections", 0))
                    else:
                        st.metric("ì˜ë¯¸ì  ì—°ê²°", "ì˜¤ë¥˜")
                
                # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                st.markdown("### [íŒ] í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
                for insight in holistic.get("key_insights", []):
                    st.markdown(f"- {insight}")
                
                # AI ì‹¬í™” ë¶„ì„
                if ai_insights and not ai_insights[0].startswith("AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"):
                    st.markdown("### [AI] AI ì‹¬í™” ë¶„ì„")
                    for insight in ai_insights:
                        if not insight.startswith("AI"):  # ì—ëŸ¬ ë©”ì‹œì§€ ì œì™¸
                            st.info(f"[AI] {insight}")
                
                # ìƒì„¸ ê²°ê³¼
                with st.expander("[í†µê³„] ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
                    st.json(holistic_result)
                    
            else:
                st.error(f"[ì‹¤íŒ¨] í™€ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤íŒ¨: {holistic_result['error']}")
    
    with tab3:
        st.markdown("## ğŸ§ ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ")
        st.markdown("**AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° êµ¬ê¸€ ìº˜ë¦°ë” ì—°ë™**")
        
        if st.button("[ì‹œì‘] ë“€ì–¼ ë¸Œë ˆì¸ í™œì„±í™”", type="primary"):
            with st.spinner("ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘..."):
                dual_brain_result = analyzer.trigger_dual_brain_system()
            
            if "error" not in dual_brain_result:
                st.success("[ì™„ë£Œ] ë“€ì–¼ ë¸Œë ˆì¸ ë¶„ì„ ì™„ë£Œ!")
                
                # AI ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
                if dual_brain_result.get("ai_insights"):
                    st.markdown("### [AI] AI ì¸ì‚¬ì´íŠ¸")
                    for insight in dual_brain_result["ai_insights"]:
                        st.info(insight)
                
                # ìƒì„¸ ê²°ê³¼
                with st.expander("ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ìƒì„¸ ê²°ê³¼"):
                    st.json(dual_brain_result)
                    
            else:
                st.error(f"[ì‹¤íŒ¨] ë“€ì–¼ ë¸Œë ˆì¸ ì‹¤íŒ¨: {dual_brain_result['error']}")
    
    with tab4:
        st.markdown("## ğŸ“‹ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
        
        if st.button("[ë¬¸ì„œ] ë³´ê³ ì„œ ìƒì„±", type="primary"):
            report = analyzer.generate_comprehensive_report()
            
            st.markdown("### ğŸ“‹ ì™„ì „ í†µí•© ë¶„ì„ ë³´ê³ ì„œ")
            st.markdown(report)
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(
                label="ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                data=report,
                file_name=f"unified_analysis_{conference_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown"
            )
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    st.markdown("---")
    st.markdown("### [íŒ] ì‚¬ìš©ë²•")
    st.markdown("""
    1. **ì‚¬ì „ì •ë³´**: ì»¨í¼ëŸ°ìŠ¤ ë°°ê²½ ì •ë³´ ì…ë ¥ìœ¼ë¡œ ë¶„ì„ í’ˆì§ˆ í–¥ìƒ
    2. **íŒŒì¼/URL ì²˜ë¦¬**: 
       - ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
       - ì›¹ ë™ì˜ìƒ URL ì§ì ‘ ë¶„ì„ (1000+ í”Œë«í¼ ì§€ì›)
       - TXT íŒŒì¼ì— URL ëª©ë¡ ì…ë ¥ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
    3. **í™€ë¦¬ìŠ¤í‹± ë¶„ì„**: ì˜ë¯¸ì  ì—°ê²° + Ollama AI ì‹¬í™” ì¸ì‚¬ì´íŠ¸
    4. **ë“€ì–¼ ë¸Œë ˆì¸**: êµ¬ê¸€ ìº˜ë¦°ë” ì—°ë™ + AI íŒ¨í„´ ë¶„ì„
    5. **ì¢…í•© ë³´ê³ ì„œ**: ì™„ì „í•œ í†µí•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    
    **[ì‹œì‘] ì§€ì› í”Œë«í¼**: YouTube, Vimeo, TikTok, Instagram, Twitch, Facebook ë“±  
    **[ë¬¸ì„œ] TXT ë°°ì¹˜**: URL ëª©ë¡ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì—…ë¡œë“œí•˜ë©´ ìë™ ì¼ê´„ ì²˜ë¦¬**
    """)

if __name__ == "__main__":
    main()