#!/usr/bin/env python3
"""
GEMMA3 ìµœì¢… ì„¤ì¹˜ ì‹œë„
"""

import subprocess
import os
import time

def find_ollama():
    """Ollama ì‹¤í–‰íŒŒì¼ ì°¾ê¸°"""
    
    username = os.getenv("USERNAME", "PC_58410")
    paths = [
        rf"C:\Users\{username}\AppData\Local\Programs\Ollama\ollama.exe",
        r"C:\Program Files\Ollama\ollama.exe",
        r"C:\Program Files (x86)\Ollama\ollama.exe"
    ]
    
    for path in paths:
        if os.path.exists(path):
            print(f"Found Ollama: {path}")
            return path
    
    print("Using default ollama command")
    return "ollama"

def install_latest_models():
    """ìµœì‹  ëª¨ë¸ë“¤ ì„¤ì¹˜ ì‹œë„ (GEMMA3 + Llama 3.2)"""
    
    print("=== 2025ë…„ ìµœì‹  ëª¨ë¸ ì„¤ì¹˜ ì‹œë„ ===")
    
    ollama_path = find_ollama()
    
    # 2025ë…„ ìµœì‹  ëª¨ë¸ë“¤
    latest_models = [
        # GEMMA3 ì‹œë¦¬ì¦ˆ (Google 3ì„¸ëŒ€)
        ("gemma3:9b", "GEMMA3 9B - Google 3ì„¸ëŒ€ ìµœì‹ "),
        ("gemma3:7b", "GEMMA3 7B - Google 3ì„¸ëŒ€"),
        ("gemma3:2b", "GEMMA3 2B - Google 3ì„¸ëŒ€ ê²½ëŸ‰"),
        
        # Llama 3.2 ì‹œë¦¬ì¦ˆ (Meta ìµœì‹ )
        ("llama3.2:8b", "Llama 3.2 8B - Meta ìµœì‹  ëª¨ë¸"),
        ("llama3.2:3b", "Llama 3.2 3B - Meta ê²½ëŸ‰ ëª¨ë¸"),
        ("llama3.2:1b", "Llama 3.2 1B - Meta ì´ˆê²½ëŸ‰ ëª¨ë¸")
    ]
    
    installed = []
    
    for model_id, description in latest_models:
        print(f"\n{description} ì„¤ì¹˜ ì¤‘...")
        print(f"ëª¨ë¸: {model_id}")
        
        try:
            print("ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            result = subprocess.run([ollama_path, "pull", model_id],
                                  capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                print(f"ì„±ê³µ: {model_id} ì„¤ì¹˜ ì™„ë£Œ!")
                installed.append(model_id)
                break  # í•˜ë‚˜ë§Œ ì„±ê³µí•´ë„ ì¶©ë¶„
            else:
                print(f"ì‹¤íŒ¨: {model_id}")
                print(f"ì˜¤ë¥˜: {result.stderr}")
                
                # ëª¨ë¸ì´ ì•„ì§ ì¡´ì¬í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„± í™•ì¸
                if "not found" in result.stderr.lower() or "pull access denied" in result.stderr.lower():
                    if "gemma3" in model_id:
                        print(f"  -> GEMMA3ê°€ ì•„ì§ ê³µì‹ ì¶œì‹œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                    elif "llama3.2" in model_id:
                        print(f"  -> Llama 3.2ê°€ Ollamaì— ì•„ì§ ë“±ë¡ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                
        except subprocess.TimeoutExpired:
            print(f"ì‹œê°„ ì´ˆê³¼: {model_id}")
        except Exception as e:
            print(f"ì„¤ì¹˜ ì˜¤ë¥˜: {str(e)}")
    
    return installed

def check_current_status():
    """í˜„ì¬ ì„¤ì¹˜ëœ ëª¨ë¸ ìƒíƒœ í™•ì¸"""
    
    print("\n=== í˜„ì¬ ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸ ===")
    
    try:
        import requests
        r = requests.get('http://localhost:11434/api/tags')
        if r.status_code == 200:
            models = r.json()['models']
            
            print("ì„¤ì¹˜ëœ ìµœì‹  ëª¨ë¸ë“¤:")
            has_gen3 = False
            
            for model in models:
                name = model['name']
                size_gb = model['size'] / (1024**3)
                
                if 'qwen3' in name or 'gemma3' in name:
                    has_gen3 = True
                    print(f"  ğŸ¥‡ {name} ({size_gb:.1f}GB) - 3ì„¸ëŒ€ ìµœì‹ !")
                elif 'gemma2' in name or 'qwen2.5' in name:
                    print(f"  ğŸ¥ˆ {name} ({size_gb:.1f}GB) - 2ì„¸ëŒ€ ìµœì‹ ")
                else:
                    print(f"  ğŸ“¦ {name} ({size_gb:.1f}GB)")
            
            if has_gen3:
                print(f"\nâœ… 3ì„¸ëŒ€ ìµœì‹  ëª¨ë¸ ë³´ìœ  ì¤‘!")
            else:
                print(f"\nâš ï¸ ì•„ì§ 3ì„¸ëŒ€ ëª¨ë¸ ì—†ìŒ (2ì„¸ëŒ€ê°€ í˜„ì¬ ìµœì‹ )")
            
            return True
    except Exception as e:
        print(f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("ğŸš€ GEMMA3 ìµœì¢… ì„¤ì¹˜ ì‹œë„")
    print("=" * 40)
    
    # 1. í˜„ì¬ ìƒíƒœ í™•ì¸
    check_current_status()
    
    # 2. ìµœì‹  ëª¨ë¸ë“¤ ì„¤ì¹˜ ì‹œë„ (GEMMA3 + Llama 3.2)
    installed = install_latest_models()
    
    if installed:
        print(f"\nğŸ‰ ìµœì‹  ëª¨ë¸ ì„¤ì¹˜ ì„±ê³µ!")
        for model in installed:
            if "gemma3" in model:
                print(f"  âœ“ {model} (Google 3ì„¸ëŒ€)")
            elif "llama3.2" in model:
                print(f"  âœ“ {model} (Meta ìµœì‹ )")
            else:
                print(f"  âœ“ {model}")
        
        print(f"\në‹¤ìŒ ë‹¨ê³„:")
        print(f"1. ìƒˆ ëª¨ë¸ë“¤ì„ ì†”ë¡œëª¬ë“œ AIì— í†µí•©")
        print(f"2. Qwen3 vs GEMMA3 vs Llama3.2 ì„±ëŠ¥ ë¹„êµ")
        print(f"3. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ ì •")
        
    else:
        print(f"\nâŒ ì¶”ê°€ ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨")
        print(f"ê°€ëŠ¥í•œ ì›ì¸:")
        print(f"1. GEMMA3ê°€ ì•„ì§ ì •ì‹ ì¶œì‹œë˜ì§€ ì•ŠìŒ")
        print(f"2. Llama 3.2ê°€ Ollamaì— ì•„ì§ ë“±ë¡ë˜ì§€ ì•ŠìŒ")
        print(f"3. ì•¡ì„¸ìŠ¤ ê¶Œí•œ ë¬¸ì œ")
        
        print(f"\nâœ… í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  ëª¨ë¸:")
        print(f"  - Qwen3:8b (3ì„¸ëŒ€, í•œêµ­ì–´ ìµœê°•)")
        print(f"  - Gemma2:9b (2ì„¸ëŒ€, Google ìµœì‹ )")
        print(f"  - Gemma2:2b (2ì„¸ëŒ€, Google ê²½ëŸ‰)")
        
        print(f"\nğŸ¯ ê¶Œì¥ì‚¬í•­:")
        print(f"Qwen3:8bê°€ í˜„ì¬ ê°€ì¥ ìµœì‹ ì´ê³  ê°•ë ¥í•œ ëª¨ë¸ì…ë‹ˆë‹¤!")
    
    # 3. ìµœì¢… ìƒíƒœ ì¬í™•ì¸
    print(f"\n=== ìµœì¢… ì„¤ì¹˜ ìƒíƒœ ===")
    check_current_status()

if __name__ == "__main__":
    main()