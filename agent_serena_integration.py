#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  SOLOMOND AI Serena ì½”ë”© ì—ì´ì „íŠ¸ - Claude Code ì„œë¸Œì—ì´ì „íŠ¸ í†µí•©
Serena Coding Agent as Claude Code Sub-Agent

ì´ ëª¨ë“ˆì€ Serenaì˜ ì½”ë”© ì—ì´ì „íŠ¸ ê¸°ëŠ¥ì„ Claude Codeì˜ ì„œë¸Œì—ì´ì „íŠ¸ë¡œ í†µí•©í•©ë‹ˆë‹¤.
/agent serena ëª…ë ¹ì–´ë¡œ í˜¸ì¶œ ê°€ëŠ¥í•œ ì‹¤ì œ Claude Code ì„œë¸Œì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
1. Symbol-level ì½”ë“œ ë¶„ì„ ë° í¸ì§‘
2. SOLOMOND AI íŠ¹í™” ì´ìŠˆ ìë™ íƒì§€  
3. ì„±ëŠ¥ ìµœì í™” ì œì•ˆ ë° ìë™ ìˆ˜ì •
4. ì •ë°€í•œ ì½”ë“œ í’ˆì§ˆ ë¶„ì„
5. í”„ë¡œì íŠ¸ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§

Author: SOLOMOND AI Team
Version: 1.0.0
Created: 2025-08-17
"""

import ast
import re
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
from collections import defaultdict, Counter

# Serena ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜ ì •ì˜
SERENA_PERSONA = {
    "name": "Serena",
    "role": "SOLOMOND AI ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸",
    "expertise": [
        "Python ì½”ë“œ ë¶„ì„ ë° ìµœì í™”",
        "SOLOMOND AI ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
        "ThreadPool ë° ë©”ëª¨ë¦¬ ê´€ë¦¬",
        "Streamlit ì„±ëŠ¥ ìµœì í™”",
        "ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ë¶„ì„",
        "Ollama AI í†µí•© ìµœì í™”"
    ],
    "personality": {
        "communication_style": "ì •ë°€í•˜ê³  ì²´ê³„ì ",
        "tone": "ê¸°ìˆ ì ì´ì§€ë§Œ ì¹œê·¼í•œ",
        "approach": "ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ì—¬ í•´ê²°"
    },
    "specialization": "SOLOMOND AI ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ ê·¹ëŒ€í™”"
}

# SOLOMOND AI íŠ¹í™” íŒ¨í„´
SOLOMOND_PATTERNS = {
    'threadpool_critical': {
        'pattern': r'ThreadPoolExecutor.*(?:submit|map).*(?!with\s)',
        'severity': 'critical',
        'description': 'ThreadPoolExecutor without context manager',
        'fix': 'Use with statement for proper resource management'
    },
    'memory_leak_risk': {
        'pattern': r'(?:torch\.cuda|np\.array|PIL\.Image).*(?:not.*del|no.*cleanup)',
        'severity': 'high',
        'description': 'Potential memory leak in GPU/large array operations',
        'fix': 'Add explicit cleanup and memory management'
    },
    'streamlit_performance': {
        'pattern': r'st\.(?!cache_data|cache_resource).*(?:heavy|large|slow)',
        'severity': 'medium',
        'description': 'Heavy operation without Streamlit caching',
        'fix': 'Use st.cache_data or st.cache_resource for optimization'
    },
    'ollama_error_handling': {
        'pattern': r'ollama.*(?:generate|chat|pull).*(?!try|except)',
        'severity': 'medium',
        'description': 'Ollama API call without error handling',
        'fix': 'Add try-except block for robust error handling'
    },
    'gpu_memory_management': {
        'pattern': r'(?:cuda|gpu).*(?:memory|allocation).*(?!empty_cache)',
        'severity': 'high',
        'description': 'GPU memory operations without cleanup',
        'fix': 'Add torch.cuda.empty_cache() calls'
    },
    'inefficient_file_io': {
        'pattern': r'open\(.*\)(?!.*with)',
        'severity': 'medium',
        'description': 'File I/O without context manager',
        'fix': 'Use with statement for safe file operations'
    }
}

@dataclass
class CodeIssue:
    """ì½”ë“œ ì´ìŠˆ ì •ë³´"""
    file_path: str
    line_number: int
    issue_type: str
    severity: str
    description: str
    code_snippet: str
    suggested_fix: str
    confidence: float

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    timestamp: str
    files_analyzed: int
    total_issues: int
    critical_issues: int
    high_issues: int
    medium_issues: int
    issues: List[CodeIssue]
    recommendations: List[str]
    health_score: float

class SerenaCodeAnalyzer:
    """Serena ì½”ë“œ ë¶„ì„ê¸° - Claude Code ìµœì í™” ë²„ì „"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.logger = self._setup_logger()
        
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("SerenaAgent")
        if not logger.handlers:
            logger.setLevel(logging.INFO)
            handler = logging.FileHandler(self.project_root / "serena_agent.log")
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def analyze_file(self, file_path: str) -> List[CodeIssue]:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        issues = []
        file_path = Path(file_path)
        
        if not file_path.exists() or file_path.suffix != '.py':
            return issues
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
                
            # SOLOMOND AI íŠ¹í™” íŒ¨í„´ ë¶„ì„
            for pattern_name, pattern_info in SOLOMOND_PATTERNS.items():
                matches = re.finditer(pattern_info['pattern'], content, re.MULTILINE | re.IGNORECASE)
                
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    code_snippet = lines[line_num-1].strip() if line_num <= len(lines) else ''
                    
                    issue = CodeIssue(
                        file_path=str(file_path),
                        line_number=line_num,
                        issue_type=pattern_name,
                        severity=pattern_info['severity'],
                        description=pattern_info['description'],
                        code_snippet=code_snippet,
                        suggested_fix=pattern_info['fix'],
                        confidence=0.85  # íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ ì‹ ë¢°ë„
                    )
                    issues.append(issue)
                    
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
            
        return issues

    def analyze_project(self, target_files: List[str] = None) -> AnalysisResult:
        """í”„ë¡œì íŠ¸ ì „ì²´ ë¶„ì„"""
        start_time = datetime.now()
        all_issues = []
        files_analyzed = 0
        
        # ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ê²°ì •
        if target_files:
            files_to_analyze = [Path(f) for f in target_files if Path(f).exists()]
        else:
            # ì£¼ìš” SOLOMOND AI íŒŒì¼ë“¤ ìš°ì„  ë¶„ì„
            priority_files = [
                "conference_analysis_COMPLETE_WORKING.py",
                "solomond_ai_main_dashboard.py",
                "dual_brain_integration.py",
                "ai_insights_engine.py",
                "google_calendar_connector.py"
            ]
            
            files_to_analyze = []
            for file_name in priority_files:
                file_path = self.project_root / file_name
                if file_path.exists():
                    files_to_analyze.append(file_path)
            
            # core ë””ë ‰í† ë¦¬ ì¶”ê°€ ë¶„ì„
            core_dir = self.project_root / "core"
            if core_dir.exists():
                core_files = list(core_dir.glob("*.py"))[:10]  # ìµœëŒ€ 10ê°œ íŒŒì¼
                files_to_analyze.extend(core_files)
        
        # íŒŒì¼ë³„ ë¶„ì„ ì‹¤í–‰
        for file_path in files_to_analyze:
            if any(skip in str(file_path) for skip in ['venv', '__pycache__', '.git', 'backup']):
                continue
                
            files_analyzed += 1
            file_issues = self.analyze_file(str(file_path))
            all_issues.extend(file_issues)
        
        # ì‹¬ê°ë„ë³„ ì´ìŠˆ ì¹´ìš´íŠ¸
        severity_counts = Counter(issue.severity for issue in all_issues)
        
        # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )
        health_score = self._calculate_health_score(severity_counts, files_analyzed)
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        recommendations = self._generate_recommendations(severity_counts, all_issues)
        
        return AnalysisResult(
            timestamp=start_time.isoformat(),
            files_analyzed=files_analyzed,
            total_issues=len(all_issues),
            critical_issues=severity_counts.get('critical', 0),
            high_issues=severity_counts.get('high', 0),
            medium_issues=severity_counts.get('medium', 0),
            issues=all_issues,
            recommendations=recommendations,
            health_score=health_score
        )

    def _calculate_health_score(self, severity_counts: Counter, files_analyzed: int) -> float:
        """ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°"""
        if files_analyzed == 0:
            return 0.0
            
        # ì‹¬ê°ë„ë³„ ê°€ì¤‘ì¹˜
        critical_penalty = severity_counts.get('critical', 0) * 15
        high_penalty = severity_counts.get('high', 0) * 8
        medium_penalty = severity_counts.get('medium', 0) * 3
        
        total_penalty = critical_penalty + high_penalty + medium_penalty
        base_score = 100.0
        
        # íŒŒì¼ë‹¹ í‰ê·  í˜ë„í‹° ê³„ì‚°
        avg_penalty = total_penalty / files_analyzed if files_analyzed > 0 else 0
        
        return max(base_score - avg_penalty, 0.0)

    def _generate_recommendations(self, severity_counts: Counter, issues: List[CodeIssue]) -> List[str]:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if severity_counts.get('critical', 0) > 0:
            recommendations.append("ğŸš¨ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ì¦‰ì‹œ ìˆ˜ì • í•„ìš” - ThreadPool ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬")
            
        if severity_counts.get('high', 0) > 0:
            recommendations.append("âš ï¸ ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆ í•´ê²° - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë° GPU ê´€ë¦¬")
            
        # íŒ¨í„´ë³„ ì¶”ì²œ
        issue_patterns = Counter(issue.issue_type for issue in issues)
        
        if issue_patterns.get('threadpool_critical', 0) > 0:
            recommendations.append("ğŸ”§ ThreadPoolExecutorë¥¼ with ë¬¸ìœ¼ë¡œ ê°ì‹¸ì„œ ë¦¬ì†ŒìŠ¤ ì•ˆì „ ê´€ë¦¬")
            
        if issue_patterns.get('streamlit_performance', 0) > 0:
            recommendations.append("âš¡ Streamlit ìºì‹± ì‹œìŠ¤í…œ ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”")
            
        if issue_patterns.get('memory_leak_risk', 0) > 0:
            recommendations.append("ğŸ§¹ ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í˜¸ì¶œ")
            
        return recommendations

    def generate_fix_script(self, issues: List[CodeIssue]) -> str:
        """ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        critical_issues = [issue for issue in issues if issue.severity == 'critical']
        
        if not critical_issues:
            return "# ìˆ˜ì •ì´ í•„ìš”í•œ í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤."
            
        script_lines = [
            "#!/usr/bin/env python3",
            "# Serena ìë™ ìƒì„± ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸",
            "# SOLOMOND AI ì‹œìŠ¤í…œ ìµœì í™”",
            "",
            "import re",
            "from pathlib import Path",
            "",
            "def apply_fixes():",
            "    \"\"\"í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ìë™ ìˆ˜ì •\"\"\"",
            "    fixes_applied = 0",
            ""
        ]
        
        # ThreadPool ì´ìŠˆ ìˆ˜ì • ë¡œì§
        threadpool_issues = [i for i in critical_issues if i.issue_type == 'threadpool_critical']
        if threadpool_issues:
            script_lines.extend([
                "    # ThreadPool ì´ìŠˆ ìˆ˜ì •",
                "    threadpool_files = [",
            ])
            
            for issue in threadpool_issues:
                script_lines.append(f"        '{issue.file_path}',")
                
            script_lines.extend([
                "    ]",
                "",
                "    for file_path in threadpool_files:",
                "        if Path(file_path).exists():",
                "            with open(file_path, 'r') as f:",
                "                content = f.read()",
                "            ",
                "            # with ë¬¸ìœ¼ë¡œ ê°ì‹¸ê¸°",
                "            pattern = r'(\\s*)(executor\\s*=\\s*ThreadPoolExecutor\\([^)]*\\))\\s*\\n'",
                "            replacement = r'\\1with ThreadPoolExecutor() as executor:\\n\\1    # ìˆ˜ì •ë¨: with ë¬¸ ì‚¬ìš©\\n'",
                "            ",
                "            new_content = re.sub(pattern, replacement, content)",
                "            if new_content != content:",
                "                with open(file_path, 'w') as f:",
                "                    f.write(new_content)",
                "                fixes_applied += 1",
                "                print(f'ìˆ˜ì • ì™„ë£Œ: {file_path}')",
                ""
            ])
        
        script_lines.extend([
            "    return fixes_applied",
            "",
            "if __name__ == '__main__':",
            "    fixes = apply_fixes()",
            "    print(f'ì´ {fixes}ê°œ íŒŒì¼ ìˆ˜ì • ì™„ë£Œ')"
        ])
        
        return "\n".join(script_lines)

def main():
    """Serena ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    print("ğŸ§  SOLOMOND AI Serena ì½”ë”© ì—ì´ì „íŠ¸")
    print("=" * 50)
    
    analyzer = SerenaCodeAnalyzer()
    
    print("ğŸ“Š í”„ë¡œì íŠ¸ ë¶„ì„ ì¤‘...")
    result = analyzer.analyze_project()
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ - {result.files_analyzed}ê°œ íŒŒì¼")
    print(f"ğŸ“ˆ ì „ì²´ ê±´ê°•ë„: {result.health_score:.1f}/100")
    print(f"ğŸ” ë°œê²¬ëœ ì´ìŠˆ: {result.total_issues}ê°œ")
    
    if result.critical_issues > 0:
        print(f"ğŸš¨ í¬ë¦¬í‹°ì»¬: {result.critical_issues}ê°œ")
    if result.high_issues > 0:
        print(f"âš ï¸  ë†’ìŒ: {result.high_issues}ê°œ")
    if result.medium_issues > 0:
        print(f"ğŸ“ ë³´í†µ: {result.medium_issues}ê°œ")
    
    # ìƒìœ„ ì´ìŠˆë“¤ í‘œì‹œ
    if result.issues:
        print(f"\nğŸ¯ ì£¼ìš” ì´ìŠˆ:")
        critical_issues = [i for i in result.issues if i.severity == 'critical'][:3]
        for issue in critical_issues:
            print(f"  - {Path(issue.file_path).name}:{issue.line_number} - {issue.description}")
    
    # ì¶”ì²œì‚¬í•­ í‘œì‹œ
    if result.recommendations:
        print(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
        for rec in result.recommendations:
            print(f"  {rec}")
    
    # ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ìˆëŠ” ê²½ìš°)
    if result.critical_issues > 0:
        print(f"\nğŸ”§ ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        fix_script = analyzer.generate_fix_script(result.issues)
        
        script_path = Path("serena_auto_fix.py")
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(fix_script)
        
        print(f"âœ… ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")
        print(f"ğŸ’¡ ì‹¤í–‰ ë°©ë²•: python {script_path}")

if __name__ == "__main__":
    main()