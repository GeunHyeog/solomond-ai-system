#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ SOLOMOND AI í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ - ì»´í“¨íŒ… ìµœì í™” ë²„ì „
Integrated Analysis System with Compute Optimization

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. í•˜ì´ë¸Œë¦¬ë“œ CPU/GPU ìë™ ì„ íƒ
2. ì‹¤ì‹œê°„ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ 
3. ì‘ì—…ë³„ ìµœì í™” ì„¤ì •
4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
"""

import streamlit as st
import os
import time
from typing import Dict, List, Any, Optional
from pathlib import Path
import json

# í•˜ì´ë¸Œë¦¬ë“œ ì»´í“¨íŒ… ë§¤ë‹ˆì € ì„í¬íŠ¸
try:
    from hybrid_compute_manager import (
        HybridComputeManager, ComputeMode, TaskType,
        auto_optimize_for_whisper, auto_optimize_for_ocr, auto_optimize_for_llm
    )
    COMPUTE_OPTIMIZATION_AVAILABLE = True
except ImportError:
    COMPUTE_OPTIMIZATION_AVAILABLE = False

# ê¸°ì¡´ ë¶„ì„ ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from conference_analysis_COMPLETE_WORKING import CompleteWorkingAnalyzer
    MAIN_ANALYZER_AVAILABLE = True
except ImportError:
    MAIN_ANALYZER_AVAILABLE = False

class OptimizedAnalysisSystem:
    """ìµœì í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.compute_manager = HybridComputeManager() if COMPUTE_OPTIMIZATION_AVAILABLE else None
        self.main_analyzer = CompleteWorkingAnalyzer() if MAIN_ANALYZER_AVAILABLE else None
        
        # ë¦¬ì†ŒìŠ¤ ì„¤ì • ë¡œë“œ
        self.load_resource_config()
    
    def load_resource_config(self):
        """ë¦¬ì†ŒìŠ¤ ì„¤ì • ë¡œë“œ"""
        config_file = Path("resource_config.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    self.resource_config = json.load(f)
            except:
                self.resource_config = {"compute_mode": "auto"}
        else:
            self.resource_config = {"compute_mode": "auto"}
    
    def optimize_for_analysis(self, file_info: Dict) -> Dict[str, Any]:
        """ë¶„ì„ ì‘ì—…ì— ìµœì í™”ëœ ì„¤ì • ë°˜í™˜"""
        if not self.compute_manager:
            return {"device": "cpu", "optimized": False}
        
        # íŒŒì¼ ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—… ìœ í˜• ê²°ì •
        file_types = file_info.get('file_types', [])
        file_count = file_info.get('file_count', 1)
        total_size_mb = file_info.get('total_size_mb', 0)
        
        optimization_settings = {}
        
        # ìŒì„± íŒŒì¼ ìµœì í™”
        if any('audio' in ft for ft in file_types):
            # ì˜ˆìƒ ìŒì„± ê¸¸ì´ (í¬ê¸° ê¸°ë°˜ ì¶”ì •)
            estimated_duration = total_size_mb * 10  # ëŒ€ëµì  ì¶”ì •
            whisper_config = auto_optimize_for_whisper(estimated_duration)
            optimization_settings['whisper'] = whisper_config
        
        # ì´ë¯¸ì§€ íŒŒì¼ ìµœì í™”
        if any('image' in ft for ft in file_types):
            image_count = len([ft for ft in file_types if 'image' in ft])
            ocr_config = auto_optimize_for_ocr(image_count, realtime=False)
            optimization_settings['ocr'] = ocr_config
        
        # LLM ìµœì í™” (ì¢…í•© ë¶„ì„ìš©)
        llm_config = auto_optimize_for_llm(context_length=2048)
        optimization_settings['llm'] = llm_config
        
        # ì „ë°˜ì ì¸ ë””ë°”ì´ìŠ¤ ì„ íƒ
        if any(config.get('device') == 'gpu' for config in optimization_settings.values()):
            optimization_settings['primary_device'] = 'gpu'
        else:
            optimization_settings['primary_device'] = 'cpu'
        
        optimization_settings['optimized'] = True
        
        return optimization_settings
    
    def render_resource_status_widget(self):
        """ë¦¬ì†ŒìŠ¤ ìƒíƒœ ìœ„ì ¯ ë Œë”ë§"""
        if not self.compute_manager:
            return
        
        st.sidebar.markdown("### âš™ï¸ ë¦¬ì†ŒìŠ¤ ìƒíƒœ")
        
        # í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        status = self.compute_manager.get_resource_status()
        
        # CPU ìƒíƒœ
        cpu_status = status.get('cpu', {})
        cpu_usage = cpu_status.get('usage_percent', 0)
        
        st.sidebar.metric(
            "CPU ì‚¬ìš©ë¥ ",
            f"{cpu_usage:.1f}%",
            delta=None
        )
        
        memory_gb = cpu_status.get('available_memory_gb', 0)
        st.sidebar.metric(
            "ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬",
            f"{memory_gb:.1f}GB"
        )
        
        # GPU ìƒíƒœ (ìˆëŠ” ê²½ìš°)
        if 'gpu' in status:
            gpu_status = status['gpu']
            gpu_memory = gpu_status.get('available_memory_gb', 0)
            gpu_usage = gpu_status.get('usage_percent', 0)
            
            st.sidebar.metric(
                "GPU ë©”ëª¨ë¦¬",
                f"{gpu_memory:.1f}GB",
                delta=f"-{gpu_usage:.1f}% ì‚¬ìš© ì¤‘"
            )
        else:
            st.sidebar.info("GPU ë¯¸ì‚¬ìš©")
        
        # ì»´í“¨íŒ… ëª¨ë“œ í‘œì‹œ
        current_mode = self.resource_config.get('compute_mode', 'auto')
        mode_display = {
            'auto': 'ğŸ¤– ìë™',
            'gpu_preferred': 'ğŸš€ GPU ìš°ì„ ',
            'cpu_preferred': 'ğŸ–¥ï¸ CPU ìš°ì„ ',
            'gpu_only': 'ğŸ’ª GPU ì „ìš©',
            'cpu_only': 'âš¡ CPU ì „ìš©'
        }
        
        st.sidebar.info(f"**ëª¨ë“œ**: {mode_display.get(current_mode, current_mode)}")
        
        # ë¦¬ì†ŒìŠ¤ ì„¤ì • ë§í¬
        if st.sidebar.button("âš™ï¸ ë¦¬ì†ŒìŠ¤ ì„¤ì •"):
            st.sidebar.markdown("ë³„ë„ ì°½ì—ì„œ `streamlit run resource_configurator.py`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
    
    def show_optimization_info(self, optimization_settings: Dict):
        """ìµœì í™” ì •ë³´ í‘œì‹œ"""
        if not optimization_settings.get('optimized', False):
            return
        
        st.info("ğŸš€ **ë¦¬ì†ŒìŠ¤ ìµœì í™” ì ìš©ë¨**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            primary_device = optimization_settings.get('primary_device', 'cpu')
            device_icon = "ğŸš€" if primary_device == 'gpu' else "ğŸ–¥ï¸"
            st.metric("ì£¼ ë””ë°”ì´ìŠ¤", f"{device_icon} {primary_device.upper()}")
        
        with col2:
            optimized_tasks = len([k for k, v in optimization_settings.items() 
                                 if isinstance(v, dict) and 'device' in v])
            st.metric("ìµœì í™” ì‘ì—…", f"{optimized_tasks}ê°œ")
        
        with col3:
            st.metric("ë©”ëª¨ë¦¬ ê´€ë¦¬", "ìë™ ì •ë¦¬")
        
        # ìƒì„¸ ìµœì í™” ì •ë³´ (í¼ì¹˜ê¸°)
        with st.expander("ğŸ” ìƒì„¸ ìµœì í™” ì„¤ì •"):
            for task_name, config in optimization_settings.items():
                if isinstance(config, dict) and 'device' in config:
                    st.write(f"**{task_name}**: {config['device']} ë””ë°”ì´ìŠ¤")
                    
                    # ì¶”ê°€ ì„¤ì • ì •ë³´
                    additional_info = []
                    if 'batch_size' in config:
                        additional_info.append(f"ë°°ì¹˜í¬ê¸°: {config['batch_size']}")
                    if 'fp16' in config and config['fp16']:
                        additional_info.append("FP16 ê°€ì†")
                    if 'parallel' in config and config['parallel']:
                        additional_info.append("ë³‘ë ¬ ì²˜ë¦¬")
                    
                    if additional_info:
                        st.caption(f"  â”” {', '.join(additional_info)}")
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.compute_manager:
            self.compute_manager.cleanup_memory("both")
            st.success("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

def render_optimized_analysis_interface():
    """ìµœì í™”ëœ ë¶„ì„ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
    st.set_page_config(
        page_title="SOLOMOND AI ìµœì í™” ë¶„ì„",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    st.title("ğŸš€ SOLOMOND AI ìµœì í™” ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("**CPU/GPU ë¦¬ì†ŒìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ ìµœê³  ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤**")
    
    # ìµœì í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = OptimizedAnalysisSystem()
    
    # ì‚¬ì´ë“œë°”ì— ë¦¬ì†ŒìŠ¤ ìƒíƒœ í‘œì‹œ
    system.render_resource_status_widget()
    
    # ì»´í“¨íŒ… ìµœì í™” ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if not COMPUTE_OPTIMIZATION_AVAILABLE:
        st.warning("âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ì»´í“¨íŒ… ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `hybrid_compute_manager.py`ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.info("ğŸ’¡ ê¸°ë³¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    if not MAIN_ANALYZER_AVAILABLE:
        st.error("âŒ ë©”ì¸ ë¶„ì„ ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `conference_analysis_COMPLETE_WORKING.py`ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_files = st.file_uploader(
        "ë¶„ì„í•  íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['mp3', 'm4a', 'wav', 'mp4', 'mov', 'jpg', 'jpeg', 'png', 'pdf', 'docx'],
        accept_multiple_files=True,
        help="ìŒì„±, ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ë¬¸ì„œ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
    )
    
    if uploaded_files:
        # íŒŒì¼ ì •ë³´ ë¶„ì„
        file_info = {
            'file_count': len(uploaded_files),
            'file_types': [f.type if hasattr(f, 'type') else 'unknown' for f in uploaded_files],
            'total_size_mb': sum(f.size for f in uploaded_files if hasattr(f, 'size')) / (1024*1024)
        }
        
        # ìµœì í™” ì„¤ì • ê³„ì‚°
        optimization_settings = system.optimize_for_analysis(file_info)
        
        # ìµœì í™” ì •ë³´ í‘œì‹œ
        system.show_optimization_info(optimization_settings)
        
        # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸ¯ ìµœì í™”ëœ ë¶„ì„ ì‹œì‘", type="primary"):
            
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if COMPUTE_OPTIMIZATION_AVAILABLE:
                system.compute_manager.cleanup_memory("both")
            
            with st.spinner("ğŸš€ ìµœì í™”ëœ ë¶„ì„ ì‹¤í–‰ ì¤‘..."):
                try:
                    # ì—¬ê¸°ì„œ ì‹¤ì œ ë¶„ì„ ë¡œì§ ì‹¤í–‰
                    # system.main_analyzerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰
                    
                    # ì§„í–‰ë¥  í‘œì‹œ
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_file in enumerate(uploaded_files):
                        progress = (i + 1) / len(uploaded_files)
                        progress_bar.progress(progress)
                        status_text.text(f"ë¶„ì„ ì¤‘: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                        
                        # ì‹¤ì œ ë¶„ì„ ë¡œì§ì€ ì—¬ê¸°ì— êµ¬í˜„
                        time.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
                    
                    progress_bar.progress(1.0)
                    status_text.text("ë¶„ì„ ì™„ë£Œ!")
                    
                    st.success("âœ… ìµœì í™”ëœ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
                    # ê²°ê³¼ í‘œì‹œ (ì‹¤ì œë¡œëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œ)
                    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
                    st.info("ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
                    
                    # ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬
                    if optimization_settings.get('optimized', False):
                        system.cleanup_resources()
                
                except Exception as e:
                    st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ì„±ëŠ¥ íŒ
    with st.expander("ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ"):
        st.markdown("""
        ### ğŸš€ ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­
        
        **GPU ì‚¬ìš© ê¶Œì¥ ìƒí™©:**
        - ëŒ€ìš©ëŸ‰ ìŒì„± íŒŒì¼ (5ë¶„ ì´ìƒ)
        - ë§ì€ ì´ë¯¸ì§€ íŒŒì¼ (10ì¥ ì´ìƒ)
        - ê³ í™”ì§ˆ ë¹„ë””ì˜¤ ì²˜ë¦¬
        
        **CPU ì‚¬ìš© ê¶Œì¥ ìƒí™©:**
        - ì†Œê·œëª¨ íŒŒì¼ ì²˜ë¦¬
        - ì‹¤ì‹œê°„ ë¶„ì„ í•„ìš”
        - GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
        
        **ë©”ëª¨ë¦¬ ìµœì í™”:**
        - íŒŒì¼ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
        - ë¶„ì„ ì™„ë£Œ í›„ ìë™ ì •ë¦¬
        - ë¶ˆí•„ìš”í•œ ìºì‹œ ì œê±°
        """)
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("ğŸ¤– **ìë™ ìµœì í™”**: íŒŒì¼ ìœ í˜•ì— ë”°ë¼ ìµœì  ë¦¬ì†ŒìŠ¤ ì„ íƒ")
    
    with col2:
        st.info("ğŸ“Š **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: CPU/GPU ì‚¬ìš©ë¥  ì§€ì† ì¶”ì ")
    
    with col3:
        st.info("ğŸ§¹ **ìë™ ì •ë¦¬**: ë¶„ì„ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ìë™ í•´ì œ")

if __name__ == "__main__":
    render_optimized_analysis_interface()