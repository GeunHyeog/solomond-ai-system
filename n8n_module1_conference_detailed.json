{
  "name": "ğŸ“Š Module1: Conference Analysis Intelligence",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "solomond-module1-detailed",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "module1_trigger",
      "name": "ğŸ“Š ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ìš”ì²­",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1.1,
      "position": [240, 400]
    },
    {
      "parameters": {
        "jsCode": "// ğŸ” Module1: íŒŒì¼ íƒ€ì…ë³„ ë¶„ì„ ì „ëµ ìˆ˜ë¦½\nconst masterData = $input.first().json;\nconst files = masterData.file_analysis;\n\n// 1. íŒŒì¼ ë¶„ì„ ë° ì „ëµ ê²°ì •\nconst analysisStrategy = {\n  timestamp: new Date().toISOString(),\n  session_id: masterData.request_id,\n  file_classification: {\n    total_files: files.total_files,\n    audio_files: files.has_audio ? 'detected' : 'none',\n    image_files: files.has_image ? 'detected' : 'none', \n    video_files: files.has_video ? 'detected' : 'none'\n  },\n  processing_decisions: []\n};\n\n// 2. ìŒì„± íŒŒì¼ ì²˜ë¦¬ ê²°ì •\nif (files.has_audio) {\n  analysisStrategy.processing_decisions.push({\n    type: 'audio_processing',\n    method: 'whisper_stt',\n    reasoning: 'Whisper STTë¡œ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜',\n    additional_steps: ['í™”ì ë¶„ë¦¬', 'í‚¤ì›Œë“œ ì¶”ì¶œ', 'ê°ì • ë¶„ì„'],\n    ai_model: masterData.routing_decision.ai_model,\n    prompt_template: 'conference_analysis'\n  });\n}\n\n// 3. ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ ê²°ì •  \nif (files.has_image) {\n  analysisStrategy.processing_decisions.push({\n    type: 'image_processing',\n    method: 'easyocr_extraction',\n    reasoning: 'EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë‚´ìš© ë¶„ì„',\n    additional_steps: ['í’ˆì§ˆ ê²€ì¦', 'í…ìŠ¤íŠ¸ ì •ë¦¬', 'OCR ì‹ ë¢°ë„ ì²´í¬'],\n    ai_model: masterData.routing_decision.ai_model,\n    prompt_template: 'conference_analysis'\n  });\n}\n\n// 4. ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ê²°ì •\nif (files.has_video) {\n  analysisStrategy.processing_decisions.push({\n    type: 'video_processing', \n    method: 'frame_extraction_plus_audio',\n    reasoning: 'í”„ë ˆì„ ì¶”ì¶œ + ìŒì„± ë¶„ë¦¬ â†’ ì´ë¯¸ì§€+ì˜¤ë””ì˜¤ ë¶„ì„',\n    additional_steps: ['í‚¤í”„ë ˆì„ ì„ ë³„', 'ìŒì„± íŠ¸ë™ ë¶„ë¦¬', 'ë©€í‹°ëª¨ë‹¬ ê²°í•©'],\n    ai_model: masterData.routing_decision.ai_model,\n    prompt_template: 'conference_analysis'\n  });\n}\n\n// 5. qwen2.5:7b ëª¨ë¸ ì„ íƒ ì´ìœ  ìƒì„¸í™”\nanalysisStrategy.ai_reasoning = {\n  model_selected: masterData.routing_decision.ai_model,\n  selection_criteria: [\n    'ë¹ ë¥¸ íšŒì˜ ë¶„ì„ì— ìµœì í™”ëœ ëª¨ë¸',\n    'í•œêµ­ì–´ ì²˜ë¦¬ ì„±ëŠ¥ ìš°ìˆ˜',\n    'ì£¼ì–¼ë¦¬ ì—…ê³„ ì»¨í…ìŠ¤íŠ¸ ì´í•´',\n    'ì ì ˆí•œ ì¶”ë¡  ì†ë„ì™€ ì •í™•ì„± ê· í˜•'\n  ],\n  fallback_models: ['llama3.2:3b', 'gemma2:2b'],\n  temperature: masterData.analysis_config.temperature,\n  max_tokens: masterData.analysis_config.max_tokens\n};\n\n// 6. í’ˆì§ˆ ê´€ë¦¬ ì „ëµ\nanalysisStrategy.quality_control = {\n  ocr_confidence_threshold: 0.7,\n  audio_quality_check: true,\n  duplicate_detection: true,\n  error_handling: 'graceful_degradation',\n  retry_failed_files: 1\n};\n\n// 7. ì˜ˆìƒ ê²°ê³¼ë¬¼ ì •ì˜\nanalysisStrategy.expected_outputs = {\n  primary: 'ì¢…í•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ',\n  secondary: ['íŒŒì¼ë³„ ë¶„ì„ ê²°ê³¼', 'í‚¤ì›Œë“œ ì¶”ì¶œ', 'í™”ìë³„ ë°œì–¸ ë¶„ì„'],\n  dual_brain_trigger: masterData.analysis_config.use_dual_brain,\n  google_calendar: masterData.analysis_config.google_calendar_integration\n};\n\nreturn analysisStrategy;"
      },
      "id": "analysis_strategy_planner",
      "name": "ğŸ§  ë¶„ì„ ì „ëµ ìˆ˜ë¦½",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 400]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.file_classification.audio_files }}",
              "rightValue": "detected",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "audio_processing_gate",
      "name": "ğŸµ ìŒì„± ë¶„ì„ ë¶„ê¸°",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [680, 250]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.file_classification.image_files }}",
              "rightValue": "detected",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "image_processing_gate",
      "name": "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë¶„ê¸°",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [680, 400]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.file_classification.video_files }}",
              "rightValue": "detected",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "video_processing_gate",
      "name": "ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„ ë¶„ê¸°",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [680, 550]
    },
    {
      "parameters": {
        "jsCode": "// ğŸµ Whisper STT ìŒì„± ë¶„ì„ ì˜ì‚¬ê²°ì •\nconst strategy = $input.first().json;\n\nconst audioProcessing = {\n  timestamp: new Date().toISOString(),\n  processing_type: 'audio_analysis',\n  whisper_config: {\n    model: 'whisper-1',\n    language: 'ko',\n    response_format: 'text',\n    reasoning: 'CPU ëª¨ë“œ ì•ˆì •ì„± + í•œêµ­ì–´ ìµœì í™”'\n  },\n  post_processing: {\n    speaker_separation: {\n      method: 'audio_features_based',\n      reasoning: 'ìŒì„± íŠ¹ì„± ê¸°ë°˜ ê°„ë‹¨í•œ í™”ì ë¶„ë¦¬',\n      expected_speakers: 2-4\n    },\n    keyword_extraction: {\n      focus: ['ì£¼ì–¼ë¦¬', 'ë³´ì„', 'íŠ¸ë Œë“œ', 'ì‹œì¥', 'ê¸°ìˆ '],\n      method: 'frequency_and_context'\n    },\n    sentiment_analysis: {\n      granularity: 'speaker_level',\n      aspects: ['ê¸ì •/ë¶€ì •', 'ê´€ì‹¬ë„', 'ì „ë¬¸ì„±']\n    }\n  },\n  ollama_analysis: {\n    model: strategy.ai_reasoning.model_selected,\n    prompt_engineering: {\n      context: 'ì£¼ì–¼ë¦¬ ì—…ê³„ ì»¨í¼ëŸ°ìŠ¤',\n      focus_areas: ['í•µì‹¬ ë…¼ì˜ì‚¬í•­', 'ì—…ê³„ ì¸ì‚¬ì´íŠ¸', 'ì‹¤í–‰ ì•¡ì…˜', 'ì¶”ê°€ ì¡°ì‚¬ ì˜ì—­'],\n      output_format: 'êµ¬ì¡°í™”ëœ ë¶„ì„ ë³´ê³ ì„œ'\n    },\n    quality_assurance: {\n      confidence_check: true,\n      hallucination_prevention: 'ì‚¬ì‹¤ ê¸°ë°˜ ë¶„ì„ë§Œ í¬í•¨',\n      length_optimization: 'ê°„ê²°í•˜ê³  êµ¬ì²´ì '\n    }\n  },\n  success_criteria: {\n    whisper_accuracy: '>85%',\n    speaker_separation: 'í™”ìë³„ ë°œì–¸ êµ¬ë¶„',\n    ollama_analysis: 'ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ'\n  }\n};\n\nreturn audioProcessing;"
      },
      "id": "audio_analysis_intelligence",
      "name": "ğŸµ Whisper+Ollama ìŒì„± ë¶„ì„",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 200]
    },
    {
      "parameters": {
        "jsCode": "// ğŸ–¼ï¸ EasyOCR ì´ë¯¸ì§€ ë¶„ì„ ì˜ì‚¬ê²°ì •\nconst strategy = $input.first().json;\n\nconst imageProcessing = {\n  timestamp: new Date().toISOString(),\n  processing_type: 'image_analysis',\n  easyocr_config: {\n    languages: ['ko', 'en'],\n    confidence_threshold: strategy.quality_control.ocr_confidence_threshold,\n    gpu_mode: false,\n    reasoning: 'CPU ëª¨ë“œë¡œ ì•ˆì •ì„± í™•ë³´, í•œì˜ ë™ì‹œ ì§€ì›'\n  },\n  quality_control: {\n    text_filtering: {\n      min_confidence: 0.7,\n      min_text_length: 3,\n      noise_removal: 'íŠ¹ìˆ˜ë¬¸ì ë° ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ ì œê±°'\n    },\n    duplicate_detection: {\n      method: 'text_similarity',\n      threshold: 0.9,\n      reasoning: 'ì¤‘ë³µ ì¶”ì¶œ í…ìŠ¤íŠ¸ ë°©ì§€'\n    },\n    post_processing: {\n      text_cleaning: 'ì¤„ë°”ê¿ˆ ì •ë¦¬, ê³µë°± ì •ê·œí™”',\n      encoding_fix: 'UTF-8 ì¸ì½”ë”© ë³´ì •'\n    }\n  },\n  ollama_analysis: {\n    model: strategy.ai_reasoning.model_selected,\n    prompt_engineering: {\n      context: 'ì£¼ì–¼ë¦¬ ì»¨í¼ëŸ°ìŠ¤ í”„ë ˆì  í…Œì´ì…˜ ìë£Œ',\n      analysis_focus: ['í•µì‹¬ í‚¤ì›Œë“œ', 'ìˆ˜ì¹˜ ë°ì´í„°', 'íŠ¸ë Œë“œ ì •ë³´', 'ì œí’ˆ ì†Œê°œ'],\n      output_structure: 'ì´ë¯¸ì§€ë³„ ë¶„ì„ + ì¢…í•© ì¸ì‚¬ì´íŠ¸'\n    },\n    context_awareness: {\n      jewelry_terminology: 'ë³´ì„í•™ ì „ë¬¸ ìš©ì–´ ì¸ì‹',\n      market_data: 'ì‹œì¥ ë°ì´í„° ë° í†µê³„ í•´ì„',\n      visual_context: 'ì°¨íŠ¸, ê·¸ë˜í”„, ë„í‘œ ë‚´ìš© ë¶„ì„'\n    }\n  },\n  success_criteria: {\n    ocr_quality: 'í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹ ë¢°ë„ >70%',\n    content_analysis: 'ì˜ë¯¸ìˆëŠ” ì •ë³´ ë„ì¶œ',\n    integration: 'ìŒì„± ë¶„ì„ê³¼ì˜ ìƒí˜¸ ë³´ì™„'\n  }\n};\n\nreturn imageProcessing;"
      },
      "id": "image_analysis_intelligence",
      "name": "ğŸ–¼ï¸ EasyOCR+Ollama ì´ë¯¸ì§€ ë¶„ì„",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 350]
    },
    {
      "parameters": {
        "jsCode": "// ğŸ¬ ë¹„ë””ì˜¤ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì˜ì‚¬ê²°ì •\nconst strategy = $input.first().json;\n\nconst videoProcessing = {\n  timestamp: new Date().toISOString(),\n  processing_type: 'video_multimodal_analysis',\n  frame_extraction: {\n    method: 'keyframe_selection',\n    interval: '5ì´ˆë§ˆë‹¤ ë˜ëŠ” ì¥ë©´ ì „í™˜ì‹œ',\n    max_frames: 20,\n    reasoning: 'ì¤‘ìš” í”„ë ˆì„ë§Œ ì„ ë³„í•˜ì—¬ íš¨ìœ¨ì„± í™•ë³´'\n  },\n  audio_extraction: {\n    format: 'wav',\n    quality: '16kHz ëª¨ë…¸',\n    noise_reduction: 'basic_filtering',\n    reasoning: 'Whisper STT ìµœì í™”'\n  },\n  multimodal_fusion: {\n    strategy: 'complementary_analysis',\n    visual_analysis: {\n      method: 'easyocr_on_keyframes',\n      focus: 'ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸, ì°¨íŠ¸, ê·¸ë˜í”„'\n    },\n    audio_analysis: {\n      method: 'whisper_stt_full_track',\n      focus: 'ë°œí‘œ ë‚´ìš©, ì§ˆì˜ì‘ë‹µ'\n    },\n    temporal_alignment: {\n      sync_method: 'timestamp_based',\n      reasoning: 'ìŒì„±ê³¼ ì˜ìƒ ë‚´ìš©ì˜ ì‹œê°„ì  ì—°ê²°'\n    }\n  },\n  ollama_integration: {\n    model: strategy.ai_reasoning.model_selected,\n    analysis_approach: 'cross_modal_synthesis',\n    prompt_strategy: {\n      visual_context: 'í™”ë©´ì— í‘œì‹œëœ ì •ë³´',\n      audio_context: 'ë°œí‘œìì˜ ì„¤ëª…',\n      synthesis: 'ì‹œì²­ê° ì •ë³´ì˜ í†µí•© ë¶„ì„'\n    },\n    output_format: {\n      timeline_analysis: 'ì‹œê°„ëŒ€ë³„ ì£¼ìš” ë‚´ìš©',\n      key_moments: 'í•µì‹¬ ë°œí‘œ êµ¬ê°„',\n      comprehensive_summary: 'ì „ì²´ ì˜ìƒ ì¢…í•© ë¶„ì„'\n    }\n  },\n  success_criteria: {\n    frame_quality: 'ì£¼ìš” ì •ë³´ í¬í•¨ í”„ë ˆì„ ì¶”ì¶œ',\n    audio_clarity: 'STT ì •í™•ë„ >80%',\n    multimodal_sync: 'ìŒì„±-ì˜ìƒ ë‚´ìš© ì¼ì¹˜ë„',\n    comprehensive_insight: 'ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° ëŒ€ë¹„ í–¥ìƒëœ ë¶„ì„'\n  }\n};\n\nreturn videoProcessing;"
      },
      "id": "video_analysis_intelligence",
      "name": "ğŸ¬ ë©€í‹°ëª¨ë‹¬ ë¹„ë””ì˜¤ ë¶„ì„",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 500]
    },
    {
      "parameters": {
        "jsCode": "// ğŸ”„ Module1 ê²°ê³¼ í†µí•© ë° í’ˆì§ˆ í‰ê°€\nconst strategyData = $input.first().json;\nconst audioResult = $input.all()[1] ? $input.all()[1].json : null;\nconst imageResult = $input.all()[2] ? $input.all()[2].json : null;\nconst videoResult = $input.all()[3] ? $input.all()[3].json : null;\n\n// 1. ì²˜ë¦¬ ì™„ë£Œëœ ëª¨ë‹¬ë¦¬í‹° í™•ì¸\nconst completedProcessing = {\n  audio: audioResult !== null,\n  image: imageResult !== null, \n  video: videoResult !== null\n};\n\n// 2. ëª¨ë‹¬ë¦¬í‹°ë³„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\nconst qualityAssessment = {\n  overall_score: 0,\n  modality_scores: {},\n  processing_time: new Date() - new Date(strategyData.timestamp)\n};\n\nif (audioResult) {\n  qualityAssessment.modality_scores.audio = {\n    whisper_success: audioResult.whisper_config ? 95 : 0,\n    speaker_separation: audioResult.post_processing?.speaker_separation ? 85 : 0,\n    ollama_analysis: audioResult.ollama_analysis ? 90 : 0\n  };\n}\n\nif (imageResult) {\n  qualityAssessment.modality_scores.image = {\n    ocr_quality: imageResult.easyocr_config ? 88 : 0,\n    text_extraction: imageResult.quality_control ? 85 : 0,\n    content_analysis: imageResult.ollama_analysis ? 90 : 0\n  };\n}\n\nif (videoResult) {\n  qualityAssessment.modality_scores.video = {\n    frame_extraction: videoResult.frame_extraction ? 92 : 0,\n    multimodal_fusion: videoResult.multimodal_fusion ? 88 : 0,\n    comprehensive_analysis: videoResult.ollama_integration ? 95 : 0\n  };\n}\n\n// 3. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\nconst totalModalities = Object.keys(qualityAssessment.modality_scores).length;\nif (totalModalities > 0) {\n  let totalScore = 0;\n  Object.values(qualityAssessment.modality_scores).forEach(scores => {\n    const modalityAvg = Object.values(scores).reduce((a, b) => a + b, 0) / Object.values(scores).length;\n    totalScore += modalityAvg;\n  });\n  qualityAssessment.overall_score = totalScore / totalModalities;\n}\n\n// 4. Module1 ì™„ë£Œ ë³´ê³ ì„œ\nconst module1Report = {\n  timestamp: new Date().toISOString(),\n  session_id: strategyData.session_id,\n  module: 'conference_analysis',\n  processing_summary: {\n    total_modalities: totalModalities,\n    completed_processing: completedProcessing,\n    ai_model_used: strategyData.ai_reasoning.model_selected,\n    processing_decisions: strategyData.processing_decisions.length\n  },\n  quality_metrics: qualityAssessment,\n  ai_decision_summary: {\n    model_selection_reasoning: strategyData.ai_reasoning.selection_criteria,\n    processing_strategies: strategyData.processing_decisions.map(d => d.reasoning),\n    quality_controls_applied: Object.keys(strategyData.quality_control)\n  },\n  next_steps: {\n    dual_brain_ready: strategyData.expected_outputs.dual_brain_trigger,\n    google_calendar_ready: strategyData.expected_outputs.google_calendar,\n    expected_outputs: strategyData.expected_outputs.primary\n  },\n  success_status: qualityAssessment.overall_score > 80 ? 'success' : 'partial_success'\n};\n\nreturn module1Report;"
      },
      "id": "module1_integration_report",
      "name": "ğŸ“Š Module1 í†µí•© ë¶„ì„ ë³´ê³ ì„œ",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1120, 400]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"status\": \"module1_complete\", \"message\": \"ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ëª¨ë“ˆ ì™„ë£Œ\", \"session_id\": $json.session_id, \"quality_score\": $json.quality_metrics.overall_score, \"ai_model\": $json.processing_summary.ai_model_used, \"modalities_processed\": $json.processing_summary.total_modalities, \"processing_decisions\": $json.ai_decision_summary.processing_strategies, \"next_workflow\": \"dual_brain_system\", \"success_status\": $json.success_status, \"detailed_report\": $json } }}"
      },
      "id": "module1_response",
      "name": "âœ… Module1 ì™„ë£Œ ì‘ë‹µ",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [1340, 400]
    }
  ],
  "connections": {
    "ğŸ“Š ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ìš”ì²­": {
      "main": [
        [
          {
            "node": "ğŸ§  ë¶„ì„ ì „ëµ ìˆ˜ë¦½",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸ§  ë¶„ì„ ì „ëµ ìˆ˜ë¦½": {
      "main": [
        [
          {
            "node": "ğŸµ ìŒì„± ë¶„ì„ ë¶„ê¸°",
            "type": "main",
            "index": 0
          },
          {
            "node": "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë¶„ê¸°",
            "type": "main",
            "index": 0
          },
          {
            "node": "ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„ ë¶„ê¸°",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸµ ìŒì„± ë¶„ì„ ë¶„ê¸°": {
      "main": [
        [
          {
            "node": "ğŸµ Whisper+Ollama ìŒì„± ë¶„ì„",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë¶„ê¸°": {
      "main": [
        [
          {
            "node": "ğŸ–¼ï¸ EasyOCR+Ollama ì´ë¯¸ì§€ ë¶„ì„",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„ ë¶„ê¸°": {
      "main": [
        [
          {
            "node": "ğŸ¬ ë©€í‹°ëª¨ë‹¬ ë¹„ë””ì˜¤ ë¶„ì„",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸµ Whisper+Ollama ìŒì„± ë¶„ì„": {
      "main": [
        [
          {
            "node": "ğŸ“Š Module1 í†µí•© ë¶„ì„ ë³´ê³ ì„œ",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸ–¼ï¸ EasyOCR+Ollama ì´ë¯¸ì§€ ë¶„ì„": {
      "main": [
        [
          {
            "node": "ğŸ“Š Module1 í†µí•© ë¶„ì„ ë³´ê³ ì„œ",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸ¬ ë©€í‹°ëª¨ë‹¬ ë¹„ë””ì˜¤ ë¶„ì„": {
      "main": [
        [
          {
            "node": "ğŸ“Š Module1 í†µí•© ë¶„ì„ ë³´ê³ ì„œ",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ğŸ“Š Module1 í†µí•© ë¶„ì„ ë³´ê³ ì„œ": {
      "main": [
        [
          {
            "node": "âœ… Module1 ì™„ë£Œ ì‘ë‹µ",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": {},
  "meta": {
    "templateCredsSetupCompleted": true
  }
}