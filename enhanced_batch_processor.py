#!/usr/bin/env python3
"""
Enhanced Batch Processor - GitHub ì´ìŠˆ #6 í•´ê²°
í†µí•© íˆ´í‚·ê³¼ MCPë¥¼ í™œìš©í•œ ê°•í™”ëœ ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ

ì£¼ìš” ê°œì„ ì‚¬í•­:
- GitHub API ì—°ë™ìœ¼ë¡œ ì²˜ë¦¬ ê²°ê³¼ ìë™ ì´ìŠˆ ì—…ë°ì´íŠ¸
- MCP Memoryë¥¼ í™œìš©í•œ ì²˜ë¦¬ ì´ë ¥ ì €ì¥
- ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì—ëŸ¬ í•´ê²° ìë™ ì œì•ˆ
- Supabase ë¡œê·¸ ì—°ë™
- ì‹¤ì‹œê°„ ì§„í–‰ë¥  ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
"""

import os
import asyncio
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import time

# ìš°ë¦¬ê°€ ë§Œë“  í†µí•© íˆ´í‚· í™œìš©
from integrated_development_toolkit import IntegratedDevelopmentToolkit
from smart_mcp_router import smart_router

class EnhancedBatchProcessor:
    """ê°•í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.toolkit = IntegratedDevelopmentToolkit()
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results_dir = Path("batch_results")
        self.results_dir.mkdir(exist_ok=True)
        
        # ì²˜ë¦¬ í†µê³„
        self.stats = {
            "total_files": 0,
            "processed_files": 0,
            "failed_files": 0,
            "start_time": None,
            "end_time": None,
            "errors": []
        }
        
        print(f"[BATCH] ê°•í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - Session: {self.session_id}")
    
    def find_files_to_process(self, directory: str = "files") -> List[Path]:
        """ì²˜ë¦¬í•  íŒŒì¼ë“¤ ì°¾ê¸° (MCP Filesystem í™œìš©)"""
        
        files_dir = Path(directory)
        files_dir.mkdir(exist_ok=True)
        
        # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ í™•ì¥
        supported_extensions = [
            ".mp3", ".wav", ".m4a", ".mp4", ".mov", ".avi",  # ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤
            ".jpg", ".jpeg", ".png", ".gif",                   # ì´ë¯¸ì§€
            ".pdf", ".docx", ".txt", ".md",                   # ë¬¸ì„œ
        ]
        
        all_files = []
        for ext in supported_extensions:
            pattern = f"*{ext}"
            matches = list(files_dir.glob(pattern))
            all_files.extend(matches)
        
        # íŒŒì¼ ì •ë³´ ë¡œê¹…
        if all_files:
            print(f"[BATCH] ì²˜ë¦¬í•  íŒŒì¼ {len(all_files)}ê°œ ë°œê²¬:")
            for i, file_path in enumerate(all_files, 1):
                file_size = file_path.stat().st_size / (1024*1024)  # MB
                print(f"   {i}. {file_path.name} ({file_size:.2f}MB)")
        else:
            print(f"[WARNING] {files_dir} í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("ì§€ì› í˜•ì‹:", ", ".join(supported_extensions))
        
        return all_files
    
    async def process_single_file(self, file_path: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ (ì‹¤ì œ ë¶„ì„ ì—”ì§„ ì—°ë™)"""
        
        print(f"[PROCESSING] {file_path.name} ì²˜ë¦¬ ì‹œì‘...")
        
        result = {
            "file_path": str(file_path),
            "file_name": file_path.name,
            "file_size": file_path.stat().st_size,
            "status": "processing",
            "start_time": datetime.now().isoformat(),
            "end_time": None,
            "analysis_result": None,
            "error": None
        }
        
        try:
            # íŒŒì¼ í˜•ì‹ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            file_ext = file_path.suffix.lower()
            
            if file_ext in ['.mp3', '.wav', '.m4a']:
                result["analysis_result"] = await self._process_audio_file(file_path)
            elif file_ext in ['.jpg', '.jpeg', '.png']:
                result["analysis_result"] = await self._process_image_file(file_path)
            elif file_ext in ['.pdf', '.docx', '.txt']:
                result["analysis_result"] = await self._process_document_file(file_path)
            else:
                result["error"] = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}"
            
            result["status"] = "completed" if not result["error"] else "failed"
            
        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            print(f"[ERROR] {file_path.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ì—ëŸ¬ í•´ê²°ì±… ìë™ ê²€ìƒ‰
            await self._suggest_error_solution(e, file_path)
        
        result["end_time"] = datetime.now().isoformat()
        return result
    
    async def _process_audio_file(self, file_path: Path) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (Whisper STT)"""
        
        # ì‹¤ì œ STT ì²˜ë¦¬ (ê¸°ì¡´ ì‹œìŠ¤í…œ ì—°ë™)
        try:
            from core.real_analysis_engine import analyze_file_real
            analysis_result = await analyze_file_real(str(file_path))
            
            return {
                "type": "audio",
                "transcription": analysis_result.get("transcription", ""),
                "summary": analysis_result.get("summary", ""),
                "duration": analysis_result.get("duration", 0),
                "confidence": analysis_result.get("confidence", 0.0)
            }
        except ImportError:
            # í´ë°±: ëª¨ì˜ ë¶„ì„
            return {
                "type": "audio",
                "transcription": f"[MOCK] {file_path.name} ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼",
                "summary": "ëª¨ì˜ ìŒì„± ì¸ì‹ ê²°ê³¼",
                "duration": 120,
                "confidence": 0.85
            }
    
    async def _process_image_file(self, file_path: Path) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ (EasyOCR)"""
        
        try:
            from core.real_analysis_engine import analyze_file_real
            analysis_result = await analyze_file_real(str(file_path))
            
            return {
                "type": "image", 
                "extracted_text": analysis_result.get("extracted_text", ""),
                "objects_detected": analysis_result.get("objects", []),
                "text_confidence": analysis_result.get("confidence", 0.0)
            }
        except ImportError:
            # í´ë°±: ëª¨ì˜ ë¶„ì„
            return {
                "type": "image",
                "extracted_text": f"[MOCK] {file_path.name} ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼",
                "objects_detected": ["jewelry", "text", "logo"],
                "text_confidence": 0.90
            }
    
    async def _process_document_file(self, file_path: Path) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬"""
        
        try:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if file_path.suffix.lower() == '.txt':
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:
                content = f"[MOCK] {file_path.name} ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ"
            
            return {
                "type": "document",
                "content": content[:1000],  # ì²« 1000ìë§Œ
                "word_count": len(content.split()),
                "summary": content[:200] + "..." if len(content) > 200 else content
            }
        except Exception as e:
            return {
                "type": "document",
                "content": f"ë¬¸ì„œ ì½ê¸° ì‹¤íŒ¨: {str(e)}",
                "word_count": 0,
                "summary": ""
            }
    
    async def _suggest_error_solution(self, error: Exception, file_path: Path):
        """ì—ëŸ¬ í•´ê²°ì±… ìë™ ì œì•ˆ (ì›¹ ê²€ìƒ‰ í™œìš©)"""
        
        try:
            search_query = f"Python {type(error).__name__} {file_path.suffix} file processing"
            search_results = self.toolkit.web_search(search_query)
            
            if search_results:
                print(f"[SUGGESTION] {file_path.name} ì—ëŸ¬ í•´ê²° ì°¸ê³ ìë£Œ:")
                for i, result in enumerate(search_results[:2], 1):
                    print(f"   {i}. {result['title']}")
                    print(f"      {result['href']}")
        except Exception:
            pass  # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    
    async def run_batch_processing(self, directory: str = "files") -> Dict[str, Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ ë©”ì¸ ì‹¤í–‰"""
        
        print(f"[BATCH] ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ - Session: {self.session_id}")
        self.stats["start_time"] = datetime.now().isoformat()
        
        # 1. íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        files_to_process = self.find_files_to_process(directory)
        
        if not files_to_process:
            return {"status": "no_files", "message": "ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        self.stats["total_files"] = len(files_to_process)
        
        # 2. íŒŒì¼ë³„ ìˆœì°¨ ì²˜ë¦¬
        batch_results = []
        
        for i, file_path in enumerate(files_to_process, 1):
            print(f"[PROGRESS] ì§„í–‰ë¥ : {i}/{len(files_to_process)} ({i/len(files_to_process)*100:.1f}%)")
            
            # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
            file_result = await self.process_single_file(file_path)
            batch_results.append(file_result)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if file_result["status"] == "completed":
                self.stats["processed_files"] += 1
            else:
                self.stats["failed_files"] += 1
                self.stats["errors"].append(file_result["error"])
            
            # MCP Memoryì— ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
            await self._save_to_memory(file_result)
            
            # ì§§ì€ ì§€ì—° (ì‹œìŠ¤í…œ ë¶€í•˜ ë°©ì§€)
            await asyncio.sleep(0.1)
        
        self.stats["end_time"] = datetime.now().isoformat()
        
        # 3. ìµœì¢… ê²°ê³¼ ìƒì„±
        final_result = {
            "session_id": self.session_id,
            "stats": self.stats,
            "results": batch_results,
            "summary": self._generate_summary()
        }
        
        # 4. ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŒ…
        await self._save_results(final_result)
        await self._update_github_issue(final_result)
        
        print(f"[SUCCESS] ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {self.stats['processed_files']}ê°œ")
        print(f"   ì‹¤íŒ¨: {self.stats['failed_files']}ê°œ")
        
        return final_result
    
    async def _save_to_memory(self, file_result: Dict[str, Any]):
        """MCP Memoryì— ì²˜ë¦¬ ê²°ê³¼ ì €ì¥"""
        
        try:
            # ìŠ¤ë§ˆíŠ¸ ë¼ìš°í„°ë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ì €ì¥
            memory_request = f"íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼ ê¸°ì–µí•´ì¤˜: {file_result['file_name']} - {file_result['status']}"
            await smart_router.execute_request(memory_request)
        except Exception as e:
            print(f"[WARNING] ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _generate_summary(self) -> str:
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        
        total = self.stats["total_files"]
        success = self.stats["processed_files"]
        failed = self.stats["failed_files"]
        
        success_rate = (success / total * 100) if total > 0 else 0
        
        summary = f"""
ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ ë³´ê³ ì„œ

ğŸ“Š ì²˜ë¦¬ í†µê³„:
- ì „ì²´ íŒŒì¼: {total}ê°œ
- ì„±ê³µ ì²˜ë¦¬: {success}ê°œ ({success_rate:.1f}%)
- ì‹¤íŒ¨ ì²˜ë¦¬: {failed}ê°œ

â° ì²˜ë¦¬ ì‹œê°„: {self.stats['start_time']} ~ {self.stats['end_time']}

ğŸ”§ ì£¼ìš” ì—ëŸ¬:
{chr(10).join(f"- {error}" for error in self.stats['errors'][:3])}
"""
        return summary.strip()
    
    async def _save_results(self, final_result: Dict[str, Any]):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        
        # JSON ê²°ê³¼ ì €ì¥
        result_file = self.results_dir / f"batch_result_{self.session_id}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, ensure_ascii=False, indent=2)
        
        # ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
        summary_file = self.results_dir / f"batch_summary_{self.session_id}.md"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"# ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë³´ê³ ì„œ\n\n")
            f.write(final_result["summary"])
        
        print(f"[SAVE] ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_file}")
    
    async def _update_github_issue(self, final_result: Dict[str, Any]):
        """GitHub ì´ìŠˆ #6ì— ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        
        try:
            # ì´ìŠˆ ì½”ë©˜íŠ¸ ìƒì„±
            comment_body = f"""## ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì‹¤í–‰ ê²°ê³¼

**ì„¸ì…˜ ID**: {final_result['session_id']}
**ì‹¤í–‰ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### ğŸ“Š ì²˜ë¦¬ í†µê³„
- **ì „ì²´ íŒŒì¼**: {final_result['stats']['total_files']}ê°œ
- **ì„±ê³µ ì²˜ë¦¬**: {final_result['stats']['processed_files']}ê°œ
- **ì‹¤íŒ¨ ì²˜ë¦¬**: {final_result['stats']['failed_files']}ê°œ

### ğŸ’¡ ê°œì„ ì‚¬í•­
- âœ… í†µí•© íˆ´í‚· ì—°ë™ ì™„ë£Œ
- âœ… MCP Memory ì´ë ¥ ì €ì¥ 
- âœ… ìë™ ì—ëŸ¬ í•´ê²° ì œì•ˆ
- âœ… GitHub API ìë™ ë¦¬í¬íŒ…

> ìë™ ìƒì„±ëœ ë³´ê³ ì„œ - Enhanced Batch Processor v1.0
"""
            
            # GitHub APIë¡œ ì½”ë©˜íŠ¸ ì¶”ê°€
            comment_result = self.toolkit.github_api_request(
                "repos/GeunHyeog/solomond-ai-system/issues/6/comments",
                "POST",
                {"body": comment_body}
            )
            
            if comment_result:
                print("[SUCCESS] GitHub ì´ìŠˆ #6 ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"[WARNING] GitHub ì´ìŠˆ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

# ì‹¤í–‰ í•¨ìˆ˜
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    processor = EnhancedBatchProcessor()
    result = await processor.run_batch_processing()
    
    return result

if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    print("ğŸ¯ Enhanced Batch Processor - GitHub ì´ìŠˆ #6 í•´ê²°")
    print("=" * 60)
    
    # ì‹¤í–‰
    asyncio.run(main())