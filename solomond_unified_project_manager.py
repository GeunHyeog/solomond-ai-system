#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– SOLOMOND AI í†µí•© í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €
Serena ì½”ë”© ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ì™„ì „ í†µí•© ë²„ì „

ì´ ëª¨ë“ˆì€ SOLOMOND AI ì‹œìŠ¤í…œì˜ ëª¨ë“  í”„ë¡œì íŠ¸ ê´€ë¦¬ ê¸°ëŠ¥ê³¼
Serenaì˜ ê³ ê¸‰ ì½”ë”© ë¶„ì„ ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ í†µí•©í•œ ìŠˆí¼ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ê¸°ëŠ¥:
1. Symbol-level ì½”ë“œ ë¶„ì„ (Serena ì—”ì§„)
2. ìë™ ì´ìŠˆ íƒì§€ ë° ìˆ˜ì • ì œì•ˆ
3. ì‹œìŠ¤í…œ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§ (0-100ì )
4. ThreadPool, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜, ì„±ëŠ¥ ë³‘ëª©ì  íƒì§€
5. SOLOMOND AI íŠ¹í™” ìµœì í™”
6. í”„ë¡œì íŠ¸ ì „ì²´ ê´€ë¦¬ ë° ë³µêµ¬

Author: SOLOMOND AI Team
Version: 2.0.0 (Serena Integration Complete)
Created: 2025-08-17
"""

import re
import json
import shutil
import ast
import inspect
import traceback
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
import subprocess
import sys

@dataclass
class CodeIssue:
    """ì½”ë“œ ì´ìŠˆ ì •ë³´"""
    file_path: str
    line_number: int
    pattern_name: str
    severity: str  # critical, high, medium, low
    message: str
    code_snippet: str
    solution: str
    confidence: float
    impact_score: int

@dataclass
class SystemHealth:
    """ì‹œìŠ¤í…œ ê±´ê°•ë„ ì •ë³´"""
    overall_score: int  # 0-100
    critical_issues: int
    high_issues: int
    medium_issues: int
    low_issues: int
    files_analyzed: int
    recommendations: List[str]

class SOLOMONDProjectManager:
    """SOLOMOND AI í†µí•© í”„ë¡œì íŠ¸ ë§¤ë‹ˆì € (Serena í†µí•©)"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.version = "2.0.0"
        self.agent_name = "SOLOMOND Project Manager"
        
        # ë¡œê¹… ì„¤ì •
        self.logger = self._setup_logger()
        
        # Serena í†µí•©: ê³ ê¸‰ ë¶„ì„ íŒ¨í„´ë“¤
        self.critical_patterns = {
            "threadpool_without_context": {
                "regex": r"executor\s*=\s*ThreadPoolExecutor\([^)]*\)(?!\s*\n\s*with)",
                "severity": "critical",
                "message": "ThreadPoolExecutorê°€ context manager ì—†ì´ ì‚¬ìš©ë¨",
                "solution": "with ThreadPoolExecutor() as executor: íŒ¨í„´ ì‚¬ìš©",
                "impact_score": 25,
                "auto_fixable": True
            },
            
            "memory_leak_cuda": {
                "regex": r"torch\.cuda\.(?!empty_cache|synchronize|is_available)",
                "severity": "high", 
                "message": "CUDA ì—°ì‚° í›„ ë©”ëª¨ë¦¬ ì •ë¦¬ ëˆ„ë½",
                "solution": "torch.cuda.empty_cache() í˜¸ì¶œ ì¶”ê°€",
                "impact_score": 15,
                "auto_fixable": True
            },
            
            "streamlit_heavy_no_cache": {
                "regex": r"def\s+(\w*(?:heavy|process|analyze|load|model)\w*)\s*\([^)]*\):(?!\s*\n\s*@st\.cache)",
                "severity": "medium",
                "message": "ë¬´ê±°ìš´ í•¨ìˆ˜ì— Streamlit ìºì‹œ ë¯¸ì ìš©",
                "solution": "@st.cache_data ë°ì½”ë ˆì´í„° ì¶”ê°€",
                "impact_score": 10,
                "auto_fixable": True
            },
            
            "ollama_no_exception": {
                "regex": r"ollama\.(?:generate|chat|create)(?!.*(?:try|except))",
                "severity": "medium",
                "message": "Ollama API í˜¸ì¶œì— ì˜ˆì™¸ ì²˜ë¦¬ ì—†ìŒ",
                "solution": "try-except ë¸”ë¡ìœ¼ë¡œ ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€",
                "impact_score": 8,
                "auto_fixable": False
            },
            
            "file_open_no_context": {
                "regex": r"(?:file|f)\s*=\s*open\([^)]+\)(?!\s*\n\s*with)",
                "severity": "high",
                "message": "íŒŒì¼ ì—´ê¸°ì— context manager ë¯¸ì‚¬ìš©",
                "solution": "with open(...) as file: íŒ¨í„´ ì‚¬ìš©",
                "impact_score": 12,
                "auto_fixable": True
            },
            
            "subprocess_shell_true": {
                "regex": r"subprocess\.(?:run|call|Popen).*shell\s*=\s*True",
                "severity": "critical",
                "message": "subprocessì—ì„œ shell=True ì‚¬ìš© (ë³´ì•ˆ ìœ„í—˜)",
                "solution": "shell=False ì‚¬ìš© ë˜ëŠ” shlex.quote() ì ìš©",
                "impact_score": 30,
                "auto_fixable": False
            }
        }
        
        # SOLOMOND AI íŠ¹í™” íŒ¨í„´
        self.solomond_patterns = {
            "conference_analysis_optimization": {
                "regex": r"conference.*analysis.*(?!cache|optimize)",
                "severity": "low",
                "message": "ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ìµœì í™” ê¸°íšŒ",
                "solution": "ìºì‹œ ë° ë°°ì¹˜ ì²˜ë¦¬ ì ìš©",
                "impact_score": 5,
                "auto_fixable": False
            },
            
            "multimodal_resource_leak": {
                "regex": r"(?:whisper|easyocr|transformers).*(?!del|cleanup)",
                "severity": "medium",
                "message": "ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ëˆ„ë½",
                "solution": "ëª…ì‹œì  ëª¨ë¸ ì‚­ì œ ë° ë©”ëª¨ë¦¬ ì •ë¦¬",
                "impact_score": 12,
                "auto_fixable": True
            }
        }
        
        # ìë™ ìˆ˜ì • í…œí”Œë¦¿
        self.fix_templates = {
            "threadpool_fix": """
# Serena ìë™ ìˆ˜ì •: ThreadPool ì•ˆì „ ê´€ë¦¬
with ThreadPoolExecutor() as executor:
    # ê¸°ì¡´ ì½”ë“œë¥¼ ì´ ë¸”ë¡ ì•ˆìœ¼ë¡œ ì´ë™
    {original_code}
""",
            
            "cuda_cleanup": """
{original_code}
torch.cuda.empty_cache()  # Serena ì¶”ê°€: GPU ë©”ëª¨ë¦¬ ì •ë¦¬
""",
            
            "streamlit_cache": """
@st.cache_data  # Serena ì¶”ê°€: ì„±ëŠ¥ ìµœì í™”
{original_function}
"""
        }

    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("SOLOMONDProjectManager")
        if not logger.handlers:
            logger.setLevel(logging.INFO)
            log_file = self.project_root / "solomond_project_manager.log"
            handler = logging.FileHandler(log_file, encoding='utf-8')
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def analyze_codebase(self, target_files: List[str] = None) -> Dict[str, Any]:
        """
        í†µí•© ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ (Serena ì—”ì§„ + í”„ë¡œì íŠ¸ ê´€ë¦¬)
        """
        self.logger.info("ğŸ” SOLOMOND AI í†µí•© ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ì‹œì‘")
        
        analysis_result = {
            "manager": {
                "name": self.agent_name,
                "version": self.version,
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "Comprehensive Code Analysis (Serena Engine Integrated)"
            },
            "project_summary": {
                "files_analyzed": 0,
                "total_lines": 0,
                "total_issues": 0,
                "critical_issues": 0,
                "high_issues": 0,
                "medium_issues": 0,
                "low_issues": 0
            },
            "issues_found": [],
            "health_assessment": {},
            "optimization_recommendations": [],
            "solomond_specific_insights": [],
            "auto_fix_available": False,
            "system_status": {},
            "errors": []
        }
        
        try:
            # ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ê²°ì •
            if not target_files:
                target_files = self._get_priority_files()
            
            # ê° íŒŒì¼ ë¶„ì„
            for file_path in target_files:
                if not Path(file_path).exists():
                    continue
                
                try:
                    file_analysis = self._analyze_single_file(file_path)
                    analysis_result["issues_found"].extend(file_analysis["issues"])
                    analysis_result["project_summary"]["files_analyzed"] += 1
                    analysis_result["project_summary"]["total_lines"] += file_analysis["line_count"]
                    
                except Exception as e:
                    error_msg = f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {str(e)}"
                    self.logger.error(error_msg)
                    analysis_result["errors"].append(error_msg)
            
            # ì´ìŠˆ ë¶„ë¥˜ ë° í†µê³„
            self._categorize_issues(analysis_result)
            
            # ê±´ê°•ë„ í‰ê°€
            analysis_result["health_assessment"] = self._assess_system_health(analysis_result)
            
            # ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
            analysis_result["optimization_recommendations"] = self._generate_recommendations(analysis_result)
            
            # SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸
            analysis_result["solomond_specific_insights"] = self._generate_solomond_insights(analysis_result)
            
            # ìë™ ìˆ˜ì • ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            analysis_result["auto_fix_available"] = self._check_auto_fix_availability(analysis_result)
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
            analysis_result["system_status"] = self._check_system_status()
            
        except Exception as e:
            error_msg = f"ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {str(e)}"
            self.logger.error(error_msg)
            analysis_result["errors"].append(error_msg)
        
        self.logger.info("âœ… í†µí•© ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ì™„ë£Œ")
        return analysis_result

    def _get_priority_files(self) -> List[str]:
        """SOLOMOND AI ìš°ì„ ìˆœìœ„ íŒŒì¼ ëª©ë¡"""
        priority_files = [
            "conference_analysis_COMPLETE_WORKING.py",
            "solomond_ai_main_dashboard.py",
            "dual_brain_integration.py",
            "ai_insights_engine.py",
            "google_calendar_connector.py",
            "hybrid_compute_manager.py",
            "n8n_connector.py"
        ]
        
        existing_files = []
        for file_name in priority_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                existing_files.append(str(file_path))
        
        # core ë””ë ‰í† ë¦¬ ì¤‘ìš” íŒŒì¼ ì¶”ê°€
        core_dir = self.project_root / "core"
        if core_dir.exists():
            core_files = [
                "multimodal_pipeline.py",
                "batch_processing_engine.py",
                "memory_optimizer.py",
                "insight_generator.py"
            ]
            
            for file_name in core_files:
                file_path = core_dir / file_name
                if file_path.exists():
                    existing_files.append(str(file_path))
        
        return existing_files

    def _analyze_single_file(self, file_path: str) -> Dict[str, Any]:
        """Symbol-level ë‹¨ì¼ íŒŒì¼ ë¶„ì„ (Serena ì—”ì§„)"""
        file_result = {
            "file_path": str(Path(file_path).name),
            "full_path": file_path,
            "line_count": 0,
            "issues": [],
            "symbols": {},
            "complexity": 0
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
                file_result["line_count"] = len(lines)
            
            # Symbol-level ë¶„ì„ (AST íŒŒì‹±)
            try:
                tree = ast.parse(content)
                file_result["symbols"] = self._extract_symbols(tree)
                file_result["complexity"] = self._calculate_complexity(tree)
            except SyntaxError:
                # Python ë¬¸ë²• ì˜¤ë¥˜ íŒŒì¼ì€ íŒ¨í„´ ë§¤ì¹­ë§Œ ìˆ˜í–‰
                pass
            
            # í¬ë¦¬í‹°ì»¬ íŒ¨í„´ ê²€ì‚¬
            for pattern_name, pattern_info in self.critical_patterns.items():
                matches = list(re.finditer(
                    pattern_info["regex"],
                    content,
                    re.MULTILINE | re.IGNORECASE
                ))
                
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    code_line = lines[line_num - 1].strip() if line_num <= len(lines) else ""
                    
                    issue = CodeIssue(
                        file_path=str(Path(file_path).name),
                        line_number=line_num,
                        pattern_name=pattern_name,
                        severity=pattern_info["severity"],
                        message=pattern_info["message"],
                        code_snippet=code_line,
                        solution=pattern_info["solution"],
                        confidence=0.9,
                        impact_score=pattern_info["impact_score"]
                    )
                    file_result["issues"].append(asdict(issue))
            
            # SOLOMOND AI íŠ¹í™” íŒ¨í„´ ê²€ì‚¬
            for pattern_name, pattern_info in self.solomond_patterns.items():
                matches = list(re.finditer(
                    pattern_info["regex"],
                    content,
                    re.MULTILINE | re.IGNORECASE
                ))
                
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    code_line = lines[line_num - 1].strip() if line_num <= len(lines) else ""
                    
                    issue = CodeIssue(
                        file_path=str(Path(file_path).name),
                        line_number=line_num,
                        pattern_name=pattern_name,
                        severity=pattern_info["severity"],
                        message=pattern_info["message"],
                        code_snippet=code_line,
                        solution=pattern_info["solution"],
                        confidence=0.8,
                        impact_score=pattern_info["impact_score"]
                    )
                    file_result["issues"].append(asdict(issue))
                    
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {file_path}: {str(e)}")
            
        return file_result

    def _extract_symbols(self, tree: ast.AST) -> Dict[str, Any]:
        """ASTì—ì„œ ì‹¬ë³¼ ì •ë³´ ì¶”ì¶œ"""
        symbols = {
            "functions": [],
            "classes": [],
            "imports": [],
            "globals": []
        }
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                symbols["functions"].append({
                    "name": node.name,
                    "args": len(node.args.args),
                    "lineno": node.lineno,
                    "decorators": [ast.unparse(d) for d in node.decorator_list]
                })
            elif isinstance(node, ast.ClassDef):
                symbols["classes"].append({
                    "name": node.name,
                    "lineno": node.lineno,
                    "methods": len([n for n in node.body if isinstance(n, ast.FunctionDef)])
                })
            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                symbols["imports"].append({
                    "module": ast.unparse(node),
                    "lineno": node.lineno
                })
        
        return symbols

    def _calculate_complexity(self, tree: ast.AST) -> int:
        """ì½”ë“œ ë³µì¡ë„ ê³„ì‚° (Cyclomatic Complexity ê·¼ì‚¬)"""
        complexity = 1  # ê¸°ë³¸ ë³µì¡ë„
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.Try, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return complexity

    def _categorize_issues(self, analysis_result: Dict[str, Any]):
        """ì´ìŠˆ ë¶„ë¥˜ ë° í†µê³„ ê³„ì‚°"""
        summary = analysis_result["project_summary"]
        
        for issue in analysis_result["issues_found"]:
            summary["total_issues"] += 1
            
            severity = issue["severity"]
            if severity == "critical":
                summary["critical_issues"] += 1
            elif severity == "high":
                summary["high_issues"] += 1
            elif severity == "medium":
                summary["medium_issues"] += 1
            else:
                summary["low_issues"] += 1

    def _assess_system_health(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ í‰ê°€ (0-100ì )"""
        summary = analysis_result["project_summary"]
        
        # ê¸°ë³¸ ì ìˆ˜ì—ì„œ ì´ìŠˆì— ë”°ë¼ ê°ì 
        base_score = 100
        penalty = (
            summary["critical_issues"] * 25 +
            summary["high_issues"] * 15 +
            summary["medium_issues"] * 8 +
            summary["low_issues"] * 3
        )
        
        overall_score = max(base_score - penalty, 0)
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []
        if summary["critical_issues"] > 0:
            recommendations.append(f"ğŸš¨ {summary['critical_issues']}ê°œ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ì¦‰ì‹œ ìˆ˜ì • í•„ìš”")
        
        if summary["high_issues"] > 3:
            recommendations.append(f"âš ï¸ {summary['high_issues']}ê°œ ì¤‘ìš” ì´ìŠˆ ìš°ì„  í•´ê²° ê¶Œì¥")
        
        if overall_score >= 90:
            recommendations.append("âœ… ì‹œìŠ¤í…œì´ ë§¤ìš° ê±´ê°•í•œ ìƒíƒœì…ë‹ˆë‹¤")
        elif overall_score >= 70:
            recommendations.append("ğŸ‘ ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•˜ë‚˜ ëª‡ ê°€ì§€ ê°œì„  í•„ìš”")
        else:
            recommendations.append("âš ï¸ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìœ„í•´ ì¦‰ì‹œ ê°œì„  í•„ìš”")
        
        return {
            "overall_score": overall_score,
            "critical_issues": summary["critical_issues"],
            "high_issues": summary["high_issues"],
            "medium_issues": summary["medium_issues"],
            "low_issues": summary["low_issues"],
            "files_analyzed": summary["files_analyzed"],
            "recommendations": recommendations
        }

    def _generate_recommendations(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        summary = analysis_result["project_summary"]
        
        # í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if summary["critical_issues"] > 0:
            recommendations.append({
                "priority": "critical",
                "title": "í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ì¦‰ì‹œ í•´ê²°",
                "description": f"{summary['critical_issues']}ê°œì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìœ„í˜‘í•©ë‹ˆë‹¤.",
                "solomond_benefit": "ì‹œìŠ¤í…œ í¬ë˜ì‹œ ë°©ì§€, ì•ˆì •ì ì¸ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë³´ì¥",
                "estimated_time": "30ë¶„-2ì‹œê°„"
            })
        
        # ThreadPool ì´ìŠˆ íŠ¹ë³„ ì²˜ë¦¬
        threadpool_issues = [
            issue for issue in analysis_result["issues_found"]
            if "threadpool" in issue["pattern_name"].lower()
        ]
        
        if threadpool_issues:
            recommendations.append({
                "priority": "high",
                "title": "ThreadPool ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ìµœì í™”",
                "description": "ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ì˜ ë³‘ë ¬ ì²˜ë¦¬ ì•ˆì •ì„±ì„ ìœ„í•´ ThreadPool ê´€ë¦¬ ê°œì„ ",
                "solomond_benefit": "ë©€í‹°íŒŒì¼ ë¶„ì„ ì‹œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€, ì•ˆì •ì ì¸ ë°°ì¹˜ ì²˜ë¦¬",
                "estimated_time": "15ë¶„-1ì‹œê°„"
            })
        
        # GPU ë©”ëª¨ë¦¬ ìµœì í™”
        cuda_issues = [
            issue for issue in analysis_result["issues_found"]
            if "cuda" in issue["pattern_name"].lower() or "memory" in issue["pattern_name"].lower()
        ]
        
        if cuda_issues:
            recommendations.append({
                "priority": "medium",
                "title": "GPU ë©”ëª¨ë¦¬ ìµœì í™”",
                "description": "AI ëª¨ë¸ ë¡œë”© ì‹œ GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ ",
                "solomond_benefit": "ëŒ€ìš©ëŸ‰ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì„±ëŠ¥ í–¥ìƒ, OOM ì—ëŸ¬ ë°©ì§€",
                "estimated_time": "20ë¶„-45ë¶„"
            })
        
        # Streamlit ì„±ëŠ¥ ìµœì í™”
        streamlit_issues = [
            issue for issue in analysis_result["issues_found"]
            if "streamlit" in issue["pattern_name"].lower()
        ]
        
        if streamlit_issues:
            recommendations.append({
                "priority": "medium",
                "title": "Streamlit ìºì‹± ìµœì í™”",
                "description": "ëŒ€ì‹œë³´ë“œ ì‘ë‹µ ì†ë„ í–¥ìƒì„ ìœ„í•œ ìºì‹± ì „ëµ ì ìš©",
                "solomond_benefit": "ì‚¬ìš©ì ê²½í—˜ ê°œì„ , AI ëª¨ë¸ ë¡œë”© ì‹œê°„ ë‹¨ì¶•",
                "estimated_time": "10ë¶„-30ë¶„"
            })
        
        return recommendations

    def _generate_solomond_insights(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ íŠ¹í™” ì¸ì‚¬ì´íŠ¸
        conference_files = [
            issue for issue in analysis_result["issues_found"]
            if "conference" in issue["file_path"].lower()
        ]
        
        if conference_files:
            insights.append({
                "level": "enhancement",
                "title": "ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ ìµœì í™” ê¸°íšŒ",
                "message": f"ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ íŒŒì¼ì—ì„œ {len(conference_files)}ê°œ ê°œì„ ì  ë°œê²¬",
                "impact": "ë¶„ì„ ì†ë„ ë° ì •í™•ë„ í–¥ìƒ",
                "action": "ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹± ìµœì í™” ì ìš©"
            })
        
        # ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸
        multimodal_patterns = [
            issue for issue in analysis_result["issues_found"]
            if any(keyword in issue["code_snippet"].lower() 
                  for keyword in ["whisper", "easyocr", "transformers"])
        ]
        
        if multimodal_patterns:
            insights.append({
                "level": "improvement",
                "title": "ë©€í‹°ëª¨ë‹¬ AI ë¦¬ì†ŒìŠ¤ ê´€ë¦¬",
                "message": "AI ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ íŒ¨í„´ ê°œì„ ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¦ëŒ€ ê°€ëŠ¥",
                "impact": "ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì•ˆì •ì„± í–¥ìƒ",
                "action": "ëª…ì‹œì  ëª¨ë¸ ì •ë¦¬ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°•í™”"
            })
        
        # ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸
        if analysis_result["project_summary"]["files_analyzed"] > 0:
            health_score = analysis_result.get("health_assessment", {}).get("overall_score", 0)
            
            if health_score >= 85:
                insights.append({
                    "level": "positive",
                    "title": "ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì•ˆì •ì„± ìš°ìˆ˜",
                    "message": f"ì‹œìŠ¤í…œ ê±´ê°•ë„ {health_score}ì ìœ¼ë¡œ ë§¤ìš° ì•ˆì •ì ì¸ ìƒíƒœ",
                    "impact": "ì•ˆì •ì ì¸ AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ìº˜ë¦°ë” í†µí•©",
                    "action": "í˜„ì¬ í’ˆì§ˆ ìœ ì§€í•˜ë©° ì‹ ê·œ ê¸°ëŠ¥ ê°œë°œ ì§‘ì¤‘"
                })
            else:
                insights.append({
                    "level": "warning",
                    "title": "ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ê°œì„  í•„ìš”",
                    "message": f"ì‹œìŠ¤í…œ ê±´ê°•ë„ {health_score}ì , ì•ˆì •ì„± ê°•í™” í•„ìš”",
                    "impact": "AI ì¸ì‚¬ì´íŠ¸ í’ˆì§ˆ ë° ì‹œìŠ¤í…œ ì‹ ë¢°ì„± í–¥ìƒ",
                    "action": "í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ìš°ì„  í•´ê²° í›„ ì „ì²´ ìµœì í™”"
                })
        
        return insights

    def _check_auto_fix_availability(self, analysis_result: Dict[str, Any]) -> bool:
        """ìë™ ìˆ˜ì • ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        auto_fixable_issues = [
            issue for issue in analysis_result["issues_found"]
            if issue["pattern_name"] in ["threadpool_without_context", "memory_leak_cuda", 
                                        "streamlit_heavy_no_cache", "file_open_no_context"]
        ]
        return len(auto_fixable_issues) > 0

    def _check_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
        status = {
            "streamlit_ports": [],
            "ollama_status": False,
            "key_files_present": {},
            "git_status": {},
            "disk_space_gb": 0
        }
        
        try:
            # í•µì‹¬ íŒŒì¼ ì¡´ì¬ í™•ì¸
            key_files = [
                "conference_analysis_COMPLETE_WORKING.py",
                "solomond_ai_main_dashboard.py",
                "dual_brain_integration.py"
            ]
            
            for file_name in key_files:
                file_path = self.project_root / file_name
                status["key_files_present"][file_name] = file_path.exists()
            
            # Git ìƒíƒœ í™•ì¸
            try:
                git_status = subprocess.run(
                    ["git", "status", "--porcelain"], 
                    capture_output=True, text=True, cwd=self.project_root
                )
                status["git_status"] = {
                    "clean": len(git_status.stdout.strip()) == 0,
                    "modified_files": len(git_status.stdout.strip().split('\n')) if git_status.stdout.strip() else 0
                }
            except:
                status["git_status"] = {"clean": None, "modified_files": 0}
            
            # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
            disk_usage = shutil.disk_usage(self.project_root)
            status["disk_space_gb"] = disk_usage.free // (1024**3)
            
        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬ ì˜¤ë¥˜: {str(e)}")
        
        return status

    def auto_fix_issues(self, analysis_result: Dict[str, Any], create_backups: bool = True) -> Dict[str, Any]:
        """ìë™ ì´ìŠˆ ìˆ˜ì • (Serena ì—”ì§„)"""
        fix_result = {
            "timestamp": datetime.now().isoformat(),
            "fixes_applied": 0,
            "files_modified": [],
            "backups_created": [],
            "errors": [],
            "summary": {}
        }
        
        if not analysis_result.get("auto_fix_available", False):
            fix_result["summary"]["message"] = "ìë™ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤."
            return fix_result
        
        # ìë™ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆë“¤ í•„í„°ë§
        auto_fixable_issues = [
            issue for issue in analysis_result["issues_found"]
            if issue["pattern_name"] in ["threadpool_without_context", "memory_leak_cuda", 
                                        "streamlit_heavy_no_cache", "file_open_no_context"]
        ]
        
        # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
        files_to_fix = {}
        for issue in auto_fixable_issues:
            full_path = None
            for file_path in self._get_priority_files():
                if Path(file_path).name == issue["file_path"]:
                    full_path = file_path
                    break
            
            if full_path and Path(full_path).exists():
                if full_path not in files_to_fix:
                    files_to_fix[full_path] = []
                files_to_fix[full_path].append(issue)
        
        # ê° íŒŒì¼ ìˆ˜ì •
        for file_path, issues in files_to_fix.items():
            try:
                # ë°±ì—… ìƒì„±
                if create_backups:
                    backup_path = self._create_backup(file_path)
                    fix_result["backups_created"].append(backup_path)
                
                # íŒŒì¼ ìˆ˜ì •
                modified = self._apply_auto_fixes(file_path, issues)
                
                if modified:
                    fix_result["fixes_applied"] += len(issues)
                    fix_result["files_modified"].append(file_path)
                    self.logger.info(f"ìë™ ìˆ˜ì • ì™„ë£Œ: {file_path} ({len(issues)}ê°œ ì´ìŠˆ)")
                
            except Exception as e:
                error_msg = f"íŒŒì¼ ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {str(e)}"
                fix_result["errors"].append(error_msg)
                self.logger.error(error_msg)
        
        # ìš”ì•½ ìƒì„±
        fix_result["summary"] = {
            "message": f"ì´ {fix_result['fixes_applied']}ê°œ ì´ìŠˆê°€ {len(fix_result['files_modified'])}ê°œ íŒŒì¼ì—ì„œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "success": fix_result['fixes_applied'] > 0,
            "recommendation": "ìˆ˜ì • í›„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤." if fix_result['fixes_applied'] > 0 else None
        }
        
        return fix_result

    def _create_backup(self, file_path: str) -> str:
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = Path(file_path).name
        backup_name = f"{file_name}.backup_{timestamp}"
        
        backup_dir = self.project_root / "solomond_backups"
        backup_dir.mkdir(exist_ok=True)
        
        backup_path = backup_dir / backup_name
        shutil.copy2(file_path, backup_path)
        
        return str(backup_path)

    def _apply_auto_fixes(self, file_path: str, issues: List[Dict]) -> bool:
        """íŒŒì¼ì— ìë™ ìˆ˜ì • ì ìš©"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        lines = content.split('\n')
        
        # ì´ìŠˆë³„ ìˆ˜ì • ì ìš©
        for issue in issues:
            pattern_name = issue["pattern_name"]
            
            if pattern_name == "threadpool_without_context":
                # ThreadPool context manager ìˆ˜ì •
                pattern = r"(\s*)(executor\s*=\s*ThreadPoolExecutor\([^)]*\))\s*\n"
                replacement = r"\1with ThreadPoolExecutor() as executor:\n\1    # Serena ìë™ ìˆ˜ì •: ì•ˆì „í•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬\n"
                content = re.sub(pattern, replacement, content, flags=re.MULTILINE)
            
            elif pattern_name == "memory_leak_cuda":
                # CUDA ë©”ëª¨ë¦¬ ì •ë¦¬ ì¶”ê°€
                line_num = issue["line_number"]
                if line_num <= len(lines):
                    lines[line_num - 1] += "\n    torch.cuda.empty_cache()  # Serena ìë™ ì¶”ê°€: GPU ë©”ëª¨ë¦¬ ì •ë¦¬"
                    content = '\n'.join(lines)
            
            elif pattern_name == "streamlit_heavy_no_cache":
                # Streamlit ìºì‹œ ë°ì½”ë ˆì´í„° ì¶”ê°€
                line_num = issue["line_number"]
                if line_num > 0 and line_num <= len(lines):
                    indent = len(lines[line_num - 1]) - len(lines[line_num - 1].lstrip())
                    cache_decorator = " " * indent + "@st.cache_data  # Serena ìë™ ì¶”ê°€: ì„±ëŠ¥ ìµœì í™”"
                    lines.insert(line_num - 1, cache_decorator)
                    content = '\n'.join(lines)
            
            elif pattern_name == "file_open_no_context":
                # íŒŒì¼ ì˜¤í”ˆ context manager ìˆ˜ì •
                pattern = r"(\s*)((?:file|f)\s*=\s*open\([^)]+\))\s*\n"
                replacement = r"\1with open(...) as file:\n\1    # Serena ìë™ ìˆ˜ì •: íŒŒì¼ ì•ˆì „ ê´€ë¦¬\n"
                content = re.sub(pattern, replacement, content, flags=re.MULTILINE)
        
        # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ íŒŒì¼ ì €ì¥
        if content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            return True
        
        return False

    def generate_health_report(self, analysis_result: Dict[str, Any]) -> str:
        """ê±´ê°•ë„ ë³´ê³ ì„œ ìƒì„±"""
        health = analysis_result.get("health_assessment", {})
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ê±´ê°•ë„ ë“±ê¸‰ ê²°ì •
        score = health.get("overall_score", 0)
        if score >= 90:
            grade = "ìµœìš°ìˆ˜ ğŸ†"
            emoji = "ğŸ’š"
        elif score >= 80:
            grade = "ìš°ìˆ˜ â­"
            emoji = "ğŸ’š"
        elif score >= 70:
            grade = "ì–‘í˜¸ ğŸ‘"
            emoji = "ğŸ’›"
        elif score >= 60:
            grade = "ë³´í†µ ğŸ‘Œ"
            emoji = "ğŸ§¡"
        else:
            grade = "ì£¼ì˜ í•„ìš” âš ï¸"
            emoji = "â¤ï¸"
        
        report_lines = [
            "# ğŸ¥ SOLOMOND AI ì‹œìŠ¤í…œ ê±´ê°• ì§„ë‹¨ ë³´ê³ ì„œ",
            "",
            f"**ğŸ“… ì§„ë‹¨ ì‹œê°„**: {timestamp}",
            f"**ğŸ¤– ì§„ë‹¨ ì—ì´ì „íŠ¸**: {self.agent_name} v{self.version}",
            f"**ğŸ¯ ì‹œìŠ¤í…œ**: SOLOMOND AI Conference Analysis Platform",
            "",
            f"## {emoji} ì „ì²´ ê±´ê°•ë„: {score}/100 ({grade})",
            "",
            "## ğŸ“Š ìƒì„¸ ì§„ë‹¨ ê²°ê³¼",
            "",
            f"- **ë¶„ì„ëœ íŒŒì¼**: {health.get('files_analyzed', 0)}ê°œ",
            f"- **ğŸš¨ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ**: {health.get('critical_issues', 0)}ê°œ",
            f"- **âš ï¸ ì¤‘ìš” ì´ìŠˆ**: {health.get('high_issues', 0)}ê°œ", 
            f"- **ğŸ“‹ ë³´í†µ ì´ìŠˆ**: {health.get('medium_issues', 0)}ê°œ",
            f"- **â„¹ï¸ ê²½ë¯¸í•œ ì´ìŠˆ**: {health.get('low_issues', 0)}ê°œ",
            "",
            "## ğŸ’¡ ê¶Œì¥ì‚¬í•­",
            ""
        ]
        
        for recommendation in health.get("recommendations", []):
            report_lines.append(f"- {recommendation}")
        
        # SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        insights = analysis_result.get("solomond_specific_insights", [])
        if insights:
            report_lines.extend([
                "",
                "## ğŸ§  SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸",
                ""
            ])
            
            for insight in insights:
                emoji_map = {"positive": "âœ…", "warning": "âš ï¸", "improvement": "ğŸ“ˆ", "enhancement": "ğŸ”§"}
                emoji = emoji_map.get(insight.get("level"), "ğŸ’¡")
                report_lines.extend([
                    f"### {emoji} {insight.get('title', '')}",
                    f"{insight.get('message', '')}",
                    f"**ì˜í–¥**: {insight.get('impact', '')}",
                    f"**ê¶Œì¥ ì¡°ì¹˜**: {insight.get('action', '')}",
                    ""
                ])
        
        # ìë™ ìˆ˜ì • ì •ë³´
        if analysis_result.get("auto_fix_available", False):
            report_lines.extend([
                "## ğŸ”§ ìë™ ìˆ˜ì • ê°€ëŠ¥",
                "",
                "ì¼ë¶€ ì´ìŠˆëŠ” ìë™ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "`manager.auto_fix_issues(analysis_result)` í˜¸ì¶œë¡œ ìë™ ìˆ˜ì •ì„ ì ìš©í•˜ì„¸ìš”.",
                ""
            ])
        
        report_lines.extend([
            "---",
            f"*ì´ ë³´ê³ ì„œëŠ” {self.agent_name}ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"
        ])
        
        return "\n".join(report_lines)

    def get_agent_capabilities(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ì •ë³´ ë°˜í™˜"""
        return {
            "name": self.agent_name,
            "version": self.version,
            "role": "SOLOMOND AI ì‹œìŠ¤í…œ í†µí•© ê°œë°œ ë§¤ë‹ˆì €",
            "serena_integrated": True,
            "core_capabilities": [
                "Symbol-level ì½”ë“œ ë¶„ì„ (AST íŒŒì‹±)",
                "ThreadPool ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ìµœì í™”",
                "GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìë™ íƒì§€",
                "Streamlit ì„±ëŠ¥ ìµœì í™”",
                "SOLOMOND AI íŠ¹í™” ë¶„ì„",
                "ìë™ ì´ìŠˆ ìˆ˜ì • (ë°±ì—… í¬í•¨)",
                "ì‹œìŠ¤í…œ ê±´ê°•ë„ í‰ê°€ (0-100ì )",
                "ì‹¤ì‹œê°„ í”„ë¡œì íŠ¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§"
            ],
            "solomond_specializations": [
                "ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ ìµœì í™”",
                "ë©€í‹°ëª¨ë‹¬ AI ë¦¬ì†ŒìŠ¤ ê´€ë¦¬",
                "ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì•ˆì •ì„±",
                "n8n ì›Œí¬í”Œë¡œìš° í†µí•© ì§€ì›",
                "êµ¬ê¸€ ìº˜ë¦°ë” API ìµœì í™”"
            ],
            "analysis_patterns": len(self.critical_patterns) + len(self.solomond_patterns),
            "auto_fix_patterns": len([p for p in self.critical_patterns.values() if p.get("auto_fixable", False)]),
            "supported_commands": [
                "analyze_codebase() - í†µí•© ì½”ë“œë² ì´ìŠ¤ ë¶„ì„",
                "auto_fix_issues() - ìë™ ì´ìŠˆ ìˆ˜ì •",
                "generate_health_report() - ê±´ê°•ë„ ë³´ê³ ì„œ ìƒì„±",
                "get_agent_capabilities() - ì—ì´ì „íŠ¸ ì •ë³´"
            ]
        }

def main():
    """SOLOMOND Project Manager ì‹¤í–‰ ë°ëª¨"""
    print("ğŸ¤– SOLOMOND AI í†µí•© í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €")
    print("ğŸ”— Serena ì½”ë”© ì—ì´ì „íŠ¸ ì™„ì „ í†µí•© ë²„ì „")
    print("=" * 70)
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = SOLOMONDProjectManager()
    
    # ì—ì´ì „íŠ¸ ì •ë³´ í‘œì‹œ
    capabilities = manager.get_agent_capabilities()
    print(f"ğŸ§  {capabilities['name']} v{capabilities['version']}")
    print(f"ğŸ“‹ ì—­í• : {capabilities['role']}")
    print(f"âš¡ Serena í†µí•©: {'âœ… ì™„ë£Œ' if capabilities['serena_integrated'] else 'âŒ ë¯¸ì™„ë£Œ'}")
    print(f"ğŸ¯ ë¶„ì„ íŒ¨í„´: {capabilities['analysis_patterns']}ê°œ")
    print(f"ğŸ”§ ìë™ ìˆ˜ì • íŒ¨í„´: {capabilities['auto_fix_patterns']}ê°œ")
    
    # í†µí•© ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ì‹¤í–‰
    print(f"\nğŸ“Š SOLOMOND AI í†µí•© ë¶„ì„ ì‹œì‘...")
    analysis_result = manager.analyze_codebase()
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
    summary = analysis_result["project_summary"]
    print(f"ğŸ“ ë¶„ì„ëœ íŒŒì¼: {summary['files_analyzed']}ê°œ")
    print(f"ğŸ“„ ì´ ì½”ë“œ ë¼ì¸: {summary['total_lines']:,}ì¤„")
    print(f"ğŸ” ë°œê²¬ëœ ì´ìŠˆ: {summary['total_issues']}ê°œ")
    
    if summary["critical_issues"] > 0:
        print(f"ğŸš¨ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ: {summary['critical_issues']}ê°œ")
    
    # ê±´ê°•ë„ í‰ê°€
    health = analysis_result.get("health_assessment", {})
    if health:
        score = health.get("overall_score", 0)
        print(f"ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„: {score}/100")
    
    # ìë™ ìˆ˜ì • ê°€ëŠ¥ ì—¬ë¶€
    if analysis_result.get("auto_fix_available", False):
        print(f"ğŸ”§ ìë™ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆ ë°œê²¬!")
    
    # SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸
    insights = analysis_result.get("solomond_specific_insights", [])
    if insights:
        print(f"\nğŸ§  SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ({len(insights)}ê°œ):")
        for i, insight in enumerate(insights[:3], 1):
            emoji_map = {"positive": "âœ…", "warning": "âš ï¸", "improvement": "ğŸ“ˆ", "enhancement": "ğŸ”§"}
            emoji = emoji_map.get(insight.get("level"), "ğŸ’¡")
            print(f"  {i}. {emoji} {insight.get('title', '')}")
    
    # ìµœì í™” ê¶Œì¥ì‚¬í•­
    recommendations = analysis_result.get("optimization_recommendations", [])
    if recommendations:
        print(f"\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­ ({len(recommendations)}ê°œ):")
        for i, rec in enumerate(recommendations[:3], 1):
            priority_emoji = {"critical": "ğŸš¨", "high": "âš ï¸", "medium": "ğŸ“‹"}
            emoji = priority_emoji.get(rec.get("priority"), "ğŸ’¡")
            print(f"  {i}. {emoji} {rec.get('title', '')}")
    
    # ê±´ê°•ë„ ë³´ê³ ì„œ ìƒì„±
    print(f"\nğŸ“‹ ìƒì„¸ ê±´ê°•ë„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    health_report = manager.generate_health_report(analysis_result)
    
    report_file = Path("solomond_health_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(health_report)
    
    print(f"âœ… ê±´ê°•ë„ ë³´ê³ ì„œ ìƒì„±: {report_file}")
    
    # ìë™ ìˆ˜ì • ì‹¤í–‰ (ì‚¬ìš©ì í™•ì¸)
    if analysis_result.get("auto_fix_available", False):
        print(f"\nğŸ¤” ìë™ ìˆ˜ì •ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ", end="")
        user_input = input().strip().lower()
        
        if user_input == 'y':
            print(f"ğŸ”§ ìë™ ìˆ˜ì • ì‹¤í–‰ ì¤‘...")
            fix_result = manager.auto_fix_issues(analysis_result)
            
            print(f"âœ… ìë™ ìˆ˜ì • ì™„ë£Œ!")
            print(f"ğŸ“Š ìˆ˜ì •ëœ ì´ìŠˆ: {fix_result['fixes_applied']}ê°œ")
            print(f"ğŸ“ ìˆ˜ì •ëœ íŒŒì¼: {len(fix_result['files_modified'])}ê°œ")
            
            if fix_result["backups_created"]:
                print(f"ğŸ’¾ ë°±ì—… ìƒì„±: {len(fix_result['backups_created'])}ê°œ")
        else:
            print(f"â„¹ï¸ ìë™ ìˆ˜ì •ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")
    
    print(f"\nğŸ‰ SOLOMOND AI í†µí•© í”„ë¡œì íŠ¸ ë§¤ë‹ˆì € ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“‹ ìƒì„¸ ë‚´ìš©ì€ {report_file}ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()