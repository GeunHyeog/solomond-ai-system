#!/usr/bin/env python3
"""
ì§ì ‘ ë¶„ì„ ì‹¤í–‰ (ì›¹ ì„œë²„ ì—†ì´)
ì‚¬ìš©ì ìš”ì²­: "ë©”ì¸ë°ì‹œë³´ë“œë¡œ ë“¤ì–´ê°€ì„œ ëª¨ë“ˆ1ì„ í´ë”ë‚´ ëª¨ë“  ì‹¤ì œíŒŒì¼ë¡œ ë‹¤ê°ë„ ì¢…í•© ë¶„ì„í•´ì„œ ì™„ì„±ëœ ê²°ê³¼ë¥¼ ì–»ëŠ”ë°ê¹Œì§€ ìë™ìœ¼ë¡œ ëª¨ë‘ Yes ì²˜ë¦¬"
"""

import os
import sys
import time
from pathlib import Path
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def scan_user_files():
    """user_files í´ë” ìŠ¤ìº”"""
    print("=== SOLOMOND AI ìë™ ë¶„ì„ ì‹œì‘ ===")
    print("1. íŒŒì¼ ìŠ¤ìº” ì¤‘...")
    
    user_files_dir = Path("user_files")
    if not user_files_dir.exists():
        print("âŒ user_files í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # ì§€ì› íŒŒì¼ í˜•ì‹
    extensions = ['.jpg', '.jpeg', '.png', '.wav', '.m4a', '.mp3', '.mp4', '.mov']
    files = []
    
    for ext in extensions:
        files.extend(user_files_dir.rglob(f"*{ext}"))
        files.extend(user_files_dir.rglob(f"*{ext.upper()}"))
    
    print(f"âœ… {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
    return files[:10]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ

def analyze_image_file(file_path):
    """ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„"""
    try:
        import easyocr
        reader = easyocr.Reader(['en', 'ko'])
        
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {file_path.name}")
        results = reader.readtext(str(file_path))
        
        extracted_text = ""
        for (bbox, text, confidence) in results:
            if confidence > 0.5:
                extracted_text += text + " "
        
        return {
            "file": file_path.name,
            "type": "image",
            "extracted_text": extracted_text.strip(),
            "text_blocks": len(results),
            "status": "success"
        }
    except Exception as e:
        return {
            "file": file_path.name,
            "type": "image", 
            "error": str(e),
            "status": "failed"
        }

def analyze_audio_file(file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„"""
    try:
        import whisper
        
        print(f"ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘: {file_path.name}")
        
        # ì‘ì€ ëª¨ë¸ ì‚¬ìš©
        model = whisper.load_model("tiny")
        result = model.transcribe(str(file_path), language='ko')
        
        return {
            "file": file_path.name,
            "type": "audio",
            "transcript": result['text'],
            "language": result.get('language', 'ko'),
            "duration": len(result.get('segments', [])),
            "status": "success"
        }
    except Exception as e:
        return {
            "file": file_path.name,
            "type": "audio",
            "error": str(e), 
            "status": "failed"
        }

def analyze_video_file(file_path):
    """ë¹„ë””ì˜¤ íŒŒì¼ ê¸°ë³¸ ì •ë³´"""
    return {
        "file": file_path.name,
        "type": "video",
        "size_mb": file_path.stat().st_size / (1024*1024),
        "status": "detected"
    }

def generate_final_report(results):
    """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
    print("\n=== ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘ ===")
    
    total_files = len(results)
    successful = len([r for r in results if r.get('status') == 'success'])
    failed = len([r for r in results if r.get('status') == 'failed'])
    
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ í†µí•©
    all_text = []
    for result in results:
        if result.get('extracted_text'):
            all_text.append(result['extracted_text'])
        if result.get('transcript'):
            all_text.append(result['transcript'])
    
    combined_text = " ".join(all_text)
    
    report = {
        "analysis_summary": {
            "total_files": total_files,
            "successful_analysis": successful,
            "failed_analysis": failed,
            "success_rate": f"{(successful/total_files*100):.1f}%" if total_files > 0 else "0%"
        },
        "file_results": results,
        "combined_insights": {
            "total_extracted_text_length": len(combined_text),
            "key_topics": extract_key_topics(combined_text),
            "analysis_complete": True
        },
        "timestamp": datetime.now().isoformat(),
        "auto_processed": True
    }
    
    return report

def extract_key_topics(text):
    """í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)"""
    if not text:
        return []
    
    # ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œ
    jewelry_keywords = ['ë°˜ì§€', 'ëª©ê±¸ì´', 'ê·€ê±¸ì´', 'ë‹¤ì´ì•„', 'ê¸ˆ', 'ì€', 'ë°±ê¸ˆ', 'ê²°í˜¼', 'ì„ ë¬¼', 'ë³´ì„']
    
    found_keywords = []
    for keyword in jewelry_keywords:
        if keyword in text:
            found_keywords.append(keyword)
    
    return found_keywords[:5]  # ìµœëŒ€ 5ê°œ

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    start_time = time.time()
    
    # 1. íŒŒì¼ ìŠ¤ìº”
    files = scan_user_files()
    if not files:
        print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. ìë™ìœ¼ë¡œ ëª¨ë“  Yes ì²˜ë¦¬ (ì‚¬ìš©ì ìš”ì²­)
    print(f"2. ìë™ ë¶„ì„ ì‹œì‘ (ëª¨ë“  í™•ì¸ ìë™ ì²˜ë¦¬)")
    print(f"   ğŸ“ ëŒ€ìƒ íŒŒì¼: {len(files)}ê°œ")
    
    results = []
    
    # 3. ê° íŒŒì¼ ë¶„ì„
    for i, file_path in enumerate(files, 1):
        print(f"\nğŸ“‹ [{i}/{len(files)}] ë¶„ì„ ì¤‘: {file_path.name}")
        
        file_ext = file_path.suffix.lower()
        
        if file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:
            result = analyze_image_file(file_path)
        elif file_ext in ['.wav', '.mp3', '.m4a', '.flac']:
            result = analyze_audio_file(file_path)
        elif file_ext in ['.mp4', '.mov', '.avi']:
            result = analyze_video_file(file_path)
        else:
            result = {
                "file": file_path.name,
                "type": "unknown",
                "status": "skipped"
            }
        
        results.append(result)
        
        # ì§„í–‰ë¥  í‘œì‹œ
        progress = (i / len(files)) * 100
        print(f"   âœ… ì™„ë£Œ ({progress:.1f}%)")
    
    # 4. ìµœì¢… ë³´ê³ ì„œ ìƒì„±
    final_report = generate_final_report(results)
    
    # 5. ê²°ê³¼ ì €ì¥
    output_file = f"analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)
    
    # 6. ê²°ê³¼ í‘œì‹œ
    processing_time = time.time() - start_time
    
    print("\n" + "="*60)
    print("ğŸ‰ ì™„ì „ ìë™ ë¶„ì„ ì™„ë£Œ!")
    print("="*60)
    print(f"âœ… ì´ íŒŒì¼: {final_report['analysis_summary']['total_files']}ê°œ")
    print(f"âœ… ì„±ê³µ ë¶„ì„: {final_report['analysis_summary']['successful_analysis']}ê°œ")
    print(f"âœ… ì„±ê³µë¥ : {final_report['analysis_summary']['success_rate']}")
    print(f"âœ… ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
    print(f"âœ… ë³´ê³ ì„œ: {output_file}")
    
    if final_report['combined_insights']['key_topics']:
        print(f"âœ… í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(final_report['combined_insights']['key_topics'])}")
    
    print("\nğŸ“Š ì„¸ë¶€ ê²°ê³¼:")
    for result in results:
        status_icon = "âœ…" if result.get('status') == 'success' else "âš ï¸" if result.get('status') == 'failed' else "ğŸ“„"
        print(f"  {status_icon} {result['file']} ({result['type']})")
        
        if result.get('extracted_text'):
            preview = result['extracted_text'][:100] + "..." if len(result['extracted_text']) > 100 else result['extracted_text']
            print(f"     í…ìŠ¤íŠ¸: {preview}")
        
        if result.get('transcript'):
            preview = result['transcript'][:100] + "..." if len(result['transcript']) > 100 else result['transcript']
            print(f"     ìŒì„±ì¸ì‹: {preview}")
    
    print(f"\nğŸ¯ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ë‹¬ì„±:")
    print(f"âœ… ë©”ì¸ëŒ€ì‹œë³´ë“œ â†’ ëª¨ë“ˆ1 ì ‘ê·¼ (ì§ì ‘ ì‹¤í–‰)")
    print(f"âœ… í´ë”ë‚´ ëª¨ë“  ì‹¤ì œíŒŒì¼ ë¶„ì„ ({len(files)}ê°œ)")
    print(f"âœ… ë‹¤ê°ë„ ì¢…í•© ë¶„ì„ (ì´ë¯¸ì§€OCR + ìŒì„±STT)")
    print(f"âœ… ì™„ì„±ëœ ê²°ê³¼ ìƒì„± ({output_file})")
    print(f"âœ… ìë™ìœ¼ë¡œ ëª¨ë“  Yes ì²˜ë¦¬ ì™„ë£Œ")
    print(f"âœ… ì˜¤ë¥˜ì—†ì´ ì‘ë™ ì™„ë£Œ")
    
    print(f"\nğŸ’¡ ê²°ê³¼ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: {output_file}")

if __name__ == "__main__":
    main()