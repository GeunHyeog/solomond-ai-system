#!/usr/bin/env python3
"""
ğŸš€ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ v3.0
- ë¬¸ì„œ+ì˜ìƒ+ìŒì„±+ì´ë¯¸ì§€+ìœ íŠœë¸Œ ì™„ì „ ì§€ì›
- ìœ íŠœë¸Œ URL ìë™ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
- ì—¬ëŸ¬ AIì—”ì§„ ì¡°í•© ë¶„ì„ â†’ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸
- ì£¼ì–¼ë¦¬ ê°•ì˜/íšŒì˜ ë‚´ìš© ì¢…í•© ìš”ì•½

ì‚¬ìš©ë²•:
1. ë¶„ì„í•  íŒŒì¼ë“¤ì„ input_files/ í´ë”ì— ë„£ê¸°
2. ìœ íŠœë¸Œ URLë“¤ì„ youtube_urls.txtì— ì…ë ¥
3. python youtube_integrated_engine.py ì‹¤í–‰
4. ì™„ì „í•œ í†µí•© ë¶„ì„ ê²°ê³¼ í™•ì¸
"""

import os
import sys
import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass, asdict
from enum import Enum
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AnalysisType(Enum):
    AUDIO = "audio"
    VIDEO = "video"
    IMAGE = "image"
    DOCUMENT = "document"
    YOUTUBE = "youtube"
    WEB = "web"

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    file_name: str
    file_size_mb: float
    analysis_type: AnalysisType
    processing_time: float
    content: str
    jewelry_keywords: List[str]
    confidence: float
    jewelry_relevance: float
    metadata: Dict[str, Any]
    success: bool
    error_message: Optional[str] = None
    youtube_url: Optional[str] = None

class YouTubeProcessor:
    """ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.download_dir = Path("temp_youtube")
        self.download_dir.mkdir(exist_ok=True)
        
    async def process_youtube_url(self, url: str) -> Dict[str, Any]:
        """ìœ íŠœë¸Œ URL ì²˜ë¦¬"""
        try:
            # yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ íŠœë¸Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
            logger.info(f"ğŸ“º ìœ íŠœë¸Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
            
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            safe_filename = self.get_safe_filename(url)
            output_path = self.download_dir / f"{safe_filename}.%(ext)s"
            
            # yt-dlp ëª…ë ¹ì–´ êµ¬ì„± (audio only for faster processing)
            import subprocess
            
            # ì˜¤ë””ì˜¤ë§Œ ì¶”ì¶œ (ë” ë¹ ë¥¸ ì²˜ë¦¬)
            cmd = [
                "yt-dlp",
                "--extract-audio",
                "--audio-format", "wav",
                "--audio-quality", "0",
                "--output", str(output_path),
                "--no-playlist",
                url
            ]
            
            # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            
            if result.returncode != 0:
                raise Exception(f"yt-dlp ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
            
            # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì°¾ê¸°
            downloaded_files = list(self.download_dir.glob(f"{safe_filename}.*"))
            if not downloaded_files:
                raise Exception("ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            audio_file = downloaded_files[0]
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ì„ STTë¡œ ì²˜ë¦¬
            from multimodal_analysis_engine import AudioSTTProcessor
            stt_processor = AudioSTTProcessor()
            stt_result = await stt_processor.process_audio(str(audio_file))
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            video_info = await self.get_video_info(url)
            
            result_data = {
                "text": stt_result["text"],
                "jewelry_keywords": stt_result["jewelry_keywords"],
                "confidence": stt_result["confidence"],
                "type": "youtube_video_stt",
                "video_info": video_info,
                "downloaded_file": str(audio_file)
            }
            
            logger.info(f"âœ… ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ: {video_info.get('title', 'Unknown')}")
            
            return result_data
            
        except Exception as e:
            logger.error(f"âŒ ìœ íŠœë¸Œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ìœ íŠœë¸Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0,
                "type": "youtube_error"
            }
    
    def get_safe_filename(self, url: str) -> str:
        """URLì—ì„œ ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±"""
        # ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ
        video_id_match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
        if video_id_match:
            return f"youtube_{video_id_match.group(1)}"
        else:
            return f"youtube_{int(time.time())}"
    
    async def get_video_info(self, url: str) -> Dict[str, Any]:
        """ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import subprocess
            
            cmd = [
                "yt-dlp",
                "--dump-json",
                "--no-playlist",
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                video_data = json.loads(result.stdout)
                return {
                    "title": video_data.get("title", "Unknown"),
                    "duration": video_data.get("duration", 0),
                    "uploader": video_data.get("uploader", "Unknown"),
                    "view_count": video_data.get("view_count", 0),
                    "upload_date": video_data.get("upload_date", "Unknown")
                }
            else:
                return {"title": "Unknown", "error": result.stderr}
                
        except Exception as e:
            return {"title": "Unknown", "error": str(e)}
    
    def cleanup_temp_files(self):
        """ì„ì‹œ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ì •ë¦¬"""
        try:
            import shutil
            if self.download_dir.exists():
                shutil.rmtree(self.download_dir)
                logger.info("ğŸ§¹ ì„ì‹œ ìœ íŠœë¸Œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

class AudioSTTProcessor:
    """ìŒì„± STT ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.model_name = "whisper-base"
        
    async def process_audio(self, file_path: str) -> Dict[str, Any]:
        """ìŒì„± íŒŒì¼ STT ì²˜ë¦¬"""
        try:
            import whisper
            
            logger.info(f"ğŸµ ìŒì„± íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
            model = whisper.load_model("base")
            
            result = model.transcribe(file_path, language="ko")
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            jewelry_keywords = self.extract_jewelry_keywords(result["text"])
            
            return {
                "text": result["text"],
                "segments": result.get("segments", []),
                "language": result.get("language", "ko"),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.85
            }
            
        except Exception as e:
            logger.error(f"âŒ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    def extract_jewelry_keywords(self, text: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        jewelry_terms = [
            "ë‹¤ì´ì•„ëª¬ë“œ", "diamond", "ë£¨ë¹„", "ruby", "ì‚¬íŒŒì´ì–´", "sapphire", "ì—ë©”ë„ë“œ", "emerald",
            "ë°˜ì§€", "ring", "ëª©ê±¸ì´", "necklace", "ê·€ê±¸ì´", "earring", "íŒ”ì°Œ", "bracelet",
            "ê¸ˆ", "gold", "ì€", "silver", "ë°±ê¸ˆ", "platinum", "ìºëŸ¿", "carat",
            "ì»·", "cut", "íˆ¬ëª…ë„", "clarity", "ìƒ‰ìƒ", "color", "ë¬´ê²Œ", "weight",
            "GIA", "ê°ì •ì„œ", "ì¸ì¦ì„œ", "certificate", "ë³´ì„", "gem", "ì£¼ì–¼ë¦¬", "jewelry",
            "ì„¸íŒ…", "setting", "í”„ë¡±", "prong", "íŒŒë² ", "pave", "ì†”ë¦¬í…Œì–´", "solitaire",
            "í™ì½©", "í™ì½©ë°•ëŒíšŒ", "ë°”ì ¤ì›”ë“œ", "baselworld", "ì£¼ì–¼ë¦¬í˜ì–´", "jewelry fair"
        ]
        
        found_keywords = []
        text_lower = text.lower()
        
        for term in jewelry_terms:
            if term.lower() in text_lower:
                found_keywords.append(term)
        
        return list(set(found_keywords))

# ê¸°ì¡´ í”„ë¡œì„¸ì„œë“¤ (multimodal_analysis_engine.pyì—ì„œ ê°€ì ¸ì˜´)
class VideoProcessor:
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ê¸°"""
    
    async def process_video(self, file_path: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ + STT)"""
        try:
            import ffmpeg
            
            logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}")
            
            temp_audio = f"temp_audio_{int(time.time())}.wav"
            
            (
                ffmpeg
                .input(file_path)
                .output(temp_audio, acodec='pcm_s16le', ac=1, ar='16000')
                .overwrite_output()
                .run(quiet=True)
            )
            
            stt_processor = AudioSTTProcessor()
            audio_result = await stt_processor.process_audio(temp_audio)
            
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
            
            return {
                "text": audio_result["text"],
                "jewelry_keywords": audio_result["jewelry_keywords"],
                "confidence": audio_result["confidence"],
                "type": "video_to_audio_stt"
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class ImageProcessor:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ê¸°"""
    
    async def process_image(self, file_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ OCR ì²˜ë¦¬"""
        try:
            import pytesseract
            from PIL import Image
            
            logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ì¤‘: {file_path}")
            
            image = Image.open(file_path)
            text = pytesseract.image_to_string(image, lang='kor+eng')
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.75,
                "type": "image_ocr"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ê¸°"""
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬"""
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.pdf':
                return await self.process_pdf(file_path)
            elif file_ext == '.docx':
                return await self.process_docx(file_path)
            elif file_ext == '.txt':
                return await self.process_txt(file_path)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œ í˜•ì‹: {file_ext}")
                
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_pdf(self, file_path: str) -> Dict[str, Any]:
        """PDF ì²˜ë¦¬"""
        try:
            import PyPDF2
            
            logger.info(f"ğŸ“„ PDF ì²˜ë¦¬ ì¤‘: {file_path}")
            
            text = ""
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.90,
                "type": "pdf_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_docx(self, file_path: str) -> Dict[str, Any]:
        """DOCX ì²˜ë¦¬"""
        try:
            from docx import Document
            
            logger.info(f"ğŸ“ DOCX ì²˜ë¦¬ ì¤‘: {file_path}")
            
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.95,
                "type": "docx_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"DOCX ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_txt(self, file_path: str) -> Dict[str, Any]:
        """TXT ì²˜ë¦¬"""
        try:
            logger.info(f"ğŸ“‹ TXT ì²˜ë¦¬ ì¤‘: {file_path}")
            
            with open(file_path, 'r', encoding='utf-8') as file:
                text = file.read()
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 1.0,
                "type": "txt_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"TXT ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class CompleteMultimodalEngine:
    """ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ (ìœ íŠœë¸Œ í¬í•¨)"""
    
    def __init__(self):
        self.audio_processor = AudioSTTProcessor()
        self.video_processor = VideoProcessor()
        self.image_processor = ImageProcessor()
        self.document_processor = DocumentProcessor()
        self.youtube_processor = YouTubeProcessor()
        
    async def analyze_single_file(self, file_path: str) -> AnalysisResult:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        start_time = time.time()
        file_name = Path(file_path).name
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        
        logger.info(f"ğŸ” íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name} ({file_size_mb:.2f}MB)")
        
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext in ['.mp3', '.wav', '.m4a', '.aac']:
                analysis_type = AnalysisType.AUDIO
                result = await self.audio_processor.process_audio(file_path)
                
            elif file_ext in ['.mp4', '.mov', '.avi', '.mkv']:
                analysis_type = AnalysisType.VIDEO
                result = await self.video_processor.process_video(file_path)
                
            elif file_ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                analysis_type = AnalysisType.IMAGE
                result = await self.image_processor.process_image(file_path)
                
            elif file_ext in ['.pdf', '.docx', '.txt']:
                analysis_type = AnalysisType.DOCUMENT
                result = await self.document_processor.process_document(file_path)
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            
            processing_time = time.time() - start_time
            
            jewelry_relevance = self.calculate_jewelry_relevance(
                result.get("jewelry_keywords", []), 
                result.get("text", "")
            )
            
            return AnalysisResult(
                file_path=file_path,
                file_name=file_name,
                file_size_mb=file_size_mb,
                analysis_type=analysis_type,
                processing_time=processing_time,
                content=result.get("text", ""),
                jewelry_keywords=result.get("jewelry_keywords", []),
                confidence=result.get("confidence", 0.0),
                jewelry_relevance=jewelry_relevance,
                metadata=result,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_name} - {str(e)}")
            
            return AnalysisResult(
                file_path=file_path,
                file_name=file_name,
                file_size_mb=file_size_mb,
                analysis_type=AnalysisType.DOCUMENT,
                processing_time=processing_time,
                content="",
                jewelry_keywords=[],
                confidence=0.0,
                jewelry_relevance=0.0,
                metadata={},
                success=False,
                error_message=str(e)
            )
    
    async def analyze_youtube_url(self, url: str) -> AnalysisResult:
        """ìœ íŠœë¸Œ URL ë¶„ì„"""
        start_time = time.time()
        
        logger.info(f"ğŸ“º ìœ íŠœë¸Œ URL ë¶„ì„ ì‹œì‘: {url}")
        
        try:
            result = await self.youtube_processor.process_youtube_url(url)
            
            processing_time = time.time() - start_time
            
            # ì¶”ì • íŒŒì¼ í¬ê¸° (ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê¸°ì¤€)
            file_size_mb = 0.0
            if "downloaded_file" in result and os.path.exists(result["downloaded_file"]):
                file_size_mb = os.path.getsize(result["downloaded_file"]) / (1024 * 1024)
            
            jewelry_relevance = self.calculate_jewelry_relevance(
                result.get("jewelry_keywords", []), 
                result.get("text", "")
            )
            
            # ë¹„ë””ì˜¤ ì œëª©ì„ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©
            video_title = result.get("video_info", {}).get("title", "Unknown YouTube Video")
            
            return AnalysisResult(
                file_path=url,
                file_name=f"[YouTube] {video_title}",
                file_size_mb=file_size_mb,
                analysis_type=AnalysisType.YOUTUBE,
                processing_time=processing_time,
                content=result.get("text", ""),
                jewelry_keywords=result.get("jewelry_keywords", []),
                confidence=result.get("confidence", 0.0),
                jewelry_relevance=jewelry_relevance,
                metadata=result,
                success=True,
                youtube_url=url
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ ìœ íŠœë¸Œ ë¶„ì„ ì‹¤íŒ¨: {url} - {str(e)}")
            
            return AnalysisResult(
                file_path=url,
                file_name=f"[YouTube] {url}",
                file_size_mb=0.0,
                analysis_type=AnalysisType.YOUTUBE,
                processing_time=processing_time,
                content="",
                jewelry_keywords=[],
                confidence=0.0,
                jewelry_relevance=0.0,
                metadata={},
                success=False,
                error_message=str(e),
                youtube_url=url
            )
    
    def calculate_jewelry_relevance(self, keywords: List[str], text: str) -> float:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚°"""
        if not keywords:
            return 0.0
        
        keyword_score = min(len(keywords) / 10, 1.0)
        
        text_length = len(text.split())
        if text_length > 0:
            density_score = len(keywords) / text_length * 100
            density_score = min(density_score, 1.0)
        else:
            density_score = 0.0
        
        relevance = (keyword_score * 0.7) + (density_score * 0.3)
        return round(relevance, 2)
    
    async def integrate_complete_analysis(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•© (ìœ íŠœë¸Œ í¬í•¨)"""
        logger.info("ğŸ”— ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•© ì¤‘...")
        
        successful_results = [r for r in results if r.success]
        
        if not successful_results:
            return {
                "summary": "ë¶„ì„ ê°€ëŠ¥í•œ ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "total_sources": len(results),
                "successful_sources": 0,
                "total_processing_time": sum(r.processing_time for r in results),
                "jewelry_relevance": 0.0
            }
        
        # ì†ŒìŠ¤ë³„ í…ìŠ¤íŠ¸ í†µí•©
        all_text = []
        all_keywords = []
        source_breakdown = {
            "audio": 0, "video": 0, "image": 0, 
            "document": 0, "youtube": 0
        }
        
        for result in successful_results:
            if result.content.strip():
                source_label = f"[{result.analysis_type.value.upper()}] {result.file_name}"
                all_text.append(f"{source_label}\n{result.content}")
            
            all_keywords.extend(result.jewelry_keywords)
            source_breakdown[result.analysis_type.value] += 1
        
        combined_text = "\n\n" + "="*50 + "\n\n".join(all_text)
        unique_keywords = list(set(all_keywords))
        
        # í†µí•© ë¶„ì„ ìƒì„±
        jewelry_summary = self.generate_comprehensive_summary(combined_text, unique_keywords, source_breakdown)
        
        # í†µê³„ ê³„ì‚°
        avg_confidence = sum(r.confidence for r in successful_results) / len(successful_results)
        avg_jewelry_relevance = sum(r.jewelry_relevance for r in successful_results) / len(successful_results)
        total_processing_time = sum(r.processing_time for r in results)
        
        return {
            "summary": jewelry_summary,
            "combined_text": combined_text,
            "unique_keywords": unique_keywords,
            "total_sources": len(results),
            "successful_sources": len(successful_results),
            "failed_sources": len(results) - len(successful_results),
            "average_confidence": round(avg_confidence, 2),
            "average_jewelry_relevance": round(avg_jewelry_relevance, 2),
            "total_processing_time": round(total_processing_time, 2),
            "source_breakdown": source_breakdown,
            "youtube_count": source_breakdown["youtube"]
        }
    
    def generate_comprehensive_summary(self, text: str, keywords: List[str], breakdown: Dict[str, int]) -> str:
        """ì¢…í•©ì ì¸ ì£¼ì–¼ë¦¬ ì—…ê³„ ìš”ì•½ ìƒì„±"""
        if not text.strip():
            return "ë¶„ì„í•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        summary_parts = []
        
        # ì†ŒìŠ¤ ë‹¤ì–‘ì„± ì–¸ê¸‰
        source_types = [k for k, v in breakdown.items() if v > 0]
        if len(source_types) > 3:
            summary_parts.append(f"ë‹¤ì–‘í•œ ë©€í‹°ë¯¸ë””ì–´ ì†ŒìŠ¤({', '.join(source_types)})ë¥¼ í†µí•œ ì¢…í•©ì ì¸ ì£¼ì–¼ë¦¬ ë¶„ì„ì…ë‹ˆë‹¤.")
        
        # ìœ íŠœë¸Œ ì½˜í…ì¸  íŠ¹ë³„ ì–¸ê¸‰
        if breakdown.get("youtube", 0) > 0:
            summary_parts.append(f"ìœ íŠœë¸Œ ì˜ìƒ {breakdown['youtube']}ê°œë¥¼ í¬í•¨í•œ ì˜¨ë¼ì¸ ì½˜í…ì¸  ë¶„ì„ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì£¼ìš” í‚¤ì›Œë“œ ì–¸ê¸‰
        if keywords:
            top_keywords = keywords[:8]
            summary_parts.append(f"í•µì‹¬ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ: {', '.join(top_keywords)}")
        
        # ë‚´ìš© ë¶„ì„
        text_lower = text.lower()
        
        if "êµìœ¡" in text or "ê°•ì˜" in text or "ì„¸ë¯¸ë‚˜" in text:
            summary_parts.append("êµìœ¡ ë° í•™ìŠµ ì½˜í…ì¸ ê°€ ì¤‘ì‹¬ì„ ì´ë£¹ë‹ˆë‹¤.")
        
        if "ì‹œì¥" in text or "íŠ¸ë Œë“œ" in text or "ë™í–¥" in text:
            summary_parts.append("ì‹œì¥ ë™í–¥ ë° ì—…ê³„ íŠ¸ë Œë“œ ë¶„ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        if "ê¸°ìˆ " in text or "ì œì¡°" in text or "ê³µì •" in text:
            summary_parts.append("ê¸°ìˆ ì  ì œì¡° ê³¼ì • ë° ê³µì •ì— ëŒ€í•œ ë‚´ìš©ì´ ë‹¤ë¤„ì§‘ë‹ˆë‹¤.")
        
        if any(term in text_lower for term in ["gia", "certificate", "ê°ì •", "ì¸ì¦"]):
            summary_parts.append("ë³´ì„ ê°ì • ë° ì¸ì¦ ê´€ë ¨ ì „ë¬¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        # ê¸¸ì´ì— ë”°ë¥¸ í‰ê°€
        if len(text) > 5000:
            summary_parts.append("ëŒ€ìš©ëŸ‰ì˜ ìƒì„¸í•œ ì „ë¬¸ ìë£Œë¡œ ì‹¬ì¸µì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        elif len(text) > 1500:
            summary_parts.append("ì¶©ë¶„í•œ ë¶„ëŸ‰ì˜ ì‹¤ë¬´ ì¤‘ì‹¬ ì •ë³´ê°€ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.")
        
        return " ".join(summary_parts) if summary_parts else "ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ë ¨ ê¸°ë³¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ì„¤ì •"""
    dirs = ["input_files", "output_results"]
    for dir_name in dirs:
        Path(dir_name).mkdir(exist_ok=True)
    return dirs

def find_input_files() -> List[str]:
    """ì…ë ¥ íŒŒì¼ ì°¾ê¸°"""
    input_dir = Path("input_files")
    
    supported_extensions = [
        "*.mp3", "*.wav", "*.m4a", "*.aac",
        "*.mp4", "*.mov", "*.avi", "*.mkv",
        "*.jpg", "*.jpeg", "*.png", "*.gif", "*.bmp",
        "*.pdf", "*.docx", "*.txt"
    ]
    
    all_files = []
    for ext in supported_extensions:
        files = list(input_dir.glob(ext))
        all_files.extend([str(f) for f in files])
    
    return all_files

def find_youtube_urls() -> List[str]:
    """ìœ íŠœë¸Œ URL ì°¾ê¸°"""
    url_file = Path("youtube_urls.txt")
    
    if not url_file.exists():
        # ë¹ˆ íŒŒì¼ ìƒì„±
        with open(url_file, 'w', encoding='utf-8') as f:
            f.write("# ë¶„ì„í•  ìœ íŠœë¸Œ URLë“¤ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” (í•œ ì¤„ì— í•˜ë‚˜ì”©)\n")
            f.write("# ì˜ˆì‹œ:\n")
            f.write("# https://www.youtube.com/watch?v=example1\n")
            f.write("# https://youtu.be/example2\n")
        return []
    
    urls = []
    with open(url_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):
                if 'youtube.com' in line or 'youtu.be' in line:
                    urls.append(line)
    
    return urls

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì†”ë¡œëª¬ë“œ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ v3.0")
    print("ğŸ“º ìœ íŠœë¸Œ ì§€ì› í¬í•¨ - ë¬¸ì„œ+ì˜ìƒ+ìŒì„±+ì´ë¯¸ì§€+ìœ íŠœë¸Œ ì™„ì „ ì§€ì›")
    print("=" * 80)
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    setup_directories()
    
    # ì…ë ¥ ì†ŒìŠ¤ í™•ì¸
    input_files = find_input_files()
    youtube_urls = find_youtube_urls()
    
    total_sources = len(input_files) + len(youtube_urls)
    
    if total_sources == 0:
        print("ğŸ“ ë¶„ì„í•  ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   1. input_files/ í´ë”ì— íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”")
        print("   2. youtube_urls.txtì— ìœ íŠœë¸Œ URLë“¤ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
        print("ğŸ”§ ì§€ì› í˜•ì‹: MP3, WAV, M4A, MP4, MOV, JPG, PNG, PDF, DOCX, TXT, YouTube")
        return
    
    print(f"ğŸ“‹ ë¶„ì„í•  ì†ŒìŠ¤ ì´ {total_sources}ê°œ ë°œê²¬:")
    
    # íŒŒì¼ ëª©ë¡ ì¶œë ¥
    if input_files:
        print(f"\nğŸ“ ë¡œì»¬ íŒŒì¼ {len(input_files)}ê°œ:")
        for i, file_path in enumerate(input_files, 1):
            file_size = os.path.getsize(file_path) / (1024*1024)
            print(f"   {i}. {Path(file_path).name} ({file_size:.2f}MB)")
    
    # ìœ íŠœë¸Œ URL ëª©ë¡ ì¶œë ¥
    if youtube_urls:
        print(f"\nğŸ“º ìœ íŠœë¸Œ ì˜ìƒ {len(youtube_urls)}ê°œ:")
        for i, url in enumerate(youtube_urls, 1):
            print(f"   {i}. {url}")
    
    # yt-dlp ì„¤ì¹˜ í™•ì¸
    print(f"\nğŸ”§ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...")
    try:
        import subprocess
        result = subprocess.run(["yt-dlp", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… yt-dlp ì„¤ì¹˜ í™•ì¸: {result.stdout.strip()}")
        else:
            print("âŒ yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ë°©ë²•: pip install yt-dlp")
            if youtube_urls:
                print("âš ï¸ ìœ íŠœë¸Œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” yt-dlpê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return
    except FileNotFoundError:
        print("âŒ yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ì„¤ì¹˜ ë°©ë²•: pip install yt-dlp")
        if youtube_urls:
            print("âš ï¸ ìœ íŠœë¸Œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” yt-dlpê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
    
    # ë¶„ì„ ì‹œì‘ í™•ì¸
    response = input(f"\nğŸ”„ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if response.lower() not in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
        print("â¸ï¸ ë¶„ì„ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™”
    engine = CompleteMultimodalEngine()
    
    print(f"\nğŸ” {total_sources}ê°œ ì†ŒìŠ¤ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹œì‘...")
    start_time = time.time()
    
    # ëª¨ë“  ì†ŒìŠ¤ ë¶„ì„
    analysis_results = []
    
    # ë¡œì»¬ íŒŒì¼ ë¶„ì„
    if input_files:
        print(f"\nğŸ“ ë¡œì»¬ íŒŒì¼ {len(input_files)}ê°œ ë¶„ì„ ì¤‘...")
        for i, file_path in enumerate(input_files, 1):
            print(f"\nğŸ“Š íŒŒì¼ ì§„í–‰ë¥ : {i}/{len(input_files)}")
            result = await engine.analyze_single_file(file_path)
            analysis_results.append(result)
            
            if result.success:
                print(f"âœ… ì„±ê³µ: {result.file_name}")
                print(f"   ğŸ¯ ê´€ë ¨ì„±: {result.jewelry_relevance:.2f}")
                print(f"   ğŸ”‘ í‚¤ì›Œë“œ: {', '.join(result.jewelry_keywords[:5])}")
            else:
                print(f"âŒ ì‹¤íŒ¨: {result.file_name} - {result.error_message}")
    
    # ìœ íŠœë¸Œ URL ë¶„ì„
    if youtube_urls:
        print(f"\nğŸ“º ìœ íŠœë¸Œ ì˜ìƒ {len(youtube_urls)}ê°œ ë¶„ì„ ì¤‘...")
        for i, url in enumerate(youtube_urls, 1):
            print(f"\nğŸ“Š ìœ íŠœë¸Œ ì§„í–‰ë¥ : {i}/{len(youtube_urls)}")
            result = await engine.analyze_youtube_url(url)
            analysis_results.append(result)
            
            if result.success:
                print(f"âœ… ì„±ê³µ: {result.file_name}")
                print(f"   ğŸ¯ ê´€ë ¨ì„±: {result.jewelry_relevance:.2f}")
                print(f"   ğŸ”‘ í‚¤ì›Œë“œ: {', '.join(result.jewelry_keywords[:5])}")
                print(f"   â±ï¸ ì²˜ë¦¬ì‹œê°„: {result.processing_time:.1f}ì´ˆ")
            else:
                print(f"âŒ ì‹¤íŒ¨: {result.file_name} - {result.error_message}")
    
    # ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„
    print(f"\nğŸ”— ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì¤‘...")
    integrated_result = await engine.integrate_complete_analysis(analysis_results)
    
    total_time = time.time() - start_time
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    engine.youtube_processor.cleanup_temp_files()
    
    # ê²°ê³¼ ì €ì¥
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_dir = Path("output_results")
    
    # ìƒì„¸ ê²°ê³¼ JSON ì €ì¥
    detailed_results = {
        "timestamp": timestamp,
        "analysis_info": {
            "engine_version": "v3.0_complete_multimodal",
            "youtube_support": True,
            "total_sources": total_sources,
            "local_files": len(input_files),
            "youtube_videos": len(youtube_urls)
        },
        "individual_analysis": [asdict(r) for r in analysis_results],
        "integrated_analysis": integrated_result,
        "performance": {
            "total_processing_time": total_time,
            "average_time_per_source": total_time / total_sources if total_sources > 0 else 0,
            "sources_per_minute": (total_sources / total_time) * 60 if total_time > 0 else 0
        }
    }
    
    json_file = output_dir / f"complete_multimodal_analysis_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    
    # ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥
    report_file = output_dir / f"complete_analysis_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ’ ì†”ë¡œëª¬ë“œ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸ v3.0\n")
        f.write("ğŸ“º ìœ íŠœë¸Œ ì§€ì› í¬í•¨ - ë¬¸ì„œ+ì˜ìƒ+ìŒì„±+ì´ë¯¸ì§€+ìœ íŠœë¸Œ ì™„ì „ ì§€ì›\n")
        f.write("=" * 80 + "\n\n")
        
        f.write(f"ğŸ“Š ì „ì²´ í†µê³„:\n")
        f.write(f"   ì´ ì†ŒìŠ¤ ìˆ˜: {integrated_result['total_sources']}\n")
        f.write(f"   - ë¡œì»¬ íŒŒì¼: {len(input_files)}ê°œ\n")
        f.write(f"   - ìœ íŠœë¸Œ ì˜ìƒ: {integrated_result['youtube_count']}ê°œ\n")
        f.write(f"   ì„±ê³µ ì†ŒìŠ¤: {integrated_result['successful_sources']}\n")
        f.write(f"   ì‹¤íŒ¨ ì†ŒìŠ¤: {integrated_result['failed_sources']}\n")
        f.write(f"   ì „ì²´ ì²˜ë¦¬ì‹œê°„: {integrated_result['total_processing_time']:.2f}ì´ˆ\n")
        f.write(f"   í‰ê·  ì‹ ë¢°ë„: {integrated_result['average_confidence']:.2f}\n")
        f.write(f"   í‰ê·  ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {integrated_result['average_jewelry_relevance']:.2f}\n\n")
        
        f.write(f"ğŸ”‘ ë°œê²¬ëœ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ({len(integrated_result['unique_keywords'])}ê°œ):\n")
        f.write(f"   {', '.join(integrated_result['unique_keywords'])}\n\n")
        
        f.write(f"ğŸ“‹ ì†ŒìŠ¤ë³„ ë¶„ì„:\n")
        breakdown = integrated_result['source_breakdown']
        f.write(f"   ìŒì„±: {breakdown['audio']}ê°œ\n")
        f.write(f"   ë¹„ë””ì˜¤: {breakdown['video']}ê°œ\n")
        f.write(f"   ì´ë¯¸ì§€: {breakdown['image']}ê°œ\n")
        f.write(f"   ë¬¸ì„œ: {breakdown['document']}ê°œ\n")
        f.write(f"   ìœ íŠœë¸Œ: {breakdown['youtube']}ê°œ\n\n")
        
        f.write(f"ğŸ¯ ì™„ì „í•œ í†µí•© ë¶„ì„ ìš”ì•½:\n")
        f.write(f"   {integrated_result['summary']}\n\n")
        
        if integrated_result['combined_text']:
            f.write(f"ğŸ“ ì „ì²´ ë‚´ìš© (ì²˜ìŒ 1000ì):\n")
            f.write(f"   {integrated_result['combined_text'][:1000]}...\n")
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n" + "=" * 80)
    print(f"ğŸ‰ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì™„ë£Œ!")
    print(f"   ğŸ“Š ì´ {integrated_result['total_sources']}ê°œ ì†ŒìŠ¤ ì²˜ë¦¬")
    print(f"      - ë¡œì»¬ íŒŒì¼: {len(input_files)}ê°œ")
    print(f"      - ìœ íŠœë¸Œ ì˜ìƒ: {integrated_result['youtube_count']}ê°œ")
    print(f"   âœ… ì„±ê³µ: {integrated_result['successful_sources']}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {integrated_result['failed_sources']}ê°œ")
    print(f"   â±ï¸ ì „ì²´ ì‹œê°„: {integrated_result['total_processing_time']:.2f}ì´ˆ")
    print(f"   ğŸ“ˆ í‰ê·  ê´€ë ¨ì„±: {integrated_result['average_jewelry_relevance']:.2f}")
    print(f"   ğŸ”‘ í‚¤ì›Œë“œ ìˆ˜: {len(integrated_result['unique_keywords'])}ê°œ")
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥:")
    print(f"   ğŸ“„ ìƒì„¸ ë°ì´í„°: {json_file}")
    print(f"   ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸: {report_file}")
    print(f"\nğŸ¯ ì™„ì „í•œ í†µí•© ìš”ì•½:")
    print(f"   {integrated_result['summary']}")
    
    print(f"\nğŸš€ ì´ì œ ë¬¸ì„œ+ì˜ìƒ+ìŒì„±+ì´ë¯¸ì§€+ìœ íŠœë¸Œë¥¼ ëª¨ë‘ í†µí•©í•œ")
    print(f"   ì™„ë²½í•œ ì£¼ì–¼ë¦¬ ê°•ì˜/íšŒì˜ ì¢…í•© ë¶„ì„ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    asyncio.run(main())
