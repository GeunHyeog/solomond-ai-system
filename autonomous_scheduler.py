#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬ - SOLOMOND AI ììœ¨ì„± ê°•í™” ì‹œìŠ¤í…œ
Autonomous Scheduler for SOLOMOND AI Agent System

í•µì‹¬ ê¸°ëŠ¥:
1. ìë™ íŠ¸ë¦¬ê±° ì¡°ê±´ ëª¨ë‹ˆí„°ë§
2. ì •ê¸° ë¶„ì„ ìŠ¤ì¼€ì¤„ë§
3. ìƒí™© ì¸ì‹ ìë™ ë¶„ì„
4. ììœ¨ì  ì˜ì‚¬ê²°ì •
"""

import os
import json
import time
import schedule
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import threading
import logging

# ë¡œê¹… ì„¤ì • (Windows í˜¸í™˜ì„±)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('autonomous_scheduler.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AutonomousScheduler:
    """SOLOMOND AI ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”"""
        self.config = self._load_config()
        self.is_running = False
        self.last_analysis_time = None
        self.analysis_history_dir = Path("analysis_history")
        self.analysis_history_dir.mkdir(exist_ok=True)
        
        # n8n ì›Œí¬í”Œë¡œìš° ì—”ë“œí¬ì¸íŠ¸
        self.n8n_base_url = "http://localhost:5678/webhook"
        self.master_trigger_url = f"{self.n8n_base_url}/solomond-ai-trigger"
        
        logger.info("SOLOMOND AI ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_config(self) -> Dict[str, Any]:
        """ì„¤ì • ë¡œë“œ"""
        default_config = {
            "autonomous_mode": True,
            "monitoring_intervals": {
                "trend_check": 30,  # 30ë¶„ë§ˆë‹¤ íŠ¸ë Œë“œ í™•ì¸
                "system_health": 15,  # 15ë¶„ë§ˆë‹¤ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
                "data_analysis": 120  # 2ì‹œê°„ë§ˆë‹¤ ë°ì´í„° ë¶„ì„
            },
            "auto_triggers": {
                "industry_news": True,
                "market_analysis": True,
                "competitor_tracking": False,
                "technology_trends": True
            },
            "analysis_thresholds": {
                "min_interval_hours": 1,  # ìµœì†Œ 1ì‹œê°„ ê°„ê²©
                "max_daily_analyses": 10,  # í•˜ë£¨ ìµœëŒ€ 10íšŒ ë¶„ì„
                "priority_boost_keywords": ["ì£¼ì–¼ë¦¬", "ë³´ì„", "AI", "íŠ¸ë Œë“œ", "í˜ì‹ "]
            }
        }
        
        config_file = Path("autonomous_config.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    loaded_config = json.load(f)
                    default_config.update(loaded_config)
            except Exception as e:
                logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        
        return default_config
    
    def start_autonomous_mode(self):
        """ììœ¨ ëª¨ë“œ ì‹œì‘"""
        if self.is_running:
            logger.info("ììœ¨ ëª¨ë“œê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.is_running = True
        logger.info("SOLOMOND AI ììœ¨ ëª¨ë“œ ì‹œì‘")
        
        # ìŠ¤ì¼€ì¤„ ë“±ë¡
        self._register_schedules()
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        scheduler_thread.start()
        
        logger.info("ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬ í™œì„±í™” ì™„ë£Œ")
    
    def _register_schedules(self):
        """ìë™ ìŠ¤ì¼€ì¤„ ë“±ë¡"""
        intervals = self.config["monitoring_intervals"]
        
        # íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§
        schedule.every(intervals["trend_check"]).minutes.do(self._monitor_trends)
        
        # ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸
        schedule.every(intervals["system_health"]).minutes.do(self._check_system_health)
        
        # ì •ê¸° ë°ì´í„° ë¶„ì„
        schedule.every(intervals["data_analysis"]).minutes.do(self._perform_periodic_analysis)
        
        # ë§¤ì¼ ì•„ì¹¨ 9ì‹œ ì¼ì¼ ë³´ê³ ì„œ
        schedule.every().day.at("09:00").do(self._generate_daily_report)
        
        # ë§¤ì£¼ ì›”ìš”ì¼ ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„
        schedule.every().monday.at("10:00").do(self._perform_weekly_analysis)
        
        logger.info("ìë™ ìŠ¤ì¼€ì¤„ ë“±ë¡ ì™„ë£Œ")
    
    def _run_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ë£¨í”„"""
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ í™•ì¸
            except Exception as e:
                logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                time.sleep(60)
    
    def _monitor_trends(self):
        """íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§"""
        logger.info("íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        try:
            # ì—…ê³„ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê²€ìƒ‰
            trend_keywords = ["jewelry AI", "gemstone technology", "smart jewelry", "ì£¼ì–¼ë¦¬ íŠ¸ë Œë“œ"]
            
            for keyword in trend_keywords:
                if self._should_analyze_keyword(keyword):
                    self._trigger_autonomous_analysis({
                        "type": "trend_analysis",
                        "keyword": keyword,
                        "source": "autonomous_trend_monitoring",
                        "priority": "normal",
                        "description": f"ìë™ íŠ¸ë Œë“œ ë¶„ì„: {keyword}"
                    })
                    
        except Exception as e:
            logger.error(f"íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
    
    def _check_system_health(self):
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸"""
        logger.info("ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸")
        
        try:
            health_status = {
                "n8n": self._check_n8n_health(),
                "ollama": self._check_ollama_health(),
                "disk_space": self._check_disk_space(),
                "memory_usage": self._check_memory_usage()
            }
            
            # ë¬¸ì œ ë°œê²¬ ì‹œ ìë™ ëŒ€ì‘
            if not health_status["n8n"]:
                logger.warning("n8n ì„œë¹„ìŠ¤ ë¬¸ì œ ê°ì§€")
                self._handle_service_issue("n8n")
            
            if not health_status["ollama"]:
                logger.warning("Ollama ì„œë¹„ìŠ¤ ë¬¸ì œ ê°ì§€")
                self._handle_service_issue("ollama")
            
            # ê±´ê°•ë„ ë³´ê³ ì„œ ì €ì¥
            self._save_health_report(health_status)
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸ ì˜¤ë¥˜: {e}")
    
    def _perform_periodic_analysis(self):
        """ì •ê¸° ë°ì´í„° ë¶„ì„"""
        logger.info("ì •ê¸° ë°ì´í„° ë¶„ì„ ì‹œì‘")
        
        try:
            # ìµœê·¼ ë¶„ì„ ê°„ê²© í™•ì¸
            if not self._should_perform_analysis():
                logger.info("ë¶„ì„ ê°„ê²© ì¡°ê±´ ë¶ˆë§Œì¡±, ê±´ë„ˆë›°ê¸°")
                return
            
            # ë¶„ì„í•  ë°ì´í„° ì†ŒìŠ¤ ê²°ì •
            analysis_targets = self._identify_analysis_targets()
            
            for target in analysis_targets:
                self._trigger_autonomous_analysis({
                    "type": "periodic_analysis", 
                    "target": target,
                    "source": "autonomous_periodic",
                    "priority": "low",
                    "description": f"ì •ê¸° ìë™ ë¶„ì„: {target['name']}"
                })
                
        except Exception as e:
            logger.error(f"ì •ê¸° ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def _generate_daily_report(self):
        """ì¼ì¼ ë³´ê³ ì„œ ìƒì„±"""
        logger.info("ì¼ì¼ ë³´ê³ ì„œ ìƒì„±")
        
        try:
            # ì–´ì œ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
            yesterday = datetime.now() - timedelta(days=1)
            daily_summary = self._collect_daily_summary(yesterday)
            
            # ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œì— ë³´ê³ ì„œ ìƒì„± ìš”ì²­
            report_request = {
                "type": "daily_report",
                "date": yesterday.strftime("%Y-%m-%d"),
                "summary": daily_summary,
                "source": "autonomous_daily_report",
                "priority": "normal",
                "description": "ìë™ ìƒì„± ì¼ì¼ ë³´ê³ ì„œ"
            }
            
            self._trigger_autonomous_analysis(report_request)
            
        except Exception as e:
            logger.error(f"ì¼ì¼ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    def _perform_weekly_analysis(self):
        """ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„"""
        logger.info("ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘")
        
        try:
            # ì§€ë‚œ ì£¼ ë°ì´í„° ì¢…í•© ë¶„ì„
            weekly_data = self._collect_weekly_data()
            
            analysis_request = {
                "type": "weekly_trends",
                "data": weekly_data,
                "source": "autonomous_weekly_analysis",
                "priority": "high",
                "description": "ì£¼ê°„ íŠ¸ë Œë“œ ì¢…í•© ë¶„ì„"
            }
            
            self._trigger_autonomous_analysis(analysis_request)
            
        except Exception as e:
            logger.error(f"ì£¼ê°„ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def _trigger_autonomous_analysis(self, request_data: Dict[str, Any]):
        """ììœ¨ ë¶„ì„ íŠ¸ë¦¬ê±°"""
        try:
            # n8n ë§ˆìŠ¤í„° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì— ìš”ì²­
            response = requests.post(
                self.master_trigger_url,
                json={
                    **request_data,
                    "autonomous": True,
                    "timestamp": datetime.now().isoformat(),
                    "scheduler_id": f"auto_{int(time.time())}"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                logger.info(f"ììœ¨ ë¶„ì„ íŠ¸ë¦¬ê±° ì„±ê³µ: {request_data['type']}")
                self.last_analysis_time = datetime.now()
            else:
                logger.warning(f"ììœ¨ ë¶„ì„ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {response.status_code}")
                
        except Exception as e:
            logger.error(f"ììœ¨ ë¶„ì„ íŠ¸ë¦¬ê±° ì˜¤ë¥˜: {e}")
    
    def _should_analyze_keyword(self, keyword: str) -> bool:
        """í‚¤ì›Œë“œ ë¶„ì„ í•„ìš”ì„± íŒë‹¨"""
        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œì¸ì§€ í™•ì¸
        priority_keywords = self.config["analysis_thresholds"]["priority_boost_keywords"]
        return any(pk.lower() in keyword.lower() for pk in priority_keywords)
    
    def _should_perform_analysis(self) -> bool:
        """ë¶„ì„ ìˆ˜í–‰ ì¡°ê±´ í™•ì¸"""
        if not self.last_analysis_time:
            return True
        
        min_interval = self.config["analysis_thresholds"]["min_interval_hours"]
        time_diff = datetime.now() - self.last_analysis_time
        
        return time_diff >= timedelta(hours=min_interval)
    
    def _check_n8n_health(self) -> bool:
        """n8n ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get("http://localhost:5678/api/v1/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def _check_ollama_health(self) -> bool:
        """Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def _check_disk_space(self) -> Dict[str, Any]:
        """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸"""
        import shutil
        total, used, free = shutil.disk_usage(".")
        return {
            "total_gb": total // (1024**3),
            "used_gb": used // (1024**3),
            "free_gb": free // (1024**3),
            "usage_percent": (used / total) * 100
        }
    
    def _check_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸"""
        import psutil
        memory = psutil.virtual_memory()
        return {
            "total_gb": memory.total // (1024**3),
            "used_gb": memory.used // (1024**3),
            "available_gb": memory.available // (1024**3),
            "usage_percent": memory.percent
        }
    
    def _handle_service_issue(self, service_name: str):
        """ì„œë¹„ìŠ¤ ë¬¸ì œ ìë™ ëŒ€ì‘"""
        logger.info(f"{service_name} ì„œë¹„ìŠ¤ ë¬¸ì œ ìë™ ëŒ€ì‘ ì‹œì‘")
        # ì¶”í›„ ìë™ ì¬ì‹œì‘ ë¡œì§ êµ¬í˜„
    
    def _save_health_report(self, health_status: Dict[str, Any]):
        """ê±´ê°•ë„ ë³´ê³ ì„œ ì €ì¥"""
        report_file = self.analysis_history_dir / f"health_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": datetime.now().isoformat(),
                "health_status": health_status
            }, f, ensure_ascii=False, indent=2)
    
    def _identify_analysis_targets(self) -> List[Dict[str, Any]]:
        """ë¶„ì„ ëŒ€ìƒ ì‹ë³„"""
        return [
            {"name": "ì—…ê³„ ë‰´ìŠ¤", "type": "news", "priority": "normal"},
            {"name": "ê¸°ìˆ  íŠ¸ë Œë“œ", "type": "technology", "priority": "high"},
            {"name": "ì‹œì¥ ë¶„ì„", "type": "market", "priority": "normal"}
        ]
    
    def _collect_daily_summary(self, date: datetime) -> Dict[str, Any]:
        """ì¼ì¼ ìš”ì•½ ìˆ˜ì§‘"""
        return {
            "date": date.strftime("%Y-%m-%d"),
            "analyses_performed": 0,  # ì‹¤ì œ ë¶„ì„ ìˆ˜ ê³„ì‚°
            "key_insights": [],
            "system_performance": "good"
        }
    
    def _collect_weekly_data(self) -> Dict[str, Any]:
        """ì£¼ê°„ ë°ì´í„° ìˆ˜ì§‘"""
        return {
            "week_start": (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d"),
            "total_analyses": 0,
            "trending_topics": [],
            "performance_metrics": {}
        }
    
    def stop_autonomous_mode(self):
        """ììœ¨ ëª¨ë“œ ì •ì§€"""
        self.is_running = False
        schedule.clear()
        logger.info("ììœ¨ ëª¨ë“œ ì •ì§€ ì™„ë£Œ")
    
    def get_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return {
            "is_running": self.is_running,
            "last_analysis": self.last_analysis_time.isoformat() if self.last_analysis_time else None,
            "scheduled_jobs": len(schedule.jobs),
            "config": self.config
        }

# ìŠ¤íŠ¸ë¦¼ë¦¿ ì¸í„°í˜ì´ìŠ¤
def render_autonomous_dashboard():
    """ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬ ëŒ€ì‹œë³´ë“œ"""
    import streamlit as st
    
    st.title("ğŸ¤– SOLOMOND AI ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬")
    st.markdown("**AI ì—ì´ì „íŠ¸ì˜ ììœ¨ì„± ê°•í™” ì‹œìŠ¤í…œ**")
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
    if 'autonomous_scheduler' not in st.session_state:
        st.session_state.autonomous_scheduler = AutonomousScheduler()
    
    scheduler = st.session_state.autonomous_scheduler
    
    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    status = scheduler.get_status()
    
    with col1:
        status_icon = "ğŸŸ¢" if status["is_running"] else "ğŸ”´"
        st.metric("ììœ¨ ëª¨ë“œ", f"{status_icon} {'í™œì„±í™”' if status['is_running'] else 'ë¹„í™œì„±í™”'}")
    
    with col2:
        st.metric("ìŠ¤ì¼€ì¤„ëœ ì‘ì—…", status["scheduled_jobs"])
    
    with col3:
        last_analysis = status["last_analysis"]
        if last_analysis:
            last_time = datetime.fromisoformat(last_analysis)
            time_ago = datetime.now() - last_time
            st.metric("ë§ˆì§€ë§‰ ë¶„ì„", f"{time_ago.seconds//60}ë¶„ ì „")
        else:
            st.metric("ë§ˆì§€ë§‰ ë¶„ì„", "ì—†ìŒ")
    
    with col4:
        st.metric("ì‹œìŠ¤í…œ ìƒíƒœ", "ì •ìƒ")
    
    # ì œì–´ ë²„íŠ¼
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸš€ ììœ¨ ëª¨ë“œ ì‹œì‘", disabled=status["is_running"]):
            scheduler.start_autonomous_mode()
            st.success("ììœ¨ ëª¨ë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    with col2:
        if st.button("ğŸ›‘ ììœ¨ ëª¨ë“œ ì •ì§€", disabled=not status["is_running"]):
            scheduler.stop_autonomous_mode()
            st.success("ììœ¨ ëª¨ë“œê°€ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    # ì„¤ì • í‘œì‹œ
    st.subheader("âš™ï¸ í˜„ì¬ ì„¤ì •")
    st.json(status["config"])
    
    # ë¡œê·¸ í‘œì‹œ
    st.subheader("ğŸ“‹ ìµœê·¼ ë¡œê·¸")
    if Path("autonomous_scheduler.log").exists():
        with open("autonomous_scheduler.log", 'r', encoding='utf-8') as f:
            logs = f.readlines()[-20:]  # ìµœê·¼ 20ì¤„
            for log in logs:
                st.text(log.strip())

if __name__ == "__main__":
    import streamlit as st
    
    st.set_page_config(
        page_title="ììœ¨ ìŠ¤ì¼€ì¤„ëŸ¬",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    render_autonomous_dashboard()