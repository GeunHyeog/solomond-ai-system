"""
ê°„ë‹¨í•œ ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì‘ë™í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ LLM ì‹œìŠ¤í…œìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬

ì‚¬ìš©ë²•:
1. files/ í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ë“¤ì„ ë„£ê¸°
2. python simple_batch_processor.py ì‹¤í–‰
"""

import os
import asyncio
import glob
from pathlib import Path
import time
import json

def create_files_directory():
    """files ë””ë ‰í† ë¦¬ ìƒì„±"""
    files_dir = Path("files")
    files_dir.mkdir(exist_ok=True)
    print(f"ğŸ“ íŒŒì¼ ë””ë ‰í† ë¦¬ ì¤€ë¹„: {files_dir.absolute()}")
    return files_dir

def find_files_to_process():
    """ì²˜ë¦¬í•  íŒŒì¼ë“¤ ì°¾ê¸°"""
    files_dir = create_files_directory()
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹
    supported_extensions = [
        "*.mp3", "*.wav", "*.m4a", "*.mp4", "*.mov", "*.avi",
        "*.jpg", "*.jpeg", "*.png", "*.gif",
        "*.pdf", "*.docx", "*.txt"
    ]
    
    all_files = []
    for ext in supported_extensions:
        pattern = files_dir / ext
        files = glob.glob(str(pattern))
        all_files.extend(files)
    
    if not all_files:
        print("âš ï¸ files/ í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ì§€ì› í˜•ì‹: MP3, WAV, M4A, MP4, MOV, AVI, JPG, PNG, PDF, DOCX, TXT")
        return []
    
    print(f"ğŸ“‹ ì²˜ë¦¬í•  íŒŒì¼ {len(all_files)}ê°œ ë°œê²¬:")
    for i, file_path in enumerate(all_files, 1):
        file_size = os.path.getsize(file_path) / (1024*1024)  # MB
        print(f"   {i}. {Path(file_path).name} ({file_size:.2f}MB)")
    
    return all_files

async def process_single_file_with_hybrid_llm(file_path):
    """í•˜ì´ë¸Œë¦¬ë“œ LLMìœ¼ë¡œ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
    
    file_name = Path(file_path).name
    file_size = os.path.getsize(file_path) / (1024*1024)
    
    print(f"\nğŸ”„ ì²˜ë¦¬ ì‹œì‘: {file_name} ({file_size:.2f}MB)")
    start_time = time.time()
    
    try:
        # í•˜ì´ë¸Œë¦¬ë“œ LLM ë§¤ë‹ˆì € import
        from core.hybrid_llm_manager import HybridLLMManager
        
        manager = HybridLLMManager()
        
        # íŒŒì¼ íƒ€ì…ë³„ ë°ì´í„° ì¤€ë¹„
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext in ['.mp3', '.wav', '.m4a']:
            input_data = {
                'audio': file_path,
                'text': f'{file_name} ìŒì„± íŒŒì¼ ë¶„ì„',
                'context': 'ì£¼ì–¼ë¦¬ ì—…ê³„ ë°°ì¹˜ ë¶„ì„'
            }
            analysis_type = 'audio_jewelry_analysis'
            
        elif file_ext in ['.mp4', '.mov', '.avi']:
            input_data = {
                'video': file_path,
                'text': f'{file_name} ë™ì˜ìƒ íŒŒì¼ ë¶„ì„',
                'context': 'ì£¼ì–¼ë¦¬ ì—…ê³„ ë°°ì¹˜ ë¶„ì„'
            }
            analysis_type = 'video_jewelry_analysis'
            
        elif file_ext in ['.jpg', '.jpeg', '.png', '.gif']:
            input_data = {
                'image': file_path,
                'text': f'{file_name} ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„',
                'context': 'ì£¼ì–¼ë¦¬ ì—…ê³„ ë°°ì¹˜ ë¶„ì„'
            }
            analysis_type = 'image_jewelry_analysis'
            
        else:
            input_data = {
                'document': file_path,
                'text': f'{file_name} ë¬¸ì„œ íŒŒì¼ ë¶„ì„',
                'context': 'ì£¼ì–¼ë¦¬ ì—…ê³„ ë°°ì¹˜ ë¶„ì„'
            }
            analysis_type = 'document_jewelry_analysis'
        
        # í•˜ì´ë¸Œë¦¬ë“œ LLM ë¶„ì„ ì‹¤í–‰
        result = await manager.analyze_with_best_model(input_data, analysis_type)
        
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ ì •ë¦¬
        analysis_result = {
            'file_name': file_name,
            'file_size_mb': file_size,
            'processing_time': processing_time,
            'selected_model': result.model_type.value,
            'confidence': result.confidence,
            'jewelry_relevance': result.jewelry_relevance,
            'content': result.content,
            'token_usage': result.token_usage,
            'cost': result.cost
        }
        
        print(f"âœ… ì™„ë£Œ: {file_name}")
        print(f"   ğŸ¤– ì„ íƒëœ ëª¨ë¸: {result.model_type.value}")
        print(f"   ğŸ“Š ì‹ ë¢°ë„: {result.confidence:.2f}")
        print(f"   ğŸ’ ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {result.jewelry_relevance:.2f}")
        print(f"   â±ï¸ ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"   ğŸ“ ë¶„ì„ ë‚´ìš©: {result.content[:100]}...")
        
        return analysis_result
        
    except Exception as e:
        processing_time = time.time() - start_time
        error_result = {
            'file_name': file_name,
            'file_size_mb': file_size,
            'processing_time': processing_time,
            'error': str(e),
            'status': 'failed'
        }
        
        print(f"âŒ ì‹¤íŒ¨: {file_name}")
        print(f"   ì˜¤ë¥˜: {str(e)}")
        
        return error_result

def save_results_to_file(results):
    """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # JSON ê²°ê³¼ ì €ì¥
    json_file = results_dir / f"batch_analysis_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥
    report_file = results_dir / f"batch_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ’ ì†”ë¡œëª¬ë“œ í•˜ì´ë¸Œë¦¬ë“œ LLM ë°°ì¹˜ ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 60 + "\n\n")
        
        successful_files = [r for r in results['individual_results'] if 'error' not in r]
        failed_files = [r for r in results['individual_results'] if 'error' in r]
        
        f.write(f"ğŸ“Š ì „ì²´ í†µê³„:\n")
        f.write(f"   - ì´ íŒŒì¼ ìˆ˜: {len(results['individual_results'])}\n")
        f.write(f"   - ì„±ê³µ: {len(successful_files)}ê°œ\n")
        f.write(f"   - ì‹¤íŒ¨: {len(failed_files)}ê°œ\n")
        f.write(f"   - ì „ì²´ ì²˜ë¦¬ì‹œê°„: {results['total_processing_time']:.2f}ì´ˆ\n\n")
        
        if successful_files:
            f.write("âœ… ì„±ê³µí•œ íŒŒì¼ë“¤:\n")
            for result in successful_files:
                f.write(f"\nğŸ“ {result['file_name']}\n")
                f.write(f"   ğŸ¤– ëª¨ë¸: {result.get('selected_model', 'N/A')}\n")
                f.write(f"   ğŸ“Š ì‹ ë¢°ë„: {result.get('confidence', 0):.2f}\n")
                f.write(f"   ğŸ’ ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {result.get('jewelry_relevance', 0):.2f}\n")
                f.write(f"   â±ï¸ ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.2f}ì´ˆ\n")
                f.write(f"   ğŸ“ ë¶„ì„: {result.get('content', 'N/A')[:200]}...\n")
        
        if failed_files:
            f.write("\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\n")
            for result in failed_files:
                f.write(f"\nğŸ“ {result['file_name']}\n")
                f.write(f"   ì˜¤ë¥˜: {result['error']}\n")
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print(f"   ğŸ“„ JSON: {json_file}")
    print(f"   ğŸ“‹ ë¦¬í¬íŠ¸: {report_file}")

async def run_batch_processing():
    """ë°°ì¹˜ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸš€ ì†”ë¡œëª¬ë“œ í•˜ì´ë¸Œë¦¬ë“œ LLM ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # ì²˜ë¦¬í•  íŒŒì¼ ì°¾ê¸°
    files_to_process = find_files_to_process()
    
    if not files_to_process:
        print("\nğŸ“ files/ í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ì„ ë„£ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"\nğŸ”„ {len(files_to_process)}ê°œ íŒŒì¼ ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘...")
    
    start_time = time.time()
    results = []
    
    # ê° íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
    for i, file_path in enumerate(files_to_process, 1):
        print(f"\nğŸ“‹ ì§„í–‰ë¥ : {i}/{len(files_to_process)}")
        
        result = await process_single_file_with_hybrid_llm(file_path)
        results.append(result)
        
        # ì²˜ë¦¬ ê°„ ì ì‹œ ëŒ€ê¸° (ì‹œìŠ¤í…œ ì•ˆì •ì„±)
        if i < len(files_to_process):
            await asyncio.sleep(1)
    
    total_time = time.time() - start_time
    
    # ì „ì²´ ê²°ê³¼ ì •ë¦¬
    batch_results = {
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'total_files': len(files_to_process),
        'total_processing_time': total_time,
        'individual_results': results
    }
    
    # ê²°ê³¼ ì €ì¥
    save_results_to_file(batch_results)
    
    # ìµœì¢… ìš”ì•½
    successful_files = [r for r in results if 'error' not in r]
    failed_files = [r for r in results if 'error' in r]
    
    print(f"\n" + "=" * 60)
    print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   ğŸ“Š ì´ {len(files_to_process)}ê°œ íŒŒì¼ ì²˜ë¦¬")
    print(f"   âœ… ì„±ê³µ: {len(successful_files)}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {len(failed_files)}ê°œ")
    print(f"   â±ï¸ ì „ì²´ ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"   ğŸ“ˆ í‰ê·  ì‹œê°„: {total_time/len(files_to_process):.2f}ì´ˆ/íŒŒì¼")
    
    if successful_files:
        avg_confidence = sum(r.get('confidence', 0) for r in successful_files) / len(successful_files)
        avg_jewelry_relevance = sum(r.get('jewelry_relevance', 0) for r in successful_files) / len(successful_files)
        print(f"   ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")
        print(f"   ğŸ’ í‰ê·  ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {avg_jewelry_relevance:.2f}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # files ë””ë ‰í† ë¦¬ ìƒì„±
    files_dir = create_files_directory()
    
    print("ğŸ’¡ ì‚¬ìš©ë²•:")
    print(f"1. {files_dir} í´ë”ì— ë¶„ì„í•  íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”")
    print("2. ì§€ì› í˜•ì‹: MP3, WAV, M4A, MP4, MOV, AVI, JPG, PNG, PDF, DOCX, TXT")
    print("3. ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”")
    print()
    
    # í˜„ì¬ íŒŒì¼ í™•ì¸
    files_to_process = find_files_to_process()
    
    if files_to_process:
        response = input("ğŸ”„ ì§€ê¸ˆ ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
            asyncio.run(run_batch_processing())
        else:
            print("â¸ï¸ ì²˜ë¦¬ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"â³ íŒŒì¼ì„ {files_dir} í´ë”ì— ë„£ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
