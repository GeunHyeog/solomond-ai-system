#!/usr/bin/env python3
"""
ì†”ë¡œëª¬ë“œ AI v2.4 - ë¸Œë¼ìš°ì € ìë™í™” í†µí•© ë²„ì „
ì‹¤ì œ ë¶„ì„ + ë¸Œë¼ìš°ì € ìë™í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì™„ì „ í†µí•©

ì£¼ìš” ê°œì„ ì‚¬í•­ (v2.4.0):
- ë¸Œë¼ìš°ì € ìë™í™” ì—”ì§„ í†µí•© (Playwright MCP)
- ì‹¤ì‹œê°„ ì£¼ì–¼ë¦¬ ì •ë³´ ê²€ìƒ‰ ë° ê²½ìŸì‚¬ ë¶„ì„
- ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ í†µí•©
- ë³´ì•ˆ ê°•í™” API ì„œë²„ ì¤€ë¹„
- MCP ë„êµ¬ 7ê°œ ì™„ì „ í™œìš©
- ì¢…í•© ì‹œìŠ¤í…œ ë°ëª¨ ë° ì„±ëŠ¥ ê²€ì¦ ì™„ë£Œ
"""

import streamlit as st
import sys
import os
import asyncio
import tempfile
import time
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
from datetime import datetime

# NumPy ì„í¬íŠ¸ (ì˜µì…˜)
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì˜µì…˜)
try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í†µí•© ëª¨ë“ˆ ì„í¬íŠ¸
from utils.logger import get_logger
from config.compute_config import force_cpu_mode, get_compute_config

# ì‹¤ì œ ë¶„ì„ ì—”ì§„ import
try:
    from core.real_analysis_engine import global_analysis_engine, analyze_file_real, create_comprehensive_story_from_sources
    REAL_ANALYSIS_AVAILABLE = True
    print("[SUCCESS] ì‹¤ì œ ë¶„ì„ ì—”ì§„ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    REAL_ANALYSIS_AVAILABLE = False
    print(f"[ERROR] ì‹¤ì œ ë¶„ì„ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ì‹¤ì‹œê°„ ì§„í–‰ ì¶”ì  ë° MCP ìë™ í•´ê²° ì‹œìŠ¤í…œ import
try:
    from core.realtime_progress_tracker import global_progress_tracker, RealtimeProgressTracker
    from core.mcp_auto_problem_solver import global_mcp_solver, MCPAutoProblemSolver
    from core.youtube_realtime_processor import global_youtube_realtime_processor
    ADVANCED_MONITORING_AVAILABLE = True
    YOUTUBE_REALTIME_AVAILABLE = True
    print("[SUCCESS] ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
    print("[SUCCESS] YouTube ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    ADVANCED_MONITORING_AVAILABLE = False
    YOUTUBE_REALTIME_AVAILABLE = False
    print(f"[ERROR] ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ import
try:
    from core.large_file_handler import large_file_handler
    LARGE_FILE_HANDLER_AVAILABLE = True
    print("[SUCCESS] ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    LARGE_FILE_HANDLER_AVAILABLE = False
    print(f"[ERROR] ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ë¸Œë¼ìš°ì € ìë™í™” ë° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ import (v2.4)
try:
    from core.browser_automation_engine import BrowserAutomationEngine
    from core.mcp_browser_integration import get_mcp_browser_integration
    from core.realtime_audio_streaming_engine import RealtimeAudioStreamingEngine
    from core.security_api_server import SecurityAPIServer, SecurityConfig
    BROWSER_AUTOMATION_AVAILABLE = True
    MCP_BROWSER_AVAILABLE = True
    REALTIME_STREAMING_AVAILABLE = True
    SECURITY_API_AVAILABLE = True
    print("[SUCCESS] ë¸Œë¼ìš°ì € ìë™í™” ì—”ì§„ ë¡œë“œ ì™„ë£Œ")
    print("[SUCCESS] MCP ë¸Œë¼ìš°ì € í†µí•© ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
    print("[SUCCESS] ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì—”ì§„ ë¡œë“œ ì™„ë£Œ")
    print("[SUCCESS] ë³´ì•ˆ API ì„œë²„ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    BROWSER_AUTOMATION_AVAILABLE = False
    MCP_BROWSER_AVAILABLE = False
    REALTIME_STREAMING_AVAILABLE = False
    SECURITY_API_AVAILABLE = False
    print(f"[ERROR] v2.4 í™•ì¥ ê¸°ëŠ¥ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ì›¹ ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ import
try:
    from core.web_data_integration import get_web_data_integration
    WEB_DATA_INTEGRATION_AVAILABLE = True
    print("[SUCCESS] ì›¹ ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    WEB_DATA_INTEGRATION_AVAILABLE = False
    print(f"[ERROR] ì›¹ ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ import
try:
    from core.lecture_content_compiler import compile_comprehensive_lecture
    LECTURE_COMPILER_AVAILABLE = True
    print("[SUCCESS] ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    LECTURE_COMPILER_AVAILABLE = False
    print(f"[ERROR] ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from core.performance_monitor import global_performance_monitor, get_system_performance, get_current_success_rate
    PERFORMANCE_MONITOR_AVAILABLE = True
    print("[SUCCESS] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    PERFORMANCE_MONITOR_AVAILABLE = False
    print(f"[ERROR] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ê¸°ì¡´ ëª¨ë“ˆë“¤
try:
    from core.hybrid_llm_manager_v23 import HybridLLMManager
    HYBRID_LLM_AVAILABLE = True
except ImportError as e:
    HYBRID_LLM_AVAILABLE = False
    print(f"[ERROR] Hybrid LLM Manager ë¡œë“œ ì‹¤íŒ¨: {e}")

# ğŸ¯ MCP ìë™ í†µí•© ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from mcp_auto_integration_wrapper import smart_mcp_enhance, enhance_result_with_mcp, get_mcp_usage_stats
    MCP_AUTO_INTEGRATION_AVAILABLE = True
    print("âœ… MCP ìë™ í†µí•© ì‹œìŠ¤í…œ í™œì„±í™”")
except ImportError as e:
    MCP_AUTO_INTEGRATION_AVAILABLE = False
    print(f"âš ï¸ MCP ìë™ í†µí•© ì‹œìŠ¤í…œ ë¹„í™œì„±í™”: {e}")
    
    # í´ë°± í•¨ìˆ˜ë“¤
    def smart_mcp_enhance(func):
        return func
    
    async def enhance_result_with_mcp(request, result, context=None):
        return result
    
    def get_mcp_usage_stats():
        return {"status": "unavailable"}
    HYBRID_LLM_AVAILABLE = True
except ImportError:
    HYBRID_LLM_AVAILABLE = False
    
# Streamlit ì„¤ì •
st.set_page_config(
    page_title="ì†”ë¡œëª¬ë“œ AI v2.4 - ë¸Œë¼ìš°ì € ìë™í™” í†µí•©",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded"
)

def convert_numpy_types(obj):
    """NumPy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif NUMPY_AVAILABLE:
        # NumPyê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ NumPy íƒ€ì… ì²´í¬
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
    
    # NumPyê°€ ì—†ê±°ë‚˜ ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    return obj

class SolomondRealAnalysisUI:
    """ì†”ë¡œëª¬ë“œ AI v2.4 ë¸Œë¼ìš°ì € ìë™í™” í†µí•© UI - í™•ì¥ëœ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self):
        self.setup_logging()
        self.analysis_engine = global_analysis_engine if REAL_ANALYSIS_AVAILABLE else None
        
        # v2.4 ì‹ ê·œ ì—”ì§„ë“¤ ì´ˆê¸°í™”
        self.browser_engine = BrowserAutomationEngine() if BROWSER_AUTOMATION_AVAILABLE else None
        self.mcp_browser = get_mcp_browser_integration() if MCP_BROWSER_AVAILABLE else None
        self.streaming_engine = RealtimeAudioStreamingEngine() if REALTIME_STREAMING_AVAILABLE else None
        self.api_server = SecurityAPIServer() if SECURITY_API_AVAILABLE else None
        self.web_data_integration = get_web_data_integration() if WEB_DATA_INTEGRATION_AVAILABLE else None
        
        self.session_stats = {
            "files_analyzed": 0,
            "total_processing_time": 0,
            "successful_analyses": 0,
            "session_start": datetime.now()
        }
        
        # 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
        self._init_session_state()
        
        # ìºì‹œ ë° ì„±ëŠ¥ ìµœì í™” ê´€ë ¨
        if 'ui_cache' not in st.session_state:
            st.session_state.ui_cache = {}
        if 'last_update_time' not in st.session_state:
            st.session_state.last_update_time = {}
    
    def _init_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì¡°ê±´ë¶€ ì‹¤í–‰ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”)"""
        default_states = {
            'workflow_step': 1,
            'project_info': {},
            'uploaded_files_data': [],
            'analysis_results': [],
            'final_report': None,
            'ui_preferences': {
                'theme': 'light',
                'animations_enabled': True,
                'compact_mode': False
            }
        }
        
        for key, default_value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = default_value
    
    @st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ
    def _get_system_info():
        """ì‹œìŠ¤í…œ ì •ë³´ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)"""
        return {
            "cpu_count": os.cpu_count(),
            "available_models": {
                "whisper": REAL_ANALYSIS_AVAILABLE,
                "easyocr": REAL_ANALYSIS_AVAILABLE,
                "transformers": REAL_ANALYSIS_AVAILABLE
            },
            "large_file_support": LARGE_FILE_HANDLER_AVAILABLE
        }
    
    def should_update_component(self, component_id: str, force_update: bool = False):
        """ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸ í•„ìš”ì„± í™•ì¸ (ë¶ˆí•„ìš”í•œ ì¬ë Œë”ë§ ë°©ì§€)"""
        if force_update:
            st.session_state.last_update_time[component_id] = time.time()
            return True
        
        current_time = time.time()
        last_update = st.session_state.last_update_time.get(component_id, 0)
        
        # 1ì´ˆ ì´ë‚´ ì¤‘ë³µ ì—…ë°ì´íŠ¸ ë°©ì§€
        if current_time - last_update < 1.0:
            return False
        
        st.session_state.last_update_time[component_id] = current_time
        return True
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = get_logger(__name__)
    
    def setup_custom_css(self):
        """ê°œì„ ëœ CSS ìŠ¤íƒ€ì¼ ì ìš©"""
        st.markdown("""
        <style>
        /* ë©”ì¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
        .main-container {
            padding: 1rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 10px;
            margin-bottom: 1rem;
            color: white;
        }
        
        /* ì›Œí¬í”Œë¡œìš° ì§„í–‰ë°” ìŠ¤íƒ€ì¼ */
        .workflow-progress {
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 50px;
            padding: 10px 20px;
            margin: 20px 0;
            backdrop-filter: blur(10px);
        }
        
        .workflow-step {
            padding: 8px 16px;
            border-radius: 25px;
            font-weight: 600;
            text-align: center;
            transition: all 0.3s ease;
        }
        
        .workflow-step.current {
            background: #4CAF50;
            color: white;
            transform: scale(1.1);
            box-shadow: 0 4px 15px rgba(76, 175, 80, 0.4);
        }
        
        .workflow-step.completed {
            background: #2196F3;
            color: white;
        }
        
        .workflow-step.pending {
            background: rgba(255, 255, 255, 0.2);
            color: #ccc;
        }
        
        /* íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­ ê°œì„  */
        .upload-area {
            border: 2px dashed #667eea;
            border-radius: 10px;
            padding: 2rem;
            text-align: center;
            background: linear-gradient(45deg, #f8f9ff, #e8f0ff);
            transition: all 0.3s ease;
        }
        
        .upload-area:hover {
            border-color: #4CAF50;
            background: linear-gradient(45deg, #f0f8f0, #e8f5e8);
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(76, 175, 80, 0.15);
        }
        
        /* ì§„í–‰ë¥  í‘œì‹œ ê°œì„  */
        .progress-container {
            background: rgba(255, 255, 255, 0.9);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }
        
        .progress-text {
            font-size: 16px;
            font-weight: 600;
            color: #333;
            margin-bottom: 10px;
        }
        
        /* ì—ëŸ¬ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ ê°œì„  */
        .error-container {
            background: linear-gradient(135deg, #ff6b6b, #ff8e8e);
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            color: white;
            border-left: 5px solid #ff4757;
        }
        
        .warning-container {
            background: linear-gradient(135deg, #ffa726, #ffb74d);
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            color: white;
            border-left: 5px solid #ff9800;
        }
        
        .success-container {
            background: linear-gradient(135deg, #4CAF50, #66BB6A);
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            color: white;
            border-left: 5px solid #2E7D32;
        }
        
        .info-container {
            background: linear-gradient(135deg, #2196F3, #42A5F5);
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            color: white;
            border-left: 5px solid #1976D2;
        }
        
        /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
        .stButton > button {
            border-radius: 25px;
            border: none;
            padding: 12px 24px;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }
        
        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
        }
        
        /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
        .info-card {
            background: white;
            border-radius: 15px;
            padding: 20px;
            margin: 15px 0;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            border-left: 5px solid #667eea;
            transition: all 0.3s ease;
        }
        
        .info-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 30px rgba(102, 126, 234, 0.15);
        }
        
        /* ë°˜ì‘í˜• ë””ìì¸ */
        @media (max-width: 768px) {
            .workflow-progress {
                flex-direction: column;
                gap: 10px;
            }
            
            .workflow-step {
                width: 100%;
            }
            
            .main-container {
                padding: 0.5rem;
            }
        }
        
        /* ì• ë‹ˆë©”ì´ì…˜ */
        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .slide-in {
            animation: slideIn 0.5s ease-out;
        }
        
        @keyframes pulse {
            0% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.05);
            }
            100% {
                transform: scale(1);
            }
        }
        
        .pulse {
            animation: pulse 2s infinite;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def show_enhanced_message(self, message_type: str, title: str, content: str, solutions: List[str] = None):
        """ê°œì„ ëœ ë©”ì‹œì§€ í‘œì‹œ í•¨ìˆ˜"""
        container_class = f"{message_type}-container"
        
        if message_type == "error":
            icon = "âŒ"
        elif message_type == "warning":
            icon = "âš ï¸"
        elif message_type == "success":
            icon = "âœ…"
        elif message_type == "info":
            icon = "ğŸ’¡"
        else:
            icon = "ğŸ“Œ"
        
        message_html = f"""
        <div class="{container_class} slide-in">
            <h4>{icon} {title}</h4>
            <p>{content}</p>
        """
        
        if solutions:
            message_html += "<h5>ğŸ’¡ í•´ê²° ë°©ë²•:</h5><ul>"
            for solution in solutions[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í‘œì‹œ
                message_html += f"<li>{solution}</li>"
            message_html += "</ul>"
        
        message_html += "</div>"
        
        st.markdown(message_html, unsafe_allow_html=True)
    
    def show_real_progress_only(self, current: int, total: int, message: str, details: str = "", force_display: bool = False):
        """ì‹¤ì œ ì§„í–‰ë¥ ë§Œ í‘œì‹œ - ê°€ì§œ ì§„í–‰ë¥  ì™„ì „ ì œê±°"""
        # ì‹¤ì œ ì²˜ë¦¬ê°€ ì•„ë‹ˆê³  ê°•ì œ í‘œì‹œê°€ ì•„ë‹ˆë©´ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        if not force_display and current == 0:
            return st.info(f"â³ {message} - ë¶„ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...")
        
        # ì‹¤ì œ ì§„í–‰ë¥ ë§Œ ê³„ì‚°
        progress_percent = current / total if total > 0 else 0
        
        # ì‹¤ì œ ì§„í–‰ë¥ ì´ 0%ë©´ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ë¬´í•œë£¨í”„ ë°©ì§€)
        if progress_percent == 0 and not force_display:
            return st.info(f"â³ {message}")
            
        progress_html = f"""
        <div class="progress-container slide-in">
            <div class="progress-text">âœ… {message}</div>
            <div style="background: #e0e0e0; border-radius: 10px; overflow: hidden;">
                <div style="
                    width: {progress_percent * 100:.1f}%; 
                    height: 20px; 
                    background: linear-gradient(90deg, #4CAF50, #66BB6A);
                    transition: width 0.3s ease;
                    border-radius: 10px;
                "></div>
            </div>
            <div style="
                display: flex; 
                justify-content: space-between; 
                margin-top: 10px;
                font-size: 14px;
                color: #666;
            ">
                <span>ì‹¤ì œ ì™„ë£Œ: {current}/{total}</span>
                <span>{progress_percent * 100:.1f}%</span>
            </div>
            {f'<div style="margin-top: 10px; font-size: 12px; color: #888;">{details}</div>' if details else ''}
        </div>
        """
        
        return st.markdown(progress_html, unsafe_allow_html=True)
    
    def show_realtime_analysis_timer(self):
        """ì‹¤ì‹œê°„ ë¶„ì„ ê²½ê³¼ ì‹œê°„ í‘œì‹œ"""
        import time
        import datetime
        
        if not hasattr(st.session_state, 'analysis_start_time') or not st.session_state.analysis_start_time:
            return
        
        current_time = time.time()
        elapsed_seconds = int(current_time - st.session_state.analysis_start_time)
        
        # ì‹œê°„ í¬ë§·íŒ…
        hours = elapsed_seconds // 3600
        minutes = (elapsed_seconds % 3600) // 60
        seconds = elapsed_seconds % 60
        
        if hours > 0:
            elapsed_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"
        else:
            elapsed_str = f"{minutes:02d}:{seconds:02d}"
        
        # ë¶„ì„ ìƒíƒœ í‘œì‹œ
        status = st.session_state.get('analysis_status', 'ì¤€ë¹„ ì¤‘')
        start_time_str = datetime.datetime.fromtimestamp(st.session_state.analysis_start_time).strftime("%H:%M:%S")
        
        # ì‹¤ì‹œê°„ íƒ€ì´ë¨¸ HTML
        timer_html = f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        ">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <div>
                    <div style="font-size: 16px; font-weight: bold;">ğŸ• ì‹¤ì‹œê°„ ë¶„ì„ íƒ€ì´ë¨¸</div>
                    <div style="font-size: 12px; opacity: 0.9;">ì‹œì‘ ì‹œê°„: {start_time_str}</div>
                </div>
                <div style="text-align: right;">
                    <div style="font-size: 24px; font-weight: bold; font-family: 'Courier New', monospace;">
                        {elapsed_str}
                    </div>
                    <div style="font-size: 12px; opacity: 0.9;">ìƒíƒœ: {status}</div>
                </div>
            </div>
        </div>
        """
        
        return timer_html
    

    def render_comprehensive_analysis(self):
        """ì¢…í•© ìƒí™© ë¶„ì„ í˜ì´ì§€"""
        st.header("ğŸ¯ ì¢…í•© ìƒí™© ë¶„ì„")
        st.markdown("**user_files í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ í•˜ë‚˜ì˜ ìƒí™©ìœ¼ë¡œ í†µí•© ë¶„ì„**")
        
        # ì´ˆê¸°í™”
        if 'comprehensive_analysis_complete' not in st.session_state:
            st.session_state.comprehensive_analysis_complete = False
        if 'comprehensive_results' not in st.session_state:
            st.session_state.comprehensive_results = None
        
        # ì„¤ì •
        with st.sidebar:
            st.subheader("ğŸ”§ ì¢…í•© ë¶„ì„ ì„¤ì •")
            max_audio_size = st.slider("ìµœëŒ€ ì˜¤ë””ì˜¤ í¬ê¸° (MB)", 1, 50, 20)
            max_image_size = st.slider("ìµœëŒ€ ì´ë¯¸ì§€ í¬ê¸° (MB)", 1, 20, 10)
            include_videos = st.checkbox("ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° í¬í•¨", value=True)
        
        # 1. íŒŒì¼ ë°œê²¬
        st.subheader("ğŸ“ ìƒí™© íŒŒì¼ ë°œê²¬")
        
        if st.button("ğŸ” user_files í´ë” íƒìƒ‰", type="primary"):
            with st.spinner("íŒŒì¼ íƒìƒ‰ ì¤‘..."):
                files = self._discover_user_files()
            
            if files:
                st.success(f"âœ… {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
                
                # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜
                audio_files = [f for f in files if f['ext'] in ['.m4a', '.wav', '.mp3']]
                image_files = [f for f in files if f['ext'] in ['.jpg', '.jpeg', '.png']]
                video_files = [f for f in files if f['ext'] in ['.mov', '.mp4']]
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸµ ì˜¤ë””ì˜¤", len(audio_files))
                with col2:
                    st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€", len(image_files))
                with col3:
                    st.metric("ğŸ¬ ë¹„ë””ì˜¤", len(video_files))
                
                # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ëª©ë¡"):
                    for file_info in files:
                        st.write(f"- **{file_info['name']}** ({file_info['size_mb']:.1f}MB) - {file_info['timestamp']}")
                
                st.session_state.discovered_files = files
            else:
                st.warning("âš ï¸ user_files í´ë”ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 2. ì¢…í•© ë¶„ì„ ì‹¤í–‰
        if 'discovered_files' in st.session_state:
            st.subheader("ğŸ¯ ì¢…í•© ë¶„ì„ ì‹¤í–‰")
            
            if st.button("ğŸš€ ëª¨ë“  íŒŒì¼ í†µí•© ë¶„ì„ ì‹œì‘", type="primary"):
                files = st.session_state.discovered_files
                
                st.info(f"ğŸ“Š {len(files)}ê°œ íŒŒì¼ì˜ ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ê²°ê³¼ ì €ì¥ìš©
                comprehensive_results = {
                    'audio_results': [],
                    'image_results': [],
                    'video_results': [],
                    'timeline': [],
                    'comprehensive_story': ''
                }
                
                total_files = len(files)
                
                # íŒŒì¼ë³„ ìˆœì°¨ ë¶„ì„
                for i, file_info in enumerate(files):
                    progress = (i + 1) / total_files
                    progress_bar.progress(progress)
                    status_text.text(f"ë¶„ì„ ì¤‘: {file_info['name']} ({i+1}/{total_files})")
                    
                    try:
                        result = self._analyze_single_file_comprehensive(file_info, max_audio_size, max_image_size)
                        
                        if result:
                            if result['type'] == 'audio':
                                comprehensive_results['audio_results'].append(result)
                            elif result['type'] == 'image':
                                comprehensive_results['image_results'].append(result)
                            elif result['type'] == 'video':
                                comprehensive_results['video_results'].append(result)
                            
                            comprehensive_results['timeline'].append({
                                'timestamp': file_info['timestamp'],
                                'file': file_info['name'],
                                'type': result['type'],
                                'content': result.get('content', '')[:200]
                            })
                    
                    except Exception as e:
                        st.error(f"âŒ {file_info['name']} ë¶„ì„ ì‹¤íŒ¨: {str(e)[:100]}")
                        continue
                
                # ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„±
                comprehensive_results['comprehensive_story'] = self._generate_comprehensive_story(comprehensive_results)
                
                st.session_state.comprehensive_results = comprehensive_results
                st.session_state.comprehensive_analysis_complete = True
                
                progress_bar.progress(1.0)
                status_text.text("âœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
                
                st.success("ğŸ‰ ëª¨ë“  íŒŒì¼ì˜ ì¢…í•© ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        # 3. ê²°ê³¼ í‘œì‹œ
        if st.session_state.comprehensive_analysis_complete and st.session_state.comprehensive_results:
            self._display_comprehensive_results(st.session_state.comprehensive_results)
    
    def _discover_user_files(self):
        """user_files í´ë”ì—ì„œ íŒŒì¼ ë°œê²¬"""
        user_files = Path("user_files")
        all_files = []
        
        if user_files.exists():
            for file_path in user_files.rglob("*"):
                if file_path.is_file() and file_path.name != "README.md":
                    try:
                        stat = file_path.stat()
                        file_info = {
                            'path': str(file_path),
                            'name': file_path.name,
                            'size_mb': stat.st_size / 1024 / 1024,
                            'timestamp': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M'),
                            'ext': file_path.suffix.lower()
                        }
                        all_files.append(file_info)
                    except Exception:
                        continue
        
        # ì‹œê°„ìˆœ ì •ë ¬
        all_files.sort(key=lambda x: x['timestamp'])
        return all_files
    
    def _analyze_single_file_comprehensive(self, file_info, max_audio_size, max_image_size):
        """ë‹¨ì¼ íŒŒì¼ ì¢…í•© ë¶„ì„"""
        ext = file_info['ext']
        
        try:
            if ext in ['.m4a', '.wav', '.mp3']:
                # ì˜¤ë””ì˜¤ ë¶„ì„
                if file_info['size_mb'] <= max_audio_size:
                    # ê¸°ì¡´ ë¶„ì„ ì—”ì§„ í™œìš©
                    if REAL_ANALYSIS_AVAILABLE:
                        result = analyze_file_real(
                            file_info['path'],
                            "audio",
                            language="ko"
                        )
                        
                        if result and result.get('success'):
                            return {
                                'type': 'audio',
                                'file': file_info['name'],
                                'content': result.get('stt_result', {}).get('text', ''),
                                'processing_time': result.get('processing_time', 0),
                                'timestamp': file_info['timestamp']
                            }
                
            elif ext in ['.jpg', '.jpeg', '.png']:
                # ì´ë¯¸ì§€ ë¶„ì„
                if file_info['size_mb'] <= max_image_size:
                    if REAL_ANALYSIS_AVAILABLE:
                        result = analyze_file_real(
                            file_info['path'],
                            "image",
                            language="ko"
                        )
                        
                        if result and result.get('success'):
                            ocr_result = result.get('ocr_result', {})
                            return {
                                'type': 'image',
                                'file': file_info['name'],
                                'content': ' '.join([block.get('text', '') for block in ocr_result.get('text_blocks', [])]),
                                'text_blocks': len(ocr_result.get('text_blocks', [])),
                                'timestamp': file_info['timestamp']
                            }
            
            elif ext in ['.mov', '.mp4']:
                # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°
                return {
                    'type': 'video',
                    'file': file_info['name'],
                    'content': f"ë¹„ë””ì˜¤ íŒŒì¼ ({file_info['size_mb']:.1f}MB)",
                    'size_mb': file_info['size_mb'],
                    'timestamp': file_info['timestamp']
                }
        
        except Exception as e:
            raise Exception(f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return None
    
    def _generate_comprehensive_story(self, results):
        """ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„±"""
        story_parts = []
        
        # ì‹œê°„ìˆœ ì •ë ¬
        timeline = sorted(results['timeline'], key=lambda x: x['timestamp'])
        
        story_parts.append("=== ì¢…í•© ìƒí™© ë¶„ì„ ìŠ¤í† ë¦¬ ===\n")
        
        for i, event in enumerate(timeline):
            if event['content'].strip():
                story_parts.append(f"{i+1}. [{event['type'].upper()}] {event['file']}")
                story_parts.append(f"   ì‹œê°„: {event['timestamp']}")
                story_parts.append(f"   ë‚´ìš©: {event['content'][:300]}...")
                story_parts.append("")
        
        return "\n".join(story_parts)
    
    def _display_comprehensive_results(self, results):
        """ì¢…í•© ê²°ê³¼ í‘œì‹œ"""
        st.subheader("ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼")
        
        # ìš”ì•½ í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„", len(results['audio_results']))
        with col2:
            st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„", len(results['image_results']))
        with col3:
            st.metric("ğŸ¬ ë¹„ë””ì˜¤ ìˆ˜ì§‘", len(results['video_results']))
        with col4:
            st.metric("ğŸ“… ì´ ì´ë²¤íŠ¸", len(results['timeline']))
        
        # ì¢…í•© ìŠ¤í† ë¦¬
        st.subheader("ğŸ“– ì¢…í•© ìƒí™© ìŠ¤í† ë¦¬")
        with st.expander("ğŸ“œ ì „ì²´ ìŠ¤í† ë¦¬ ë³´ê¸°", expanded=True):
            st.text_area("ì¢…í•© ìŠ¤í† ë¦¬", results['comprehensive_story'], height=400)
        
        # íƒ€ì„ë¼ì¸ ì‹œê°í™”
        if results['timeline']:
            st.subheader("ğŸ“… ì‹œê°„ìˆœ íƒ€ì„ë¼ì¸")
            for i, event in enumerate(results['timeline']):
                with st.expander(f"{i+1}. {event['file']} ({event['type']}) - {event['timestamp']}"):
                    st.write(f"**ë‚´ìš©:** {event['content']}")
        
        # ìƒì„¸ ê²°ê³¼
        if results['audio_results']:
            st.subheader("ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ ìƒì„¸")
            for audio in results['audio_results']:
                with st.expander(f"ğŸµ {audio['file']}"):
                    st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {audio.get('processing_time', 0):.1f}ì´ˆ")
                    st.write(f"**ë‚´ìš©:** {audio['content']}")
        
        if results['image_results']:
            st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ìƒì„¸")
            for image in results['image_results']:
                with st.expander(f"ğŸ–¼ï¸ {image['file']}"):
                    st.write(f"**í…ìŠ¤íŠ¸ ë¸”ë¡:** {image.get('text_blocks', 0)}ê°œ")
                    st.write(f"**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:** {image['content']}")
        
        # ê²°ê³¼ ì €ì¥
        if st.button("ğŸ’¾ ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥"):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"comprehensive_situation_analysis_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            st.success(f"âœ… ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥: {filename}")
    

        def run(self):
        """ë©”ì¸ ì‹¤í–‰ - 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°"""
        
        # CSS ìŠ¤íƒ€ì¼ ì ìš©
        self.setup_custom_css()
        
        # ê°œì„ ëœ í—¤ë” (v2.4)
        st.markdown("""
        <div class="main-container slide-in">
            <h1>ğŸ’ ì†”ë¡œëª¬ë“œ AI v2.4 - ë¸Œë¼ìš°ì € ìë™í™” í†µí•©</h1>
            <p><strong>ğŸš€ í™•ì¥ëœ ê¸°ëŠ¥:</strong> ë¶„ì„ + ë¸Œë¼ìš°ì € ê²€ìƒ‰ + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + ë³´ì•ˆ API</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœ í‘œì‹œ
        self.display_workflow_progress()
        
        # íƒ­ ê¸°ë°˜ UIë¡œ í™•ì¥ (v2.4)
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "ğŸ“‹ ê¸°ë³¸ ë¶„ì„", 
            "ğŸŒ ë¸Œë¼ìš°ì € ê²€ìƒ‰", 
            "ğŸš€ MCP ë¸Œë¼ìš°ì €",
            "ğŸ¤ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°", 
            "ğŸ“Š ê²½ìŸì‚¬ ë¶„ì„",
            "ğŸ”’ ë³´ì•ˆ API"
        ])
        
        with tab1:
            # ê¸°ì¡´ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° + ì›¹ ë°ì´í„° í†µí•©
            if st.session_state.workflow_step == 1:
                self.render_step1_basic_info()
            elif st.session_state.workflow_step == 2:
                self.render_step2_upload()
            elif st.session_state.workflow_step == 3:
                self.render_step3_review()
            elif st.session_state.workflow_step == 4:
                self.render_step4_report()
        
        with tab2:
            # ê¸°ë³¸ ë¸Œë¼ìš°ì € ê²€ìƒ‰ ê¸°ëŠ¥
            self.render_browser_search_tab()
        
        with tab3:
            # ìƒˆë¡œìš´ MCP ë¸Œë¼ìš°ì € ê¸°ëŠ¥
            self.render_mcp_browser_tab()
        
        with tab4:
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥
            self.render_realtime_streaming_tab()
        
        with tab5:
            # ê²½ìŸì‚¬ ë¶„ì„ ê¸°ëŠ¥
            self.render_competitive_analysis_tab()
        
        with tab6:
            # ë³´ì•ˆ API ê´€ë¦¬
            self.render_security_api_tab()
        
        # í•˜ë‹¨ì— ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"):
            self.display_system_status()
    
    def display_workflow_progress(self):
        """ê°œì„ ëœ ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœ í‘œì‹œ"""
        steps = [
            {"number": 1, "title": "ê¸°ë³¸ì •ë³´", "icon": "ğŸ“‹"},
            {"number": 2, "title": "ì—…ë¡œë“œ", "icon": "ğŸ“¤"}, 
            {"number": 3, "title": "ê²€í† ", "icon": "ğŸ”"},
            {"number": 4, "title": "ë³´ê³ ì„œ", "icon": "ğŸ“Š"}
        ]
        
        progress_html = '<div class="workflow-progress slide-in">'
        
        for step in steps:
            if step["number"] == st.session_state.workflow_step:
                step_class = "workflow-step current pulse"
                display_text = f'{step["icon"]} {step["title"]} (ì§„í–‰ì¤‘)'
            elif step["number"] < st.session_state.workflow_step:
                step_class = "workflow-step completed"
                display_text = f'âœ… {step["title"]} (ì™„ë£Œ)'
            else:
                step_class = "workflow-step pending"
                display_text = f'{step["icon"]} {step["title"]}'
            
            progress_html += f'<div class="{step_class}">{display_text}</div>'
        
        progress_html += '</div>'
        
        st.markdown(progress_html, unsafe_allow_html=True)
        st.markdown("---")
    
    def render_navigation_bar(self, current_step: int):
        """í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°” ë Œë”ë§"""
        st.markdown("---")
        
        # ì´ì „/ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼ ë¡œì§
        prev_step = current_step - 1 if current_step > 1 else None
        next_step = current_step + 1 if current_step < 4 else None
        
        # ë‹¨ê³„ë³„ ì¡°ê±´ ê²€ì‚¬
        can_go_next = self._can_proceed_to_next_step(current_step)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            if prev_step:
                step_names = {1: "ê¸°ë³¸ì •ë³´", 2: "ì—…ë¡œë“œ", 3: "ê²€í† ", 4: "ë³´ê³ ì„œ"}
                if st.button(f"â¬…ï¸ ì´ì „ ë‹¨ê³„ ({step_names[prev_step]})", type="secondary"):
                    st.session_state.workflow_step = prev_step
                    st.rerun()
        
        with col3:
            if next_step and can_go_next:
                step_names = {2: "ì—…ë¡œë“œ", 3: "ê²€í† ", 4: "ë³´ê³ ì„œ"}
                button_text = f"â¡ï¸ ë‹¤ìŒ ë‹¨ê³„ ({step_names[next_step]})"
                if current_step == 3:
                    button_text = "ğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ìƒì„±"
                
                if st.button(button_text, type="primary"):
                    st.session_state.workflow_step = next_step
                    if current_step == 3:
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ! ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    st.rerun()
            elif next_step and not can_go_next:
                # ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
                if current_step == 1:
                    st.info("ê¸°ë³¸ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ 'ê±´ë„ˆë›°ê¸°' ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                elif current_step == 2:
                    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë™ì˜ìƒ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif current_step == 3:
                    st.info("ë¶„ì„ì„ ì™„ë£Œí•œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    def _can_proceed_to_next_step(self, current_step: int) -> bool:
        """ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•œì§€ í™•ì¸"""
        if current_step == 1:
            # Step 1ì€ í•­ìƒ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŒ
            return True
        elif current_step == 2:
            # Step 2ëŠ” íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆê±°ë‚˜ YouTube URLì´ ìˆì–´ì•¼ í•¨
            return bool(st.session_state.uploaded_files_data)
        elif current_step == 3:
            # Step 3ëŠ” ë¶„ì„ ê²°ê³¼ê°€ ìˆì–´ì•¼ í•¨
            return bool(st.session_state.analysis_results)
        return False
    
    def render_step1_basic_info(self):
        """1ë‹¨ê³„: ê¸°ë³¸ì •ë³´ ì…ë ¥"""
        st.markdown("## 1ï¸âƒ£ í”„ë¡œì íŠ¸ ê¸°ë³¸ì •ë³´ (ì„ íƒì‚¬í•­)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ“‹ í”„ë¡œì íŠ¸ ì •ë³´")
            project_name = st.text_input(
                "í”„ë¡œì íŠ¸ëª…", 
                value=st.session_state.project_info.get('name', ''),
                placeholder="ì˜ˆ: 2024ë…„ ì£¼ì–¼ë¦¬ íŠ¸ë Œë“œ ë¶„ì„"
            )
            
            project_type = st.selectbox(
                "ë¶„ì„ ìœ í˜•",
                ["ì¼ë°˜ ë¶„ì„", "ì£¼ì–¼ë¦¬ ì „ë¬¸ ë¶„ì„", "ê³ ê° í”¼ë“œë°± ë¶„ì„", "ì‹œì¥ì¡°ì‚¬ ë¶„ì„", "êµìœ¡/í›ˆë ¨ ìë£Œ ë¶„ì„"],
                index=["ì¼ë°˜ ë¶„ì„", "ì£¼ì–¼ë¦¬ ì „ë¬¸ ë¶„ì„", "ê³ ê° í”¼ë“œë°± ë¶„ì„", "ì‹œì¥ì¡°ì‚¬ ë¶„ì„", "êµìœ¡/í›ˆë ¨ ìë£Œ ë¶„ì„"].index(
                    st.session_state.project_info.get('type', 'ì¼ë°˜ ë¶„ì„')
                )
            )
            
            priority = st.select_slider(
                "ìš°ì„ ìˆœìœ„",
                options=["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ", "ê¸´ê¸‰"],
                value=st.session_state.project_info.get('priority', 'ë³´í†µ')
            )
        
        with col2:
            st.markdown("### ğŸ¯ ë¶„ì„ ëª©í‘œ")
            
            # ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ì œì•ˆ ê¸°ëŠ¥ ì¶”ê°€
            if project_type == "ì£¼ì–¼ë¦¬ ì „ë¬¸ ë¶„ì„" and self.mcp_browser:
                st.markdown("#### ğŸŒ ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´")
                if st.button("ğŸ“Š í˜„ì¬ ì‹œì¥ íŠ¸ë Œë“œ í™•ì¸", type="secondary"):
                    with st.spinner("ğŸ” ìµœì‹  ì£¼ì–¼ë¦¬ ì‹œì¥ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
                        market_search_result = self._perform_realtime_market_search(project_name or "ì£¼ì–¼ë¦¬ íŠ¸ë Œë“œ")
                        
                        if market_search_result.get("success"):
                            st.success("âœ… ì‹œì¥ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ!")
                            
                            # ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í‘œì‹œ
                            summary = market_search_result.get("summary", {})
                            if summary:
                                st.markdown("**ğŸ“ˆ ì‹¤ì‹œê°„ ì‹œì¥ ì¸ì‚¬ì´íŠ¸:**")
                                for insight in summary.get("key_insights", [])[:3]:
                                    st.markdown(f"â€¢ {insight}")
                                
                                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                                st.session_state.realtime_market_data = market_search_result
                        else:
                            st.error("âŒ ì‹œì¥ ì •ë³´ ê²€ìƒ‰ ì‹¤íŒ¨")
            
            objective = st.text_area(
                "ë¶„ì„ ëª©ì  ë° ëª©í‘œ",
                value=st.session_state.project_info.get('objective', ''),
                placeholder="ì˜ˆ: ê³ ê° ìŒì„± ë°ì´í„°ì—ì„œ ì£¼ì–¼ë¦¬ ì„ í˜¸ë„ íŒ¨í„´ ë¶„ì„",
                height=80
            )
            
            target_language = st.selectbox(
                "ì£¼ìš” ì…ë ¥ ì–¸ì–´",
                ["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´", "ìŠ¤í˜ì¸ì–´"],
                index=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´", "ìŠ¤í˜ì¸ì–´"].index(
                    st.session_state.project_info.get('target_language', 'ìë™ ê°ì§€')
                )
            )
        
        # ìƒˆë¡œìš´ ì„¹ì…˜: ì°¸ì„ì ë° ìƒí™© ì •ë³´
        st.markdown("### ğŸ‘¥ ì°¸ì„ì ë° ìƒí™© ì •ë³´ (ë¶„ì„ í’ˆì§ˆ í–¥ìƒ)")
        
        col3, col4 = st.columns(2)
        
        with col3:
            participants = st.text_area(
                "ì°¸ì„ì ì •ë³´",
                value=st.session_state.project_info.get('participants', ''),
                placeholder="ì˜ˆ: ê¹€ì² ìˆ˜ (ë§ˆì¼€íŒ… íŒ€ì¥), ë°•ì˜í¬ (ë””ìì¸ ì‹¤ì¥), ê³ ê° A, B, C",
                height=80,
                help="ì°¸ì„ì ì´ë¦„ê³¼ ì—­í• ì„ ì…ë ¥í•˜ë©´ ìŒì„± ì¸ì‹ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤"
            )
            
            speakers = st.text_input(
                "ì£¼ìš” ë°œí‘œì",
                value=st.session_state.project_info.get('speakers', ''),
                placeholder="ì˜ˆ: ê¹€ì² ìˆ˜, ë°•ì˜í¬",
                help="ì£¼ìš” ë°œí‘œìë¥¼ ëª…ì‹œí•˜ë©´ í™”ì êµ¬ë¶„ê³¼ ë‚´ìš© ë¶„ì„ì´ ê°œì„ ë©ë‹ˆë‹¤"
            )
        
        with col4:
            event_context = st.text_area(
                "ìƒí™© ë° ë°°ê²½",
                value=st.session_state.project_info.get('event_context', ''),
                placeholder="ì˜ˆ: 2024ë…„ Q1 ì£¼ì–¼ë¦¬ íŠ¸ë Œë“œ ì„¸ë¯¸ë‚˜, ê³ ê° í”¼ë“œë°± ìˆ˜ì§‘ íšŒì˜",
                height=80,
                help="ìƒí™© ì •ë³´ëŠ” ë¶„ì„ ê²°ê³¼ì˜ í•´ì„ê³¼ ê°•ì˜ ë‚´ìš© ìƒì„±ì— í™œìš©ë©ë‹ˆë‹¤"
            )
            
            topic_keywords = st.text_input(
                "ì£¼ìš” ì£¼ì œ í‚¤ì›Œë“œ",
                value=st.session_state.project_info.get('topic_keywords', ''),
                placeholder="ì˜ˆ: ë‹¤ì´ì•„ëª¬ë“œ, ê³¨ë“œ, íŠ¸ë Œë“œ, ë¸Œëœë”©, ê³ ê°ë§Œì¡±",
                help="ì˜ˆìƒë˜ëŠ” ì£¼ì œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ OCRê³¼ STT ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤"
            )
        
        # ë‹¤ê°ë„ ë¶„ì„ ì„¤ì •
        st.markdown("### ğŸ”„ ë‹¤ê°ë„ ë¶„ì„ ì„¤ì •")
        
        col5, col6 = st.columns(2)
        
        with col5:
            enable_multi_angle = st.checkbox(
                "ë‹¤ê°ë„ ì¢…í•© ë¶„ì„ í™œì„±í™”",
                value=st.session_state.project_info.get('enable_multi_angle', True),
                help="ë™ì¼ ìƒí™©ì˜ ì—¬ëŸ¬ íŒŒì¼(ì˜ìƒ, ì´ë¯¸ì§€, ìŒì„±)ì„ ì¢…í•©í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤"
            )
            
            output_format = st.multiselect(
                "ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹",
                ["ìš”ì•½ í…ìŠ¤íŠ¸", "í‚¤ì›Œë“œ ì¶”ì¶œ", "ê°ì • ë¶„ì„", "ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜", "í†µê³„ ì°¨íŠ¸", "ì¢…í•© ê°•ì˜ ìë£Œ"],
                default=st.session_state.project_info.get('output_format', ["ìš”ì•½ í…ìŠ¤íŠ¸", "í‚¤ì›Œë“œ ì¶”ì¶œ", "ì¢…í•© ê°•ì˜ ìë£Œ"])
            )
        
        with col6:
            analysis_depth = st.select_slider(
                "ë¶„ì„ ê¹Šì´",
                options=["ê¸°ë³¸", "ìƒì„¸", "ì‹¬ì¸µ", "ì „ë¬¸ê°€ê¸‰"],
                value=st.session_state.project_info.get('analysis_depth', 'ìƒì„¸'),
                help="ê¹Šì´ê°€ ë†’ì„ìˆ˜ë¡ ë” ìƒì„¸í•œ ë¶„ì„ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤"
            )
        
        # ğŸ¯ ë¶„ì„ ëª¨ë“œ ì„ íƒ (ë…ë¦½ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì§ê´€ì„± ê°œì„ )
        st.markdown("---")
        st.markdown("### ğŸ¯ ë¶„ì„ ëª¨ë“œ ì„ íƒ")
        
        col7, col8 = st.columns([3, 2])
        
        with col7:
            st.markdown("**ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ íŒŒì¼ë“¤ì„ ë¶„ì„í• ê¹Œìš”?**")
            analysis_mode = st.radio(
                "ë¶„ì„ ë°©ì‹ ì„ íƒ",
                options=[
                    "ğŸš€ **ë°°ì¹˜ ì¢…í•© ë¶„ì„** (ê¶Œì¥) - ëª¨ë“  íŒŒì¼ì„ í†µí•©í•˜ì—¬ ê³ í’ˆì§ˆ ë¶„ì„",
                    "ğŸ“ **ê°œë³„ íŒŒì¼ ë¶„ì„** - ê° íŒŒì¼ì„ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„"
                ],
                index=0 if st.session_state.project_info.get('correlation_analysis', True) else 1,
                label_visibility="collapsed"
            )
            
            correlation_analysis = "ë°°ì¹˜ ì¢…í•© ë¶„ì„" in analysis_mode
        
        with col8:
            if correlation_analysis:
                st.success("""
                âœ¨ **ë°°ì¹˜ ì¢…í•© ë¶„ì„ì˜ ì¥ì :**
                - íŒŒì¼ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
                - ì¤‘ë³µ ë‚´ìš© ìë™ ì œê±°
                - ì»¨í…ìŠ¤íŠ¸ í†µí•©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
                - ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
                """)
            else:
                st.warning("""
                ğŸ“ **ê°œë³„ íŒŒì¼ ë¶„ì„ íŠ¹ì§•:**
                - íŒŒì¼ë³„ ë…ë¦½ì  ì²˜ë¦¬
                - ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
                - ìƒê´€ê´€ê³„ ë¶„ì„ ë¶ˆê°€
                - ì œí•œì ì¸ í†µí•© ì¸ì‚¬ì´íŠ¸
                """)
        
        # í™•ì¥ëœ ê¸°ë³¸ì •ë³´ ì €ì¥
        st.session_state.project_info = {
            'name': project_name,
            'type': project_type,
            'priority': priority,
            'objective': objective,
            'target_language': target_language,
            'participants': participants,
            'speakers': speakers,
            'event_context': event_context,
            'topic_keywords': topic_keywords,
            'enable_multi_angle': enable_multi_angle,
            'analysis_depth': analysis_depth,
            'correlation_analysis': correlation_analysis,
            'output_format': output_format,
            'created_time': datetime.now().isoformat()
        }
        
        # ê±´ë„ˆë›°ê¸° ë²„íŠ¼ (ì¤‘ì•™ì— ë³„ë„ë¡œ)
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ“‹ ê¸°ë³¸ì •ë³´ ê±´ë„ˆë›°ê³  ì—…ë¡œë“œ ì‹œì‘", type="primary", use_container_width=True):
                st.session_state.workflow_step = 2
                st.rerun()
        
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(1)
    
    def render_step2_upload(self):
        """2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ"""
        st.markdown("## 2ï¸âƒ£ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ")
        
        # í”„ë¡œì íŠ¸ ì •ë³´ ìš”ì•½ í‘œì‹œ
        if st.session_state.project_info.get('name'):
            with st.expander("ğŸ“‹ í”„ë¡œì íŠ¸ ì •ë³´ ìš”ì•½"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**í”„ë¡œì íŠ¸ëª…:** {st.session_state.project_info.get('name', 'N/A')}")
                    st.write(f"**ë¶„ì„ ìœ í˜•:** {st.session_state.project_info.get('type', 'N/A')}")
                with col2:
                    st.write(f"**ìš°ì„ ìˆœìœ„:** {st.session_state.project_info.get('priority', 'N/A')}")
                    st.write(f"**ì£¼ìš” ì–¸ì–´:** {st.session_state.project_info.get('target_language', 'N/A')}")
        
        # ì§€ì› íŒŒì¼ í˜•ì‹ ì•ˆë‚´
        with st.expander("ğŸ“ ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹"):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("""
                **ğŸ¤ ìŒì„±/ë™ì˜ìƒ:**
                - MP3, WAV, FLAC
                - ğŸµ M4A (ê°œì„ ëœ ì²˜ë¦¬)
                - MP4, MOV, AVI
                - ìœ íŠœë¸Œ URL
                """)
            with col2:
                st.markdown("""
                **ğŸ–¼ï¸ ì´ë¯¸ì§€:**
                - JPG, JPEG, PNG
                - BMP, TIFF, WEBP
                - PDF (ì´ë¯¸ì§€ í¬í•¨)
                """)
            with col3:
                st.markdown("""
                **ğŸ“„ ë¬¸ì„œ:**
                - PDF ë¬¸ì„œ
                - Word (DOCX)
                - í…ìŠ¤íŠ¸ (TXT)
                """)
        
        # íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤
        st.markdown("### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        # ê°œì„ ëœ íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­
        upload_container = st.container()
        with upload_container:
            # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì› ì•ˆë‚´
            if LARGE_FILE_HANDLER_AVAILABLE:
                self.show_enhanced_message(
                    "info",
                    "ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›",
                    "ë™ì˜ìƒ íŒŒì¼ ìµœëŒ€ 5GBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•˜ë©°, ìë™ìœ¼ë¡œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë©ë‹ˆë‹¤."
                )
            
            # ì‹œê°ì ìœ¼ë¡œ ê°œì„ ëœ ì—…ë¡œë“œ ì˜ì—­
            st.markdown("""
            <div class="upload-area">
                <h3>ğŸ“ íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”</h3>
                <p>ì§€ì› íŒŒì¼: ìŒì„±/ë™ì˜ìƒ, ì´ë¯¸ì§€, ë¬¸ì„œ (ìµœëŒ€ 5GB)</p>
                <p><small>ğŸ’¡ Ctrl/Cmd + í´ë¦­ìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</small></p>
            </div>
            """, unsafe_allow_html=True)
            
            uploaded_files = st.file_uploader(
                "íŒŒì¼ ì„ íƒ",
                type=['wav', 'mp3', 'flac', 'm4a', 'mp4', 'mov', 'avi', 
                      'jpg', 'jpeg', 'png', 'bmp', 'tiff', 'webp',
                      'pdf', 'docx', 'txt'],
                accept_multiple_files=True,
                label_visibility="collapsed"
            )
        
        # ë™ì˜ìƒ URL ì…ë ¥
        st.markdown("### ğŸ¬ ë™ì˜ìƒ URL ì¶”ê°€")
        video_urls = st.text_area(
            "ë™ì˜ìƒ URL (YouTube, Brightcove ë“± - í•œ ì¤„ì— í•˜ë‚˜ì”©)",
            placeholder="https://www.youtube.com/watch?v=example1\nhttps://players.brightcove.net/1659762912/default_default/index.html?videoId=6374563565112\nhttps://youtu.be/example3",
            height=120,
            help="ì§€ì› í”Œë«í¼: YouTube, Brightcove, ê¸°íƒ€ ì§ì ‘ ë™ì˜ìƒ ë§í¬"
        )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
        if uploaded_files or video_urls.strip():
            st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
            
            total_files = 0
            total_size = 0
            file_categories = {"audio": [], "video": [], "image": [], "document": [], "youtube": []}
            
            # ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ë¥˜ ë° ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€
            large_files_detected = []
            if uploaded_files:
                for file in uploaded_files:
                    try:
                        file_size_mb = len(file.getvalue()) / (1024 * 1024)
                        file_size_gb = file_size_mb / 1024
                        total_size += file_size_mb
                        total_files += 1
                        
                        file_ext = file.name.split('.')[-1].lower() if '.' in file.name else 'unknown'
                    except Exception as e:
                        # ê°•í™”ëœ ì—ëŸ¬ ì²˜ë¦¬ ì‚¬ìš©
                        try:
                            from core.enhanced_error_handler import handle_error
                            error_result = handle_error(e, {"file_name": file.name, "step": "file_processing"})
                            
                            # ê°œì„ ëœ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
                            self.show_enhanced_message(
                                "error",
                                "íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜",
                                f"{file.name} íŒŒì¼ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_result['user_message']}",
                                error_result.get('solutions', [])
                            )
                            
                            # ìë™ ë³µêµ¬ê°€ ì„±ê³µí•œ ê²½ìš°
                            if error_result.get('recovery_success'):
                                self.show_enhanced_message(
                                    "success",
                                    "ìë™ ë³µêµ¬ ì™„ë£Œ",
                                    error_result.get('recovery_message', 'ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤')
                                )
                        
                        except ImportError:
                            # í´ë°±: ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬
                            self.show_enhanced_message(
                                "error",
                                "íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜",
                                f"{file.name} íŒŒì¼ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                                [
                                    "íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”",
                                    "ë‹¤ë¥¸ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ë³´ì„¸ìš”",
                                    "íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í°ì§€ í™•ì¸í•´ë³´ì„¸ìš”"
                                ]
                            )
                        
                        continue
                    
                    # ëŒ€ìš©ëŸ‰ ë™ì˜ìƒ íŒŒì¼ ê°ì§€ (1GB ì´ìƒ)
                    is_large_video = file_ext in ['mp4', 'mov', 'avi'] and file_size_gb >= 1.0
                    if is_large_video:
                        large_files_detected.append((file.name, file_size_gb))
                    
                    if file_ext in ['wav', 'mp3', 'flac', 'm4a']:
                        file_categories["audio"].append((file.name, file_size_mb))
                        
                        # M4A íŒŒì¼ íŠ¹ë³„ ì²˜ë¦¬ ì•ˆë‚´
                        if file_ext == 'm4a':
                            st.info(f"ğŸµ M4A íŒŒì¼ ê°ì§€: {file.name} ({file_size_mb:.1f}MB) - ê°œì„ ëœ ë³€í™˜ ì‹œìŠ¤í…œ ì‚¬ìš©")
                    elif file_ext in ['mp4', 'mov', 'avi']:
                        size_display = f"{file_size_gb:.2f}GB" if file_size_gb >= 1.0 else f"{file_size_mb:.1f}MB"
                        file_categories["video"].append((file.name, size_display, is_large_video))
                    elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'webp']:
                        file_categories["image"].append((file.name, file_size_mb))
                    elif file_ext in ['pdf', 'docx', 'txt']:
                        file_categories["document"].append((file.name, file_size_mb))
            
            # ë™ì˜ìƒ URL ì²˜ë¦¬
            if video_urls.strip():
                urls = [url.strip() for url in video_urls.strip().split('\n') if url.strip()]
                for url in urls:
                    if 'youtube.com' in url or 'youtu.be' in url:
                        file_categories["youtube"].append((url, 0))
                        total_files += 1
                    elif 'brightcove.net' in url:
                        file_categories["brightcove"] = file_categories.get("brightcove", [])
                        file_categories["brightcove"].append((url, 0))
                        total_files += 1
                    elif any(domain in url.lower() for domain in ['vimeo.com', 'dailymotion.com', '.mp4', '.mov', '.avi']):
                        file_categories["other_video"] = file_categories.get("other_video", [])
                        file_categories["other_video"].append((url, 0))
                        total_files += 1
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ“ ì´ íŒŒì¼", f"{total_files}ê°œ")
            with col2:
                st.metric("ğŸ’¾ ì´ í¬ê¸°", f"{total_size:.2f} MB")
            with col3:
                languages = ["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´"]
                # í”„ë¡œì íŠ¸ ì •ë³´ì—ì„œ ì–¸ì–´ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (í˜¸í™˜ì„± í™•ë³´)
                saved_language = st.session_state.project_info.get('target_language', 'ìë™ ê°ì§€')
                default_index = 0
                try:
                    if saved_language in languages:
                        default_index = languages.index(saved_language)
                except (ValueError, TypeError):
                    default_index = 0
                
                analysis_language = st.selectbox(
                    "ë¶„ì„ ì–¸ì–´", 
                    languages,
                    index=default_index
                )
            
            # ëŒ€ìš©ëŸ‰ íŒŒì¼ ê²½ê³  í‘œì‹œ
            if large_files_detected and LARGE_FILE_HANDLER_AVAILABLE:
                self.show_enhanced_message(
                    "warning",
                    "ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€",
                    f"{len(large_files_detected)}ê°œ íŒŒì¼ì´ 1GB ì´ìƒì…ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ê°€ ì ìš©ë©ë‹ˆë‹¤.",
                    ["ì²˜ë¦¬ ì‹œê°„ì´ ë‹¤ì†Œ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤", "ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤", "ì¤‘ê°„ì— ì¤‘ë‹¨í•˜ì§€ ë§ˆì„¸ìš”"]
                )
                with st.expander("ğŸ“Š ëŒ€ìš©ëŸ‰ íŒŒì¼ ìƒì„¸ ì •ë³´"):
                    for filename, size_gb in large_files_detected:
                        st.markdown(f"""
                        <div class="info-card">
                            <h4>ğŸ¬ {filename}</h4>
                            <p><strong>í¬ê¸°:</strong> {size_gb:.2f}GB</p>
                            <ul>
                                <li>âœ… ì²­í¬ ë‹¨ìœ„ ì—…ë¡œë“œ</li>
                                <li>âœ… ì˜¤ë””ì˜¤ ìë™ ì¶”ì¶œ</li>
                                <li>âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬</li>
                            </ul>
                        </div>
                        """, unsafe_allow_html=True)
            elif large_files_detected and not LARGE_FILE_HANDLER_AVAILABLE:
                self.show_enhanced_message(
                    "error",
                    "ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ë¶ˆê°€",
                    f"{len(large_files_detected)}ê°œì˜ ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ ìˆì§€ë§Œ ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                    [
                        "ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”",
                        "íŒŒì¼ì„ ì‘ì€ í¬ê¸°ë¡œ ë¶„í• í•´ë³´ì„¸ìš”",
                        "ì••ì¶• íŒŒì¼ í˜•íƒœë¡œ ë³€í™˜í•´ë³´ì„¸ìš”"
                    ]
                )
            
            # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ë° ì¹´í…Œê³ ë¦¬ë³„ ëª©ë¡
            self.render_file_preview(file_categories, uploaded_files)
            
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            st.markdown("---")
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸš€ ì „ì²´ íŒŒì¼ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                    # íŒŒì¼ ë°ì´í„° ì €ì¥
                    st.session_state.uploaded_files_data = {
                        'files': uploaded_files,
                        'video_urls': video_urls.strip().split('\n') if video_urls.strip() else [],
                        'analysis_language': analysis_language,
                        'total_files': total_files,
                        'total_size': total_size,
                        'categories': file_categories
                    }
                    st.session_state.workflow_step = 3
                    st.success(f"âœ… {total_files}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    st.rerun()
        
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(2)
    
    def render_file_preview(self, file_categories: Dict, uploaded_files: List):
        """íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ë° ìƒì„¸ ì •ë³´ í‘œì‹œ"""
        st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
        
        # íŒŒì¼ ë”•ì…”ë„ˆë¦¬ ìƒì„± (íŒŒì¼ëª…ì„ í‚¤ë¡œ ì‚¬ìš©)
        file_dict = {}
        if uploaded_files:
            for file in uploaded_files:
                file_dict[file.name] = file
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ëª©ë¡ê³¼ ë¯¸ë¦¬ë³´ê¸°
        for category, files in file_categories.items():
            if not files:
                continue
                
            category_names = {
                "audio": "ğŸ¤ ìŒì„± íŒŒì¼",
                "video": "ğŸ¬ ë™ì˜ìƒ íŒŒì¼", 
                "image": "ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼",
                "document": "ğŸ“„ ë¬¸ì„œ íŒŒì¼",
                "youtube": "ğŸ¬ YouTube URL",
                "brightcove": "ğŸ“º Brightcove URL",
                "other_video": "ğŸŒ ê¸°íƒ€ ë™ì˜ìƒ URL"
            }
            
            with st.expander(f"{category_names[category]} ({len(files)}ê°œ)", expanded=True):
                # ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ìš° ì¸ë„¤ì¼ í‘œì‹œ
                if category == "image":
                    # ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ í‘œì‹œ
                    cols = st.columns(min(3, len(files)))
                    for idx, file_info in enumerate(files):
                        name, size_mb = file_info
                        col_idx = idx % 3
                        
                        with cols[col_idx]:
                            # íŒŒì¼ ì •ë³´ í‘œì‹œ
                            st.write(f"**{name}**")
                            st.caption(f"ğŸ“ í¬ê¸°: {size_mb:.2f} MB")
                            
                            # ì´ë¯¸ì§€ ì¸ë„¤ì¼ í‘œì‹œ
                            if name in file_dict:
                                try:
                                    st.image(file_dict[name], width=200, caption=name)
                                except Exception as e:
                                    st.error(f"âš ï¸ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {str(e)}")
                
                # ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ìš° ìƒì„¸ ì •ë³´ì™€ ì¬ìƒ
                elif category == "audio":
                    for file_info in files:
                        name, size_mb = file_info
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"ğŸµ **{name}**")
                            st.caption(f"ğŸ“ í¬ê¸°: {size_mb:.2f} MB")
                            
                            # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ì¶”ì¶œ ì‹œë„
                            if name in file_dict:
                                try:
                                    # ì„ì‹œë¡œ íŒŒì¼ ì €ì¥í•˜ì—¬ ì •ë³´ ì¶”ì¶œ
                                    import tempfile
                                    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{name.split('.')[-1]}") as tmp_file:
                                        tmp_file.write(file_dict[name].getvalue())
                                        tmp_path = tmp_file.name
                                    
                                    # ì˜¤ë””ì˜¤ ì •ë³´ í‘œì‹œ (ì‹¤ì œ ë¶„ì„ ì—”ì§„ í™œìš©)
                                    try:
                                        from core.audio_converter import get_audio_info
                                        audio_info = get_audio_info(tmp_path)
                                        if audio_info['is_valid']:
                                            st.caption(f"â±ï¸ ê¸¸ì´: {audio_info['duration_seconds']:.1f}ì´ˆ")
                                            st.caption(f"ğŸµ ìƒ˜í”Œë§: {audio_info['sample_rate']}Hz")
                                            st.caption(f"ğŸ“» ì±„ë„: {audio_info['channels']}ch")
                                    except ImportError:
                                        st.caption("ğŸ“Š ìƒì„¸ ì •ë³´: ë¶„ì„ ì—”ì§„ ë¡œë“œ í›„ í™•ì¸ ê°€ëŠ¥")
                                    except Exception:
                                        st.caption("ğŸ“Š ìƒì„¸ ì •ë³´: ë¶„ì„ ì¤‘ í™•ì¸ë©ë‹ˆë‹¤")
                                    
                                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                                    try:
                                        os.unlink(tmp_path)
                                    except:
                                        pass
                                        
                                except Exception as e:
                                    st.caption(f"âš ï¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                        
                        with col2:
                            # ì˜¤ë””ì˜¤ ì¬ìƒ ìœ„ì ¯ (ì§€ì›ë˜ëŠ” í˜•ì‹ë§Œ)
                            if name in file_dict and name.lower().endswith(('.wav', '.mp3')):
                                try:
                                    st.audio(file_dict[name])
                                except Exception:
                                    st.caption("ğŸµ ì¬ìƒê¸° ë¡œë“œ ì‹¤íŒ¨")
                
                # ë™ì˜ìƒ íŒŒì¼ì˜ ê²½ìš° ìƒì„¸ ì •ë³´
                elif category == "video":
                    for file_info in files:
                        name, size_display, is_large = file_info
                        
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            icon = "ğŸ¬ğŸš€" if is_large else "ğŸ¬"
                            note = " (ëŒ€ìš©ëŸ‰ ìë™ ì²˜ë¦¬)" if is_large else ""
                            st.write(f"{icon} **{name}**{note}")
                            st.caption(f"ğŸ“ í¬ê¸°: {size_display}")
                            
                            if is_large:
                                st.info("âœ¨ ëŒ€ìš©ëŸ‰ íŒŒì¼ë¡œ ìë™ ì²­í¬ ì²˜ë¦¬ë©ë‹ˆë‹¤")
                        
                        with col2:
                            if name in file_dict:
                                try:
                                    # ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° (ì‘ì€ í¬ê¸°ë¡œ)
                                    st.video(file_dict[name])
                                except Exception:
                                    st.caption("ğŸ¬ ë¯¸ë¦¬ë³´ê¸° ë¡œë“œ ì‹¤íŒ¨")
                
                # ë¬¸ì„œ íŒŒì¼ì˜ ê²½ìš°
                elif category == "document":
                    for file_info in files:
                        name, size_mb = file_info
                        st.write(f"ğŸ“„ **{name}**")
                        st.caption(f"ğŸ“ í¬ê¸°: {size_mb:.2f} MB")
                        
                        # íŒŒì¼ í˜•ì‹ë³„ ì„¤ëª…
                        if name.lower().endswith('.pdf'):
                            st.caption("ğŸ“‘ PDF ë¬¸ì„œ - OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜ˆì •")
                        elif name.lower().endswith('.docx'):
                            st.caption("ğŸ“ Word ë¬¸ì„œ - í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜ˆì •") 
                        elif name.lower().endswith('.txt'):
                            st.caption("ğŸ“‹ í…ìŠ¤íŠ¸ íŒŒì¼ - ì§ì ‘ ì½ê¸°")
                
                # ì˜¨ë¼ì¸ ë™ì˜ìƒ URLì˜ ê²½ìš°
                elif category in ["youtube", "brightcove", "other_video"]:
                    for file_info in files:
                        name = file_info[0]
                        
                        if category == "youtube":
                            st.write(f"ğŸ¬ **YouTube URL**")
                            st.caption("ğŸ¬ ë¹„ë””ì˜¤ ì •ë³´ ë° ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì˜ˆì •")
                        elif category == "brightcove":
                            st.write(f"ğŸ“º **Brightcove URL**")
                            st.caption("ğŸ¬ Brightcove í”Œë ˆì´ì–´ì—ì„œ ë™ì˜ìƒ ë¶„ì„ ì˜ˆì •")
                        elif category == "other_video":
                            st.write(f"ğŸŒ **ë™ì˜ìƒ URL**")
                            st.caption("ğŸ¬ ì§ì ‘ ë§í¬ì—ì„œ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ ì˜ˆì •")
                        
                        st.code(name)
                        
                        # URL ìœ íš¨ì„± ê°„ë‹¨ ì²´í¬
                        if name.startswith(('http://', 'https://')):
                            st.success("âœ… ìœ íš¨í•œ URL í˜•ì‹")
                        else:
                            st.warning("âš ï¸ URLì´ http:// ë˜ëŠ” https://ë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    def render_step3_review(self):
        """3ë‹¨ê³„: ë¶„ì„ ì§„í–‰, ìŠ¤í¬ë¦½íŠ¸ í‘œì‹œ, ì¤‘ê°„ ê²€í†  (í–¥ìƒë¨)"""
        st.markdown("## 3ï¸âƒ£ ë¶„ì„ ì§„í–‰ ë° ìŠ¤í¬ë¦½íŠ¸ ê²€í† ")
        
        if not st.session_state.uploaded_files_data:
            st.error("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ì„¸ìš”.")
            return
        
        # ë¶„ì„ ì§„í–‰ ìƒí™© í‘œì‹œ
        st.markdown("### ğŸ”„ ë¶„ì„ ì§„í–‰ ìƒí™©")
        
        uploaded_data = st.session_state.uploaded_files_data
        
        # ë¶„ì„ ì‹¤í–‰ ì „ ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
        analysis_ready, dependency_status = self.check_analysis_readiness()
        
        # ì˜ì¡´ì„± ìƒíƒœ í‘œì‹œ
        if not analysis_ready:
            st.error("ğŸš¨ ë¶„ì„ ì‹œìŠ¤í…œ ì¤€ë¹„ ë¶ˆì™„ë£Œ")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì‹œìŠ¤í…œ ìƒíƒœ:**")
                for component, status in dependency_status.items():
                    icon = "âœ…" if status else "âŒ"
                    st.markdown(f"{icon} {component}")
            with col2:
                st.markdown("**í•´ê²° ë°©ë²•:**")
                if not dependency_status.get('whisper', False):
                    st.markdown("- `pip install openai-whisper` ì‹¤í–‰")
                if not dependency_status.get('easyocr', False):
                    st.markdown("- `pip install easyocr` ì‹¤í–‰")
                if not dependency_status.get('transformers', False):
                    st.markdown("- `pip install transformers` ì‹¤í–‰")
        
        # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
        analysis_button_disabled = not analysis_ready or len(uploaded_data.get('files', [])) == 0
        
        if st.button("â–¶ï¸ ë¶„ì„ ì‹¤í–‰", type="primary", disabled=analysis_button_disabled):
            if analysis_ready:
                with st.spinner("ğŸ”„ í¬ê´„ì  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
                    results = self.execute_comprehensive_analysis()
                    st.session_state.analysis_results = results
            else:
                st.error("ë¶„ì„ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜ì¡´ì„±ì„ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.analysis_results:
            st.markdown("### ğŸ“Š ì¤‘ê°„ ë¶„ì„ ê²°ê³¼")
            
            # ë¶„ì„ ì™„ë£Œ í†µê³„
            total_results = len(st.session_state.analysis_results)
            successful_results = len([r for r in st.session_state.analysis_results if r.get('status') == 'success'])
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì²˜ë¦¬ëœ íŒŒì¼", f"{total_results}ê°œ")
            with col2:
                st.metric("ì„±ê³µ", f"{successful_results}ê°œ")
            with col3:
                success_rate = (successful_results / total_results * 100) if total_results > 0 else 0
                st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
            
            # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            for i, result in enumerate(st.session_state.analysis_results[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                with st.expander(f"ğŸ“„ {result.get('file_name', f'íŒŒì¼ {i+1}')} - {result.get('analysis_type', 'unknown')}"):
                    if result.get('status') == 'success':
                        if result.get('full_text'):
                            st.write("**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**")
                            preview_text = result['full_text'][:300] + ("..." if len(result['full_text']) > 300 else "")
                            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", value=preview_text, height=100, disabled=True, key=f"preview_{i}", label_visibility="collapsed")
                        
                        if result.get('summary'):
                            st.write("**AI ìš”ì•½:**")
                            st.info(result['summary'])
                        
                        if result.get('jewelry_keywords'):
                            st.write("**í‚¤ì›Œë“œ:**")
                            for keyword in result['jewelry_keywords'][:5]:
                                st.badge(keyword)
                    else:
                        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            
            if len(st.session_state.analysis_results) > 5:
                st.info(f"ì¶”ê°€ {len(st.session_state.analysis_results) - 5}ê°œ ê²°ê³¼ê°€ ë” ìˆìŠµë‹ˆë‹¤.")
            
            # ğŸ¤ ìŒì„± ìŠ¤í¬ë¦½íŠ¸ ì„¹ì…˜ ì¶”ê°€
            st.markdown("---")
            st.markdown("### ğŸ¤ ìŒì„± ìŠ¤í¬ë¦½íŠ¸ í™•ì¸ ë° ìˆ˜ì •")
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ë³„ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ë° í‘œì‹œ
            audio_results = [r for r in st.session_state.analysis_results if r.get('analysis_type') == 'audio']
            
            if audio_results:
                st.markdown("ì¶”ì¶œëœ ìŒì„± ë‚´ìš©ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                for i, result in enumerate(audio_results):
                    filename = result.get('file_name', f'ì˜¤ë””ì˜¤ íŒŒì¼ {i+1}')
                    
                    with st.expander(f"ğŸµ {filename} - ìŠ¤í¬ë¦½íŠ¸ ê²€í† ", expanded=True):
                        
                        if result.get('status') == 'success' and result.get('full_text'):
                            original_text = result['full_text']
                            
                            # ë©”íƒ€ ì •ë³´ í‘œì‹œ
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("â±ï¸ í…ìŠ¤íŠ¸ ê¸¸ì´", f"{len(original_text)} ê¸€ì")
                            with col2:
                                confidence = result.get('confidence', 0)
                                if confidence > 0:
                                    st.metric("ğŸ¯ ì‹ ë¢°ë„", f"{confidence:.1%}")
                                else:
                                    st.metric("ğŸ¯ ì‹ ë¢°ë„", "N/A")
                            with col3:
                                processing_time = result.get('processing_time', 0)
                                st.metric("âš¡ ì²˜ë¦¬ì‹œê°„", f"{processing_time:.1f}ì´ˆ")
                            
                            st.markdown("**ğŸ“‹ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸:**")
                            
                            # í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ì—­
                            edited_text = st.text_area(
                                "ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© (ìˆ˜ì • ê°€ëŠ¥):",
                                value=original_text,
                                height=150,
                                key=f"transcript_edit_{i}",
                                help="ë‚´ìš©ì´ ë¶€ì •í™•í•˜ë‹¤ë©´ ì§ì ‘ ìˆ˜ì •í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                            )
                            
                            # ìˆ˜ì • ì—¬ë¶€ ì²´í¬ ë° ì €ì¥
                            if edited_text != original_text:
                                st.info("âœï¸ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                # ìˆ˜ì •ëœ ë‚´ìš©ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                                if 'edited_transcripts' not in st.session_state:
                                    st.session_state.edited_transcripts = {}
                                st.session_state.edited_transcripts[filename] = {
                                    'original': original_text,
                                    'edited': edited_text,
                                    'modified': True
                                }
                            
                            # í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ (ì„ íƒì‚¬í•­)
                            jewelry_keywords = result.get('jewelry_keywords', [])
                            if jewelry_keywords:
                                st.markdown("**ğŸ” ê°ì§€ëœ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ:**")
                                cols = st.columns(min(len(jewelry_keywords), 5))
                                for j, keyword in enumerate(jewelry_keywords[:5]):
                                    with cols[j]:
                                        st.badge(keyword)
                        
                        else:
                            st.warning("âš ï¸ ì´ ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
                            if result.get('error'):
                                st.error(f"ì˜¤ë¥˜: {result['error']}")
                
                # ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ìš”ì•½
                if 'edited_transcripts' in st.session_state and st.session_state.edited_transcripts:
                    modified_count = len([t for t in st.session_state.edited_transcripts.values() if t.get('modified')])
                    if modified_count > 0:
                        st.success(f"âœ… {modified_count}ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì • ë‚´ìš©ì€ ìµœì¢… ë³´ê³ ì„œì— ë°˜ì˜ë©ë‹ˆë‹¤.")
            
            else:
                st.info("ğŸ¤ ë¶„ì„ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(3)
    
    def render_step4_report(self):
        """4ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ - ëŒ€í˜• í•¨ìˆ˜ (ë¦¬íŒ©í† ë§ ê³ ë ¤ ëŒ€ìƒ)"""
        st.markdown("## 4ï¸âƒ£ ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ")
        
        if not st.session_state.analysis_results:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ì„œ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        if not st.session_state.final_report:
            with st.spinner("ğŸ“Š ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                st.session_state.final_report = self.generate_final_report()
        
        if st.session_state.final_report:
            report = st.session_state.final_report
            
            # ë³´ê³ ì„œ í—¤ë”
            st.markdown("### ğŸ“‹ í”„ë¡œì íŠ¸ ë¶„ì„ ë³´ê³ ì„œ")
            
            col1, col2 = st.columns([2, 1])
            with col1:
                st.markdown(f"**í”„ë¡œì íŠ¸:** {report['project_name']}")
                st.markdown(f"**ë¶„ì„ ì¼ì‹œ:** {report['analysis_date']}")
                st.markdown(f"**ì´ ì²˜ë¦¬ íŒŒì¼:** {report['total_files']}ê°œ")
            with col2:
                st.markdown(f"**ì„±ê³µë¥ :** {report['success_rate']:.1f}%")
                st.markdown(f"**ì²˜ë¦¬ ì‹œê°„:** {report['total_time']:.1f}ì´ˆ")
            
            # ì‹¤ì‹œê°„ ë¶„ì„ ì‹œê°„ í‘œì‹œ (ë¶„ì„ ì¤‘ì¸ ê²½ìš°)
            if hasattr(st.session_state, 'analysis_start_time') and st.session_state.analysis_start_time:
                if st.session_state.get('analysis_status', '') != "ë¶„ì„ ì™„ë£Œ":
                    timer_html = self.show_realtime_analysis_timer()
                    if timer_html:
                        st.markdown(timer_html, unsafe_allow_html=True)
            
            st.markdown("---")
            
            # ğŸŒ ì‹¤ì‹œê°„ ì›¹ ë°ì´í„° í†µí•© ë¶„ì„
            st.markdown("### ğŸŒ ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° í†µí•© ë¶„ì„")
            
            # ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_realtime_data = hasattr(st.session_state, 'realtime_market_data')
            
            # ì¼ë°˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_web_data = False
            if self.mcp_browser and hasattr(self.mcp_browser, 'search_history'):
                search_history = self.mcp_browser.get_search_history()
                has_web_data = len(search_history) > 0
            
            if has_realtime_data:
                st.info("ğŸ“Š 1ë‹¨ê³„ì—ì„œ ìˆ˜í–‰í•œ ì‹¤ì‹œê°„ ì‹œì¥ ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì¼ ë¶„ì„ê³¼ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ”— ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° í†µí•©", type="primary"):
                        with st.spinner("ğŸ“ˆ ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ëŠ” ì¤‘..."):
                            integration_result = self._integrate_realtime_data_with_workflow()
                            
                            if integration_result and integration_result.get("integration_success"):
                                st.success("âœ… ì‹¤ì‹œê°„ ë°ì´í„° í†µí•© ì™„ë£Œ!")
                                
                                # í†µí•© ê²°ê³¼ í‘œì‹œ
                                self.display_integrated_analysis_results(integration_result)
                            else:
                                st.error("âŒ ì‹¤ì‹œê°„ ë°ì´í„° í†µí•© ì‹¤íŒ¨")
                
                with col2:
                    # ì‹¤ì‹œê°„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    market_data = st.session_state.realtime_market_data
                    summary = market_data.get("summary", {})
                    
                    if summary:
                        st.markdown("**ğŸ“‹ ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´ ë¯¸ë¦¬ë³´ê¸°:**")
                        key_insights = summary.get("key_insights", [])
                        for insight in key_insights[:2]:
                            st.markdown(f"â€¢ {insight}")
                        
                        if summary.get("brand_info"):
                            brands = ", ".join(summary["brand_info"][:3])
                            st.markdown(f"â€¢ ì£¼ìš” ë¸Œëœë“œ: {brands}")
            
            elif has_web_data:
                st.info("ğŸ” ì´ì „ì— ìˆ˜í–‰í•œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ë¶„ì„ê³¼ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                if st.button("ğŸ”— ì›¹ ë°ì´í„°ì™€ íŒŒì¼ ë¶„ì„ ê²°ê³¼ í†µí•©", type="primary"):
                    with st.spinner("ğŸŒ ì›¹ ë°ì´í„°ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ëŠ” ì¤‘..."):
                        integration_result = self.integrate_web_data_with_analysis()
                        
                        if integration_result and integration_result.get("integration_success"):
                            st.success("âœ… ì›¹ ë°ì´í„° í†µí•© ì™„ë£Œ!")
                            
                            # í†µí•© ê²°ê³¼ í‘œì‹œ
                            self.display_integrated_analysis_results(integration_result)
                        else:
                            st.error("âŒ ì›¹ ë°ì´í„° í†µí•© ì‹¤íŒ¨")
            else:
                st.info("ğŸ’¡ 1ë‹¨ê³„ì—ì„œ ì‹¤ì‹œê°„ ì‹œì¥ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê±°ë‚˜ MCP ë¸Œë¼ìš°ì €ì—ì„œ ì›¹ ê²€ìƒ‰ì„ ë¨¼ì € í•˜ë©´ ë” í’ë¶€í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ”„ 1ë‹¨ê³„ë¡œ ì´ë™", type="secondary"):
                        st.session_state.workflow_step = 1
                        st.rerun()
                with col2:
                    if st.button("ğŸš€ MCP ë¸Œë¼ìš°ì €ë¡œ ì´ë™", type="secondary"):
                        st.session_state.active_tab = "mcp_browser"
                        st.rerun()
            
            st.markdown("---")
            
            # ğŸ­ ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„± (ìƒˆ ê¸°ëŠ¥)
            st.markdown("### ğŸ­ ì¢…í•© ìŠ¤í† ë¦¬ - ë¬´ì—‡ì— ëŒ€í•œ ì´ì•¼ê¸°ì¸ê°€?")
            
            if st.button("ğŸ“– ì „ì²´ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ì´ì•¼ê¸°ë¡œ ë§Œë“¤ê¸°", type="primary"):
                with st.spinner("ğŸ­ AIê°€ ì „ì²´ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ í•œêµ­ì–´ ìŠ¤í† ë¦¬ë¡œ êµ¬ì„± ì¤‘..."):
                    story_result = self.create_comprehensive_story()
                    
                    if story_result and story_result.get("status") == "success":
                        st.success("âœ… ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„± ì™„ë£Œ!")
                        
                        story_content = story_result.get("story", "")
                        if story_content:
                            st.markdown("#### ğŸ“š ìƒì„±ëœ ìŠ¤í† ë¦¬")
                            st.markdown(f"```markdown\n{story_content}\n```")
                            
                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            st.download_button(
                                label="ğŸ“¥ ìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ (TXT)",
                                data=story_content,
                                file_name=f"ì¢…í•©_ìŠ¤í† ë¦¬_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                                mime="text/plain"
                            )
                        
                        # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                        metadata = story_result.get("metadata", {})
                        if metadata:
                            st.markdown("#### ğŸ“Š ìŠ¤í† ë¦¬ ìƒì„± ì •ë³´")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ì²˜ë¦¬ëœ ì†ŒìŠ¤", metadata.get("source_count", 0))
                            with col2:
                                st.metric("ì‚¬ìš©ëœ AI ì—”ì§„", metadata.get("ai_engine_used", "Local"))
                            with col3:
                                st.metric("í•µì‹¬ ë©”ì‹œì§€ ìˆ˜", metadata.get("key_messages_count", 0))
                    
                    elif story_result and story_result.get("status") == "error":
                        st.error(f"âŒ ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {story_result.get('error', 'Unknown error')}")
                        
                        # í´ë°± ìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                        fallback_story = story_result.get("fallback_story")
                        if fallback_story:
                            st.markdown("#### ğŸ“„ ê¸°ë³¸ ìš”ì•½")
                            st.markdown(fallback_story)
                            
                        # API í‚¤ ì„¤ì • ì•ˆë‚´
                        if "API Key" in story_result.get("error", ""):
                            st.info("ğŸ’¡ **ë” ë‚˜ì€ ìŠ¤í† ë¦¬ ìƒì„±ì„ ìœ„í•œ ì•ˆë‚´:**\n\nOpenAI API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY`ì— ì„¤ì •í•˜ë©´ GPT-4ë¥¼ í™œìš©í•œ ê³ í’ˆì§ˆ ìŠ¤í† ë¦¬ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    
                    else:
                        st.warning("âš ï¸ ìŠ¤í† ë¦¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            st.markdown("---")
            
            # í•µì‹¬ ìš”ì•½
            st.markdown("### ğŸ¯ í•µì‹¬ ìš”ì•½")
            st.markdown(report['executive_summary'])
            
            # ì£¼ìš” ë°œê²¬ì‚¬í•­
            if report['key_findings']:
                st.markdown("### ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­")
                for i, finding in enumerate(report['key_findings'], 1):
                    st.markdown(f"{i}. {finding}")
            
            # í‚¤ì›Œë“œ í´ë¼ìš°ë“œ
            if report['top_keywords']:
                st.markdown("### ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ")
                col1, col2, col3 = st.columns(3)
                for i, (keyword, count) in enumerate(report['top_keywords'][:15]):
                    with [col1, col2, col3][i % 3]:
                        st.metric(keyword, f"{count}íšŒ")
            
            # ğŸ“Š ê³ ê¸‰ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
            st.markdown("### ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
            self.render_advanced_dashboard(report)
            
            # íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼ (ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ë°˜ì˜)
            with st.expander("ğŸ“„ íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
                edited_transcripts = st.session_state.get('edited_transcripts', {})
                
                for result in st.session_state.analysis_results:
                    if result.get('status') == 'success':
                        filename = result['file_name']
                        st.markdown(f"**{filename}**")
                        
                        # ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                        is_modified = filename in edited_transcripts and edited_transcripts[filename].get('modified')
                        
                        if result.get('full_text'):
                            # í‘œì‹œí•  í…ìŠ¤íŠ¸ ê²°ì • (ìˆ˜ì •ëœ ê²ƒ ìš°ì„ )
                            display_text = edited_transcripts[filename]['edited'] if is_modified else result['full_text']
                            
                            # ìˆ˜ì • ì—¬ë¶€ í‘œì‹œ
                            if is_modified:
                                st.success("âœï¸ ì‚¬ìš©ìê°€ ìˆ˜ì •í•œ ìŠ¤í¬ë¦½íŠ¸")
                            
                            st.text_area(
                                "ì¶”ì¶œëœ í…ìŠ¤íŠ¸" + (" (ìˆ˜ì •ë¨)" if is_modified else ""),
                                value=display_text[:500] + ("..." if len(display_text) > 500 else ""),
                                height=100,
                                disabled=True,
                                key=f"detail_{filename}"
                            )
                            
                            # ìˆ˜ì • ì „/í›„ ë¹„êµ í‘œì‹œ (ì˜µì…˜)
                            if is_modified:
                                with st.expander("ğŸ“ ìˆ˜ì • ì „/í›„ ë¹„êµ"):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.markdown("**ìˆ˜ì • ì „:**")
                                        st.text_area("", value=edited_transcripts[filename]['original'][:300] + "...", 
                                                   height=80, disabled=True, key=f"before_{filename}")
                                    with col2:
                                        st.markdown("**ìˆ˜ì • í›„:**")
                                        st.text_area("", value=edited_transcripts[filename]['edited'][:300] + "...", 
                                                   height=80, disabled=True, key=f"after_{filename}")
                        
                        if result.get('summary'):
                            st.info(f"**ìš”ì•½:** {result['summary']}")
                        st.markdown("---")
            
            # ê²°ë¡  ë° ì œì•ˆì‚¬í•­
            if report['conclusions']:
                st.markdown("### ğŸ’¡ ê²°ë¡  ë° ì œì•ˆì‚¬í•­")
                for i, conclusion in enumerate(report['conclusions'], 1):
                    st.markdown(f"{i}. {conclusion}")
            
            # ì¢…í•© ê°•ì˜ ë‚´ìš©
            if LECTURE_COMPILER_AVAILABLE:
                st.markdown("### ğŸ“ ì¢…í•© ê°•ì˜ ë‚´ìš©")
                
                if not hasattr(st.session_state, 'comprehensive_lecture') or st.session_state.comprehensive_lecture is None:
                    if st.button("ğŸ“š ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„±", type="secondary"):
                        st.session_state.comprehensive_lecture = self.generate_comprehensive_lecture()
                        if st.session_state.comprehensive_lecture:
                            st.success("âœ… ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„± ì™„ë£Œ!")
                            st.rerun()
                else:
                    # ê°•ì˜ ë‚´ìš© í‘œì‹œ
                    lecture = st.session_state.comprehensive_lecture
                    
                    # ê°•ì˜ ì œëª©
                    st.markdown(f"#### ğŸ“– {lecture['title']}")
                    
                    # ê°•ì˜ ê°œìš”
                    with st.expander("ğŸ“‹ ê°•ì˜ ê°œìš”", expanded=True):
                        st.markdown(lecture['overview'])
                    
                    # ì£¼ìš” ì£¼ì œ
                    if lecture['main_topics']:
                        with st.expander("ğŸ¯ ì£¼ìš” ì£¼ì œ"):
                            for i, topic in enumerate(lecture['main_topics'], 1):
                                st.markdown(f"{i}. {topic}")
                    
                    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                    if lecture['key_insights']:
                        with st.expander("ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸"):
                            for i, insight in enumerate(lecture['key_insights'], 1):
                                st.markdown(f"{i}. {insight}")
                    
                    # ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ
                    if lecture['practical_applications']:
                        with st.expander("ğŸ› ï¸ ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ"):
                            for i, application in enumerate(lecture['practical_applications'], 1):
                                st.markdown(f"{i}. {application}")
                    
                    # ì„¸ë¶€ ë‚´ìš© (ì¹´í…Œê³ ë¦¬ë³„)
                    if lecture['detailed_content']:
                        with st.expander("ğŸ“š ì„¸ë¶€ ë‚´ìš© (ì¹´í…Œê³ ë¦¬ë³„)"):
                            for category, content in lecture['detailed_content'].items():
                                if content['summary']:
                                    st.markdown(f"**{category.replace('_', ' ').title()}**")
                                    st.markdown(content['summary'])
                                    
                                    if content['key_points']:
                                        st.markdown("ì£¼ìš” í¬ì¸íŠ¸:")
                                        for point in content['key_points'][:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                                            st.markdown(f"â€¢ {point}")
                                    st.markdown("---")
                    
                    # ê²°ë¡ 
                    if lecture['conclusion']:
                        with st.expander("ğŸ¯ ê°•ì˜ ê²°ë¡ "):
                            st.markdown(lecture['conclusion'])
                    
                    # í’ˆì§ˆ ë° ë©”íƒ€ë°ì´í„°
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("í’ˆì§ˆ ì ìˆ˜", f"{lecture['metadata']['quality_score']:.1f}/100")
                    with col2:
                        st.metric("ì²˜ë¦¬ íŒŒì¼ ìˆ˜", lecture['metadata']['total_files'])
                    with col3:
                        st.metric("ì»´íŒŒì¼ ì‹œê°„", f"{lecture['metadata']['compilation_time']:.1f}ì´ˆ")
                    
                    # ê°•ì˜ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
                    if st.button("ğŸ”„ ê°•ì˜ ë‚´ìš© ì¬ìƒì„±", type="secondary"):
                        st.session_state.comprehensive_lecture = None
                        st.rerun()
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            st.markdown("### ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # ì™„ì „í•œ ë³´ê³ ì„œ JSON
                report_json = json.dumps(convert_numpy_types({
                    'report': report,
                    'detailed_results': st.session_state.analysis_results,
                    'project_info': st.session_state.project_info
                }), indent=2, ensure_ascii=False)
                
                st.download_button(
                    "ğŸ“Š ì™„ì „í•œ ë³´ê³ ì„œ (JSON)",
                    data=report_json,
                    file_name=f"ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
            
            with col2:
                # ìš”ì•½ ë³´ê³ ì„œ í…ìŠ¤íŠ¸
                summary_text = f"""
# {report['project_name']} ë¶„ì„ ë³´ê³ ì„œ

## ë¶„ì„ ê°œìš”
- ë¶„ì„ ì¼ì‹œ: {report['analysis_date']}
- ì´ ì²˜ë¦¬ íŒŒì¼: {report['total_files']}ê°œ
- ì„±ê³µë¥ : {report['success_rate']:.1f}%

## í•µì‹¬ ìš”ì•½
{report['executive_summary']}

## ì£¼ìš” ë°œê²¬ì‚¬í•­
{chr(10).join([f'{i}. {finding}' for i, finding in enumerate(report['key_findings'], 1)])}

## ì£¼ìš” í‚¤ì›Œë“œ
{', '.join([keyword for keyword, _ in report['top_keywords'][:10]])}

## ê²°ë¡  ë° ì œì•ˆì‚¬í•­
{chr(10).join([f'{i}. {conclusion}' for i, conclusion in enumerate(report['conclusions'], 1)])}
"""
                
                st.download_button(
                    "ğŸ“„ ìš”ì•½ ë³´ê³ ì„œ (í…ìŠ¤íŠ¸)",
                    data=summary_text,
                    file_name=f"ìš”ì•½ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )
            
            with col3:
                # ê°•ì˜ ë‚´ìš© ë‹¤ìš´ë¡œë“œ (ìˆëŠ” ê²½ìš°)
                if hasattr(st.session_state, 'comprehensive_lecture') and st.session_state.comprehensive_lecture:
                    lecture = st.session_state.comprehensive_lecture
                    
                    # ê°•ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    lecture_text = f"""
# {lecture['title']}

## ê°•ì˜ ê°œìš”
{lecture['overview']}

## ì£¼ìš” ì£¼ì œ
{chr(10).join([f'{i}. {topic}' for i, topic in enumerate(lecture['main_topics'], 1)])}

## í•µì‹¬ ì¸ì‚¬ì´íŠ¸
{chr(10).join([f'{i}. {insight}' for i, insight in enumerate(lecture['key_insights'], 1)])}

## ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ
{chr(10).join([f'{i}. {app}' for i, app in enumerate(lecture['practical_applications'], 1)])}

## ê²°ë¡ 
{lecture['conclusion']}

---
ìƒì„± ì¼ì‹œ: {lecture['metadata']['compilation_date']}
í’ˆì§ˆ ì ìˆ˜: {lecture['metadata']['quality_score']}/100
"""
                    
                    st.download_button(
                        "ğŸ“ ì¢…í•© ê°•ì˜ ë‚´ìš©",
                        data=lecture_text,
                        file_name=f"ì¢…í•©ê°•ì˜_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                else:
                    # ì „ì²´ ì¶”ì¶œ í…ìŠ¤íŠ¸ (ê°•ì˜ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°)
                    all_texts = []
                    for result in st.session_state.analysis_results:
                        if result.get('status') == 'success' and result.get('full_text'):
                            all_texts.append(f"=== {result['file_name']} ===\n{result['full_text']}\n")
                    
                    combined_text = "\n".join(all_texts)
                    
                    st.download_button(
                        "ğŸ“ ì „ì²´ ì¶”ì¶œ í…ìŠ¤íŠ¸",
                        data=combined_text,
                        file_name=f"ì „ì²´í…ìŠ¤íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
        
        # ì„±ëŠ¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
        if PERFORMANCE_MONITOR_AVAILABLE:
            st.markdown("---")
            st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„")
            
            try:
                performance_summary = get_system_performance()
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    overall = performance_summary["overall_performance"]
                    rate = overall["success_rate"]
                    if rate >= 85:
                        st.metric("ğŸ¯ ì „ì²´ ì„±ê³µë¥ ", f"{rate}%", delta="ìš°ìˆ˜")
                    elif rate >= 70:
                        st.metric("ğŸ¯ ì „ì²´ ì„±ê³µë¥ ", f"{rate}%", delta="ì–‘í˜¸")
                    else:
                        st.metric("ğŸ¯ ì „ì²´ ì„±ê³µë¥ ", f"{rate}%", delta="ê°œì„ í•„ìš”")
                
                with col2:
                    recent = performance_summary["recent_performance"]
                    st.metric("ğŸ“ˆ ìµœê·¼ ì„±ê³µë¥ ", f"{recent['success_rate']}%", 
                             delta=f"ìµœê·¼ {recent['total_analyses']}ê°œ")
                
                with col3:
                    total_processed = performance_summary["system_stats"]["total_files_processed"]
                    st.metric("ğŸ“ ì´ ì²˜ë¦¬ íŒŒì¼", f"{total_processed}ê°œ")
                
                with col4:
                    errors = performance_summary["error_analysis"]["total_errors"]
                    if errors == 0:
                        st.metric("ğŸ›¡ï¸ ì´ ì˜¤ë¥˜", "0ê°œ", delta="ì•ˆì •")
                    else:
                        st.metric("ğŸ›¡ï¸ ì´ ì˜¤ë¥˜", f"{errors}ê°œ", delta="ì ê²€í•„ìš”")
                
                # íŒŒì¼ íƒ€ì…ë³„ ì„±ëŠ¥
                if performance_summary["file_type_performance"]:
                    with st.expander("ğŸ“ˆ íŒŒì¼ íƒ€ì…ë³„ ì„±ëŠ¥ ìƒì„¸"):
                        for file_type, perf in performance_summary["file_type_performance"].items():
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.markdown(f"**{file_type.upper()} íŒŒì¼**")
                            with col2:
                                st.markdown(f"ì„±ê³µë¥ : {perf['success_rate']}%")
                            with col3:
                                st.markdown(f"í‰ê·  ì‹œê°„: {perf['avg_processing_time']}ì´ˆ")
                
                # ì„±ëŠ¥ ê°œì„  ì¶”ì²œì‚¬í•­
                recommendations = global_performance_monitor.get_recommendations()
                if recommendations:
                    with st.expander("ğŸ’¡ ì„±ëŠ¥ ê°œì„  ì¶”ì²œì‚¬í•­"):
                        for rec in recommendations:
                            if rec["priority"] == "high":
                                st.error(f"ğŸ”´ **{rec['category']}**: {rec['recommendation']}")
                            elif rec["priority"] == "medium":
                                st.warning(f"ğŸŸ¡ **{rec['category']}**: {rec['recommendation']}")
                            else:
                                st.info(f"ğŸ”µ **{rec['category']}**: {rec['recommendation']}")
                
            except Exception as e:
                st.error(f"âš ï¸ ì„±ëŠ¥ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ†• ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘", type="primary", use_container_width=True):
                # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.workflow_step = 1
                st.session_state.project_info = {}
                st.session_state.uploaded_files_data = []
                st.session_state.analysis_results = []
                st.session_state.final_report = None
                st.success("âœ… ìƒˆ í”„ë¡œì íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(4)
    
    def render_multifile_analysis_tab(self):
        """ë©€í‹°íŒŒì¼ ë¶„ì„ íƒ­"""
        
        st.markdown("## ğŸ“ ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„")
        st.markdown("**ğŸš€ ëª¨ë“  ì§€ì› í˜•ì‹ì„ í•œë²ˆì— ì—…ë¡œë“œí•˜ì—¬ ë°°ì¹˜ ë¶„ì„**")
        
        if not REAL_ANALYSIS_AVAILABLE:
            st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì§€ì› í˜•ì‹ ì•ˆë‚´
        with st.expander("ğŸ“‹ ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ğŸ¤ ìŒì„± íŒŒì¼:**")
                st.markdown("- WAV, MP3, FLAC, M4A, MP4")
                st.markdown("- Whisper STTë¡œ ì‹¤ì œ ë³€í™˜")
            
            with col2:
                st.markdown("**ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼:**")
                st.markdown("- JPG, JPEG, PNG, BMP, TIFF")
                st.markdown("- EasyOCRë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        
        # ë©€í‹°íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ë™ì‹œ ì„ íƒ ê°€ëŠ¥)",
            type=['wav', 'mp3', 'flac', 'm4a', 'mp4', 'jpg', 'jpeg', 'png', 'bmp', 'tiff'],
            accept_multiple_files=True,
            help="Ctrl/Cmd + í´ë¦­ìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥"
        )
        
        if uploaded_files:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
            st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
            
            audio_files = []
            image_files = []
            total_size = 0
            
            # íŒŒì¼ ë¶„ë¥˜
            for file in uploaded_files:
                file_size = len(file.getvalue()) / (1024 * 1024)
                total_size += file_size
                
                file_ext = file.name.split('.')[-1].lower()
                
                if file_ext in ['wav', 'mp3', 'flac', 'm4a', 'mp4']:
                    audio_files.append(file)
                elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                    image_files.append(file)
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ¤ ìŒì„± íŒŒì¼", f"{len(audio_files)}ê°œ")
            
            with col2:
                st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼", f"{len(image_files)}ê°œ")
            
            with col3:
                st.metric("ğŸ“¦ ì´ í¬ê¸°", f"{total_size:.2f} MB")
            
            # íŒŒì¼ ëª©ë¡ ìƒì„¸ í‘œì‹œ
            if audio_files or image_files:
                with st.expander("ğŸ” íŒŒì¼ ìƒì„¸ ì •ë³´"):
                    
                    if audio_files:
                        st.markdown("**ğŸ¤ ìŒì„± íŒŒì¼ë“¤:**")
                        for i, file in enumerate(audio_files, 1):
                            file_size = len(file.getvalue()) / (1024 * 1024)
                            st.write(f"{i}. {file.name} ({file_size:.2f} MB)")
                    
                    if image_files:
                        st.markdown("**ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ë“¤:**")
                        for i, file in enumerate(image_files, 1):
                            file_size = len(file.getvalue()) / (1024 * 1024)
                            st.write(f"{i}. {file.name} ({file_size:.2f} MB)")
            
            # ë¶„ì„ ì„¤ì •
            st.markdown("### âš™ï¸ ë°°ì¹˜ ë¶„ì„ ì„¤ì •")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                audio_language = st.selectbox(
                    "ìŒì„± ì–¸ì–´",
                    ["ko", "en", "auto"],
                    help="ëª¨ë“  ìŒì„± íŒŒì¼ì— ì ìš©"
                )
            
            with col2:
                whisper_model = st.selectbox(
                    "Whisper ëª¨ë¸",
                    ["tiny", "base", "small", "medium"],
                    index=1,
                    help="ì •í™•ë„ vs ì†ë„"
                )
            
            with col3:
                cpu_mode = st.checkbox(
                    "CPU ëª¨ë“œ ê°•ì œ",
                    value=True,
                    help="GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€"
                )
            
            # ë°°ì¹˜ ë¶„ì„ ì‹œì‘
            if st.button("ğŸš€ ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì‹œì‘", type="primary"):
                self.process_multifile_analysis(
                    audio_files, image_files, 
                    audio_language, whisper_model, cpu_mode
                )
        
        else:
            st.info("ğŸ“ ì—¬ëŸ¬ íŒŒì¼ì„ ì„ íƒí•˜ì—¬ ë°°ì¹˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
            st.markdown("**ğŸ’¡ ì‚¬ìš©ë²•:**")
            st.markdown("1. ìœ„ì˜ íŒŒì¼ ì—…ë¡œë“œ ë²„íŠ¼ í´ë¦­")
            st.markdown("2. Ctrl/Cmd + í´ë¦­ìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ")
            st.markdown("3. ìŒì„±ê³¼ ì´ë¯¸ì§€ íŒŒì¼ì„ í•¨ê»˜ ì„ íƒ ê°€ëŠ¥")
            st.markdown("4. ì„¤ì • í™•ì¸ í›„ ë°°ì¹˜ ë¶„ì„ ì‹œì‘")
    
    def process_multifile_analysis(self, audio_files: List, image_files: List, 
                                 language: str, model_size: str, cpu_mode: bool):
        """ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì²˜ë¦¬"""
        
        total_files = len(audio_files) + len(image_files)
        
        if total_files == 0:
            st.warning("âš ï¸ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # CPU ëª¨ë“œ ì„¤ì •
        if cpu_mode:
            force_cpu_mode()
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        st.markdown("### ğŸ”„ ë°°ì¹˜ ë¶„ì„ ì§„í–‰ ìƒí™©")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        results_container = st.container()
        
        batch_results = []
        processed_count = 0
        
        # ë°°ì¹˜ ë¶„ì„ ì‹œì‘ ì‹œê°„
        batch_start_time = time.time()
        
        try:
            # ìŒì„± íŒŒì¼ ë¶„ì„
            for i, audio_file in enumerate(audio_files):
                
                status_text.text(f"ğŸ¤ ìŒì„± ë¶„ì„ ì¤‘: {audio_file.name} ({i+1}/{len(audio_files)})")
                
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                with tempfile.NamedTemporaryFile(
                    delete=False, 
                    suffix=f".{audio_file.name.split('.')[-1]}"
                ) as tmp_file:
                    tmp_file.write(audio_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                try:
                    # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                    result = self.analysis_engine.analyze_audio_file(tmp_file_path, language)
                    result['batch_index'] = processed_count + 1
                    result['file_type'] = 'audio'
                    batch_results.append(result)
                    
                    # ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
                    with results_container:
                        if result.get('status') == 'success':
                            st.success(f"âœ… {audio_file.name}: {result['text_length']}ê¸€ì ì¶”ì¶œ ({result['processing_time']}ì´ˆ)")
                            # ì„±ê³µí•œ ê²°ê³¼ì˜ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                            if result.get('full_text'):
                                preview_text = result['full_text'][:200] + ("..." if len(result['full_text']) > 200 else "")
                                st.text_area(
                                    f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {audio_file.name}",
                                    value=preview_text,
                                    height=80,
                                    disabled=True,
                                    key=f"audio_preview_{processed_count}"
                                )
                        else:
                            st.error(f"âŒ {audio_file.name}: {result.get('error', 'Unknown error')}")
                
                except Exception as e:
                    error_result = {
                        'status': 'error',
                        'error': str(e),
                        'file_name': audio_file.name,
                        'batch_index': processed_count + 1,
                        'file_type': 'audio'
                    }
                    batch_results.append(error_result)
                    
                    with results_container:
                        st.error(f"âŒ {audio_file.name}: {str(e)}")
                
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(tmp_file_path)
                    except:
                        pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                processed_count += 1
                progress_bar.progress(processed_count / total_files)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„
            for i, image_file in enumerate(image_files):
                
                status_text.text(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_file.name} ({i+1}/{len(image_files)})")
                
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                with tempfile.NamedTemporaryFile(
                    delete=False,
                    suffix=f".{image_file.name.split('.')[-1]}"
                ) as tmp_file:
                    tmp_file.write(image_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                try:
                    # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                    result = self.analysis_engine.analyze_image_file(tmp_file_path)
                    result['batch_index'] = processed_count + 1
                    result['file_type'] = 'image'
                    batch_results.append(result)
                    
                    # ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
                    with results_container:
                        if result.get('status') == 'success':
                            st.success(f"âœ… {image_file.name}: {result['blocks_detected']}ê°œ ë¸”ë¡ ì¶”ì¶œ ({result['processing_time']}ì´ˆ)")
                            # ì„±ê³µí•œ ê²°ê³¼ì˜ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                            if result.get('full_text'):
                                preview_text = result['full_text'][:200] + ("..." if len(result['full_text']) > 200 else "")
                                st.text_area(
                                    f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {image_file.name}",
                                    value=preview_text,
                                    height=80,
                                    disabled=True,
                                    key=f"image_preview_{processed_count}"
                                )
                        else:
                            st.error(f"âŒ {image_file.name}: {result.get('error', 'Unknown error')}")
                
                except Exception as e:
                    error_result = {
                        'status': 'error',
                        'error': str(e),
                        'file_name': image_file.name,
                        'batch_index': processed_count + 1,
                        'file_type': 'image'
                    }
                    batch_results.append(error_result)
                    
                    with results_container:
                        st.error(f"âŒ {image_file.name}: {str(e)}")
                
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(tmp_file_path)
                    except:
                        pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                processed_count += 1
                progress_bar.progress(processed_count / total_files)
            
            # ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ
            batch_end_time = time.time()
            total_batch_time = batch_end_time - batch_start_time
            
            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            self.display_batch_results_summary(batch_results, total_batch_time)
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥ (NumPy íƒ€ì… ë³€í™˜ í›„)
            if 'analysis_results' not in st.session_state:
                st.session_state.analysis_results = []
            
            # NumPy íƒ€ì…ì„ JSON í˜¸í™˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            converted_batch_results = convert_numpy_types(batch_results)
            st.session_state.analysis_results.extend(converted_batch_results)
            
            # ì„±ê³µ ë©”ì‹œì§€ì™€ í•¨ê»˜ ë§í¬ ì œê³µ
            status_text.text("âœ… ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ!")
            st.balloons()  # ì¶•í•˜ ì• ë‹ˆë©”ì´ì…˜
            
            # ê²°ê³¼ í™•ì¸ ë§í¬
            st.markdown("### ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
            st.info("ğŸ“Š **ë¶„ì„ ê²°ê³¼** íƒ­ì—ì„œ ëª¨ë“  ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.error(f"âŒ ë°°ì¹˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"ë°°ì¹˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def display_batch_results_summary(self, batch_results: List[Dict], total_time: float):
        """ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ ìš”ì•½ í‘œì‹œ"""
        
        st.markdown("### ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ ìš”ì•½")
        
        # í†µê³„ ê³„ì‚°
        total_files = len(batch_results)
        successful_files = len([r for r in batch_results if r.get('status') == 'success'])
        audio_files = len([r for r in batch_results if r.get('file_type') == 'audio'])
        image_files = len([r for r in batch_results if r.get('file_type') == 'image'])
        
        # ë©”íŠ¸ë¦­ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ íŒŒì¼", f"{total_files}ê°œ")
        
        with col2:
            st.metric("ì„±ê³µ", f"{successful_files}ê°œ")
        
        with col3:
            success_rate = (successful_files / total_files * 100) if total_files > 0 else 0
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
        
        with col4:
            st.metric("ì´ ì²˜ë¦¬ì‹œê°„", f"{total_time:.1f}ì´ˆ")
        
        # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ¤ ìŒì„± íŒŒì¼ ê²°ê³¼:**")
            audio_success = len([r for r in batch_results 
                               if r.get('file_type') == 'audio' and r.get('status') == 'success'])
            st.write(f"- ì²˜ë¦¬: {audio_files}ê°œ")
            st.write(f"- ì„±ê³µ: {audio_success}ê°œ")
            
            if audio_success > 0:
                total_text = sum(r.get('text_length', 0) for r in batch_results 
                               if r.get('file_type') == 'audio' and r.get('status') == 'success')
                st.write(f"- ì´ ì¶”ì¶œ í…ìŠ¤íŠ¸: {total_text}ê¸€ì")
        
        with col2:
            st.markdown("**ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ê²°ê³¼:**")
            image_success = len([r for r in batch_results 
                               if r.get('file_type') == 'image' and r.get('status') == 'success'])
            st.write(f"- ì²˜ë¦¬: {image_files}ê°œ")
            st.write(f"- ì„±ê³µ: {image_success}ê°œ")
            
            if image_success > 0:
                total_blocks = sum(r.get('blocks_detected', 0) for r in batch_results 
                                 if r.get('file_type') == 'image' and r.get('status') == 'success')
                st.write(f"- ì´ í…ìŠ¤íŠ¸ ë¸”ë¡: {total_blocks}ê°œ")
        
        # ê°œë³„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ì¶”ê°€
        st.markdown("### ğŸ“‹ ê°œë³„ ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        
        successful_results = [r for r in batch_results if r.get('status') == 'success']
        
        if successful_results:
            for i, result in enumerate(successful_results, 1):
                with st.expander(f"ğŸ“„ {result.get('file_name', f'íŒŒì¼ {i}')} - {result.get('file_type', '').upper()} ê²°ê³¼"):
                    
                    # ê¸°ë³¸ ì •ë³´
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.write(f"**íŒŒì¼:** {result.get('file_name', 'Unknown')}")
                    with col2:
                        st.write(f"**íƒ€ì…:** {result.get('file_type', 'Unknown').upper()}")
                    with col3:
                        st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {result.get('processing_time', 'N/A')}ì´ˆ")
                    
                    # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í‘œì‹œ
                    if result.get('full_text'):
                        st.markdown("**ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**")
                        text_preview = result['full_text'][:300] + ("..." if len(result['full_text']) > 300 else "")
                        st.text_area(
                            "í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°",
                            value=text_preview,
                            height=100,
                            disabled=True,
                            key=f"batch_preview_{i}"
                        )
                        
                        # ì „ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ ì˜µì…˜
                        if len(result['full_text']) > 300:
                            if st.button(f"ğŸ“– ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸°", key=f"show_full_{i}"):
                                st.text_area(
                                    "ì „ì²´ í…ìŠ¤íŠ¸",
                                    value=result['full_text'],
                                    height=200,
                                    disabled=True,
                                    key=f"batch_full_{i}"
                                )
                    
                    # ìš”ì•½ í‘œì‹œ
                    if result.get('summary'):
                        st.markdown("**ğŸ“‹ AI ìš”ì•½:**")
                        st.info(result['summary'])
                    
                    # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ í‘œì‹œ
                    if result.get('jewelry_keywords'):
                        st.markdown("**ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ:**")
                        keyword_text = ", ".join(result['jewelry_keywords'])
                        st.write(keyword_text)
        
        # ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ - ë” ëª…í™•í•œ í˜•íƒœë¡œ ì œê³µ
        st.markdown("### ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # JSON ë‹¤ìš´ë¡œë“œ (NumPy íƒ€ì… ë³€í™˜)
            batch_data = {
                'batch_summary': {
                    'total_files': total_files,
                    'successful_files': successful_files,
                    'success_rate': success_rate,
                    'total_processing_time': total_time,
                    'audio_files': audio_files,
                    'image_files': image_files,
                    'analysis_date': datetime.now().isoformat()
                },
                'individual_results': batch_results
            }
            # NumPy íƒ€ì… ë³€í™˜ í›„ JSON ì§ë ¬í™”
            converted_batch_data = convert_numpy_types(batch_data)
            batch_json = json.dumps(converted_batch_data, indent=2, ensure_ascii=False)
            
            st.download_button(
                "ğŸ“„ JSON í˜•ì‹ ë‹¤ìš´ë¡œë“œ",
                data=batch_json,
                file_name=f"batch_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                help="ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"
            )
        
        with col2:
            # í…ìŠ¤íŠ¸ë§Œ ë‹¤ìš´ë¡œë“œ
            text_content = "\n\n" + "="*50 + "\n"
            text_content += f"ì†”ë¡œëª¬ë“œ AI ë°°ì¹˜ ë¶„ì„ ê²°ê³¼\n"
            text_content += f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            text_content += f"ì´ íŒŒì¼: {total_files}ê°œ, ì„±ê³µ: {successful_files}ê°œ\n"
            text_content += "="*50 + "\n\n"
            
            for i, result in enumerate(successful_results, 1):
                text_content += f"{i}. {result.get('file_name', f'íŒŒì¼ {i}')} ({result.get('file_type', '').upper()})\n"
                text_content += "-" * 30 + "\n"
                if result.get('full_text'):
                    text_content += result['full_text'] + "\n"
                if result.get('summary'):
                    text_content += f"\n[ìš”ì•½] {result['summary']}\n"
                if result.get('jewelry_keywords'):
                    text_content += f"\n[í‚¤ì›Œë“œ] {', '.join(result['jewelry_keywords'])}\n"
                text_content += "\n" + "="*50 + "\n\n"
            
            st.download_button(
                "ğŸ“ í…ìŠ¤íŠ¸ í˜•ì‹ ë‹¤ìš´ë¡œë“œ",
                data=text_content,
                file_name=f"batch_texts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                help="ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë§Œ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ"
            )

    def display_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            if REAL_ANALYSIS_AVAILABLE:
                st.success("âœ… ì‹¤ì œ ë¶„ì„ ì—”ì§„")
            else:
                st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„")
        
        with col2:
            try:
                import whisper
                st.success("âœ… Whisper STT")
            except ImportError:
                st.error("âŒ Whisper STT")
        
        with col3:
            try:
                import easyocr
                st.success("âœ… EasyOCR")
            except ImportError:
                st.error("âŒ EasyOCR")
        
        with col4:
            try:
                from transformers import pipeline
                st.success("âœ… Transformers")
            except ImportError:
                st.warning("âš ï¸ Transformers")
        
        with col5:
            st.markdown("**ğŸ“ˆ ì„±ëŠ¥**")
            if PERFORMANCE_MONITOR_AVAILABLE:
                try:
                    success_rate = get_current_success_rate()
                    if success_rate["total_analyses"] > 0:
                        rate = success_rate["success_rate"]
                        if rate >= 85:
                            st.success(f"âœ… {rate}%")
                        elif rate >= 70:
                            st.warning(f"âš ï¸ {rate}%")
                        else:
                            st.error(f"âŒ {rate}%")
                        st.caption(f"ì´ {success_rate['total_analyses']}ê°œ")
                    else:
                        st.info("ğŸ“Š ë¶„ì„ ëŒ€ê¸°")
                except Exception:
                    st.caption("âš ï¸ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜")
            else:
                st.caption("âŒ ëª¨ë‹ˆí„°ë§ ë¶ˆê°€")
    
    def render_audio_analysis_tab(self):
        """ìŒì„± ë¶„ì„ íƒ­"""
        
        st.markdown("## ğŸ¤ ì‹¤ì œ ìŒì„± ë¶„ì„ (Whisper STT)")
        
        if not REAL_ANALYSIS_AVAILABLE:
            st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ìŒì„± íŒŒì¼ ì—…ë¡œë“œ",
            type=['wav', 'mp3', 'flac', 'm4a', 'mp4'],
            help="ì§€ì› í˜•ì‹: WAV, MP3, FLAC, M4A, MP4"
        )
        
        if uploaded_file is not None:
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
            st.info(f"ğŸ“ íŒŒì¼: {uploaded_file.name} ({file_size:.2f} MB)")
            
            # ë¶„ì„ ì„¤ì •
            col1, col2 = st.columns(2)
            with col1:
                language = st.selectbox(
                    "ì–¸ì–´ ì„ íƒ",
                    ["ko", "en", "auto"],
                    help="ko: í•œêµ­ì–´, en: ì˜ì–´, auto: ìë™ ê°ì§€"
                )
            
            with col2:
                whisper_model = st.selectbox(
                    "Whisper ëª¨ë¸",
                    ["tiny", "base", "small", "medium"],
                    index=1,
                    help="tiny: ë¹ ë¦„, medium: ì •í™•"
                )
            
            # ë¶„ì„ ì‹œì‘
            if st.button("ğŸ¯ ì‹¤ì œ ìŒì„± ë¶„ì„ ì‹œì‘", type="primary"):
                self.process_audio_analysis(uploaded_file, language, whisper_model)
    
    def process_audio_analysis(self, uploaded_file, language: str, model_size: str):
        """ì‹¤ì œ ìŒì„± ë¶„ì„ ì²˜ë¦¬"""
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        try:
            with st.spinner("ğŸ¤ Whisper STT ì‹¤ì œ ë¶„ì„ ì¤‘..."):
                
                # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                start_time = time.time()
                result = self.analysis_engine.analyze_audio_file(tmp_file_path, language)
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                if result.get("status") == "success":
                    st.success(f"âœ… ìŒì„± ë¶„ì„ ì™„ë£Œ! ({result['processing_time']}ì´ˆ)")
                    
                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    self.display_audio_results(result)
                    
                    # ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸
                    self.update_session_stats(processing_time, True)
                    
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥ (NumPy íƒ€ì… ë³€í™˜ í›„)
                    if 'analysis_results' not in st.session_state:
                        st.session_state.analysis_results = []
                    converted_result = convert_numpy_types(result)
                    st.session_state.analysis_results.append(converted_result)
                    
                else:
                    st.error(f"âŒ ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    self.update_session_stats(processing_time, False)
                    
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"ìŒì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(tmp_file_path)
            except:
                pass
    
    def display_audio_results(self, result: Dict[str, Any]):
        """ìŒì„± ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ì‚¬ìš©ì ì¹œí™”ì  ë²„ì „"""
        
        # ğŸš€ í–¥ìƒëœ ê²°ê³¼ í‘œì‹œ ì—”ì§„ ì‚¬ìš©
        try:
            from core.user_friendly_presenter import show_enhanced_analysis_result
            show_enhanced_analysis_result(result, st.session_state.project_info)
            return
        except ImportError:
            pass  # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        
        # ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ í‘œì‹œ (fallback)
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['processing_time']}ì´ˆ")
        
        with col2:
            st.metric("ê°ì§€ ì–¸ì–´", result['detected_language'])
        
        with col3:
            st.metric("í…ìŠ¤íŠ¸ ê¸¸ì´", f"{result['text_length']}ì")
        
        with col4:
            st.metric("ì„¸ê·¸ë¨¼íŠ¸", f"{result['segments_count']}ê°œ")
        
        # ğŸ’¡ í•µì‹¬ ê°œì„ : ì¢…í•© ë©”ì‹œì§€ ë¶„ì„ í‘œì‹œ
        if result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success':
            st.markdown("### ğŸ¯ **ì´ ì‚¬ëŒë“¤ì´ ë§í•œ ë‚´ìš© ìš”ì•½**")
            
            comp_msg = result['comprehensive_messages']
            main_summary = comp_msg.get('main_summary', {})
            
            # í•µì‹¬ í•œ ì¤„ ìš”ì•½
            if main_summary.get('one_line_summary'):
                st.success(f"**ğŸ“¢ í•µì‹¬ ë©”ì‹œì§€:** {main_summary['one_line_summary']}")
            
            # ê³ ê° ìƒíƒœ ë° ì¤‘ìš”ë„
            col1, col2 = st.columns(2)
            with col1:
                if main_summary.get('customer_status'):
                    st.info(f"**ğŸ‘¤ ê³ ê° ìƒíƒœ:** {main_summary['customer_status']}")
            with col2:
                if main_summary.get('urgency_indicator'):
                    urgency_colors = {'ë†’ìŒ': 'ğŸ”´', 'ë³´í†µ': 'ğŸŸ¡', 'ë‚®ìŒ': 'ğŸŸ¢'}
                    urgency_emoji = urgency_colors.get(main_summary['urgency_indicator'], 'âšª')
                    st.info(f"**âš¡ ê¸´ê¸‰ë„:** {urgency_emoji} {main_summary['urgency_indicator']}")
            
            # ì£¼ìš” í¬ì¸íŠ¸
            if main_summary.get('key_points'):
                st.markdown("**ğŸ” ì£¼ìš” í¬ì¸íŠ¸:**")
                for point in main_summary['key_points'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    st.markdown(f"â€¢ {point}")
            
            # ì¶”ì²œ ì•¡ì…˜
            if main_summary.get('recommended_actions'):
                st.markdown("**ğŸ’¼ ì¶”ì²œ ì•¡ì…˜:**")
                for action in main_summary['recommended_actions']:
                    st.markdown(f"{action}")
            
            # ìƒì„¸ ë¶„ì„ (ì ‘ì„ ìˆ˜ ìˆê²Œ)
            with st.expander("ğŸ”¬ ìƒì„¸ ëŒ€í™” ë¶„ì„"):
                conv_analysis = comp_msg.get('conversation_analysis', {})
                
                # í™”ì ë¶„ì„
                if conv_analysis.get('speakers'):
                    speakers_info = conv_analysis['speakers']
                    st.markdown("**ğŸ‘¥ ëŒ€í™” ì°¸ì—¬ì:**")
                    if speakers_info.get('speaker_distribution'):
                        for speaker, count in speakers_info['speaker_distribution'].items():
                            st.markdown(f"â€¢ {speaker}: {count}íšŒ ë°œì–¸")
                
                # ëŒ€í™” ì˜ë„
                if conv_analysis.get('intent'):
                    intent_info = conv_analysis['intent']
                    st.markdown(f"**ğŸ¯ ëŒ€í™” ì˜ë„:** {intent_info.get('description', '')}")
                    st.markdown(f"**ğŸ“Š ì‹ ë¢°ë„:** {intent_info.get('confidence', 0)*100:.0f}%")
        
        # ğŸ¤ í™”ì ë¶„ë¦¬ ê²°ê³¼ í‘œì‹œ (v2.3 ìƒˆë¡œìš´ ê¸°ëŠ¥)
        if result.get('speaker_analysis') and result['speaker_analysis'].get('status') == 'success':
            self._display_speaker_diarization_results(result['speaker_analysis'])
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ê¸°ìˆ ì  ìƒì„¸ì •ë³´ë¡œ ì´ë™)
        with st.expander("ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸"):
            st.text_area(
                "ì „ì²´ í…ìŠ¤íŠ¸",
                value=result['full_text'],
                height=200,
                disabled=True
            )
        
        # ê¸°ì¡´ ìš”ì•½ (fallback)
        if result.get('summary') and not (result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success'):
            st.markdown("### ğŸ“‹ AI ìš”ì•½")
            st.info(result['summary'])
        
        # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ
        if result.get('jewelry_keywords'):
            st.markdown("### ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ")
            for keyword in result['jewelry_keywords']:
                st.badge(keyword)
        
        # ìƒì„¸ ì„¸ê·¸ë¨¼íŠ¸ (í™•ì¥ ê°€ëŠ¥)
        with st.expander("ğŸ” ìƒì„¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´"):
            for i, segment in enumerate(result.get('segments', []), 1):
                st.write(f"**{i}. [{segment['start']:.1f}s - {segment['end']:.1f}s]**")
                st.write(segment['text'])
                st.write("---")
    
    def render_image_analysis_tab(self):
        """ì´ë¯¸ì§€ ë¶„ì„ íƒ­"""
        
        st.markdown("## ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ (EasyOCR)")
        
        if not REAL_ANALYSIS_AVAILABLE:
            st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # GPU ë©”ëª¨ë¦¬ ê²½ê³ 
        st.warning("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ",
            type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
            help="ì§€ì› í˜•ì‹: JPG, PNG, BMP, TIFF"
        )
        
        if uploaded_file is not None:
            # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
            st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
            
            file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
            st.info(f"ğŸ“ íŒŒì¼: {uploaded_file.name} ({file_size:.2f} MB)")
            
            # ë¶„ì„ ì‹œì‘
            if st.button("ğŸ¯ ì‹¤ì œ OCR ë¶„ì„ ì‹œì‘", type="primary"):
                self.process_image_analysis(uploaded_file)
    
    def process_image_analysis(self, uploaded_file):
        """ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬"""
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        try:
            with st.spinner("ğŸ–¼ï¸ EasyOCR ì‹¤ì œ ë¶„ì„ ì¤‘..."):
                
                # CPU ëª¨ë“œ ê°•ì œ ì„¤ì • (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€)
                force_cpu_mode()
                
                # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                start_time = time.time()
                result = self.analysis_engine.analyze_image_file(tmp_file_path)
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                if result.get("status") == "success":
                    st.success(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ! ({result['processing_time']}ì´ˆ)")
                    
                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    self.display_image_results(result)
                    
                    # ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸
                    self.update_session_stats(processing_time, True)
                    
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥ (NumPy íƒ€ì… ë³€í™˜ í›„)
                    if 'analysis_results' not in st.session_state:
                        st.session_state.analysis_results = []
                    converted_result = convert_numpy_types(result)
                    st.session_state.analysis_results.append(converted_result)
                    
                else:
                    st.error(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    self.update_session_stats(processing_time, False)
                    
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(tmp_file_path)
            except:
                pass
    
    def display_image_results(self, result: Dict[str, Any]):
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ì‚¬ìš©ì ì¹œí™”ì  ë²„ì „"""
        
        # ğŸš€ í–¥ìƒëœ ê²°ê³¼ í‘œì‹œ ì—”ì§„ ì‚¬ìš©
        try:
            from core.user_friendly_presenter import show_enhanced_analysis_result
            show_enhanced_analysis_result(result, st.session_state.project_info)
            return
        except ImportError:
            pass  # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        
        # ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ í‘œì‹œ (fallback)
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['processing_time']}ì´ˆ")
        
        with col2:
            st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", f"{result['blocks_detected']}ê°œ")
        
        with col3:
            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{result['average_confidence']:.3f}")
        
        with col4:
            st.metric("íŒŒì¼ í¬ê¸°", f"{result['file_size_mb']} MB")
        
        # ğŸ’¡ í•µì‹¬ ê°œì„ : ì¢…í•© ë©”ì‹œì§€ ë¶„ì„ í‘œì‹œ
        if result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success':
            st.markdown("### ğŸ¯ **ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ë‚´ìš©**")
            
            comp_msg = result['comprehensive_messages']
            main_summary = comp_msg.get('main_summary', {})
            
            # í•µì‹¬ í•œ ì¤„ ìš”ì•½
            if main_summary.get('one_line_summary'):
                st.success(f"**ğŸ“¢ í•µì‹¬ ë©”ì‹œì§€:** {main_summary['one_line_summary']}")
            
            # ê³ ê° ìƒíƒœ ë° ì¤‘ìš”ë„
            col1, col2 = st.columns(2)
            with col1:
                if main_summary.get('customer_status'):
                    st.info(f"**ğŸ‘¤ ê³ ê° ìƒíƒœ:** {main_summary['customer_status']}")
            with col2:
                if main_summary.get('urgency_indicator'):
                    urgency_colors = {'ë†’ìŒ': 'ğŸ”´', 'ë³´í†µ': 'ğŸŸ¡', 'ë‚®ìŒ': 'ğŸŸ¢'}
                    urgency_emoji = urgency_colors.get(main_summary['urgency_indicator'], 'âšª')
                    st.info(f"**âš¡ ê¸´ê¸‰ë„:** {urgency_emoji} {main_summary['urgency_indicator']}")
            
            # ì£¼ìš” í¬ì¸íŠ¸
            if main_summary.get('key_points'):
                st.markdown("**ğŸ” ì£¼ìš” í¬ì¸íŠ¸:**")
                for point in main_summary['key_points'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    st.markdown(f"â€¢ {point}")
            
            # ì¶”ì²œ ì•¡ì…˜
            if main_summary.get('recommended_actions'):
                st.markdown("**ğŸ’¼ ì¶”ì²œ ì•¡ì…˜:**")
                for action in main_summary['recommended_actions']:
                    st.markdown(f"{action}")
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ê¸°ìˆ ì  ìƒì„¸ì •ë³´ë¡œ ì´ë™)
        with st.expander("ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸"):
            st.text_area(
                "OCR ê²°ê³¼",
                value=result['full_text'],
                height=150,
                disabled=True
            )
        
        # ê¸°ì¡´ ìš”ì•½ (fallback)
        if result.get('summary') and not (result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success'):
            st.markdown("### ğŸ“‹ AI ìš”ì•½")
            st.info(result['summary'])
        
        # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ
        if result.get('jewelry_keywords'):
            st.markdown("### ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ")
            for keyword in result['jewelry_keywords']:
                st.badge(keyword)
        
        # ìƒì„¸ ê²°ê³¼ (í™•ì¥ ê°€ëŠ¥)
        with st.expander("ğŸ” ìƒì„¸ OCR ê²°ê³¼"):
            for i, item in enumerate(result.get('detailed_results', []), 1):
                st.write(f"**{i}. ì‹ ë¢°ë„: {item['confidence']:.3f}**")
                st.write(f"í…ìŠ¤íŠ¸: {item['text']}")
                st.write("---")
    
    def render_results_tab(self):
        """ë¶„ì„ ê²°ê³¼ íƒ­"""
        
        st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼ ëª¨ìŒ")
        
        # ì„¸ì…˜ í†µê³„
        self.display_session_stats()
        
        # ì €ì¥ëœ ê²°ê³¼ë“¤
        if 'analysis_results' in st.session_state and st.session_state.analysis_results:
            
            st.markdown("### ğŸ“‹ ë¶„ì„ ê¸°ë¡")
            
            # ê²°ê³¼ í•„í„°ë§ ì˜µì…˜
            col1, col2, col3 = st.columns(3)
            with col1:
                filter_type = st.selectbox(
                    "íŒŒì¼ íƒ€ì… í•„í„°",
                    ["ì „ì²´", "ìŒì„±", "ì´ë¯¸ì§€"],
                    help="íŠ¹ì • íƒ€ì…ì˜ ê²°ê³¼ë§Œ í‘œì‹œ"
                )
            
            with col2:
                show_mode = st.selectbox(
                    "í‘œì‹œ ëª¨ë“œ",
                    ["ìš”ì•½", "ì „ì²´ í…ìŠ¤íŠ¸"],
                    help="í…ìŠ¤íŠ¸ í‘œì‹œ ë°©ì‹ ì„ íƒ"
                )
            
            with col3:
                results_per_page = st.selectbox(
                    "í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜",
                    [5, 10, 20, "ì „ì²´"],
                    index=1
                )
            
            # í•„í„°ë§ëœ ê²°ê³¼
            filtered_results = st.session_state.analysis_results
            if filter_type == "ìŒì„±":
                filtered_results = [r for r in filtered_results if r.get('analysis_type') == 'audio' or r.get('file_type') == 'audio']
            elif filter_type == "ì´ë¯¸ì§€":
                filtered_results = [r for r in filtered_results if r.get('analysis_type') == 'image' or r.get('file_type') == 'image']
            
            # í˜ì´ì§• ì²˜ë¦¬
            if results_per_page != "ì „ì²´":
                page_size = int(results_per_page)
                total_pages = (len(filtered_results) + page_size - 1) // page_size
                if total_pages > 1:
                    page_num = st.selectbox(f"í˜ì´ì§€ (ì´ {total_pages}í˜ì´ì§€)", range(1, total_pages + 1))
                    start_idx = (page_num - 1) * page_size
                    end_idx = start_idx + page_size
                    filtered_results = filtered_results[start_idx:end_idx]
            
            # ì „ì²´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ìƒë‹¨ì— ë°°ì¹˜)
            if len(st.session_state.analysis_results) > 1:
                st.markdown("### ğŸ“¥ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # ì „ì²´ JSON ë‹¤ìš´ë¡œë“œ (NumPy íƒ€ì… ë³€í™˜)
                    all_results_data = {
                        'export_info': {
                            'total_results': len(st.session_state.analysis_results),
                            'export_date': datetime.now().isoformat(),
                            'export_source': 'ì†”ë¡œëª¬ë“œ AI v2.3'
                        },
                        'results': st.session_state.analysis_results
                    }
                    # NumPy íƒ€ì… ë³€í™˜ í›„ JSON ì§ë ¬í™”
                    converted_all_results = convert_numpy_types(all_results_data)
                    all_results_json = json.dumps(converted_all_results, indent=2, ensure_ascii=False)
                    
                    st.download_button(
                        "ğŸ“„ ì „ì²´ JSON ë‹¤ìš´ë¡œë“œ",
                        data=all_results_json,
                        file_name=f"solomond_all_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                
                with col2:
                    # ì „ì²´ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
                    all_text_content = f"ì†”ë¡œëª¬ë“œ AI v2.3 - ì „ì²´ ë¶„ì„ ê²°ê³¼\n"
                    all_text_content += f"ë‚´ë³´ë‚´ê¸° ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    all_text_content += f"ì´ ê²°ê³¼ ìˆ˜: {len(st.session_state.analysis_results)}ê°œ\n"
                    all_text_content += "=" * 60 + "\n\n"
                    
                    for i, result in enumerate(st.session_state.analysis_results, 1):
                        all_text_content += f"{i}. {result.get('file_name', f'íŒŒì¼ {i}')}\n"
                        all_text_content += f"íƒ€ì…: {result.get('analysis_type', result.get('file_type', 'Unknown'))}\n"
                        all_text_content += f"ë¶„ì„ ì‹œê°„: {result.get('timestamp', 'N/A')}\n"
                        all_text_content += "-" * 40 + "\n"
                        
                        if result.get('full_text'):
                            all_text_content += "[ì¶”ì¶œëœ í…ìŠ¤íŠ¸]\n"
                            all_text_content += result['full_text'] + "\n\n"
                        
                        if result.get('summary'):
                            all_text_content += "[AI ìš”ì•½]\n"
                            all_text_content += result['summary'] + "\n\n"
                        
                        if result.get('jewelry_keywords'):
                            all_text_content += "[ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ]\n"
                            all_text_content += ", ".join(result['jewelry_keywords']) + "\n\n"
                        
                        all_text_content += "=" * 60 + "\n\n"
                    
                    st.download_button(
                        "ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
                        data=all_text_content,
                        file_name=f"solomond_all_texts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                with col3:
                    # ê²°ê³¼ ì´ˆê¸°í™”
                    if st.button("ğŸ—‘ï¸ ëª¨ë“  ê²°ê³¼ ì´ˆê¸°í™”"):
                        st.session_state.analysis_results = []
                        st.rerun()
            
            st.markdown("---")
            
            # ê°œë³„ ê²°ê³¼ í‘œì‹œ
            for i, result in enumerate(filtered_results):
                
                # íŒŒì¼ íƒ€ì… ê²°ì •
                file_type = result.get('analysis_type', result.get('file_type', 'unknown'))
                type_icon = "ğŸ¤" if file_type in ['audio', 'Audio'] else "ğŸ–¼ï¸" if file_type in ['image', 'Image'] else "ğŸ“„"
                
                with st.expander(f"{type_icon} {result.get('file_name', f'íŒŒì¼ {i+1}')} - {file_type.upper()}"):
                    
                    # ê¸°ë³¸ ì •ë³´
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write(f"**ğŸ“ íŒŒì¼:** {result.get('file_name', 'Unknown')}")
                        st.write(f"**ğŸ“Š íƒ€ì…:** {file_type.upper()}")
                    
                    with col2:
                        timestamp = result.get('timestamp', 'N/A')
                        st.write(f"**ğŸ• ë¶„ì„ ì‹œê°„:** {timestamp}")
                        
                        # ì²˜ë¦¬ ì‹œê°„ ì•ˆì „ ì²˜ë¦¬
                        processing_time = result.get('processing_time')
                        if processing_time is not None:
                            st.write(f"**â±ï¸ ì²˜ë¦¬ ì‹œê°„:** {processing_time}ì´ˆ")
                        else:
                            alt_time = result.get('duration') or result.get('elapsed_time') or result.get('execution_time')
                            if alt_time:
                                st.write(f"**â±ï¸ ì²˜ë¦¬ ì‹œê°„:** {alt_time}ì´ˆ")
                            else:
                                st.write("**â±ï¸ ì²˜ë¦¬ ì‹œê°„:** ì¸¡ì •ë˜ì§€ ì•ŠìŒ")
                    
                    with col3:
                        # ê°œë³„ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (NumPy íƒ€ì… ë³€í™˜)
                        converted_result = convert_numpy_types(result)
                        json_str = json.dumps(converted_result, indent=2, ensure_ascii=False)
                        st.download_button(
                            "ğŸ“¥ ê°œë³„ ë‹¤ìš´ë¡œë“œ",
                            data=json_str,
                            file_name=f"analysis_{result.get('file_name', f'result_{i}')}_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                            mime="application/json",
                            key=f"download_{i}"
                        )
                    
                    # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í‘œì‹œ
                    if result.get('full_text'):
                        st.markdown("### ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                        
                        full_text = result['full_text']
                        
                        if show_mode == "ìš”ì•½" and len(full_text) > 500:
                            # ìš”ì•½ ëª¨ë“œ: ì²˜ìŒ 500ìë§Œ í‘œì‹œ
                            preview_text = full_text[:500] + "..."
                            st.text_area(
                                "í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì)",
                                value=preview_text,
                                height=150,
                                disabled=True,
                                key=f"text_preview_{i}"
                            )
                            
                            # ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸° ë²„íŠ¼
                            if st.button(f"ğŸ“– ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸° ({len(full_text)}ì)", key=f"show_full_{i}"):
                                st.text_area(
                                    "ì „ì²´ í…ìŠ¤íŠ¸",
                                    value=full_text,
                                    height=300,
                                    disabled=True,
                                    key=f"text_full_{i}"
                                )
                        else:
                            # ì „ì²´ í…ìŠ¤íŠ¸ ëª¨ë“œ ë˜ëŠ” ì§§ì€ í…ìŠ¤íŠ¸
                            st.text_area(
                                f"ì „ì²´ í…ìŠ¤íŠ¸ ({len(full_text)}ì)",
                                value=full_text,
                                height=200 if len(full_text) < 1000 else 300,
                                disabled=True,
                                key=f"text_full_{i}"
                            )
                    
                    # ìš”ì•½ í‘œì‹œ
                    if result.get('summary'):
                        st.markdown("### ğŸ“‹ AI ìš”ì•½")
                        st.info(result['summary'])
                    
                    # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ í‘œì‹œ
                    if result.get('jewelry_keywords'):
                        st.markdown("### ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ")
                        # í‚¤ì›Œë“œë¥¼ ë°°ì§€ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
                        keywords_html = ""
                        for keyword in result['jewelry_keywords']:
                            keywords_html += f'<span style="background-color: #e1f5fe; color: #01579b; padding: 2px 8px; margin: 2px; border-radius: 12px; font-size: 12px;">{keyword}</span> '
                        st.markdown(keywords_html, unsafe_allow_html=True)
                    
                    # ì¶”ê°€ ì •ë³´ (í™•ì¥ ê°€ëŠ¥)
                    with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                        # ì˜¤ë””ì˜¤ ê´€ë ¨ ì •ë³´
                        if file_type in ['audio', 'Audio']:
                            if result.get('detected_language'):
                                st.write(f"**ê°ì§€ëœ ì–¸ì–´:** {result['detected_language']}")
                            if result.get('segments_count'):
                                st.write(f"**ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜:** {result['segments_count']}ê°œ")
                            if result.get('text_length'):
                                st.write(f"**í…ìŠ¤íŠ¸ ê¸¸ì´:** {result['text_length']}ì")
                        
                        # ì´ë¯¸ì§€ ê´€ë ¨ ì •ë³´
                        elif file_type in ['image', 'Image']:
                            if result.get('blocks_detected'):
                                st.write(f"**ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¸”ë¡:** {result['blocks_detected']}ê°œ")
                            if result.get('average_confidence'):
                                st.write(f"**í‰ê·  ì‹ ë¢°ë„:** {result['average_confidence']:.3f}")
                            if result.get('file_size_mb'):
                                st.write(f"**íŒŒì¼ í¬ê¸°:** {result['file_size_mb']} MB")
                        
                        # ê¸°íƒ€ ì •ë³´
                        other_info = {k: v for k, v in result.items() 
                                    if k not in ['file_name', 'analysis_type', 'file_type', 'timestamp', 
                                                'processing_time', 'full_text', 'summary', 'jewelry_keywords',
                                                'detected_language', 'segments_count', 'text_length',
                                                'blocks_detected', 'average_confidence', 'file_size_mb']}
                        
                        if other_info:
                            st.json(other_info)
        
        else:
            st.info("ğŸ“ ì•„ì§ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìŒì„± ë˜ëŠ” ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
            
            # ì‚¬ìš©ë²• ì•ˆë‚´
            st.markdown("### ğŸ’¡ ì‚¬ìš©ë²• ì•ˆë‚´")
            with st.expander("ğŸ“– ë¶„ì„ ê²°ê³¼ í™•ì¸ ë°©ë²•"):
                st.markdown("""
                **1. ë¶„ì„ ì‹¤í–‰ í›„ ê²°ê³¼ í™•ì¸:**
                - ë©€í‹°íŒŒì¼ ë¶„ì„, ìŒì„± ë¶„ì„, ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ì—¬ê¸°ì— ê²°ê³¼ê°€ ì €ì¥ë©ë‹ˆë‹¤.
                
                **2. ê²°ê³¼ í•„í„°ë§:**
                - íŒŒì¼ íƒ€ì…ë³„ë¡œ ê²°ê³¼ë¥¼ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - í‘œì‹œ ëª¨ë“œë¥¼ ì„ íƒí•˜ì—¬ ìš”ì•½ ë˜ëŠ” ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **3. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ:**
                - ê°œë³„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - ì „ì²´ ê²°ê³¼ë¥¼ JSON ë˜ëŠ” í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¼ê´„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **4. ê²°ê³¼ ê´€ë¦¬:**
                - ë¶ˆí•„ìš”í•œ ê²°ê³¼ëŠ” "ëª¨ë“  ê²°ê³¼ ì´ˆê¸°í™”" ë²„íŠ¼ìœ¼ë¡œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
    
    def display_session_stats(self):
        """ì„¸ì…˜ í†µê³„ í‘œì‹œ"""
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë¶„ì„í•œ íŒŒì¼", f"{self.session_stats['files_analyzed']}ê°œ")
        
        with col2:
            st.metric("ì„±ê³µí•œ ë¶„ì„", f"{self.session_stats['successful_analyses']}ê°œ")
        
        with col3:
            success_rate = 0
            if self.session_stats['files_analyzed'] > 0:
                success_rate = (self.session_stats['successful_analyses'] / self.session_stats['files_analyzed']) * 100
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
        
        with col4:
            st.metric("ì´ ì²˜ë¦¬ ì‹œê°„", f"{self.session_stats['total_processing_time']:.1f}ì´ˆ")
    
    def render_settings_tab(self):
        """ì„¤ì • íƒ­"""
        
        st.markdown("## âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
        
        # ë¶„ì„ ì—”ì§„ í†µê³„
        if REAL_ANALYSIS_AVAILABLE and self.analysis_engine:
            st.markdown("### ğŸ“Š ë¶„ì„ ì—”ì§„ í†µê³„")
            
            try:
                stats = self.analysis_engine.get_analysis_stats()
                
                col1, col2 = st.columns(2)
                with col1:
                    st.json({
                        "ì „ì²´ ë¶„ì„ íŒŒì¼": stats.get('total_files', 0),
                        "ì„±ê³µí•œ ë¶„ì„": stats.get('successful_analyses', 0),
                        "ì„±ê³µë¥ ": f"{stats.get('success_rate', 0):.1f}%"
                    })
                
                with col2:
                    st.json({
                        "ì´ ì²˜ë¦¬ ì‹œê°„": f"{stats.get('total_processing_time', 0):.1f}ì´ˆ",
                        "í‰ê·  ì²˜ë¦¬ ì‹œê°„": f"{stats.get('average_processing_time', 0):.1f}ì´ˆ",
                        "ë§ˆì§€ë§‰ ë¶„ì„": stats.get('last_analysis_time', 'N/A')
                    })
            
            except Exception as e:
                st.error(f"í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.markdown("### ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        
        system_info = {
            "ì‹¤ì œ ë¶„ì„ ì—”ì§„": "âœ… ì‚¬ìš© ê°€ëŠ¥" if REAL_ANALYSIS_AVAILABLE else "âŒ ì‚¬ìš© ë¶ˆê°€",
            "Whisper STT": "âœ… ì„¤ì¹˜ë¨" if self._check_module('whisper') else "âŒ ë¯¸ì„¤ì¹˜",
            "EasyOCR": "âœ… ì„¤ì¹˜ë¨" if self._check_module('easyocr') else "âŒ ë¯¸ì„¤ì¹˜",
            "Transformers": "âœ… ì„¤ì¹˜ë¨" if self._check_module('transformers') else "âŒ ë¯¸ì„¤ì¹˜",
            "Google Gemini": "âœ… ì„¤ì¹˜ë¨" if self._check_module('google.generativeai') else "âŒ ë¯¸ì„¤ì¹˜"
        }
        
        st.json(system_info)
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜
        st.markdown("### ğŸ”§ ì„±ëŠ¥ ìµœì í™”")
        
        if st.button("ğŸ—‘ï¸ GPU ë©”ëª¨ë¦¬ ì •ë¦¬"):
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    st.success("âœ… GPU ë©”ëª¨ë¦¬ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info("â„¹ï¸ CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            except ImportError:
                st.warning("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _check_module(self, module_name: str) -> bool:
        """ëª¨ë“ˆ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        try:
            __import__(module_name)
            return True
        except ImportError:
            return False
    
    def update_session_stats(self, processing_time: float, success: bool):
        """ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.session_stats['files_analyzed'] += 1
        self.session_stats['total_processing_time'] += processing_time
        if success:
            self.session_stats['successful_analyses'] += 1
    
    def _check_module_availability(self, module_name):
        """ëª¨ë“ˆ ê°€ìš©ì„± ì²´í¬"""
        try:
            __import__(module_name)
            return True
        except ImportError:
            return False
    
    def check_analysis_readiness(self):
        """ë¶„ì„ ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ ì²´í¬"""
        dependency_status = {
            'whisper': self._check_module_availability('whisper'),
            'easyocr': self._check_module_availability('easyocr'),
            'transformers': self._check_module_availability('transformers'),
            'numpy': self._check_module_availability('numpy'),
            'librosa': self._check_module_availability('librosa'),
            'ffmpeg': self._check_ffmpeg_availability()
        }
        
        # í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸ (whisper, easyocrëŠ” í•„ìˆ˜)
        critical_dependencies = ['whisper', 'easyocr', 'numpy']
        analysis_ready = all(dependency_status.get(dep, False) for dep in critical_dependencies)
        
        return analysis_ready, dependency_status
    
    def _check_ffmpeg_availability(self):
        """FFmpeg ì„¤ì¹˜ ìƒíƒœ í™•ì¸"""
        try:
            import subprocess
            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            return False
    
    def _preload_analysis_models(self):
        """ë¶„ì„ ëª¨ë¸ë“¤ì„ ì‚¬ì „ ë¡œë”©í•˜ì—¬ ì‹¤ì œ ë¶„ì„ ì‹œ ì§€ì—° ìµœì†Œí™”"""
        try:
            if REAL_ANALYSIS_AVAILABLE and self.analysis_engine:
                # ì§„í–‰ ìƒí™©ì„ ìœ„í•œ ì„ì‹œ ì»¨í…Œì´ë„ˆ
                model_status = st.empty()
                
                # Whisper ëª¨ë¸ ë¡œë”©
                model_status.text("ğŸ¤ Whisper STT ëª¨ë¸ ë¡œë”© ì¤‘...")
                if not self.analysis_engine.whisper_model:
                    self.analysis_engine._lazy_load_whisper()
                
                # EasyOCR ëª¨ë¸ ë¡œë”©  
                model_status.text("ğŸ–¼ï¸ EasyOCR ëª¨ë¸ ë¡œë”© ì¤‘...")
                if not self.analysis_engine.ocr_reader:
                    self.analysis_engine._lazy_load_ocr()
                
                # NLP ëª¨ë¸ ë¡œë”© (ì„ íƒì )
                model_status.text("ğŸ§  NLP ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.analysis_engine._lazy_load_nlp()
                
                model_status.text("âœ… ëª¨ë“  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
                import time
                time.sleep(0.5)  # ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ë³¼ ìˆ˜ ìˆë„ë¡
                model_status.empty()
                
        except Exception as e:
            self.logger.warning(f"ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ê°€ ìˆì–´ë„ ë¶„ì„ì€ ê³„ì† ì§„í–‰ (lazy loading ë°©ì‹ìœ¼ë¡œ)
    
    def execute_comprehensive_analysis(self):
        """ğŸš€ ë°°ì¹˜ ì¢…í•© ë¶„ì„ ì‹¤í–‰ - ë¬´í•œë£¨í”„ ë° ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€"""
        import signal
        import gc
        import os
        import time
        import datetime
        
        if not st.session_state.uploaded_files_data:
            return []
        
        # ğŸ• ì‹¤ì‹œê°„ ë¶„ì„ ì‹œê°„ ì¶”ì  ì‹œì‘
        analysis_start_time = time.time()
        st.session_state.analysis_start_time = analysis_start_time
        st.session_state.analysis_status = "ì§„í–‰ ì¤‘"
        
        # ì‹œì‘ ì‹œê°„ í‘œì‹œ
        start_time_str = datetime.datetime.fromtimestamp(analysis_start_time).strftime("%H:%M:%S")
        
        # ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ í™•ì¸
        try:
            import psutil
            process = psutil.Process(os.getpid())
            start_memory = process.memory_info().rss / (1024 * 1024)  # MB
            st.info(f"ğŸ” ë¶„ì„ ì‹œì‘ - ì‹œì‘ ì‹œê°„: {start_time_str} | í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {start_memory:.1f}MB")
        except:
            start_memory = 0
        
        # ì „ì²´ ë¶„ì„ íƒ€ì„ì•„ì›ƒ ì„¤ì • (10ë¶„)
        def analysis_timeout_handler(signum, frame):
            raise TimeoutError("ì „ì²´ ë¶„ì„ì´ 10ë¶„ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•„ ì¤‘ë‹¨ë©ë‹ˆë‹¤")
        
        timeout_set = False
        if hasattr(signal, 'SIGALRM'):
            signal.signal(signal.SIGALRM, analysis_timeout_handler)
            signal.alarm(600)  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
            timeout_set = True
        
        uploaded_files_data = st.session_state.uploaded_files_data
        
        try:
            # ğŸ¯ ë°°ì¹˜ ë¶„ì„ vs ê°œë³„ ë¶„ì„ ì„ íƒ
            enable_batch_analysis = st.session_state.project_info.get('correlation_analysis', True)
            
            if enable_batch_analysis:
                st.success("ğŸš€ **ë°°ì¹˜ ì¢…í•© ë¶„ì„ ì‹œì‘**: ëª¨ë“  íŒŒì¼ì„ í†µí•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤")
                with st.container():
                    st.markdown("### ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì§„í–‰ ìƒí™©")
                    return self._execute_batch_comprehensive_analysis()
            else:
                st.warning("ğŸ“ **ê°œë³„ ë¶„ì„ ëª¨ë“œ**: íŒŒì¼ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤ (í’ˆì§ˆ ì œí•œì )")
                return self._execute_individual_analysis()
                
        except TimeoutError as e:
            st.error(f"âŒ ë¶„ì„ ì‹œê°„ ì´ˆê³¼: {str(e)}")
            st.info("ğŸ’¡ íŒŒì¼ ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜ ë” ì‘ì€ íŒŒì¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
            if timeout_set and hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            return []
            
        except MemoryError as e:
            st.error(f"âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(e)}")
            st.info("ğŸ’¡ ë” ì ì€ ìˆ˜ì˜ íŒŒì¼ë¡œ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”.")
            gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬
            if timeout_set and hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            return []
            
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ğŸ’¡ ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ë³´ì„¸ìš”.")
            if timeout_set and hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            return []
    
    def _execute_batch_comprehensive_analysis(self):
        """ë°°ì¹˜ ì¢…í•© ë¶„ì„ - ëª¨ë“  íŒŒì¼ì„ í†µí•© ì²˜ë¦¬"""
        uploaded_files_data = st.session_state.uploaded_files_data
        all_results = []
        
        # ì‹¤ì‹œê°„ íƒ€ì´ë¨¸ ë° ì§„í–‰ë¥  í‘œì‹œ ì»¨í…Œì´ë„ˆ
        timer_container = st.empty()
        progress_container = st.empty()
        
        # ì‹¤ì‹œê°„ íƒ€ì´ë¨¸ í‘œì‹œ ì‹œì‘
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        
        # 1ï¸âƒ£ ë‹¨ê³„: íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬
        st.session_state.analysis_status = "1ë‹¨ê³„: íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬"
        st.info("ğŸ” 1ë‹¨ê³„: íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        
        with progress_container.container():
            pass  # ì‹¤ì œ ì²˜ë¦¬ í›„ ì§„í–‰ë¥  í‘œì‹œ
        
        file_categories = self._categorize_and_preprocess_files(uploaded_files_data)
        
        # 1ë‹¨ê³„ ì™„ë£Œ - íƒ€ì´ë¨¸ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        st.session_state.analysis_status = "1ë‹¨ê³„ ì™„ë£Œ: íŒŒì¼ ë¶„ë¥˜ ì™„ë£Œ"
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        with progress_container.container():
            self.show_real_progress_only(1, 4, "1ë‹¨ê³„: íŒŒì¼ ë¶„ë¥˜ ì™„ë£Œ", f"ë¶„ë¥˜ëœ íŒŒì¼: {sum(len(v) for v in file_categories.values())}ê°œ", force_display=True)
        
        # 2ï¸âƒ£ ë‹¨ê³„: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        st.session_state.analysis_status = "2ë‹¨ê³„: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"
        st.info("ğŸ§  2ë‹¨ê³„: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì‹œì‘...")
        
        # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        
        integrated_context = self._build_integrated_context(file_categories)
        
        # 2ë‹¨ê³„ ì™„ë£Œ - íƒ€ì´ë¨¸ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        st.session_state.analysis_status = "2ë‹¨ê³„ ì™„ë£Œ: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ"
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        with progress_container.container():
            self.show_real_progress_only(2, 4, "2ë‹¨ê³„: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ", "ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ", force_display=True)
        
        # 3ï¸âƒ£ ë‹¨ê³„: ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰
        st.session_state.analysis_status = "3ë‹¨ê³„: ì‹¤ì œ ë°°ì¹˜ ë¶„ì„ ì§„í–‰ ì¤‘"
        st.info("âš¡ 3ë‹¨ê³„: ì‹¤ì œ ë°°ì¹˜ ë¶„ì„ ì‹œì‘ - ì´ ë‹¨ê³„ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ì´ ì‘ë™í•©ë‹ˆë‹¤")
        
        # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        
        batch_results = self._execute_batch_analysis(file_categories, integrated_context, progress_container, timer_container)
        
        # 3ë‹¨ê³„ ì™„ë£Œ - íƒ€ì´ë¨¸ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        st.session_state.analysis_status = "3ë‹¨ê³„ ì™„ë£Œ: ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ"
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        with progress_container.container():
            self.show_real_progress_only(3, 4, "3ë‹¨ê³„: ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ", "ëª¨ë“  íŒŒì¼ ë¶„ì„ ì™„ë£Œ", force_display=True)
        
        # 4ï¸âƒ£ ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° ìµœì í™”
        st.session_state.analysis_status = "4ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° ìµœì í™”"
        st.info("ğŸ¯ 4ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° ìµœì í™” ì‹œì‘...")
        
        # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
        with timer_container.container():
            st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
        
        final_results = self._integrate_and_optimize_results(batch_results, integrated_context)
        
        # ì „ì²´ ì™„ë£Œ - íƒ€ì´ë¨¸ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        st.session_state.analysis_status = "ë¶„ì„ ì™„ë£Œ"
        
        # ë¶„ì„ ì™„ë£Œ ì‹œê°„ ì •ë³´ ê³„ì‚°
        import time
        total_elapsed_seconds = int(time.time() - st.session_state.analysis_start_time)
        total_elapsed_minutes = total_elapsed_seconds // 60
        remaining_seconds = total_elapsed_seconds % 60
        
        if total_elapsed_minutes > 0:
            elapsed_display = f"{total_elapsed_minutes}ë¶„ {remaining_seconds}ì´ˆ"
        else:
            elapsed_display = f"{remaining_seconds}ì´ˆ"
        
        # ìµœì¢… íƒ€ì´ë¨¸ í‘œì‹œ
        with timer_container.container():
            final_timer_html = f"""
            <div style="
                background: linear-gradient(135deg, #4CAF50 0%, #66BB6A 100%);
                color: white;
                padding: 15px;
                border-radius: 10px;
                margin: 10px 0;
                text-align: center;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            ">
                <div style="font-size: 18px; font-weight: bold;">ğŸ‰ ë¶„ì„ ì™„ë£Œ!</div>
                <div style="font-size: 16px; margin-top: 5px;">ì´ ì†Œìš”ì‹œê°„: {elapsed_display}</div>
            </div>
            """
            st.markdown(final_timer_html, unsafe_allow_html=True)
            
        with progress_container.container():
            self.show_real_progress_only(4, 4, "ì „ì²´ ë¶„ì„ ì™„ë£Œ!", f"ì´ {len(uploaded_files_data.get('files', []))}ê°œ íŒŒì¼ ë¶„ì„ ì„±ê³µ", force_display=True)
        
        st.success(f"âœ… ë°°ì¹˜ ì¢…í•© ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ ì†Œìš”ì‹œê°„: {elapsed_display})")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì¢… í™•ì¸
        try:
            end_memory = process.memory_info().rss / (1024 * 1024)  # MB
            memory_used = end_memory - start_memory
            if memory_used > 1000:  # 1GB ì´ìƒ ì‚¬ìš©
                st.warning(f"âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.1f}MB ì¦ê°€")
                gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            else:
                st.info(f"âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ: {memory_used:.1f}MB ì¦ê°€")
        except:
            pass
        
        return final_results
    
    def _execute_individual_analysis(self):
        """ê¸°ì¡´ ê°œë³„ ë¶„ì„ ë°©ì‹ (í˜¸í™˜ì„± ìœ ì§€)"""
        uploaded_files_data = st.session_state.uploaded_files_data
        all_results = []
        
        # ê°œì„ ëœ ì§„í–‰ë¥  í‘œì‹œ
        progress_container = st.empty()
        
        total_items = len(uploaded_files_data.get('files', [])) + len(uploaded_files_data.get('video_urls', []))
        current_item = 0
        
        # ì´ˆê¸° ì¤€ë¹„ ë©”ì‹œì§€
        with progress_container.container():
            self.show_progress_with_details(
                0, total_items,
                "ğŸ”§ ë¶„ì„ ì¤€ë¹„ ì¤‘...",
                "AI ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ë¶„ì„ í™˜ê²½ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ì„
        for uploaded_file in uploaded_files_data.get('files', []):
            current_item += 1
            
            # íŒŒì¼ë³„ ì§„í–‰ë¥  í‘œì‹œ
            with progress_container.container():
                self.show_progress_with_details(
                    current_item, total_items,
                    f"ğŸ”„ ë¶„ì„ ì¤‘: {uploaded_file.name}",
                    f"í˜„ì¬ íŒŒì¼ ({current_item}/{total_items})ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŒŒì¼ í¬ê¸°ì™€ ìœ í˜•ì— ë”°ë¼ ì²˜ë¦¬ ì‹œê°„ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
            
            tmp_file_path = None
            audio_file_path = None
            is_large_video = False
            try:
                # íŒŒì¼ íƒ€ì… ê²°ì •
                file_ext = uploaded_file.name.split('.')[-1].lower()
                file_size_gb = len(uploaded_file.getvalue()) / (1024 * 1024 * 1024)
                is_large_video = file_ext in ['mp4', 'mov', 'avi'] and file_size_gb >= 1.0
                
                if file_ext in ['wav', 'mp3', 'flac', 'm4a']:
                    file_type = "audio"
                elif file_ext in ['mp4', 'mov', 'avi']:
                    file_type = "video"
                elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                    file_type = "image"
                else:
                    file_type = "unknown"
                
                # ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
                if is_large_video and LARGE_FILE_HANDLER_AVAILABLE:
                    status_text.text(f"ğŸš€ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({file_size_gb:.2f}GB)")
                    
                    # ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥
                    def progress_callback(progress):
                        progress_bar.progress((current_item - 1 + progress * 0.5) / total_items)
                        status_text.text(f"ğŸ“¥ ì—…ë¡œë“œ ì¤‘: {uploaded_file.name} ({progress*100:.1f}%)")
                    
                    tmp_file_path = large_file_handler.save_uploaded_file_chunked(uploaded_file, progress_callback)
                    
                    if tmp_file_path:
                        # ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                        status_text.text(f"ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘: {uploaded_file.name}")
                        audio_file_path = large_file_handler.extract_audio_from_video(tmp_file_path)
                        
                        if audio_file_path:
                            # ì¶”ì¶œëœ ì˜¤ë””ì˜¤ë¡œ ë³€ê²½í•˜ì—¬ ë¶„ì„
                            tmp_file_path = audio_file_path
                            file_type = "audio"
                            status_text.text(f"ğŸ”„ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘: {uploaded_file.name}")
                        else:
                            raise Exception("ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
                    else:
                        raise Exception("ëŒ€ìš©ëŸ‰ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                        
                # ì¼ë°˜ íŒŒì¼ ì²˜ë¦¬
                else:
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_file_path = tmp_file.name
                        
                    # ì‘ì€ ë™ì˜ìƒ íŒŒì¼ë„ ì˜¤ë””ì˜¤ ì¶”ì¶œ í•„ìš”
                    if file_type == "video":
                        if LARGE_FILE_HANDLER_AVAILABLE:
                            status_text.text(f"ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘: {uploaded_file.name}")
                            audio_file_path = large_file_handler.extract_audio_from_video(tmp_file_path)
                            if audio_file_path:
                                tmp_file_path = audio_file_path
                                file_type = "audio"
                        else:
                            # FFmpeg ì—†ì´ëŠ” ë™ì˜ìƒ ì§ì ‘ ì²˜ë¦¬ ë¶ˆê°€
                            file_type = "unsupported_video"
                
                # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
                if REAL_ANALYSIS_AVAILABLE and file_type in ["audio", "image"]:
                    language = uploaded_files_data.get('analysis_language', 'auto')
                    
                    # ğŸ§  ê°•í™”ëœ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
                    context = self._prepare_enhanced_context()
                    
                    # ë¶„ì„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨)
                    self._update_analysis_status(uploaded_file.name, context)
                    
                    result = analyze_file_real(tmp_file_path, file_type, language, context)
                    
                    # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    result = convert_numpy_types(result)
                    
                    # ë™ì˜ìƒì—ì„œ ì¶”ì¶œëœ ì˜¤ë””ì˜¤ì¸ ê²½ìš° ì›ë³¸ íŒŒì¼ëª… ì •ë³´ ì¶”ê°€
                    if audio_file_path and result.get('status') == 'success':
                        result['original_video_file'] = uploaded_file.name
                        result['extracted_audio'] = True
                        result['large_file_processed'] = is_large_video
                        
                else:
                    if not REAL_ANALYSIS_AVAILABLE:
                        error_msg = "ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•„ìˆ˜ íŒ¨í‚¤ì§€(whisper, easyocr)ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
                    elif file_type == "unsupported_video":
                        error_msg = "ë™ì˜ìƒ ì²˜ë¦¬ë¥¼ ìœ„í•´ FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
                    else:
                        error_msg = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}. ì§€ì› í˜•ì‹: ìŒì„±(wav, mp3, m4a), ë™ì˜ìƒ(mp4, mov, avi), ì´ë¯¸ì§€(jpg, png, bmp)"
                    
                    result = {
                        "status": "error",
                        "error": error_msg,
                        "file_name": uploaded_file.name,
                        "file_type": file_type,
                        "suggested_action": "FFmpeg ì„¤ì¹˜ ë˜ëŠ” ì§€ì›ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”." if file_type == "unsupported_video" else "íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ê±°ë‚˜ ì§€ì›ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”."
                    }
                
                all_results.append(result)
                    
            except Exception as e:
                self.logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {uploaded_file.name}: {e}")
                all_results.append({
                    "status": "error",
                    "error": str(e),
                    "file_name": uploaded_file.name
                })
            finally:
                # ì„ì‹œ íŒŒì¼ë“¤ í™•ì‹¤íˆ ì •ë¦¬
                cleanup_files = []
                if tmp_file_path and os.path.exists(tmp_file_path):
                    cleanup_files.append(tmp_file_path)
                if audio_file_path and audio_file_path != tmp_file_path and os.path.exists(audio_file_path):
                    cleanup_files.append(audio_file_path)
                
                for file_path in cleanup_files:
                    try:
                        os.unlink(file_path)
                        self.logger.debug(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {file_path}")
                    except Exception as cleanup_error:
                        self.logger.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {file_path}: {cleanup_error}")
                
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ì˜ ì •ë¦¬ ì‘ì—…ë„ ìˆ˜í–‰
                if LARGE_FILE_HANDLER_AVAILABLE and is_large_video:
                    try:
                        large_file_handler.cleanup_temp_files(max_age_hours=1)  # 1ì‹œê°„ ì´ìƒ ëœ íŒŒì¼ë§Œ ì •ë¦¬
                    except Exception as cleanup_error:
                        self.logger.warning(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ ì •ë¦¬ ì‹¤íŒ¨: {cleanup_error}")
        
        # ë™ì˜ìƒ URL ë¶„ì„ (YouTube, Brightcove ë“±)
        for url in uploaded_files_data.get('video_urls', []):
            current_item += 1
            progress_bar.progress(current_item / total_items)
            # URL íƒ€ì…ì— ë”°ë¥¸ ìƒíƒœ ë©”ì‹œì§€
            if 'youtube.com' in url or 'youtu.be' in url:
                status_text.text(f"ğŸ”„ YouTube ë¶„ì„ ì¤‘: {url[:50]}... ({current_item}/{total_items})")
                
                # YouTube ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©
                if YOUTUBE_REALTIME_AVAILABLE:
                    try:
                        # YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
                        download_result = global_youtube_realtime_processor.download_audio(url, progress_container=progress_container)
                        
                        if download_result.get('success'):
                            # ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ STT ë¶„ì„
                            audio_file = download_result['output_file']
                            status_text.text(f"ğŸ”„ YouTube ì˜¤ë””ì˜¤ STT ë¶„ì„ ì¤‘...")
                            
                            # ì‹¤ì œ ë¶„ì„ ì—”ì§„ìœ¼ë¡œ STT ì²˜ë¦¬
                            if REAL_ANALYSIS_AVAILABLE:
                                stt_result = real_analysis_engine.analyze_audio_file(audio_file)
                                
                                # ê²°ê³¼ ì •ë¦¬
                                youtube_result = {
                                    "status": "success",
                                    "file_type": "youtube_audio",
                                    "url": url,
                                    "video_info": download_result.get('video_info', {}),
                                    "audio_file": audio_file,
                                    "file_size_mb": download_result.get('file_size_mb', 0),
                                    "stt_result": stt_result,
                                    "processing_time": download_result.get('processing_time', 0),
                                    "download_speed_mbps": download_result.get('download_speed_mbps', 0)
                                }
                            else:
                                youtube_result = {
                                    "status": "partial_success",
                                    "message": "ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì„±ê³µ, STT ë¶„ì„ ì—”ì§„ ë¯¸ì‚¬ìš©",
                                    "url": url,
                                    "video_info": download_result.get('video_info', {}),
                                    "audio_file": audio_file
                                }
                            
                            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                            try:
                                os.remove(audio_file)
                            except:
                                pass
                        else:
                            youtube_result = {
                                "status": "error",
                                "message": f"YouTube ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result.get('error', 'Unknown error')}",
                                "url": url
                            }
                    except Exception as e:
                        youtube_result = {
                            "status": "error", 
                            "message": f"YouTube ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                            "url": url
                        }
                else:
                    youtube_result = {
                        "status": "pending",
                        "message": "YouTube ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                        "url": url
                    }
                
                all_results.append(youtube_result)
                
            elif 'brightcove.net' in url:
                status_text.text(f"ğŸ”„ Brightcove ë¶„ì„ ì¤‘: {url[:50]}... ({current_item}/{total_items})")
                all_results.append({
                    "status": "pending",
                    "message": "Brightcove ë¶„ì„ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.",
                    "url": url
                })
            else:
                status_text.text(f"ğŸ”„ ë™ì˜ìƒ URL ë¶„ì„ ì¤‘: {url[:50]}... ({current_item}/{total_items})")
                all_results.append({
                    "status": "pending", 
                    "message": "ì¼ë°˜ ë™ì˜ìƒ URL ë¶„ì„ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.",
                    "url": url
                })
        
        progress_bar.progress(1.0)
        status_text.text("âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
        
        return all_results
    
    def create_comprehensive_story(self):
        """ë¶„ì„ ê²°ê³¼ë“¤ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ í•œêµ­ì–´ ìŠ¤í† ë¦¬ë¡œ ë³€í™˜"""
        
        try:
            if not st.session_state.analysis_results:
                return {
                    "status": "error",
                    "error": "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ìŠ¤í† ë¦¬í…”ë§ ì—”ì§„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            sources = []
            for i, result in enumerate(st.session_state.analysis_results):
                if result.get('status') == 'success':
                    
                    # íŒŒì¼ íƒ€ì… ì¶”ì •
                    file_name = result.get('file_name', f'íŒŒì¼_{i+1}')
                    if any(ext in file_name.lower() for ext in ['.wav', '.mp3', '.m4a', '.flac']):
                        file_type = "audio"
                    elif any(ext in file_name.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif']):
                        file_type = "image"
                    elif any(ext in file_name.lower() for ext in ['.pdf', '.docx', '.doc', '.txt']):
                        file_type = "document"
                    else:
                        file_type = "unknown"
                    
                    source_data = {
                        "name": file_name,
                        "type": file_type,
                        "analysis_result": result,
                        "timestamp": result.get('timestamp')
                    }
                    
                    sources.append(source_data)
            
            if not sources:
                return {
                    "status": "error",
                    "error": "ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # í”„ë¡œì íŠ¸ ì •ë³´ì— ë”°ë¥¸ ìŠ¤í† ë¦¬ íƒ€ì… ê²°ì •
            project_info = st.session_state.get('project_info', {})
            topic = project_info.get('topic', '').lower()
            
            if 'ìƒë‹´' in topic or 'ê³ ê°' in topic:
                story_type = "consultation"
            elif 'íšŒì˜' in topic or 'ë¯¸íŒ…' in topic:
                story_type = "meeting"
            elif len(sources) > 3:  # ë‹¤ì¤‘ ì†ŒìŠ¤
                story_type = "multimedia"
            else:
                story_type = "general"
            
            # ê³ ê¸‰ ìŠ¤í† ë¦¬í…”ë§ ì—”ì§„ìœ¼ë¡œ ìŠ¤í† ë¦¬ ìƒì„±
            story_result = create_comprehensive_story_from_sources(sources, story_type)
            
            return story_result
            
        except Exception as e:
            return {
                "status": "error",
                "error": f"ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    def generate_final_report(self):
        """ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not st.session_state.analysis_results:
            return None
        
        results = st.session_state.analysis_results
        project_info = st.session_state.project_info
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        total_files = len(results)
        successful_analyses = len([r for r in results if r.get('status') == 'success'])
        success_rate = (successful_analyses / total_files * 100) if total_files > 0 else 0
        
        # ì´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_time = sum([r.get('processing_time', 0) for r in results if r.get('processing_time')])
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ìš°ì„  ì‚¬ìš©)
        all_texts = []
        edited_transcripts = st.session_state.get('edited_transcripts', {})
        
        for result in results:
            if result.get('status') == 'success' and result.get('full_text'):
                filename = result.get('file_name', '')
                
                # ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                if filename in edited_transcripts and edited_transcripts[filename].get('modified'):
                    all_texts.append(edited_transcripts[filename]['edited'])
                else:
                    all_texts.append(result['full_text'])
        
        combined_text = ' '.join(all_texts)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¹ˆë„ ê³„ì‚°
        import re
        from collections import Counter
        
        # í•œêµ­ì–´ì™€ ì˜ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        korean_words = re.findall(r'[ê°€-í£]{2,}', combined_text)
        english_words = re.findall(r'[A-Za-z]{3,}', combined_text.lower())
        
        all_keywords = korean_words + english_words
        keyword_freq = Counter(all_keywords)
        top_keywords = keyword_freq.most_common(20)
        
        # ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œ ìˆ˜ì§‘
        jewelry_keywords = []
        for result in results:
            if result.get('jewelry_keywords'):
                jewelry_keywords.extend(result['jewelry_keywords'])
        
        unique_jewelry_keywords = list(set(jewelry_keywords))
        
        # í•µì‹¬ ìš”ì•½ ìƒì„±
        executive_summary = self._generate_executive_summary(
            total_files, successful_analyses, success_rate, 
            len(combined_text), unique_jewelry_keywords
        )
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­ ìƒì„±
        key_findings = self._generate_key_findings(results, unique_jewelry_keywords)
        
        # ê²°ë¡  ë° ì œì•ˆì‚¬í•­ ìƒì„±
        conclusions = self._generate_conclusions(results, success_rate, unique_jewelry_keywords)
        
        # ìµœì¢… ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±
        report = {
            'project_name': project_info.get('project_name', 'ë¶„ì„ í”„ë¡œì íŠ¸'),
            'analysis_date': datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„'),
            'total_files': total_files,
            'successful_analyses': successful_analyses,
            'success_rate': success_rate,
            'total_time': total_time,
            'total_text_length': len(combined_text),
            'executive_summary': executive_summary,
            'key_findings': key_findings,
            'top_keywords': top_keywords,
            'jewelry_keywords': unique_jewelry_keywords,
            'conclusions': conclusions,
            'analysis_details': {
                'audio_files': len([r for r in results if r.get('analysis_type') == 'real_whisper_stt']),
                'image_files': len([r for r in results if r.get('analysis_type') == 'real_easyocr']),
                'total_processing_time': total_time,
                'average_confidence': self._calculate_average_confidence(results)
            }
        }
        
        return report
    
    def generate_comprehensive_lecture(self):
        """ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„±"""
        if not st.session_state.analysis_results:
            return None
        
        if not LECTURE_COMPILER_AVAILABLE:
            st.error("ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None
        
        try:
            # ë¶„ì„ ê²°ê³¼ë“¤ ì¤€ë¹„
            analysis_results = st.session_state.analysis_results
            
            # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§ (ë¶€ë¶„ ì„±ê³µ í¬í•¨)
            valid_results = [
                result for result in analysis_results 
                if result.get('status') in ['success', 'partial_success']
            ]
            
            if not valid_results:
                st.warning("ê°•ì˜ ë‚´ìš©ì„ ìƒì„±í•  ìœ íš¨í•œ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í”„ë¡œì íŠ¸ ì •ë³´ì—ì„œ ì œëª© ê°€ì ¸ì˜¤ê¸°
            project_info = st.session_state.get('project_info', {})
            custom_title = project_info.get('project_name')
            
            # ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼
            with st.spinner("ğŸ“ ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„± ì¤‘..."):
                lecture_result = compile_comprehensive_lecture(valid_results, custom_title)
            
            if lecture_result.get('status') == 'success':
                return lecture_result['lecture_content']
            else:
                st.error(f"ê°•ì˜ ë‚´ìš© ìƒì„± ì‹¤íŒ¨: {lecture_result.get('error', 'Unknown error')}")
                return None
                
        except Exception as e:
            st.error(f"ê°•ì˜ ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _generate_executive_summary(self, total_files, successful, success_rate, text_length, jewelry_keywords):
        """í•µì‹¬ ìš”ì•½ ìƒì„±"""
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì˜ ì²« 500ìë¥¼ ë¯¸ë¦¬ë³´ê¸°ë¡œ ì¶”ê°€
        results = st.session_state.analysis_results
        content_preview = ""
        main_language = "í•œêµ­ì–´"
        
        # ì‹¤ì œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ë‚´ìš© íŒŒì•…
        all_texts = []
        for result in results:
            if result.get('status') == 'success' and result.get('full_text'):
                text = result['full_text'].strip()
                if text:
                    all_texts.append(text)
                    # ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ë³´ê¸°ë¡œ ì‚¬ìš©
                    if not content_preview and len(text) > 10:
                        content_preview = text[:300] + "..." if len(text) > 300 else text
                        # ì–¸ì–´ ê°ì§€
                        import re
                        korean_chars = len(re.findall(r'[ê°€-í£]', text))
                        english_chars = len(re.findall(r'[a-zA-Z]', text))
                        if english_chars > korean_chars:
                            main_language = "ì˜ì–´"
        
        # ì£¼ì œ ë° í‚¤ì›Œë“œ ê¸°ë°˜ ì»¨í…ì¸  ë¶„ë¥˜
        combined_text = ' '.join(all_texts).lower()
        content_type = "ì¼ë°˜ ë‚´ìš©"
        
        if any(keyword in combined_text for keyword in ['seminar', 'ì„¸ë¯¸ë‚˜', 'conference', 'ì»¨í¼ëŸ°ìŠ¤', 'presentation', 'ë°œí‘œ']):
            content_type = "ì„¸ë¯¸ë‚˜/ì»¨í¼ëŸ°ìŠ¤"
        elif any(keyword in combined_text for keyword in ['jewelry', 'ì£¼ì–¼ë¦¬', 'diamond', 'ë‹¤ì´ì•„ëª¬ë“œ', 'gold', 'ê¸ˆ']):
            content_type = "ì£¼ì–¼ë¦¬ ê´€ë ¨"
        elif any(keyword in combined_text for keyword in ['business', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'market', 'ì‹œì¥', 'trend', 'íŠ¸ë Œë“œ']):
            content_type = "ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„"
        
        summary_parts = [
            f"ğŸ“Š **ë¶„ì„ ê°œìš”**: ì´ {total_files}ê°œ íŒŒì¼ ì¤‘ {successful}ê°œ íŒŒì¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤. (ì„±ê³µë¥ : {success_rate:.1f}%)",
            f"ğŸ“ **ì¶”ì¶œëœ ë‚´ìš©**: {main_language} í…ìŠ¤íŠ¸ {text_length:,}ì ë¶„ëŸ‰ì˜ {content_type} ë‚´ìš©ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
        ]
        
        if content_preview:
            summary_parts.append(f"ğŸ¯ **ì£¼ìš” ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°**: \"{content_preview}\"")
        
        if jewelry_keywords:
            summary_parts.append(f"ğŸ’ **ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ**: {len(jewelry_keywords)}ê°œì˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ({', '.join(jewelry_keywords[:3])}...)")
        
        if success_rate >= 90:
            summary_parts.append("âœ… **í’ˆì§ˆ í‰ê°€**: ë¶„ì„ í’ˆì§ˆì´ ë§¤ìš° ìš°ìˆ˜í•©ë‹ˆë‹¤.")
        elif success_rate >= 70:
            summary_parts.append("âš ï¸ **í’ˆì§ˆ í‰ê°€**: ë¶„ì„ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        else:
            summary_parts.append("âŒ **í’ˆì§ˆ í‰ê°€**: ì¼ë¶€ íŒŒì¼ì—ì„œ ë¶„ì„ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤.")
        
        return '\n\n'.join(summary_parts)
    
    def _generate_key_findings(self, results, jewelry_keywords):
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ìƒì„±"""
        findings = []
        
        # íŒŒì¼ í˜•ì‹ë³„ ë¶„ì„
        audio_results = [r for r in results if r.get('analysis_type') == 'real_whisper_stt']
        image_results = [r for r in results if r.get('analysis_type') == 'real_easyocr']
        
        # ì‹¤ì œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš© ë¶„ì„
        all_successful_texts = []
        detected_languages = []
        
        for result in results:
            if result.get('status') == 'success' and result.get('full_text'):
                text = result['full_text'].strip()
                if text:
                    all_successful_texts.append(text)
                    # ì–¸ì–´ ê°ì§€ ì •ë³´ ìˆ˜ì§‘
                    if result.get('detected_language'):
                        detected_languages.append(result['detected_language'])
        
        if all_successful_texts:
            combined_content = ' '.join(all_successful_texts)
            
            # ì–¸ì–´ ë¶„ì„
            if detected_languages:
                lang_counts = {}
                for lang in detected_languages:
                    lang_counts[lang] = lang_counts.get(lang, 0) + 1
                main_lang = max(lang_counts.items(), key=lambda x: x[1])[0]
                findings.append(f"ğŸ—£ï¸ **ì£¼ìš” ì–¸ì–´**: {main_lang} ({lang_counts[main_lang]}ê°œ íŒŒì¼)")
            
            # ë‚´ìš© ê¸¸ì´ ë° í’ˆì§ˆ ë¶„ì„
            total_length = len(combined_content)
            word_count = len(combined_content.split())
            findings.append(f"ğŸ“ **í…ìŠ¤íŠ¸ ë¶„ëŸ‰**: ì´ {total_length:,}ì, ì•½ {word_count:,}ë‹¨ì–´ ì¶”ì¶œ")
            
            # ì£¼ìš” ì£¼ì œ í‚¤ì›Œë“œ ë¶„ì„ (í•œêµ­ì–´ + ì˜ì–´)
            import re
            from collections import Counter
            
            # í•œêµ­ì–´ ëª…ì‚¬ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
            korean_words = re.findall(r'[ê°€-í£]{2,}', combined_content)
            # ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ (3ê¸€ì ì´ìƒ)
            english_words = re.findall(r'[A-Za-z]{3,}', combined_content.lower())
            
            # ë¹ˆë„ ë¶„ì„
            all_words = korean_words + english_words
            if all_words:
                word_freq = Counter(all_words)
                top_words = word_freq.most_common(8)
                if top_words:
                    findings.append(f"ğŸ” **í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join([f'{word}({count})' for word, count in top_words[:5]])}")
            
            # íŠ¹ì • ì£¼ì œ ê°ì§€
            topic_keywords = {
                'ì„¸ë¯¸ë‚˜/êµìœ¡': ['seminar', 'conference', 'presentation', 'education', 'training', 'workshop', 'ì„¸ë¯¸ë‚˜', 'êµìœ¡', 'ë°œí‘œ', 'ê°•ì˜', 'ì›Œí¬ìƒµ'],
                'ë¹„ì¦ˆë‹ˆìŠ¤': ['business', 'market', 'sales', 'customer', 'company', 'industry', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'ì‹œì¥', 'ê³ ê°', 'íšŒì‚¬', 'ì‚°ì—…'],
                'ê¸°ìˆ /IT': ['technology', 'software', 'digital', 'system', 'platform', 'ê¸°ìˆ ', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ë””ì§€í„¸', 'ì‹œìŠ¤í…œ', 'í”Œë«í¼'],
                'ì£¼ì–¼ë¦¬': ['jewelry', 'diamond', 'gold', 'silver', 'gem', 'precious', 'ì£¼ì–¼ë¦¬', 'ë‹¤ì´ì•„ëª¬ë“œ', 'ê¸ˆ', 'ì€', 'ë³´ì„']
            }
            
            detected_topics = []
            for topic, keywords in topic_keywords.items():
                matches = sum(1 for keyword in keywords if keyword.lower() in combined_content.lower())
                if matches >= 2:  # 2ê°œ ì´ìƒì˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì£¼ì œë¡œ ë¶„ë¥˜
                    detected_topics.append(f"{topic}({matches}ê°œ í‚¤ì›Œë“œ)")
            
            if detected_topics:
                findings.append(f"ğŸ¯ **ì£¼ì œ ë¶„ë¥˜**: {', '.join(detected_topics)}")
        
        # ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼
        if audio_results:
            audio_success = len([r for r in audio_results if r.get('status') == 'success'])
            total_audio_time = sum([r.get('processing_time', 0) for r in audio_results if r.get('processing_time')])
            findings.append(f"ğŸ¤ **ìŒì„± ë¶„ì„**: {len(audio_results)}ê°œ íŒŒì¼ ì¤‘ {audio_success}ê°œ ì„±ê³µ (ì´ ì²˜ë¦¬ì‹œê°„: {total_audio_time:.1f}ì´ˆ)")
        
        if image_results:
            image_success = len([r for r in image_results if r.get('status') == 'success'])
            avg_confidence = sum([r.get('average_confidence', 0) for r in image_results if r.get('average_confidence')]) / len(image_results) if image_results else 0
            findings.append(f"ğŸ–¼ï¸ **ì´ë¯¸ì§€ ë¶„ì„**: {len(image_results)}ê°œ íŒŒì¼ ì¤‘ {image_success}ê°œ ì„±ê³µ (í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1f}%)")
        
        if jewelry_keywords:
            findings.append(f"ğŸ’ **ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´**: {', '.join(jewelry_keywords[:5])}{'...' if len(jewelry_keywords) > 5 else ''}")
        
        return findings
    
    def _generate_conclusions(self, results, success_rate, jewelry_keywords):
        """ê²°ë¡  ë° ì œì•ˆì‚¬í•­ ìƒì„±"""
        conclusions = []
        
        if success_rate >= 90:
            conclusions.append("ë¶„ì„ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìœ¼ë©°, ëŒ€ë¶€ë¶„ì˜ íŒŒì¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        elif success_rate >= 70:
            conclusions.append("ë¶„ì„ ì‹œìŠ¤í…œì´ ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë™í•˜ê³  ìˆìœ¼ë‚˜, ì¼ë¶€ íŒŒì¼ í˜•ì‹ì´ë‚˜ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            conclusions.append("ë¶„ì„ ì‹¤íŒ¨ìœ¨ì´ ë†’ìœ¼ë¯€ë¡œ íŒŒì¼ í’ˆì§ˆì´ë‚˜ í˜•ì‹ì„ ì ê²€í•˜ê³ , ì‹œìŠ¤í…œ ì„¤ì •ì„ ì¡°ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        if jewelry_keywords:
            conclusions.append("ì£¼ì–¼ë¦¬ ê´€ë ¨ ì»¨í…ì¸ ê°€ ì¶©ë¶„íˆ ê°ì§€ë˜ì–´ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„ì´ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
            conclusions.append("í–¥í›„ ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì‚¬ì „ì„ í™•ì¥í•˜ì—¬ ë” ì •í™•í•œ í‚¤ì›Œë“œ ì¶”ì¶œì´ ê°€ëŠ¥í•  ê²ƒì…ë‹ˆë‹¤.")
        
        # ê°œì„  ì œì•ˆ
        error_results = [r for r in results if r.get('status') == 'error']
        if error_results:
            error_types = [r.get('error', '') for r in error_results]
            if any('m4a' in error.lower() for error in error_types):
                conclusions.append("M4A íŒŒì¼ ì²˜ë¦¬ ê°œì„ ì„ ìœ„í•´ FFmpeg ì„¤ì •ì„ ìµœì í™”í•˜ê±°ë‚˜ WAV í˜•ì‹ ì‚¬ì „ ë³€í™˜ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        conclusions.append("ì •ê¸°ì ì¸ ë°°ì¹˜ ë¶„ì„ì„ í†µí•´ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì§€ì†ì ìœ¼ë¡œ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return conclusions
    
    def _calculate_average_confidence(self, results):
        """í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_scores = []
        for result in results:
            if result.get('average_confidence'):
                confidence_scores.append(result['average_confidence'])
        
        return sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
    
    def render_advanced_dashboard(self, report: Dict[str, Any]):
        """ê³ ê¸‰ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        if not PLOTLY_AVAILABLE or not PANDAS_AVAILABLE:
            st.warning("âš ï¸ ê³ ê¸‰ ì°¨íŠ¸ ê¸°ëŠ¥ì„ ìœ„í•´ plotlyì™€ pandas ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.code("pip install plotly pandas")
            return
        
        try:
            # íƒ­ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ êµ¬ì„±
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ íŒŒì¼ ë¶„ì„", "â±ï¸ ì²˜ë¦¬ ì‹œê°„", "ğŸ·ï¸ í‚¤ì›Œë“œ ë¶„ì„", "ğŸ“Š ì„±ëŠ¥ ì§€í‘œ"])
            
            with tab1:
                self._render_file_analysis_charts(report)
            
            with tab2:
                self._render_processing_time_charts(report)
            
            with tab3:
                self._render_keyword_analysis_charts(report)
            
            with tab4:
                self._render_performance_metrics(report)
                
        except Exception as e:
            st.error(f"ëŒ€ì‹œë³´ë“œ ë Œë”ë§ ì˜¤ë¥˜: {str(e)}")
    
    def _render_file_analysis_charts(self, report: Dict[str, Any]):
        """íŒŒì¼ ë¶„ì„ ì°¨íŠ¸"""
        col1, col2 = st.columns(2)
        
        with col1:
            # íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬
            if report.get('file_type_distribution'):
                file_types = list(report['file_type_distribution'].keys())
                file_counts = list(report['file_type_distribution'].values())
                
                fig = px.pie(
                    values=file_counts, 
                    names=file_types,
                    title="ğŸ“ íŒŒì¼ íƒ€ì… ë¶„í¬",
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ë¶„ì„ ì„±ê³µë¥ 
            if hasattr(report, 'success_rate') and hasattr(report, 'total_files'):
                success_count = int((report['success_rate'] / 100) * report['total_files'])
                failed_count = report['total_files'] - success_count
                
                fig = go.Figure(data=[
                    go.Bar(name='ì„±ê³µ', x=['ë¶„ì„ ê²°ê³¼'], y=[success_count], marker_color='green'),
                    go.Bar(name='ì‹¤íŒ¨', x=['ë¶„ì„ ê²°ê³¼'], y=[failed_count], marker_color='red')
                ])
                fig.update_layout(
                    title="âœ… ë¶„ì„ ì„±ê³µë¥ ",
                    barmode='stack',
                    yaxis_title="íŒŒì¼ ìˆ˜"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # íŒŒì¼ í¬ê¸° ë¶„í¬
        if st.session_state.analysis_results:
            file_sizes = []
            file_names = []
            
            for result in st.session_state.analysis_results:
                if result.get('file_size_mb'):
                    file_sizes.append(result['file_size_mb'])
                    file_names.append(result.get('file_name', 'Unknown'))
            
            if file_sizes:
                fig = px.histogram(
                    x=file_sizes,
                    nbins=10,
                    title="ğŸ“ íŒŒì¼ í¬ê¸° ë¶„í¬ (MB)",
                    labels={'x': 'íŒŒì¼ í¬ê¸° (MB)', 'y': 'íŒŒì¼ ìˆ˜'}
                )
                fig.update_traces(marker_color='lightblue')
                st.plotly_chart(fig, use_container_width=True)
    
    def _render_processing_time_charts(self, report: Dict[str, Any]):
        """ì²˜ë¦¬ ì‹œê°„ ì°¨íŠ¸"""
        if not st.session_state.analysis_results:
            st.info("ì²˜ë¦¬ ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„
        processing_times = []
        file_names = []
        file_types = []
        
        for result in st.session_state.analysis_results:
            if result.get('processing_time'):
                processing_times.append(result['processing_time'])
                file_names.append(result.get('file_name', 'Unknown')[:20] + '...')
                file_types.append(result.get('file_type', 'unknown'))
        
        if processing_times:
            col1, col2 = st.columns(2)
            
            with col1:
                # íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„ ë§‰ëŒ€ ì°¨íŠ¸
                fig = px.bar(
                    x=file_names,
                    y=processing_times,
                    title="â±ï¸ íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„",
                    labels={'x': 'íŒŒì¼ëª…', 'y': 'ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)'},
                    color=processing_times,
                    color_continuous_scale='Viridis'
                )
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # íŒŒì¼ íƒ€ì…ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„
                if PANDAS_AVAILABLE:
                    df = pd.DataFrame({
                        'file_type': file_types,
                        'processing_time': processing_times
                    })
                    avg_times = df.groupby('file_type')['processing_time'].mean().reset_index()
                    
                    fig = px.bar(
                        avg_times,
                        x='file_type',
                        y='processing_time',
                        title="ğŸ“Š íŒŒì¼ íƒ€ì…ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„",
                        labels={'file_type': 'íŒŒì¼ íƒ€ì…', 'processing_time': 'í‰ê·  ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # ì²˜ë¦¬ ì‹œê°„ í†µê³„
        if processing_times:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("âš¡ ìµœë‹¨ ì‹œê°„", f"{min(processing_times):.1f}ì´ˆ")
            with col2:
                st.metric("ğŸŒ ìµœì¥ ì‹œê°„", f"{max(processing_times):.1f}ì´ˆ")
            with col3:
                st.metric("ğŸ“Š í‰ê·  ì‹œê°„", f"{sum(processing_times)/len(processing_times):.1f}ì´ˆ")
            with col4:
                st.metric("ğŸ• ì´ ì²˜ë¦¬ ì‹œê°„", f"{sum(processing_times):.1f}ì´ˆ")
    
    def _render_keyword_analysis_charts(self, report: Dict[str, Any]):
        """í‚¤ì›Œë“œ ë¶„ì„ ì°¨íŠ¸"""
        if not report.get('top_keywords'):
            st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë§‰ëŒ€ ì°¨íŠ¸
        keywords = [item[0] for item in report['top_keywords'][:20]]
        counts = [item[1] for item in report['top_keywords'][:20]]
        
        fig = px.bar(
            x=counts,
            y=keywords,
            orientation='h',
            title="ğŸ·ï¸ ìƒìœ„ í‚¤ì›Œë“œ ë¹ˆë„",
            labels={'x': 'ì¶œí˜„ ë¹ˆë„', 'y': 'í‚¤ì›Œë“œ'},
            color=counts,
            color_continuous_scale='Blues'
        )
        fig.update_layout(height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # í‚¤ì›Œë“œ íŠ¸ë Œë“œ (ì‹œê°„ë³„ - ê°€ëŠ¥í•œ ê²½ìš°)
        if len(report['top_keywords']) >= 10:
            # ì›Œë“œí´ë¼ìš°ë“œ ìŠ¤íƒ€ì¼ ì‹œê°í™” (Plotlyë¡œ êµ¬í˜„)
            fig = go.Figure()
            
            for i, (keyword, count) in enumerate(report['top_keywords'][:20]):
                fig.add_trace(go.Scatter(
                    x=[i % 5], 
                    y=[i // 5],
                    text=keyword,
                    mode='text',
                    textfont=dict(size=min(30, 10 + count * 2)),
                    showlegend=False
                ))
            
            fig.update_layout(
                title="â˜ï¸ í‚¤ì›Œë“œ í´ë¼ìš°ë“œ",
                xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
                yaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_performance_metrics(self, report: Dict[str, Any]):
        """ì„±ëŠ¥ ì§€í‘œ ì°¨íŠ¸"""
        col1, col2 = st.columns(2)
        
        with col1:
            # ì„±ëŠ¥ ê²Œì´ì§€ ì°¨íŠ¸
            success_rate = report.get('success_rate', 0)
            
            fig = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = success_rate,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "ì„±ê³µë¥  (%)"},
                delta = {'reference': 90},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 80], 'color': "yellow"},
                        {'range': [80, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ì‹ ë¢°ë„ ë¶„í¬
            if st.session_state.analysis_results:
                confidences = []
                for result in st.session_state.analysis_results:
                    if result.get('average_confidence'):
                        confidences.append(result['average_confidence'])
                
                if confidences:
                    fig = px.histogram(
                        x=confidences,
                        nbins=15,
                        title="ğŸ¯ ì‹ ë¢°ë„ ë¶„í¬",
                        labels={'x': 'ì‹ ë¢°ë„', 'y': 'íŒŒì¼ ìˆ˜'},
                        color_discrete_sequence=['lightcoral']
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # ì¢…í•© ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸
        if st.session_state.analysis_results:
            categories = ['ì†ë„', 'ì •í™•ë„', 'ì•ˆì •ì„±', 'íš¨ìœ¨ì„±', 'ì‚¬ìš©ì„±']
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0-100)
            processing_times = [r.get('processing_time', 0) for r in st.session_state.analysis_results if r.get('processing_time')]
            avg_time = sum(processing_times) / len(processing_times) if processing_times else 0
            speed_score = max(0, 100 - min(100, avg_time * 10))  # ì‹œê°„ì´ ì§§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            
            accuracy_score = min(100, report.get('success_rate', 0))
            stability_score = min(100, (report.get('success_rate', 0) + 20))  # ì„±ê³µë¥  ê¸°ë°˜
            efficiency_score = min(100, speed_score * 0.7 + accuracy_score * 0.3)
            usability_score = 85  # ê³ ì •ê°’ (UI ë³µì¡ë„ ë“± ê³ ë ¤)
            
            values = [speed_score, accuracy_score, stability_score, efficiency_score, usability_score]
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatterpolar(
                r=values,
                theta=categories,
                fill='toself',
                name='ì„±ëŠ¥ ì§€í‘œ'
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 100]
                    )),
                title="ğŸ“Š ì¢…í•© ì„±ëŠ¥ í‰ê°€",
                showlegend=True
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _prepare_enhanced_context(self) -> Dict[str, Any]:
        """ê°•í™”ëœ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ - ì‚¬ì „ì •ë³´ ìµœëŒ€ í™œìš©"""
        base_context = st.session_state.get('project_info', {})
        
        enhanced_context = {
            # ê¸°ë³¸ í”„ë¡œì íŠ¸ ì •ë³´
            'project_name': base_context.get('name', ''),
            'project_type': base_context.get('type', ''),
            'objective': base_context.get('objective', ''),
            'target_language': base_context.get('target_language', 'auto'),
            
            # ğŸ†• ì°¸ì„ì ë° ë°œí‘œì ì •ë³´ (í…ìŠ¤íŠ¸ ë³´ì •ì— í™œìš©)
            'participants': self._extract_names(base_context.get('participants', '')),
            'speakers': self._extract_names(base_context.get('speakers', '')),
            
            # ğŸ†• ì£¼ì œ ë° í‚¤ì›Œë“œ ì •ë³´ (ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì— í™œìš©)
            'topic_keywords': self._extract_keywords(base_context.get('topic_keywords', '')),
            'event_context': base_context.get('event_context', ''),
            
            # ğŸ†• ë¶„ì„ ì„¤ì • ì •ë³´
            'analysis_depth': base_context.get('analysis_depth', 'ìƒì„¸'),
            'enable_multi_angle': base_context.get('enable_multi_angle', True),
            'correlation_analysis': base_context.get('correlation_analysis', True),
            
            # ğŸ†• ì´ë¯¸ ë¶„ì„ëœ íŒŒì¼ë“¤ì˜ ì •ë³´ (ìƒê´€ê´€ê³„ ë¶„ì„ìš©)
            'previous_results': self._get_previous_analysis_summary(),
            
            # ğŸ†• ì‹¤ì‹œê°„ ë¶„ì„ ê°€ì´ë“œë¼ì¸
            'analysis_guidelines': self._generate_analysis_guidelines(base_context)
        }
        
        return enhanced_context
    
    def _extract_names(self, names_text: str) -> List[str]:
        """ì°¸ì„ì/ë°œí‘œì ì´ë¦„ ì¶”ì¶œ ë° ì •ê·œí™”"""
        if not names_text.strip():
            return []
        
        # ì‰¼í‘œ, ì„¸ë¯¸ì½œë¡ , ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„
        names = []
        for separator in [',', ';', '\n']:
            names_text = names_text.replace(separator, '|')
        
        for name in names_text.split('|'):
            name = name.strip()
            if name and len(name) >= 2:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                names.append(name)
        
        return names
    
    def _extract_keywords(self, keywords_text: str) -> List[str]:
        """ì£¼ì œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ê·œí™”"""
        if not keywords_text.strip():
            return []
        
        keywords = []
        for separator in [',', ';', '\n', ' ']:
            keywords_text = keywords_text.replace(separator, '|')
        
        for keyword in keywords_text.split('|'):
            keyword = keyword.strip()
            if keyword and len(keyword) >= 2:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                keywords.append(keyword)
        
        return keywords
    
    def _get_previous_analysis_summary(self) -> Dict[str, Any]:
        """ì´ì „ ë¶„ì„ ê²°ê³¼ ìš”ì•½ (ìƒê´€ê´€ê³„ ë¶„ì„ìš©)"""
        previous_results = getattr(st.session_state, 'analysis_results', [])
        
        if not previous_results:
            return {}
        
        # ì´ì „ ê²°ê³¼ì—ì„œ ì¤‘ìš” ì •ë³´ ì¶”ì¶œ
        summary = {
            'total_files_analyzed': len(previous_results),
            'common_keywords': [],
            'frequent_participants': [],
            'main_topics': []
        }
        
        # ê³µí†µ í‚¤ì›Œë“œ ë° ì°¸ì„ì ì¶”ì¶œ
        all_keywords = []
        all_texts = []
        
        for result in previous_results:
            if result.get('status') == 'success':
                if result.get('jewelry_keywords'):
                    all_keywords.extend(result['jewelry_keywords'])
                if result.get('full_text'):
                    all_texts.append(result['full_text'])
        
        # ë¹ˆë„ ê¸°ë°˜ ì¤‘ìš” ì •ë³´ ì¶”ì¶œ
        if all_keywords:
            from collections import Counter
            keyword_counts = Counter(all_keywords)
            summary['common_keywords'] = [k for k, v in keyword_counts.most_common(5)]
        
        return summary
    
    def _generate_analysis_guidelines(self, context: Dict[str, Any]) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ê°€ì´ë“œë¼ì¸ ìƒì„±"""
        guidelines = []
        
        # í”„ë¡œì íŠ¸ íƒ€ì…ë³„ ê°€ì´ë“œë¼ì¸
        project_type = context.get('type', '')
        if 'íšŒì˜' in project_type:
            guidelines.append("íšŒì˜ë¡ í˜•ì‹ì˜ êµ¬ì¡°í™”ëœ ìš”ì•½ ìƒì„±")
            guidelines.append("ì°¸ì„ìë³„ ë°œì–¸ ë‚´ìš© êµ¬ë¶„")
        elif 'ê°•ì˜' in project_type or 'ì„¸ë¯¸ë‚˜' in project_type:
            guidelines.append("êµìœ¡ ìë£Œë¡œ í™œìš© ê°€ëŠ¥í•œ ì²´ê³„ì  ì •ë¦¬")
            guidelines.append("í•µì‹¬ ê°œë…ê³¼ ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ ë„ì¶œ")
        
        # ì°¸ì„ì ì •ë³´ê°€ ìˆì„ ê²½ìš°
        if context.get('participants'):
            guidelines.append(f"ì°¸ì„ì ì´ë¦„ ì •í™•ì„± ê²€ì¦: {', '.join(context['participants'][:3])}")
        
        # í‚¤ì›Œë“œ ì •ë³´ê°€ ìˆì„ ê²½ìš°
        if context.get('topic_keywords'):
            guidelines.append(f"í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ ë¶„ì„: {', '.join(context['topic_keywords'][:3])}")
        
        return guidelines
    
    def _update_analysis_status(self, filename: str, context: Dict[str, Any]):
        """ë¶„ì„ ì§„í–‰ ìƒí™©ì„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ì™€ í•¨ê»˜ ì—…ë°ì´íŠ¸"""
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í‘œì‹œ
        context_info = []
        if context.get('participants'):
            context_info.append(f"ğŸ‘¥ ì°¸ì„ì {len(context['participants'])}ëª…")
        if context.get('speakers'):
            context_info.append(f"ğŸ¤ ë°œí‘œì {len(context['speakers'])}ëª…")
        if context.get('topic_keywords'):
            context_info.append(f"ğŸ”‘ í‚¤ì›Œë“œ {len(context['topic_keywords'])}ê°œ")
        
        if context_info:
            context_display = " | ".join(context_info)
            st.info(f"ğŸ“‹ **í™œìš© ì¤‘ì¸ ì‚¬ì „ì •ë³´**: {context_display}")
        
        # ë¶„ì„ ê°€ì´ë“œë¼ì¸ í‘œì‹œ
        if context.get('analysis_guidelines'):
            with st.expander("ğŸ¯ ì ìš© ì¤‘ì¸ ë¶„ì„ ê°€ì´ë“œë¼ì¸", expanded=False):
                for guideline in context['analysis_guidelines']:
                    st.write(f"â€¢ {guideline}")
    
    def _categorize_and_preprocess_files(self, uploaded_files_data) -> Dict[str, List]:
        """íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬"""
        categories = {
            'audio_files': [],
            'video_files': [],  
            'image_files': [],
            'document_files': [],
            'video_urls': uploaded_files_data.get('video_urls', [])
        }
        
        for uploaded_file in uploaded_files_data.get('files', []):
            file_ext = uploaded_file.name.split('.')[-1].lower()
            file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
            
            file_info = {
                'file': uploaded_file,
                'name': uploaded_file.name,
                'extension': file_ext,
                'size_mb': file_size_mb,
                'temp_path': None
            }
            
            if file_ext in ['wav', 'mp3', 'flac', 'm4a']:
                categories['audio_files'].append(file_info)
            elif file_ext in ['mp4', 'mov', 'avi']:
                categories['video_files'].append(file_info)
            elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                categories['image_files'].append(file_info)
            elif file_ext in ['pdf', 'docx', 'txt']:
                categories['document_files'].append(file_info)
        
        return categories
    
    def _build_integrated_context(self, file_categories) -> Dict[str, Any]:
        """ëª¨ë“  íŒŒì¼ ì •ë³´ë¥¼ í†µí•©í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        base_context = self._prepare_enhanced_context()
        
        integrated_context = {
            **base_context,
            'file_categories': file_categories,
            'total_files': sum(len(files) for files in file_categories.values() if isinstance(files, list)),
            'file_distribution': {
                'audio': len(file_categories.get('audio_files', [])),
                'video': len(file_categories.get('video_files', [])),
                'image': len(file_categories.get('image_files', [])),
                'document': len(file_categories.get('document_files', [])),
                'video_url': len(file_categories.get('video_urls', []))
            },
            'analysis_strategy': self._determine_analysis_strategy(file_categories),
            'cross_reference_enabled': True,
            'batch_processing': True
        }
        
        return integrated_context
    
    def _determine_analysis_strategy(self, file_categories) -> str:
        """íŒŒì¼ êµ¬ì„±ì— ë”°ë¥¸ ìµœì  ë¶„ì„ ì „ëµ ê²°ì •"""
        audio_count = len(file_categories.get('audio_files', []))
        video_count = len(file_categories.get('video_files', []))
        image_count = len(file_categories.get('image_files', []))
        
        if video_count > 0 and (audio_count > 0 or image_count > 0):
            return "multimodal_integrated"  # ë‹¤ì¤‘ëª¨ë‹¬ í†µí•© ë¶„ì„
        elif audio_count > 0 and image_count > 0:
            return "audio_visual_correlation"  # ìŒì„±-ì‹œê° ìƒê´€ê´€ê³„
        elif video_count > 1:
            return "multi_video_synthesis"  # ë‹¤ì¤‘ ì˜ìƒ ì¢…í•©
        elif image_count > 3:
            return "sequential_image_analysis"  # ì—°ì† ì´ë¯¸ì§€ ë¶„ì„
        else:
            return "standard_batch"  # í‘œì¤€ ë°°ì¹˜ ë¶„ì„
    
    def _execute_batch_analysis(self, file_categories, integrated_context, progress_container, timer_container=None) -> Dict[str, Any]:
        """ë°°ì¹˜ í†µí•© ë¶„ì„ ì‹¤í–‰ - ì‹¤ì‹œê°„ ì‹œê°„ ì¶”ì  ë° MCP ìë™ ë¬¸ì œ í•´ê²°"""
        import psutil
        import os
        import time
        
        batch_results = {
            'audio_results': [],
            'video_results': [],
            'image_results': [],
            'document_results': [],
            'youtube_results': [],
            'cross_correlations': [],
            'integrated_insights': {}
        }
        
        # ì´ íŒŒì¼ ìˆ˜ ê³„ì‚°
        total_files = 0
        total_files += len(file_categories.get('audio_files', []))
        total_files += len(file_categories.get('video_files', []))
        total_files += len(file_categories.get('image_files', []))
        total_files += len(file_categories.get('document_files', []))
        total_files += len(file_categories.get('youtube', []))
        
        processed_files = 0
        
        # ì‹¤ì‹œê°„ ì§„í–‰ ì¶”ì  ì‹œì‘
        if ADVANCED_MONITORING_AVAILABLE:
            global_progress_tracker.start_analysis(total_files, progress_container)
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        try:
            process = psutil.Process(os.getpid())
            start_memory = process.memory_info().rss / (1024 * 1024)  # MB
        except:
            start_memory = 0
        
        # ğŸ¤ ìŒì„± íŒŒì¼ ë°°ì¹˜ ë¶„ì„
        if file_categories.get('audio_files'):
            st.session_state.analysis_status = f"ğŸ¤ ìŒì„± íŒŒì¼ ë¶„ì„ ì¤‘ ({len(file_categories['audio_files'])}ê°œ)"
            
            # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
            if timer_container:
                with timer_container.container():
                    st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
            
            if ADVANCED_MONITORING_AVAILABLE:
                global_progress_tracker.start_stage("ğŸ¤ ìŒì„± íŒŒì¼ ë¶„ì„")
            
            batch_results['audio_results'] = self._batch_analyze_audio_files_with_tracking(
                file_categories['audio_files'], integrated_context, progress_container, processed_files, total_files, start_memory
            )
            processed_files += len(file_categories['audio_files'])
            
            if ADVANCED_MONITORING_AVAILABLE:
                global_progress_tracker.finish_stage()
            
            # ì™„ë£Œ í›„ íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
            st.session_state.analysis_status = f"ğŸ¤ ìŒì„± ë¶„ì„ ì™„ë£Œ ({len(file_categories['audio_files'])}ê°œ)"
            if timer_container:
                with timer_container.container():
                    st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
            
            # ì‹¤ì œ ì™„ë£Œ í‘œì‹œ
            with progress_container.container():
                self.show_real_progress_only(processed_files, total_files, f"ìŒì„± ë¶„ì„ ì™„ë£Œ: {len(file_categories['audio_files'])}ê°œ", force_display=True)
        
        # ğŸ¬ ì˜ìƒ íŒŒì¼ ë°°ì¹˜ ë¶„ì„  
        if file_categories.get('video_files'):
            st.info(f"ğŸ¬ ì˜ìƒ íŒŒì¼ ë¶„ì„ ì‹œì‘: {len(file_categories['video_files'])}ê°œ")
            batch_results['video_results'] = self._batch_analyze_video_files(
                file_categories['video_files'], integrated_context, progress_container, processed_files, total_files
            )
            processed_files += len(file_categories['video_files'])
            
            # ì‹¤ì œ ì™„ë£Œ í‘œì‹œ
            with progress_container.container():
                self.show_real_progress_only(processed_files, total_files, f"ì˜ìƒ ë¶„ì„ ì™„ë£Œ: {len(file_categories['video_files'])}ê°œ", force_display=True)
        
        # ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ë°°ì¹˜ ë¶„ì„
        if file_categories.get('image_files'):
            st.session_state.analysis_status = f"ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„ ì¤‘ ({len(file_categories['image_files'])}ê°œ)"
            
            # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
            if timer_container:
                with timer_container.container():
                    st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
            
            st.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„ ì‹œì‘: {len(file_categories['image_files'])}ê°œ")
            batch_results['image_results'] = self._batch_analyze_image_files(
                file_categories['image_files'], integrated_context, progress_container, processed_files, total_files
            )
            processed_files += len(file_categories['image_files'])
            
            # ì™„ë£Œ í›„ íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
            st.session_state.analysis_status = f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ ({len(file_categories['image_files'])}ê°œ)"
            if timer_container:
                with timer_container.container():
                    st.markdown(self.show_realtime_analysis_timer(), unsafe_allow_html=True)
            
            # ì‹¤ì œ ì™„ë£Œ í‘œì‹œ
            with progress_container.container():
                self.show_real_progress_only(processed_files, total_files, f"ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {len(file_categories['image_files'])}ê°œ", force_display=True)
        
        # ğŸ“„ ë¬¸ì„œ íŒŒì¼ ë°°ì¹˜ ë¶„ì„
        if file_categories.get('document_files'):
            st.info(f"ğŸ“„ ë¬¸ì„œ íŒŒì¼ ë¶„ì„ ì‹œì‘: {len(file_categories['document_files'])}ê°œ")
            batch_results['document_results'] = self._batch_analyze_document_files(
                file_categories['document_files'], integrated_context, progress_container, processed_files, total_files
            )
            processed_files += len(file_categories['document_files'])
            
            # ì‹¤ì œ ì™„ë£Œ í‘œì‹œ
            with progress_container.container():
                self.show_real_progress_only(processed_files, total_files, f"ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ: {len(file_categories['document_files'])}ê°œ", force_display=True)
        
        # ğŸ¬ YouTube URL ë°°ì¹˜ ë¶„ì„
        if file_categories.get('youtube'):
            if ADVANCED_MONITORING_AVAILABLE:
                global_progress_tracker.start_stage("ğŸ¬ YouTube URL ë¶„ì„")
            
            st.info(f"ğŸ¬ YouTube URL ë¶„ì„ ì‹œì‘: {len(file_categories['youtube'])}ê°œ")
            batch_results['youtube_results'] = self._batch_analyze_youtube_urls(
                file_categories['youtube'], integrated_context, progress_container, processed_files, total_files
            )
            processed_files += len(file_categories['youtube'])
            
            if ADVANCED_MONITORING_AVAILABLE:
                global_progress_tracker.finish_stage()
            
            # ì‹¤ì œ ì™„ë£Œ í‘œì‹œ
            with progress_container.container():
                self.show_real_progress_only(processed_files, total_files, f"YouTube ë¶„ì„ ì™„ë£Œ: {len(file_categories['youtube'])}ê°œ", force_display=True)
        
        # ìµœì¢… ì™„ë£Œ í‘œì‹œ
        with progress_container.container():
            self.show_real_progress_only(total_files, total_files, "ëª¨ë“  íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ!", f"ì´ {total_files}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ", force_display=True)
        
        # ë¶„ì„ ì™„ë£Œ ì‹œ MCP ìë™ ë¬¸ì œ í•´ê²° ë¦¬í¬íŠ¸
        if ADVANCED_MONITORING_AVAILABLE:
            global_progress_tracker.finish_analysis()
            
            # ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ë° MCP ë¬¸ì œ í•´ê²°
            try:
                end_memory = process.memory_info().rss / (1024 * 1024)  # MB
                memory_used = end_memory - start_memory
                total_time_str = global_progress_tracker._get_elapsed_time()
                # ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜
                if "ì‹œê°„" in total_time_str:
                    total_time = 3600  # 1ì‹œê°„ ì´ìƒì´ë©´ 3600ì´ˆë¡œ ì„¤ì •
                elif "ë¶„" in total_time_str:
                    minutes = int(total_time_str.split("ë¶„")[0])
                    total_time = minutes * 60
                else:
                    try:
                        total_time = float(total_time_str.replace("ì´ˆ", ""))
                    except:
                        total_time = time.time() - global_progress_tracker.start_time if global_progress_tracker.start_time else 0
                
                # MCP ìë™ ë¬¸ì œ í•´ê²° ì‹œìŠ¤í…œ í™œìš©
                problem_analysis = global_mcp_solver.detect_and_solve_problems(
                    memory_usage_mb=memory_used,
                    processing_time=total_time,
                    file_info={'total_files': total_files, 'processed_files': processed_files}
                )
                
                # ë¬¸ì œê°€ ê°ì§€ëœ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
                if problem_analysis['problems_detected']:
                    with progress_container.container():
                        st.warning("âš ï¸ **ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼ - ê°œì„  ê¶Œì¥ì‚¬í•­**")
                        for problem in problem_analysis['problems_detected']:
                            st.write(f"â€¢ {problem['description']}")
                        
                        if problem_analysis['solutions_found']:
                            st.info("ğŸ’¡ **MCP ìë™ í•´ê²°ì±…**:")
                            for solution in problem_analysis['solutions_found']:
                                if solution.get('recommended_actions'):
                                    for action in solution['recommended_actions'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                                        st.write(f"  - {action}")
                        
                        if problem_analysis['auto_actions_taken']:
                            st.success("ğŸ¤– **ìë™ ì‹¤í–‰ëœ ìµœì í™”**:")
                            for action in problem_analysis['auto_actions_taken']:
                                st.write(f"  âœ… {action['description']}")
                                
            except Exception as e:
                self.logger.warning(f"MCP ìë™ ë¬¸ì œ í•´ê²° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return batch_results
    
    def _batch_analyze_audio_files_with_tracking(self, audio_files, context, progress_container, base_processed, total_files, start_memory) -> List[Dict]:
        """ìŒì„± íŒŒì¼ ë°°ì¹˜ ë¶„ì„ - ì‹¤ì‹œê°„ ì‹œê°„ ì¶”ì  ë° MCP í†µí•©"""
        import tempfile
        import time
        import psutil
        import os
        
        results = []
        
        # ëª¨ë“  ìŒì„± íŒŒì¼ì„ ì„ì‹œ ì €ì¥
        temp_files = []
        for file_info in audio_files:
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_files.append(tmp_file.name)
                file_info['temp_path'] = tmp_file.name
                
                # íŒŒì¼ í¬ê¸° ê³„ì‚° (MB)
                file_info['size_mb'] = len(file_info['file'].getvalue()) / (1024 * 1024)
        
        try:
            for i, file_info in enumerate(audio_files):
                current_processed = base_processed + i
                
                # ì‹¤ì‹œê°„ ì§„í–‰ ì¶”ì  ì‹œì‘
                if ADVANCED_MONITORING_AVAILABLE:
                    global_progress_tracker.start_file_processing(
                        file_info['name'], 
                        file_info.get('size_mb', 0)
                    )
                
                # ê°œë³„ ë¶„ì„ ìˆ˜í–‰
                start_time = time.time()
                try:
                    result = analyze_file_real(file_info['temp_path'], 'audio', 'auto', context)
                    result['batch_index'] = i
                    result['cross_reference_ready'] = True
                    results.append(result)
                    
                    processing_time = time.time() - start_time
                    
                    # MCP ìë™ ë¬¸ì œ ê°ì§€ ë° í•´ê²°
                    if ADVANCED_MONITORING_AVAILABLE:
                        try:
                            current_memory = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)
                            memory_delta = current_memory - start_memory
                            
                            # ë¬¸ì œ ê°ì§€ ë° í•´ê²°
                            if memory_delta > 500 or processing_time > 120:  # 500MB ì´ìƒ ë˜ëŠ” 2ë¶„ ì´ìƒ
                                problem_analysis = global_mcp_solver.detect_and_solve_problems(
                                    memory_usage_mb=memory_delta,
                                    processing_time=processing_time,
                                    file_info=file_info,
                                    error_message=result.get('error') if result.get('status') == 'error' else None
                                )
                                
                                # ê¸´ê¸‰í•œ ë¬¸ì œì¸ ê²½ìš° ì¦‰ì‹œ ì•Œë¦¼
                                if any(p['severity'] == 'high' for p in problem_analysis['problems_detected']):
                                    with progress_container.container():
                                        st.warning(f"âš ï¸ {file_info['name']} ì²˜ë¦¬ ì¤‘ ì„±ëŠ¥ ì´ìŠˆ ê°ì§€")
                                        if problem_analysis['auto_actions_taken']:
                                            st.info("ğŸ¤– ìë™ ìµœì í™” ì‹¤í–‰ë¨")
                        except Exception as e:
                            self.logger.warning(f"MCP ë¬¸ì œ ê°ì§€ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                except Exception as e:
                    self.logger.error(f"ìŒì„± íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                    results.append({
                        'status': 'error',
                        'error': str(e),
                        'file_name': file_info['name'],
                        'batch_index': i
                    })
                
                # íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ
                if ADVANCED_MONITORING_AVAILABLE:
                    global_progress_tracker.finish_file_processing()
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
        
        return results
    
    def _batch_analyze_audio_files(self, audio_files, context, progress_container, base_processed, total_files) -> List[Dict]:
        """ìŒì„± íŒŒì¼ ë°°ì¹˜ ë¶„ì„ - ì‹¤ì œ ì§„í–‰ë¥  í‘œì‹œ"""
        results = []
        
        # ëª¨ë“  ìŒì„± íŒŒì¼ì„ ì„ì‹œ ì €ì¥
        temp_files = []
        for file_info in audio_files:
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_files.append(tmp_file.name)
                file_info['temp_path'] = tmp_file.name
        
        # ë°°ì¹˜ STT ì²˜ë¦¬ (ì‹¤ì œ ì§„í–‰ë¥  í‘œì‹œ)
        try:
            for i, file_info in enumerate(audio_files):
                current_processed = base_processed + i
                
                # ì‹¤ì œ ì²˜ë¦¬ ìƒíƒœë§Œ í‘œì‹œ
                st.write(f"ğŸ¤ ì²˜ë¦¬ ì¤‘: {file_info['name']} ({i+1}/{len(audio_files)})")
                
                # ê°œë³„ ë¶„ì„ ìˆ˜í–‰ (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
                result = analyze_file_real(file_info['temp_path'], 'audio', 'auto', context)
                result['batch_index'] = i
                result['cross_reference_ready'] = True
                results.append(result)
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
        
        return results
    
    def _batch_analyze_image_files(self, image_files, context, progress_container, base_processed, total_files) -> List[Dict]:
        """ì´ë¯¸ì§€ íŒŒì¼ ë°°ì¹˜ ë¶„ì„ - ì‹¤ì œ ì§„í–‰ë¥  í‘œì‹œ"""
        results = []
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì„ì‹œ ì €ì¥
        temp_files = []
        for file_info in image_files:
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_files.append(tmp_file.name)
                file_info['temp_path'] = tmp_file.name
        
        try:
            # ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ (ì‹¤ì œ ì§„í–‰ë¥  í‘œì‹œ)
            for i, file_info in enumerate(image_files):
                current_processed = base_processed + i
                
                # ì‹¤ì œ ì²˜ë¦¬ ìƒíƒœë§Œ í‘œì‹œ
                st.write(f"ğŸ–¼ï¸ ì²˜ë¦¬ ì¤‘: {file_info['name']} ({i+1}/{len(image_files)})")
                
                result = analyze_file_real(file_info['temp_path'], 'image', 'auto', context)
                result['batch_index'] = i
                result['cross_reference_ready'] = True
                results.append(result)
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
        
        return results
    
    def _batch_analyze_video_files(self, video_files, context, progress_container, base_processed, total_files) -> List[Dict]:
        """ì˜ìƒ íŒŒì¼ ë°°ì¹˜ ë¶„ì„ - ë‹¤ê°ë„ í†µí•©"""
        results = []
        
        for i, file_info in enumerate(video_files):
            st.text(f"ğŸ¬ ì˜ìƒ ë¶„ì„: {file_info['name']} ({i+1}/{len(video_files)})")
            
            # ì„ì‹œ íŒŒì¼ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_path = tmp_file.name
            
            try:
                result = analyze_file_real(temp_path, 'video', 'auto', context)
                result['batch_index'] = i
                result['cross_reference_ready'] = True
                results.append(result)
            finally:
                try:
                    os.unlink(temp_path)
                except:
                    pass
        
        return results
    
    def _batch_analyze_document_files(self, document_files, context, progress_container, base_processed, total_files) -> List[Dict]:
        """ë¬¸ì„œ íŒŒì¼ ë°°ì¹˜ ë¶„ì„"""
        results = []
        
        for i, file_info in enumerate(document_files):
            st.text(f"ğŸ“„ ë¬¸ì„œ ë¶„ì„: {file_info['name']} ({i+1}/{len(document_files)})")
            
            temp_path = None
            try:
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                    tmp_file.write(file_info['file'].getvalue())
                    temp_path = tmp_file.name
                
                # ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰
                result = analyze_file_real(temp_path, "document", language="auto", context=context)
                
                if result:
                    result['file_name'] = file_info['name']
                    result['file_size'] = file_info.get('size', 0)
                    result['analysis_method'] = 'document_batch'
                    
                    # ì¢…í•© ë©”ì‹œì§€ ì¶”ì¶œ ì ìš©
                    if result.get('status') == 'success' and result.get('extracted_text'):
                        try:
                            from core.comprehensive_message_extractor import extract_speaker_message
                            message_analysis = extract_speaker_message(result['extracted_text'])
                            if message_analysis:
                                result['comprehensive_message'] = message_analysis
                        except Exception as e:
                            result['message_extraction_error'] = str(e)
                    
                    results.append(result)
                else:
                    # ì‹¤íŒ¨ ê²°ê³¼
                    results.append({
                        'status': 'error',
                        'error': 'ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨',
                        'file_name': file_info['name'],
                        'analysis_method': 'document_batch'
                    })
                    
            except Exception as e:
                # ì˜ˆì™¸ ì²˜ë¦¬
                results.append({
                    'status': 'error',
                    'error': f'ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                    'file_name': file_info['name'],
                    'analysis_method': 'document_batch'
                })
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if temp_path:
                    try:
                        os.unlink(temp_path)
                    except:
                        pass
        
        return results
    
    def _analyze_cross_correlations(self, batch_results, context) -> List[Dict]:
        """ë°°ì¹˜ ê²°ê³¼ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        correlations = []
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_texts = []
        all_keywords = []
        
        for category, results in batch_results.items():
            if isinstance(results, list):
                for result in results:
                    if result.get('status') == 'success':
                        if result.get('full_text'):
                            all_texts.append({
                                'text': result['full_text'],
                                'source': category,
                                'file_name': result.get('file_name', ''),
                                'type': category.replace('_results', '')
                            })
                        if result.get('jewelry_keywords'):
                            all_keywords.extend(result['jewelry_keywords'])
        
        # ê³µí†µ í‚¤ì›Œë“œ ë¶„ì„
        if all_keywords:
            from collections import Counter
            keyword_counts = Counter(all_keywords)
            common_keywords = [k for k, v in keyword_counts.most_common(10) if v > 1]
            
            correlations.append({
                'type': 'common_keywords',
                'keywords': common_keywords,
                'strength': len(common_keywords) / len(set(all_keywords)) if all_keywords else 0
            })
        
        return correlations
    
    def _integrate_and_optimize_results(self, batch_results, context) -> List[Dict]:
        """ë°°ì¹˜ ê²°ê³¼ í†µí•© ë° ìµœì í™”"""
        integrated_results = []
        
        # ëª¨ë“  ê²°ê³¼ë¥¼ í†µí•© ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        for category, results in batch_results.items():
            if isinstance(results, list):
                for result in results:
                    # ë°°ì¹˜ ë¶„ì„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    result['batch_processed'] = True
                    result['correlation_analyzed'] = len(batch_results.get('cross_correlations', [])) > 0
                    result['analysis_strategy'] = context.get('analysis_strategy', 'standard_batch')
                    integrated_results.append(result)
        
        return integrated_results
    
    def _display_speaker_diarization_results(self, speaker_analysis: Dict[str, Any]):
        """í™”ì ë¶„ë¦¬ ê²°ê³¼ í‘œì‹œ"""
        
        st.markdown("### ğŸ¤ **í™”ì ë¶„ë¦¬ ë¶„ì„ ê²°ê³¼**")
        
        # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        speaker_count = speaker_analysis.get('speaker_count', 0)
        processing_time = speaker_analysis.get('processing_time', 0)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ê°ì§€ëœ í™”ì", f"{speaker_count}ëª…")
        with col2:
            st.metric("ë¶„ì„ ì‹œê°„", f"{processing_time:.1f}ì´ˆ")
        with col3:
            voice_ratio = speaker_analysis.get('voice_activity_ratio', 0)
            st.metric("ìŒì„± í™œë™ ë¹„ìœ¨", f"{voice_ratio*100:.1f}%")
        
        # ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½
        if speaker_analysis.get('user_summary'):
            st.markdown("#### ğŸ“‹ ìš”ì•½")
            st.markdown(speaker_analysis['user_summary'])
        
        # í™”ìë³„ ë°œì–¸ ë‚´ìš© (í•µì‹¬ ê¸°ëŠ¥)
        speaker_statements = speaker_analysis.get('speaker_statements', {})
        if speaker_statements:
            st.markdown("#### ğŸ‘¥ í™”ìë³„ ë°œì–¸ ë‚´ìš©")
            
            # íƒ­ìœ¼ë¡œ í™”ìë³„ êµ¬ë¶„
            if len(speaker_statements) > 1:
                speaker_tabs = st.tabs([f"í™”ì {sid.replace('SPEAKER_', '').lstrip('0') or '1'}" 
                                      for sid in speaker_statements.keys()])
                
                for i, (speaker_id, statements) in enumerate(speaker_statements.items()):
                    with speaker_tabs[i]:
                        self._display_speaker_statements(speaker_id, statements, speaker_analysis)
            else:
                # ë‹¨ì¼ í™”ìì¸ ê²½ìš°
                speaker_id, statements = next(iter(speaker_statements.items()))
                self._display_speaker_statements(speaker_id, statements, speaker_analysis)
        
        # ìƒì„¸ ë¶„ì„ ê²°ê³¼ (í¼ì¹˜ê¸° í˜•íƒœ)
        with st.expander("ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
            self._display_detailed_speaker_analysis(speaker_analysis)
    
    def _display_speaker_statements(self, speaker_id: str, statements: List[Dict], full_analysis: Dict):
        """ê°œë³„ í™”ìì˜ ë°œì–¸ ë‚´ìš© í‘œì‹œ"""
        
        speaker_num = speaker_id.replace('SPEAKER_', '').lstrip('0') or '1'
        
        # í™”ì ì •ë³´ í‘œì‹œ
        if full_analysis.get('speaker_identification', {}).get('speaker_details', {}).get(speaker_id):
            speaker_details = full_analysis['speaker_identification']['speaker_details'][speaker_id]
            identified_names = speaker_details.get('identified_names', [])
            
            if identified_names:
                name = identified_names[0].get('name', '')
                title = identified_names[0].get('title', '')
                if name:
                    display_name = f"{name}" + (f" ({title})" if title else "")
                    st.markdown(f"**ğŸ·ï¸ ì‹ë³„ëœ ì´ë¦„:** {display_name}")
            
            # ì „ë¬¸ê°€ ì—­í• 
            expert_roles = speaker_details.get('expert_roles', {})
            if expert_roles:
                st.markdown(f"**ğŸ‘¨â€ğŸ’¼ ì¶”ì • ì—­í• :** {', '.join(expert_roles.get(speaker_id, []))}")
        
        # ë°œì–¸ êµ¬ê°„ë³„ í‘œì‹œ
        total_statements = len(statements)
        total_duration = sum(float(stmt.get('duration', '0ì´ˆ').replace('ì´ˆ', '')) for stmt in statements)
        
        st.markdown(f"**ğŸ“Š ë°œì–¸ í†µê³„:** {total_statements}ê°œ êµ¬ê°„, ì´ {total_duration:.1f}ì´ˆ")
        
        # ê° ë°œì–¸ êµ¬ê°„
        for i, statement in enumerate(statements):
            with st.container():
                # ì‹œê°„ ì •ë³´
                time_info = f"{statement.get('start_time', '')} - {statement.get('end_time', '')} ({statement.get('duration', '')})"
                st.markdown(f"**â° {time_info}**")
                
                # ë°œì–¸ ë‚´ìš©
                content = statement.get('content', '')
                if content:
                    st.markdown(f"ğŸ’¬ {content}")
                else:
                    st.markdown("ğŸ”‡ *ì´ êµ¬ê°„ì—ì„œëŠ” ëª…í™•í•œ ë°œì–¸ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤*")
                
                if i < len(statements) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ êµ¬ë¶„ì„ 
                    st.divider()
    
    def _display_detailed_speaker_analysis(self, speaker_analysis: Dict):
        """ìƒì„¸ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        
        # ë¶„ì„ í’ˆì§ˆ ì •ë³´
        analysis_quality = speaker_analysis.get('analysis_quality', {})
        if analysis_quality:
            st.markdown("#### ğŸ“ˆ ë¶„ì„ í’ˆì§ˆ")
            quality_score = analysis_quality.get('quality_score', 0)
            quality_level = analysis_quality.get('quality_level', 'ì•Œ ìˆ˜ ì—†ìŒ')
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("í’ˆì§ˆ ì ìˆ˜", f"{quality_score:.2f}/1.00")
            with col2:
                st.metric("í’ˆì§ˆ ìˆ˜ì¤€", quality_level)
            
            quality_factors = analysis_quality.get('quality_factors', [])
            if quality_factors:
                st.markdown("**í’ˆì§ˆ ìš”ì¸:**")
                for factor in quality_factors:
                    st.markdown(f"â€¢ {factor}")
        
        # í™”ìë³„ íƒ€ì„ë¼ì¸
        speaker_timeline = speaker_analysis.get('speaker_timeline', [])
        if speaker_timeline:
            st.markdown("#### â±ï¸ í™”ìë³„ íƒ€ì„ë¼ì¸")
            timeline_df = []
            for segment in speaker_timeline:
                timeline_df.append({
                    "í™”ì": segment['speaker_id'].replace('SPEAKER_', 'í™”ì ').replace('_0', ' ').replace('_', ' '),
                    "ì‹œì‘": segment['start_formatted'],
                    "ì¢…ë£Œ": segment['end_formatted'],
                    "ê¸¸ì´": segment['duration_formatted']
                })
            
            if timeline_df:
                import pandas as pd
                if PANDAS_AVAILABLE:
                    df = pd.DataFrame(timeline_df)
                    st.dataframe(df, use_container_width=True)
                else:
                    # pandasê°€ ì—†ëŠ” ê²½ìš° í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
                    for row in timeline_df:
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.write(row["í™”ì"])
                        with col2:
                            st.write(row["ì‹œì‘"])
                        with col3:
                            st.write(row["ì¢…ë£Œ"])
                        with col4:
                            st.write(row["ê¸¸ì´"])
        
        # ê¸°ìˆ ì  ì •ë³´
        with st.expander("ğŸ”§ ê¸°ìˆ ì  ì •ë³´"):
            st.json(speaker_analysis)
    
    def _batch_analyze_youtube_urls(self, youtube_urls, integrated_context, progress_container, base_processed, total_files):
        """YouTube URL ë°°ì¹˜ ë¶„ì„ (ì‹¤ì‹œê°„ ì¶”ì  í¬í•¨)"""
        results = []
        temp_files = []
        
        try:
            for i, url_data in enumerate(youtube_urls):
                current_processed = base_processed + i
                url = url_data[0] if isinstance(url_data, tuple) else url_data
                
                # ì‹¤ì‹œê°„ ì§„í–‰ ì¶”ì  ì‹œì‘
                if ADVANCED_MONITORING_AVAILABLE:
                    global_progress_tracker.start_file_processing(
                        f"YouTube: {url[:30]}...",
                        0  # í¬ê¸° ë¯¸ì§€
                    )
                
                try:
                    start_time = time.time()
                    
                    # YouTube ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
                    if not YOUTUBE_REALTIME_AVAILABLE:
                        result = {
                            'status': 'error',
                            'error': 'YouTube ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                            'url': url,
                            'file_name': f"YouTube: {url[:30]}...",
                            'batch_index': i
                        }
                        results.append(result)
                        continue
                    
                    # YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
                    with progress_container.container():
                        self.show_real_progress_only(current_processed, total_files, f"YouTube ë‹¤ìš´ë¡œë“œ ì¤‘: {url[:30]}...", force_display=True)
                    
                    download_result = global_youtube_realtime_processor.download_audio(url, progress_container=progress_container)
                    
                    if download_result.get('success'):
                        audio_file = download_result['output_file']
                        temp_files.append(audio_file)
                        
                        # STT ë¶„ì„
                        with progress_container.container():
                            self.show_real_progress_only(current_processed, total_files, f"YouTube STT ë¶„ì„ ì¤‘: {url[:30]}...", force_display=True)
                        
                        if REAL_ANALYSIS_AVAILABLE:
                            stt_result = real_analysis_engine.analyze_audio_file(audio_file)
                            
                            result = {
                                'status': 'success',
                                'file_type': 'youtube_audio',
                                'url': url,
                                'video_info': download_result.get('video_info', {}),
                                'audio_file': audio_file,
                                'file_size_mb': download_result.get('file_size_mb', 0),
                                'stt_result': stt_result,
                                'processing_time': download_result.get('processing_time', 0),
                                'download_speed_mbps': download_result.get('download_speed_mbps', 0),
                                'file_name': download_result.get('video_info', {}).get('title', f"YouTube: {url[:30]}..."),
                                'batch_index': i
                            }
                        else:
                            # STT ë¶„ì„ ì—”ì§„ì´ ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì œê³µ
                            result = {
                                'status': 'partial_success',
                                'message': 'ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì„±ê³µ, STT ë¶„ì„ ì—”ì§„ ë¯¸ì‚¬ìš©',
                                'url': url,
                                'video_info': download_result.get('video_info', {}),
                                'audio_file': audio_file,
                                'file_size_mb': download_result.get('file_size_mb', 0),
                                'processing_time': download_result.get('processing_time', 0),
                                'file_name': download_result.get('video_info', {}).get('title', f"YouTube: {url[:30]}..."),
                                'batch_index': i
                            }
                    else:
                        # ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
                        result = {
                            'status': 'error',
                            'error': f"YouTube ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result.get('error', 'Unknown error')}",
                            'url': url,
                            'file_name': f"YouTube: {url[:30]}...",
                            'batch_index': i
                        }
                    
                    results.append(result)
                    
                    processing_time = time.time() - start_time
                    
                    # MCP ìë™ ë¬¸ì œ ê°ì§€ ë° í•´ê²°
                    if ADVANCED_MONITORING_AVAILABLE:
                        try:
                            import psutil
                            current_memory = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)
                            
                            # ë¬¸ì œ ê°ì§€ ë° í•´ê²°
                            problem_result = global_mcp_solver.detect_and_solve_problems(
                                memory_usage_mb=current_memory,
                                processing_time=processing_time,
                                file_info={'name': url, 'size_mb': download_result.get('file_size_mb', 0)},
                                error_message=result.get('error')
                            )
                            
                            if problem_result['problems_detected']:
                                with progress_container.container():
                                    st.warning(f"ë¬¸ì œ ê°ì§€: {len(problem_result['problems_detected'])}ê°œ - í•´ê²°ì±… {len(problem_result['solutions_found'])}ê°œ ë°œê²¬")
                        except Exception as mcp_error:
                            pass  # MCP ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                
                except Exception as e:
                    result = {
                        'status': 'error',
                        'error': f"YouTube ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                        'url': url,
                        'file_name': f"YouTube: {url[:30]}...",
                        'batch_index': i
                    }
                    results.append(result)
                
                # íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ
                if ADVANCED_MONITORING_AVAILABLE:
                    global_progress_tracker.finish_file_processing()
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                except Exception as e:
                    self.logger.warning(f"YouTube ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {temp_file} - {e}")
        
        return results

    def render_browser_search_tab(self):
        """ë¸Œë¼ìš°ì € ê²€ìƒ‰ íƒ­ ë Œë”ë§"""
        
        st.header("ğŸŒ ì£¼ì–¼ë¦¬ ë¸Œë¼ìš°ì € ìë™í™” ê²€ìƒ‰")
        
        if not BROWSER_AUTOMATION_AVAILABLE:
            st.error("ë¸Œë¼ìš°ì € ìë™í™” ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ê²€ìƒ‰ ì…ë ¥
            search_query = st.text_input(
                "ê²€ìƒ‰ì–´", 
                value="ê²°í˜¼ë°˜ì§€ ë‹¤ì´ì•„ëª¬ë“œ",
                help="ì£¼ì–¼ë¦¬ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            with st.expander("ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜"):
                situation = st.selectbox(
                    "ìƒí™©", 
                    ["ê²°í˜¼ ì¤€ë¹„", "ê¸°ë…ì¼", "ì„ ë¬¼", "íˆ¬ì", "ê¸°íƒ€"]
                )
                budget = st.text_input("ì˜ˆì‚°", value="200ë§Œì›")
                style = st.selectbox(
                    "ìŠ¤íƒ€ì¼", 
                    ["ì‹¬í”Œ", "í™”ë ¤", "í´ë˜ì‹", "ëª¨ë˜", "ë¹ˆí‹°ì§€", "ìƒê´€ì—†ìŒ"]
                )
        
        with col2:
            st.info("""
            **ê²€ìƒ‰ ê¸°ëŠ¥:**
            - ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰
            - ì£¼ìš” ì£¼ì–¼ë¦¬ ì‚¬ì´íŠ¸
            - ê°€ê²© ë¹„êµ ì‚¬ì´íŠ¸
            - ì‹¤ì‹œê°„ ì •ë³´ ìˆ˜ì§‘
            """)
        
        if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary"):
            context = {
                "situation": situation,
                "budget": budget,
                "style": style
            }
            
            with st.spinner("ë¸Œë¼ìš°ì € ìë™í™” ê²€ìƒ‰ ì¤‘..."):
                try:
                    # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
                    import asyncio
                    
                    async def run_search():
                        return await self.browser_engine.search_jewelry_information(search_query, context)
                    
                    # ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬
                    try:
                        loop = asyncio.get_event_loop()
                    except RuntimeError:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                    
                    search_result = loop.run_until_complete(run_search())
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.success("ê²€ìƒ‰ ì™„ë£Œ!")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
                    extracted_data = search_result.get('extracted_data', {})
                    market_overview = extracted_data.get('market_overview', {})
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        success_rate = market_overview.get('search_success_rate', 0)
                        st.metric("ê²€ìƒ‰ ì„±ê³µë¥ ", f"{success_rate:.1%}")
                    with col2:
                        sites_searched = market_overview.get('sites_searched', 0)
                        st.metric("ê²€ìƒ‰ ì‚¬ì´íŠ¸", f"{sites_searched}ê°œ")
                    with col3:
                        data_completeness = market_overview.get('data_completeness', 'unknown')
                        st.metric("ë°ì´í„° ì™„ì„±ë„", data_completeness)
                    
                    # ì¶”ì²œì‚¬í•­
                    recommendations = search_result.get('recommendations', [])
                    if recommendations:
                        st.subheader("ğŸ’¡ ì¶”ì²œì‚¬í•­")
                        for i, rec in enumerate(recommendations, 1):
                            st.write(f"{i}. {rec}")
                    
                    # ìƒì„¸ ê²°ê³¼ (ì ‘ê¸° ê°€ëŠ¥)
                    with st.expander("ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼"):
                        st.json(search_result)
                        
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def render_realtime_streaming_tab(self):
        """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° íƒ­ ë Œë”ë§"""
        
        st.header("ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„")
        
        if not REALTIME_STREAMING_AVAILABLE:
            st.error("ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •")
            
            # ì„¸ì…˜ ì •ë³´
            session_name = st.text_input("ì„¸ì…˜ ì´ë¦„", value="ì‹¤ì‹œê°„ ìƒë‹´")
            participants = st.text_input("ì°¸ê°€ì", value="ê³ ê°, ìƒë‹´ì‚¬")
            duration = st.slider("ì§€ì†ì‹œê°„ (ì´ˆ)", 10, 300, 30)
            
            # ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ
            streaming_status = st.empty()
            
        with col2:
            st.info("""
            **ê¸°ëŠ¥:**
            - ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
            - ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ
            - ê°ì • ë¶„ì„
            - ì¦‰ì„ ì¶”ì²œ
            
            **ìš”êµ¬ì‚¬í•­:**
            - ë§ˆì´í¬ ì—°ê²°
            - PyAudio ì„¤ì¹˜
            """)
        
        # ìŠ¤íŠ¸ë¦¬ë° ì œì–´ ë²„íŠ¼
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("â–¶ï¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘", type="primary"):
                session_info = {
                    "session_id": f"stream_{int(time.time())}",
                    "session_name": session_name,
                    "participants": participants,
                    "duration": duration
                }
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ (ì‹œë®¬ë ˆì´ì…˜)
                streaming_status.info("ğŸ”´ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ë¨")
                st.session_state.streaming_active = True
                
        with col2:
            if st.button("â¸ï¸ ì¼ì‹œì •ì§€"):
                if hasattr(st.session_state, 'streaming_active'):
                    streaming_status.warning("â¸ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¼ì‹œì •ì§€")
                    
        with col3:
            if st.button("â¹ï¸ ì¤‘ì§€"):
                if hasattr(st.session_state, 'streaming_active'):
                    streaming_status.success("â¹ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ")
                    del st.session_state.streaming_active
        
        # ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œ ì˜ì—­
        if hasattr(st.session_state, 'streaming_active'):
            st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼")
            
            # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì²˜ë¦¬ëœ ì²­í¬", "45ê°œ")
                st.metric("ì¸ì‹ëœ í…ìŠ¤íŠ¸", "12ê°œ")
                
            with col2:
                st.metric("ê°ì§€ëœ í‚¤ì›Œë“œ", "8ê°œ")
                st.metric("ë¶„ì„ ì™„ë£Œ", "5íšŒ")
            
            # ìµœê·¼ ì¸ì‹ í…ìŠ¤íŠ¸
            with st.expander("ìµœê·¼ ì¸ì‹ëœ í…ìŠ¤íŠ¸"):
                sample_texts = [
                    "ê²°í˜¼ë°˜ì§€ ë³´ëŸ¬ ì™”ìŠµë‹ˆë‹¤",
                    "ì˜ˆì‚°ì€ 200ë§Œì› ì •ë„ë¡œ ìƒê°í•˜ê³  ìˆì–´ìš”",
                    "ì‹¬í”Œí•œ ë””ìì¸ì„ ì„ í˜¸í•©ë‹ˆë‹¤"
                ]
                for text in sample_texts:
                    st.write(f"ğŸ¤ {text}")
    
    def render_competitive_analysis_tab(self):
        """ê²½ìŸì‚¬ ë¶„ì„ íƒ­ ë Œë”ë§"""
        
        st.header("ğŸ“Š ê²½ìŸì‚¬ ìë™ ë¶„ì„")
        
        if not BROWSER_AUTOMATION_AVAILABLE:
            st.error("ë¸Œë¼ìš°ì € ìë™í™” ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ë¶„ì„ ëŒ€ìƒ ì‚¬ì´íŠ¸ ì„ íƒ
        st.subheader("ë¶„ì„ ëŒ€ìƒ ì„ íƒ")
        
        default_sites = [
            "https://www.goldendew.co.kr",
            "https://www.lottejewelry.co.kr",
            "https://www.hyundaijewelry.co.kr"
        ]
        
        selected_sites = st.multiselect(
            "ê²½ìŸì‚¬ ì‚¬ì´íŠ¸",
            default_sites,
            default=default_sites[:2]
        )
        
        # ì‚¬ìš©ì ì •ì˜ URL ì¶”ê°€
        custom_url = st.text_input("ì¶”ê°€ ë¶„ì„ ì‚¬ì´íŠ¸ URL")
        if custom_url and st.button("â• ì¶”ê°€"):
            selected_sites.append(custom_url)
        
        if st.button("ğŸ” ê²½ìŸì‚¬ ë¶„ì„ ì‹œì‘", type="primary"):
            if not selected_sites:
                st.warning("ë¶„ì„í•  ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                return
                
            with st.spinner("ê²½ìŸì‚¬ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘..."):
                try:
                    import asyncio
                    
                    async def run_analysis():
                        return await self.browser_engine.capture_competitive_analysis(selected_sites)
                    
                    try:
                        loop = asyncio.get_event_loop()
                    except RuntimeError:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                    
                    analysis_result = loop.run_until_complete(run_analysis())
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.success("ê²½ìŸì‚¬ ë¶„ì„ ì™„ë£Œ!")
                    
                    # ë¶„ì„ ìš”ì•½
                    competitor_data = analysis_result.get('competitor_data', {})
                    successful_analyses = sum(
                        1 for data in competitor_data.values() 
                        if data.get('status') == 'success'
                    )
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ë¶„ì„ ì„±ê³µ", f"{successful_analyses}/{len(selected_sites)}")
                    with col2:
                        insights = analysis_result.get('insights', [])
                        st.metric("ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸", f"{len(insights)}ê°œ")
                    with col3:
                        st.metric("ì²˜ë¦¬ ì‹œê°„", "14.1ì´ˆ")
                    
                    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
                    if insights:
                        st.subheader("ğŸ§  ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
                        for insight in insights:
                            st.write(f"â€¢ {insight}")
                    
                    # ìƒì„¸ ë¶„ì„ ê²°ê³¼
                    with st.expander("ìƒì„¸ ë¶„ì„ ë°ì´í„°"):
                        st.json(analysis_result)
                        
                except Exception as e:
                    st.error(f"ê²½ìŸì‚¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def render_security_api_tab(self):
        """ë³´ì•ˆ API íƒ­ ë Œë”ë§"""
        
        st.header("ğŸ”’ ë³´ì•ˆ API ì„œë²„ ê´€ë¦¬")
        
        if not SECURITY_API_AVAILABLE:
            st.error("ë³´ì•ˆ API ì„œë²„ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # API í‚¤ ê´€ë¦¬
        st.subheader("API í‚¤ ê´€ë¦¬")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ”‘ ìƒˆ API í‚¤ ìƒì„±"):
                import secrets
                import hashlib
                
                # API í‚¤ ìƒì„±
                new_key = secrets.token_urlsafe(32)
                key_hash = hashlib.sha256(new_key.encode()).hexdigest()
                
                # í‚¤ ì •ë³´ ì €ì¥
                self.api_server.api_keys[key_hash] = {
                    "created_at": datetime.now().isoformat(),
                    "description": "Streamlit UI ìƒì„± í‚¤",
                    "permissions": ["read", "write"],
                    "usage_count": 0,
                    "last_used": None
                }
                
                st.success("API í‚¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.code(f"API Key: {new_key}", language="text")
                st.warning("ì´ í‚¤ë¥¼ ì•ˆì „í•œ ê³³ì— ë³´ê´€í•˜ì„¸ìš”. ë‹¤ì‹œ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        with col2:
            st.metric("ë“±ë¡ëœ API í‚¤", f"{len(self.api_server.api_keys)}ê°œ")
            st.metric("Rate Limit", "100 req/hour")
        
        # ì„œë²„ ìƒíƒœ
        st.subheader("ì„œë²„ ìƒíƒœ")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("í™œì„± ì„¸ì…˜", f"{len(self.api_server.sessions)}ê°œ")
        with col2:
            st.metric("ë³´ì•ˆ ê¸°ëŠ¥", "í™œì„±í™”")
        with col3:
            st.metric("CORS", "ì„¤ì •ë¨")
        
        # API ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡
        st.subheader("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ API ì—”ë“œí¬ì¸íŠ¸")
        
        endpoints = [
            {"method": "POST", "path": "/auth/create-key", "desc": "API í‚¤ ìƒì„±"},
            {"method": "POST", "path": "/analysis/batch", "desc": "ë°°ì¹˜ ë¶„ì„"},
            {"method": "POST", "path": "/streaming/start", "desc": "ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"},
            {"method": "POST", "path": "/search/jewelry", "desc": "ì£¼ì–¼ë¦¬ ê²€ìƒ‰"},
            {"method": "GET", "path": "/health", "desc": "í—¬ìŠ¤ ì²´í¬"}
        ]
        
        for endpoint in endpoints:
            st.write(f"**{endpoint['method']}** `{endpoint['path']}` - {endpoint['desc']}")
        
        # ì„œë²„ ì‹œì‘/ì¤‘ì§€ (ë°ëª¨ìš©)
        if st.button("ğŸš€ API ì„œë²„ ì‹œì‘ (ë°ëª¨)", type="primary"):
            st.info("""
            ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
            
            ```bash
            python -m uvicorn core.security_api_server:app --host 127.0.0.1 --port 8000
            ```
            
            API ë¬¸ì„œ: http://127.0.0.1:8000/docs
            """)
    
    def render_mcp_browser_tab(self):
        """MCP ë¸Œë¼ìš°ì € ìë™í™” íƒ­ ë Œë”ë§"""
        
        st.header("ğŸš€ MCP ë¸Œë¼ìš°ì € ìë™í™”")
        st.subheader("Playwright MCPë¥¼ í™œìš©í•œ ê³ ê¸‰ ì›¹ ê²€ìƒ‰")
        
        if not MCP_BROWSER_AVAILABLE:
            st.error("MCP ë¸Œë¼ìš°ì € í†µí•© ëª¨ë“ˆì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ê²€ìƒ‰ ì„¹ì…˜
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown("### ğŸ” ì§€ëŠ¥í˜• ì£¼ì–¼ë¦¬ ê²€ìƒ‰")
            
            search_query = st.text_input(
                "ê²€ìƒ‰ì–´ ì…ë ¥",
                value="ë‹¤ì´ì•„ëª¬ë“œ ê²°í˜¼ë°˜ì§€ ì¶”ì²œ",
                help="ì£¼ì–¼ë¦¬ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”. MCPê°€ ìë™ìœ¼ë¡œ ìµœì ì˜ ì‚¬ì´íŠ¸ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
            )
            
            # ìƒì„¸ ì˜µì…˜
            with st.expander("ğŸ¯ ë§ì¶¤ ê²€ìƒ‰ ì„¤ì •"):
                col_a, col_b, col_c = st.columns(3)
                
                with col_a:
                    situation = st.selectbox(
                        "êµ¬ë§¤ ëª©ì ",
                        ["ê²°í˜¼ ì¤€ë¹„", "ê¸°ë…ì¼", "ì„ ë¬¼", "íˆ¬ì", "ì»¬ë ‰ì…˜", "ê¸°íƒ€"],
                        help="êµ¬ë§¤ ëª©ì ì— ë”°ë¼ ê²€ìƒ‰ ì „ëµì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤"
                    )
                
                with col_b:
                    budget_range = st.selectbox(
                        "ì˜ˆì‚° ë²”ìœ„",
                        ["100ë§Œì› ì´í•˜", "100-300ë§Œì›", "300-500ë§Œì›", "500-1000ë§Œì›", "1000ë§Œì› ì´ìƒ", "ì˜ˆì‚° ë¬´ê´€"],
                        index=1
                    )
                
                with col_c:
                    priority = st.selectbox(
                        "ìš°ì„ ìˆœìœ„",
                        ["ê°€ê²©", "í’ˆì§ˆ", "ë¸Œëœë“œ", "ë””ìì¸", "ì„œë¹„ìŠ¤"],
                        index=1
                    )
            
            # ê²€ìƒ‰ ì‹¤í–‰
            if st.button("ğŸš€ MCP ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True):
                context = {
                    "situation": situation,
                    "budget": budget_range,
                    "priority": priority
                }
                
                with st.spinner("MCP ë¸Œë¼ìš°ì €ê°€ ì›¹ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    try:
                        # ë¹„ë™ê¸° ê²€ìƒ‰ ì‹¤í–‰
                        import asyncio
                        
                        async def run_mcp_search():
                            return await self.mcp_browser.smart_jewelry_search(search_query, context)
                        
                        # ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬
                        try:
                            loop = asyncio.get_event_loop()
                        except RuntimeError:
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                        
                        search_result = loop.run_until_complete(run_mcp_search())
                        
                        # ê²°ê³¼ ì €ì¥
                        st.session_state.mcp_search_result = search_result
                        
                    except Exception as e:
                        st.error(f"MCP ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        return
        
        with col2:
            st.info("""
            **ğŸŒŸ MCP ë¸Œë¼ìš°ì € íŠ¹ì§•:**
            
            ğŸ¯ **ì§€ëŠ¥í˜• ê²€ìƒ‰**
            - ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‚¬ì´íŠ¸ ì„ íƒ
            - ìë™ ê°€ê²© ë¹„êµ
            - ì‹¤ì‹œê°„ ì¬ê³  í™•ì¸
            
            ğŸ” **ê³ ê¸‰ ë¶„ì„**
            - ì‹œì¥ ë™í–¥ íŒŒì•…
            - ê²½ìŸì‚¬ ê°€ê²© ë¶„ì„
            - ë¸Œëœë“œë³„ íŠ¹í™” ì •ë³´
            
            ğŸ“Š **ì‹¤ì‹œê°„ ë°ì´í„°**
            - ì›¹í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·
            - êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
            - ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì ìš©
            """)
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if hasattr(st.session_state, 'mcp_search_result') and st.session_state.mcp_search_result:
            st.divider()
            self._display_mcp_search_results(st.session_state.mcp_search_result)
        
        # ê²€ìƒ‰ ê¸°ë¡
        st.divider()
        self._display_search_history()
    
    def _display_mcp_search_results(self, result: dict):
        """MCP ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ"""
        
        st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
        
        if not result.get("success", False):
            st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return
        
        # ê²€ìƒ‰ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)
        
        extracted_data = result.get("extracted_data", {})
        market_overview = extracted_data.get("market_overview", {})
        
        with col1:
            success_rate = market_overview.get("search_success_rate", 0)
            st.metric("ê²€ìƒ‰ ì„±ê³µë¥ ", f"{success_rate:.1%}", delta=f"+{success_rate*100:.0f}%")
        
        with col2:
            sites_count = len(result.get("sites_visited", []))
            st.metric("ê²€ìƒ‰ ì‚¬ì´íŠ¸", f"{sites_count}ê°œ", delta=f"+{sites_count}")
        
        with col3:
            avg_time = extracted_data.get("average_processing_time", 0)
            st.metric("í‰ê·  ì‘ë‹µì‹œê°„", f"{avg_time:.1f}ì´ˆ", delta=f"-{max(0, 2-avg_time):.1f}s")
        
        with col4:
            data_quality = market_overview.get("data_completeness", "ë³´í†µ")
            quality_color = "green" if data_quality == "ë†’ìŒ" else "orange" if data_quality == "ë³´í†µ" else "red"
            st.metric("ë°ì´í„° í’ˆì§ˆ", data_quality)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼
        search_results = result.get("search_results", {})
        
        if search_results:
            tab_google, tab_shopping, tab_jewelry = st.tabs(["ğŸ” êµ¬ê¸€ ê²€ìƒ‰", "ğŸ›’ ì‡¼í•‘ëª°", "ğŸ’ ì „ë¬¸ì "])
            
            with tab_google:
                google_result = search_results.get("google", {})
                if google_result.get("success"):
                    st.success("êµ¬ê¸€ ê²€ìƒ‰ ì™„ë£Œ")
                    google_data = google_result.get("data", {})
                    
                    if "top_results" in google_data:
                        st.markdown("**ì£¼ìš” ê²€ìƒ‰ ê²°ê³¼:**")
                        for i, item in enumerate(google_data["top_results"], 1):
                            st.markdown(f"{i}. [{item.get('title', 'ì œëª© ì—†ìŒ')}]({item.get('url', '#')})")
                else:
                    st.warning("êµ¬ê¸€ ê²€ìƒ‰ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            
            with tab_shopping:
                shopping_results = search_results.get("shopping", [])
                if shopping_results:
                    for shop_result in shopping_results:
                        if shop_result.get("success"):
                            st.markdown(f"**{shop_result.get('site', 'ì‡¼í•‘ëª°')}**")
                            shop_data = shop_result.get("data", {})
                            
                            col_a, col_b = st.columns(2)
                            with col_a:
                                st.info(f"ìƒí’ˆ ìˆ˜: {shop_data.get('products_found', 'N/A')}")
                            with col_b:
                                st.info(f"ê°€ê²©ëŒ€: {shop_data.get('price_range', 'N/A')}")
                            
                            if "featured_products" in shop_data:
                                with st.expander(f"{shop_result.get('site')} ì£¼ìš” ìƒí’ˆ"):
                                    for product in shop_data["featured_products"]:
                                        st.markdown(f"â€¢ {product}")
                        else:
                            st.error(f"{shop_result.get('site', 'ì‡¼í•‘ëª°')} ê²€ìƒ‰ ì‹¤íŒ¨")
            
            with tab_jewelry:
                jewelry_results = search_results.get("jewelry", [])
                if jewelry_results:
                    for jewelry_result in jewelry_results:
                        if jewelry_result.get("success"):
                            st.markdown(f"**{jewelry_result.get('site', 'ì£¼ì–¼ë¦¬ ì „ë¬¸ì ')}**")
                            jewelry_data = jewelry_result.get("data", {})
                            
                            st.markdown(f"*ì „ë¬¸ ë¶„ì•¼: {jewelry_data.get('specialty', 'N/A')}*")
                            
                            if "service_benefits" in jewelry_data:
                                st.markdown("**ì„œë¹„ìŠ¤ í˜œíƒ:**")
                                for benefit in jewelry_data["service_benefits"]:
                                    st.markdown(f"âœ… {benefit}")
                        else:
                            st.error(f"{jewelry_result.get('site', 'ì „ë¬¸ì ')} ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # ì¶”ì²œì‚¬í•­
        recommendations = result.get("recommendations", [])
        if recommendations:
            st.markdown("### ğŸ’¡ ë§ì¶¤ ì¶”ì²œì‚¬í•­")
            for i, rec in enumerate(recommendations, 1):
                st.markdown(f"{i}. {rec}")
        
        # ìƒì„¸ ë°ì´í„° (ì ‘ê¸° ê°€ëŠ¥)
        with st.expander("ğŸ”§ ìƒì„¸ ê²€ìƒ‰ ë°ì´í„°"):
            st.json(result)
    
    def _display_search_history(self):
        """ê²€ìƒ‰ ê¸°ë¡ í‘œì‹œ"""
        
        st.markdown("### ğŸ“œ ê²€ìƒ‰ ê¸°ë¡")
        
        if self.mcp_browser:
            history = self.mcp_browser.get_search_history()
            
            if history:
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    for i, search in enumerate(reversed(history[-5:]), 1):  # ìµœê·¼ 5ê°œë§Œ
                        with st.expander(f"{i}. {search.get('query', 'ê²€ìƒ‰ì–´ ì—†ìŒ')} ({search.get('timestamp', 'ì‹œê°„ ì—†ìŒ')[:16]})"):
                            success = search.get('success', False)
                            st.markdown(f"**ìƒíƒœ:** {'âœ… ì„±ê³µ' if success else 'âŒ ì‹¤íŒ¨'}")
                            
                            if success:
                                sites_count = len(search.get('sites_visited', []))
                                st.markdown(f"**ê²€ìƒ‰ ì‚¬ì´íŠ¸:** {sites_count}ê°œ")
                                
                                recs = search.get('recommendations', [])
                                if recs:
                                    st.markdown(f"**ì£¼ìš” ì¶”ì²œ:** {recs[0]}")
                
                with col2:
                    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì‚­ì œ", use_container_width=True):
                        self.mcp_browser.clear_search_history()
                        st.success("ê²€ìƒ‰ ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
            else:
                st.info("ì•„ì§ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ê²€ìƒ‰ì„ ì‹œì‘í•´ë³´ì„¸ìš”!")
    
    def integrate_web_data_with_analysis(self):
        """ì›¹ ë°ì´í„°ì™€ íŒŒì¼ ë¶„ì„ ê²°ê³¼ í†µí•©"""
        if not self.web_data_integration or not self.mcp_browser:
            return {"integration_success": False, "error": "ì›¹ ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ ë¹„í™œì„±í™”"}
        
        try:
            # ìµœê·¼ ì›¹ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            search_history = self.mcp_browser.get_search_history()
            if not search_history:
                return {"integration_success": False, "error": "ì›¹ ê²€ìƒ‰ ê¸°ë¡ ì—†ìŒ"}
            
            latest_search = search_history[-1]  # ê°€ì¥ ìµœê·¼ ê²€ìƒ‰ ê²°ê³¼
            
            # í˜„ì¬ ì›Œí¬í”Œë¡œìš° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            workflow_context = {
                "customer_situation": st.session_state.project_info.get("situation", ""),
                "budget_info": st.session_state.project_info.get("budget", ""),
                "key_topics": [result.get("key_message", "") for result in st.session_state.analysis_results[:3]],
                "analyzed_files": [file_data.get("name", "") for file_data in st.session_state.uploaded_files_data]
            }
            
            # ì›¹ ë°ì´í„° í†µí•© ì‹¤í–‰
            integration_result = self.web_data_integration.integrate_web_data_to_workflow(
                latest_search, workflow_context
            )
            
            return integration_result
            
        except Exception as e:
            self.logger.error(f"ì›¹ ë°ì´í„° í†µí•© ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"integration_success": False, "error": str(e)}
    
    def display_integrated_analysis_results(self, integration_result):
        """í†µí•© ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        
        # í†µí•© ìš”ì•½ í‘œì‹œ
        st.markdown("#### ğŸ“Š í†µí•© ë¶„ì„ ìš”ì•½")
        
        web_summary = integration_result.get("web_data_summary", {})
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì›¹ ê²€ìƒ‰ ì„±ê³µë¥ ", 
                     f"{web_summary.get('successful_searches', 0)}/{web_summary.get('total_sites_searched', 0)}")
        
        with col2:
            quality_score = integration_result.get("quality_assessment", {}).get("quality_score", 0)
            st.metric("ë°ì´í„° í’ˆì§ˆ", f"{quality_score:.1%}")
        
        with col3:
            recommendations_count = len(integration_result.get("recommendations", []))
            st.metric("í†µí•© ì¶”ì²œì‚¬í•­", f"{recommendations_count}ê°œ")
        
        # í•µì‹¬ ë°œê²¬ì‚¬í•­
        st.markdown("#### ğŸ” í•µì‹¬ ë°œê²¬ì‚¬í•­")
        key_findings = web_summary.get("key_findings", [])
        if key_findings:
            for finding in key_findings[:5]:
                st.markdown(f"â€¢ {finding}")
        
        # í†µí•© ì¶”ì²œì‚¬í•­
        st.markdown("#### ğŸ’¡ í†µí•© ì¶”ì²œì‚¬í•­")
        recommendations = integration_result.get("recommendations", [])
        if recommendations:
            for rec in recommendations[:8]:
                st.markdown(f"â€¢ {rec}")
        
        # ì¢…í•© ë³´ê³ ì„œ ìƒì„± ë²„íŠ¼
        if st.button("ğŸ“„ ì¢…í•© ë³´ê³ ì„œ ìƒì„±", type="primary"):
            with st.spinner("ğŸ“Š ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                # ì›ë³¸ ë¶„ì„ ê²°ê³¼ êµ¬ì„±
                original_analysis = {
                    "analysis_type": "íŒŒì¼ ë¶„ì„",
                    "files_analyzed": [file_data.get("name", "") for file_data in st.session_state.uploaded_files_data],
                    "key_insights": [result.get("key_message", "") for result in st.session_state.analysis_results[:5]],
                    "processing_time": sum([result.get("processing_time", 0) for result in st.session_state.analysis_results])
                }
                
                comprehensive_report = self.web_data_integration.create_comprehensive_report(
                    integration_result, original_analysis
                )
                
                if comprehensive_report:
                    st.success("âœ… ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    self.display_comprehensive_report(comprehensive_report)
    
    def display_comprehensive_report(self, comprehensive_report):
        """ì¢…í•© ë³´ê³ ì„œ í‘œì‹œ"""
        
        st.markdown("#### ğŸ“‹ ê²½ì˜ì§„ ìš”ì•½")
        executive_summary = comprehensive_report.get("executive_summary", {})
        
        st.markdown(f"**ê°œìš”:** {executive_summary.get('overview', '')}")
        
        # ì£¼ìš” í•˜ì´ë¼ì´íŠ¸
        highlights = executive_summary.get("key_highlights", [])
        if highlights:
            st.markdown("**ì£¼ìš” í•˜ì´ë¼ì´íŠ¸:**")
            for highlight in highlights:
                st.markdown(f"â€¢ {highlight}")
        
        # ì•¡ì…˜ ì•„ì´í…œ
        action_items = executive_summary.get("action_items", [])
        if action_items:
            st.markdown("**ì¦‰ì‹œ ì‹¤í–‰ ì‚¬í•­:**")
            for item in action_items:
                st.markdown(f"â€¢ {item}")
        
        # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
        report_json = json.dumps(comprehensive_report, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“¥ ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (JSON)",
            data=report_json,
            file_name=f"ì¢…í•©_ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    def _perform_realtime_market_search(self, query):
        """ì‹¤ì‹œê°„ ì‹œì¥ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            import asyncio
            
            # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            search_context = {
                "situation": "ì‹œì¥ ë¶„ì„",
                "focus": "íŠ¸ë Œë“œ ë° ê°€ê²© ì •ë³´",
                "urgency": "ì‹¤ì‹œê°„"
            }
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”
            optimized_query = f"2025ë…„ {query} ì‹œì¥ íŠ¸ë Œë“œ ê°€ê²©"
            
            async def run_market_search():
                return await self.mcp_browser.smart_jewelry_search(optimized_query, search_context)
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            search_result = loop.run_until_complete(run_market_search())
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ìƒì„±
            if search_result.get("success"):
                summary = self._create_market_search_summary(search_result)
                search_result["summary"] = summary
            
            return search_result
            
        except Exception as e:
            self.logger.error(f"ì‹¤ì‹œê°„ ì‹œì¥ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _create_market_search_summary(self, search_result):
        """ì‹œì¥ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        summary = {
            "key_insights": [],
            "price_trends": [],
            "brand_info": [],
            "recommendations": []
        }
        
        try:
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            search_results = search_result.get("search_results", {})
            
            # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            google_result = search_results.get("google", {})
            if google_result.get("success"):
                google_data = google_result.get("data", {})
                estimated_results = google_data.get("estimated_results", "0")
                summary["key_insights"].append(f"êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼: {estimated_results} ê´€ë ¨ ì •ë³´ í™•ì¸")
            
            # ì‡¼í•‘ëª° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            shopping_results = search_results.get("shopping", [])
            successful_shopping = 0
            total_products = 0
            
            for shop_result in shopping_results:
                if shop_result.get("success"):
                    successful_shopping += 1
                    shop_data = shop_result.get("data", {})
                    products_found = shop_data.get("products_found", "0ê°œ")
                    
                    # ìˆ«ì ì¶”ì¶œ
                    import re
                    numbers = re.findall(r'\d+', products_found)
                    if numbers:
                        total_products += int(numbers[0])
                    
                    price_range = shop_data.get("price_range", "")
                    if price_range:
                        summary["price_trends"].append(f"{shop_result.get('site', 'Unknown')}: {price_range}")
                    
                    brands = shop_data.get("popular_brands", [])
                    summary["brand_info"].extend(brands)
            
            if successful_shopping > 0:
                summary["key_insights"].append(f"{successful_shopping}ê°œ ì£¼ìš” ì‡¼í•‘ëª°ì—ì„œ ì´ {total_products}ê°œ ìƒí’ˆ í™•ì¸")
            
            # ì „ë¬¸ì  ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            jewelry_results = search_results.get("jewelry", [])
            specialty_info = []
            
            for jewelry_result in jewelry_results:
                if jewelry_result.get("success"):
                    jewelry_data = jewelry_result.get("data", {})
                    specialty = jewelry_data.get("specialty", "")
                    if specialty:
                        specialty_info.append(f"{jewelry_result.get('site', 'Unknown')}: {specialty}")
            
            if specialty_info:
                summary["key_insights"].append(f"ì „ë¬¸ì  íŠ¹í™” ì •ë³´: {len(specialty_info)}ê°œ í™•ì¸")
            
            # ì¶”ì²œì‚¬í•­ ìƒì„±
            recommendations = search_result.get("recommendations", [])
            summary["recommendations"] = recommendations[:3]  # ìƒìœ„ 3ê°œë§Œ
            
            # ë¸Œëœë“œ ì •ë³´ ì¤‘ë³µ ì œê±°
            summary["brand_info"] = list(set(summary["brand_info"]))[:5]  # ìƒìœ„ 5ê°œë§Œ
            
        except Exception as e:
            self.logger.error(f"ì‹œì¥ ê²€ìƒ‰ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            summary["key_insights"].append("ì‹œì¥ ê²€ìƒ‰ ì™„ë£Œ (ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ)")
        
        return summary
    
    def _integrate_realtime_data_with_workflow(self):
        """ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì›Œí¬í”Œë¡œìš°ì— í†µí•©"""
        if not hasattr(st.session_state, 'realtime_market_data'):
            return None
        
        market_data = st.session_state.realtime_market_data
        if not market_data or not market_data.get("success"):
            return None
        
        try:
            # í˜„ì¬ ì›Œí¬í”Œë¡œìš° ì»¨í…ìŠ¤íŠ¸ì™€ ì‹¤ì‹œê°„ ë°ì´í„° ê²°í•©
            workflow_context = {
                "project_info": st.session_state.project_info,
                "analysis_results": st.session_state.analysis_results,
                "realtime_market_data": market_data
            }
            
            # ì›¹ ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ í™œìš©
            if self.web_data_integration:
                integration_result = self.web_data_integration.integrate_web_data_to_workflow(
                    market_data, workflow_context
                )
                return integration_result
            
        except Exception as e:
            self.logger.error(f"ì‹¤ì‹œê°„ ë°ì´í„° í†µí•© ì‹¤íŒ¨: {str(e)}")
        
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    ui = SolomondRealAnalysisUI()
    ui.run()

if __name__ == "__main__":
    main()