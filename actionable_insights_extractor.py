#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œê¸°
Actionable Insights Extractor for Conference Analysis

í•µì‹¬ ëª©í‘œ: ë³µì¡í•œ ì»¨í¼ëŸ°ìŠ¤ ë‚´ìš©ì„ 3ì¤„ ìš”ì•½ + 5ê°€ì§€ êµ¬ì²´ì  ì•¡ì…˜ ì•„ì´í…œìœ¼ë¡œ ì••ì¶•
"""

import json
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import streamlit as st
from dataclasses import dataclass, asdict
import re
from collections import defaultdict, Counter

try:
    from sentence_transformers import SentenceTransformer
    import spacy
    ADVANCED_NLP_AVAILABLE = True
except ImportError:
    ADVANCED_NLP_AVAILABLE = False

@dataclass
class ThreeLineSummary:
    """3ì¤„ ìš”ì•½ êµ¬ì¡°"""
    line1_what: str      # ë¬´ì—‡ì„ ë…¼ì˜í–ˆëŠ”ê°€?
    line2_why: str       # ì™œ ì¤‘ìš”í•œê°€?
    line3_outcome: str   # ê²°ê³¼/ê²°ë¡ ì€ ë¬´ì—‡ì¸ê°€?
    confidence: float

@dataclass
class ActionItem:
    """ì•¡ì…˜ ì•„ì´í…œ êµ¬ì¡°"""
    action_id: str
    title: str
    description: str
    priority: str        # high, medium, low
    owner: Optional[str]
    deadline: Optional[str]
    dependencies: List[str]
    success_criteria: str
    evidence_source: List[str]  # ê·¼ê±°ê°€ ëœ fragment_ids

@dataclass
class ConferenceInsights:
    """ì»¨í¼ëŸ°ìŠ¤ ì¸ì‚¬ì´íŠ¸ ì „ì²´ êµ¬ì¡°"""
    conference_name: str
    analysis_date: str
    three_line_summary: ThreeLineSummary
    action_items: List[ActionItem]
    key_metrics: Dict[str, Any]
    risk_factors: List[str]
    success_indicators: List[str]
    stakeholder_map: Dict[str, List[str]]

class ActionableInsightsExtractor:
    """ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œê¸°"""
    
    def __init__(self, conference_name: str = "default"):
        self.conference_name = conference_name
        self.db_path = f"conference_analysis_{conference_name}.db"
        
        # NLP ëª¨ë¸ ì´ˆê¸°í™”
        if ADVANCED_NLP_AVAILABLE:
            try:
                self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                self.use_advanced_nlp = True
            except Exception as e:
                st.warning(f"ê³ ê¸‰ NLP ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_advanced_nlp = False
        else:
            self.use_advanced_nlp = False
        
        # ë¶„ì„ ë°ì´í„°
        self.fragments = []
        self.speaker_profiles = {}
        self.topic_clusters = []
    
    def load_conference_data(self) -> bool:
        """ì»¨í¼ëŸ°ìŠ¤ ë°ì´í„° ë¡œë“œ"""
        try:
            self.fragments = self._load_fragments()
            if not self.fragments:
                return False
            
            self._build_speaker_profiles()
            self._build_topic_clusters()
            
            return True
            
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _load_fragments(self) -> List[Dict]:
        """ì¡°ê° ë°ì´í„° ë¡œë“œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('SELECT * FROM fragments ORDER BY created_at')
            rows = cursor.fetchall()
            
            fragments = []
            for row in rows:
                fragment = {
                    'fragment_id': row[0],
                    'file_source': row[1],
                    'file_type': row[2],
                    'timestamp': row[3],
                    'speaker': row[4],
                    'content': row[5],
                    'confidence': row[6],
                    'keywords': json.loads(row[7]) if row[7] else []
                }
                fragments.append(fragment)
            
            return fragments
            
        except sqlite3.OperationalError:
            return []
        finally:
            conn.close()
    
    def _build_speaker_profiles(self):
        """ë°œí‘œì í”„ë¡œí•„ êµ¬ì¶•"""
        speaker_groups = defaultdict(list)
        for fragment in self.fragments:
            speaker = fragment.get('speaker', 'Unknown')
            if speaker and speaker.strip():
                speaker_groups[speaker].append(fragment)
        
        self.speaker_profiles = speaker_groups
    
    def _build_topic_clusters(self):
        """ì£¼ì œ í´ëŸ¬ìŠ¤í„° êµ¬ì¶•"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
        all_keywords = []
        for fragment in self.fragments:
            all_keywords.extend(fragment.get('keywords', []))
        
        keyword_freq = Counter(all_keywords)
        top_keywords = [kw for kw, _ in keyword_freq.most_common(8)]
        
        self.topic_clusters = []
        for keyword in top_keywords:
            cluster_fragments = []
            for fragment in self.fragments:
                if keyword in fragment.get('keywords', []):
                    cluster_fragments.append(fragment)
            
            if len(cluster_fragments) >= 2:
                self.topic_clusters.append({
                    'cluster_name': keyword,
                    'fragments': cluster_fragments,
                    'importance': len(cluster_fragments) / len(self.fragments)
                })
        
        # ì¤‘ìš”ë„ìˆœ ì •ë ¬
        self.topic_clusters.sort(key=lambda t: t['importance'], reverse=True)
    
    def extract_actionable_insights(self) -> ConferenceInsights:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        if not self.load_conference_data():
            raise ValueError("ì»¨í¼ëŸ°ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 1. 3ì¤„ ìš”ì•½ ìƒì„±
        three_line_summary = self._generate_three_line_summary()
        
        # 2. 5ê°€ì§€ ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
        action_items = self._extract_action_items()
        
        # 3. í•µì‹¬ ë©”íŠ¸ë¦­ ê³„ì‚°
        key_metrics = self._calculate_key_metrics()
        
        # 4. ë¦¬ìŠ¤í¬ ìš”ì†Œ ì‹ë³„
        risk_factors = self._identify_risk_factors()
        
        # 5. ì„±ê³µ ì§€í‘œ ì •ì˜
        success_indicators = self._define_success_indicators()
        
        # 6. ì´í•´ê´€ê³„ì ë§µí•‘
        stakeholder_map = self._build_stakeholder_map()
        
        insights = ConferenceInsights(
            conference_name=self.conference_name,
            analysis_date=datetime.now().isoformat(),
            three_line_summary=three_line_summary,
            action_items=action_items,
            key_metrics=key_metrics,
            risk_factors=risk_factors,
            success_indicators=success_indicators,
            stakeholder_map=stakeholder_map
        )
        
        return insights
    
    def _generate_three_line_summary(self) -> ThreeLineSummary:
        """3ì¤„ ìš”ì•½ ìƒì„±"""
        # Line 1: ë¬´ì—‡ì„ ë…¼ì˜í–ˆëŠ”ê°€?
        if self.topic_clusters:
            top_topics = [cluster['cluster_name'] for cluster in self.topic_clusters[:3]]
            line1_what = f"{', '.join(top_topics)} ë“± {len(self.topic_clusters)}ê°œ ì£¼ì œì— ëŒ€í•´ {len(self.fragments)}ê°œ ìë£Œë¡œ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤."
        else:
            line1_what = f"ì´ {len(self.fragments)}ê°œì˜ ìë£Œë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤."
        
        # Line 2: ì™œ ì¤‘ìš”í•œê°€?
        if self.speaker_profiles:
            participant_count = len(self.speaker_profiles)
            most_active_speaker = max(self.speaker_profiles.keys(), key=lambda s: len(self.speaker_profiles[s]))
            line2_why = f"{participant_count}ëª…ì˜ ì°¸ì—¬ìê°€ í™œë°œíˆ ì˜ê²¬ì„ êµí™˜í–ˆìœ¼ë©°, {most_active_speaker} ë“±ì´ í•µì‹¬ ì•„ì  ë‹¤ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤."
        else:
            line2_why = "ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì‹¬ë„ ìˆëŠ” ë¶„ì„ê³¼ í† ë¡ ì´ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤."
        
        # Line 3: ê²°ê³¼/ê²°ë¡ ì€ ë¬´ì—‡ì¸ê°€?
        avg_confidence = np.mean([f['confidence'] for f in self.fragments])
        high_confidence_count = sum(1 for f in self.fragments if f['confidence'] > 0.8)
        line3_outcome = f"ë¶„ì„ ì‹ ë¢°ë„ {avg_confidence:.1%}, ê³ í’ˆì§ˆ ìë£Œ {high_confidence_count}ê°œ í™•ë³´ë¡œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        
        return ThreeLineSummary(
            line1_what=line1_what,
            line2_why=line2_why,
            line3_outcome=line3_outcome,
            confidence=avg_confidence
        )
    
    def _extract_action_items(self) -> List[ActionItem]:
        """5ê°€ì§€ ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        action_items = []
        
        # 1. ì£¼ìš” ì£¼ì œë³„ í›„ì† ì¡°ì¹˜
        for i, topic_cluster in enumerate(self.topic_clusters[:2]):
            action = ActionItem(
                action_id=f"topic_action_{i+1}",
                title=f"{topic_cluster['cluster_name']} ì‹¬í™” ë¶„ì„",
                description=f"{topic_cluster['cluster_name']} ê´€ë ¨ ë…¼ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ì„¸ë¶€ ì¼ì •ì„ í™•ì •í•©ë‹ˆë‹¤.",
                priority="high" if topic_cluster['importance'] > 0.3 else "medium",
                owner=self._suggest_topic_owner(topic_cluster),
                deadline=self._suggest_deadline(7),  # 1ì£¼ì¼
                dependencies=[],
                success_criteria=f"{topic_cluster['cluster_name']} ê´€ë ¨ ì‹¤í–‰ ê³„íšì„œ ì™„ì„± ë° ì´í•´ê´€ê³„ì ìŠ¹ì¸",
                evidence_source=[f['fragment_id'] for f in topic_cluster['fragments']]
            )
            action_items.append(action)
        
        # 2. ì´í•´ê´€ê³„ì í›„ì† ë¯¸íŒ…
        if self.speaker_profiles:
            key_speakers = sorted(self.speaker_profiles.keys(), key=lambda s: len(self.speaker_profiles[s]), reverse=True)[:3]
            action = ActionItem(
                action_id="stakeholder_followup",
                title="í•µì‹¬ ì°¸ì—¬ì í›„ì† ë¯¸íŒ…",
                description=f"{', '.join(key_speakers)} ë“± ì£¼ìš” ì°¸ì—¬ìì™€ ê°œë³„ í›„ì† ë¯¸íŒ…ì„ ì§„í–‰í•˜ì—¬ ì„¸ë¶€ ì‚¬í•­ì„ ë…¼ì˜í•©ë‹ˆë‹¤.",
                priority="high",
                owner=key_speakers[0] if key_speakers else None,
                deadline=self._suggest_deadline(5),  # 5ì¼
                dependencies=[],
                success_criteria="ëª¨ë“  í•µì‹¬ ì°¸ì—¬ìì™€ì˜ ê°œë³„ ë¯¸íŒ… ì™„ë£Œ ë° í•©ì˜ ì‚¬í•­ ì •ë¦¬",
                evidence_source=[]
            )
            action_items.append(action)
        
        # 3. ë¬¸ì„œí™” ë° ì •ë¦¬
        action = ActionItem(
            action_id="documentation",
            title="íšŒì˜ ê²°ê³¼ ë¬¸ì„œí™”",
            description="ë…¼ì˜ëœ ëª¨ë“  ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , í–¥í›„ ì°¸ì¡° ê°€ëŠ¥í•œ ë¬¸ì„œë¡œ ì‘ì„±í•©ë‹ˆë‹¤.",
            priority="medium",
            owner=None,
            deadline=self._suggest_deadline(3),  # 3ì¼
            dependencies=["stakeholder_followup"],
            success_criteria="ì™„ì „í•œ íšŒì˜ë¡ ë° ì‹¤í–‰ ê³„íšì„œ ì‘ì„±",
            evidence_source=[f['fragment_id'] for f in self.fragments]
        )
        action_items.append(action)
        
        # 4. ë¦¬ìŠ¤í¬ ê´€ë¦¬
        action = ActionItem(
            action_id="risk_management",
            title="ì ì¬ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆ ìˆ˜ë¦½",
            description="ë…¼ì˜ ê³¼ì •ì—ì„œ ì‹ë³„ëœ ì ì¬ì  ìœ„í—˜ ìš”ì†Œë“¤ì— ëŒ€í•œ ëŒ€ì‘ ë°©ì•ˆì„ ë§ˆë ¨í•©ë‹ˆë‹¤.",
            priority="medium",
            owner=None,
            deadline=self._suggest_deadline(10),  # 10ì¼
            dependencies=["documentation"],
            success_criteria="ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê³„íšì„œ ì™„ì„± ë° ëŒ€ì‘ ì²´ê³„ êµ¬ì¶•",
            evidence_source=self._find_risk_related_fragments()
        )
        action_items.append(action)
        
        # 5. ì„±ê³¼ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•
        action = ActionItem(
            action_id="monitoring_system",
            title="ì„±ê³¼ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
            description="í•©ì˜ëœ ì‚¬í•­ë“¤ì˜ ì´í–‰ ìƒí™©ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆëŠ” ì²´ê³„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.",
            priority="low",
            owner=None,
            deadline=self._suggest_deadline(14),  # 2ì£¼
            dependencies=["topic_action_1", "documentation"],
            success_criteria="KPI ì •ì˜ ë° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•",
            evidence_source=[]
        )
        action_items.append(action)
        
        return action_items
    
    def _suggest_topic_owner(self, topic_cluster: Dict) -> Optional[str]:
        """ì£¼ì œë³„ ë‹´ë‹¹ì ì¶”ì²œ"""
        # í•´ë‹¹ ì£¼ì œì—ì„œ ê°€ì¥ ë§ì´ ë°œì–¸í•œ ì‚¬ëŒ
        speaker_counts = defaultdict(int)
        
        for fragment in topic_cluster['fragments']:
            speaker = fragment.get('speaker')
            if speaker:
                speaker_counts[speaker] += 1
        
        if speaker_counts:
            return max(speaker_counts, key=speaker_counts.get)
        return None
    
    def _suggest_deadline(self, days: int) -> str:
        """ë§ˆê°ì¼ ì œì•ˆ"""
        deadline = datetime.now() + timedelta(days=days)
        return deadline.strftime("%Y-%m-%d")
    
    def _find_risk_related_fragments(self) -> List[str]:
        """ë¦¬ìŠ¤í¬ ê´€ë ¨ ì¡°ê° ì°¾ê¸°"""
        risk_keywords = ['ìœ„í—˜', 'ë¬¸ì œ', 'ìš°ë ¤', 'ë¦¬ìŠ¤í¬', 'risk', 'issue', 'concern', 'ì¥ì• ', 'ì–´ë ¤ì›€']
        risk_fragments = []
        
        for fragment in self.fragments:
            content = fragment['content'].lower()
            if any(keyword in content for keyword in risk_keywords):
                risk_fragments.append(fragment['fragment_id'])
        
        return risk_fragments
    
    def _calculate_key_metrics(self) -> Dict[str, Any]:
        """í•µì‹¬ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        return {
            "total_fragments": len(self.fragments),
            "total_participants": len(self.speaker_profiles),
            "total_topics": len(self.topic_clusters),
            "average_confidence": np.mean([f['confidence'] for f in self.fragments]) if self.fragments else 0,
            "high_quality_fragments": sum(1 for f in self.fragments if f['confidence'] > 0.8),
            "analysis_completeness": min(1.0, len(self.fragments) / 10),  # 10ê°œ ì´ìƒì´ë©´ ì™„ì „í•¨
            "stakeholder_engagement": len(self.speaker_profiles) / max(1, len(self.fragments) / 5)  # ì°¸ì—¬ë„
        }
    
    def _identify_risk_factors(self) -> List[str]:
        """ë¦¬ìŠ¤í¬ ìš”ì†Œ ì‹ë³„"""
        risks = []
        
        # ë°ì´í„° í’ˆì§ˆ ë¦¬ìŠ¤í¬
        low_confidence_count = sum(1 for f in self.fragments if f['confidence'] < 0.5)
        if low_confidence_count > len(self.fragments) * 0.3:
            risks.append(f"âš ï¸ ë¶„ì„ í’ˆì§ˆì´ ë‚®ì€ ìë£Œê°€ {low_confidence_count}ê°œ ìˆì–´ ê²°ë¡ ì˜ ì‹ ë¢°ì„±ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì°¸ì—¬ì ì§‘ì¤‘ë„ ë¦¬ìŠ¤í¬
        if self.speaker_profiles:
            max_speaker_ratio = max(len(fragments) for fragments in self.speaker_profiles.values()) / len(self.fragments)
            if max_speaker_ratio > 0.6:
                risks.append("âš ï¸ íŠ¹ì • ì¸ë¬¼ì˜ ë°œì–¸ ë¹„ì¤‘ì´ ë†’ì•„ ë‹¤ì–‘í•œ ê´€ì ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì£¼ì œ í¸ì¤‘ ë¦¬ìŠ¤í¬
        if self.topic_clusters:
            max_topic_ratio = self.topic_clusters[0]['importance']
            if max_topic_ratio > 0.5:
                risks.append("âš ï¸ íŠ¹ì • ì£¼ì œì— ë…¼ì˜ê°€ ì§‘ì¤‘ë˜ì–´ ë‹¤ë¥¸ ì¤‘ìš” ì‚¬ì•ˆì´ ì†Œí™€íˆ ë‹¤ë¤„ì¡Œì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì†Œí†µ ë¦¬ìŠ¤í¬
        if len(self.speaker_profiles) < 3:
            risks.append("âš ï¸ ì°¸ì—¬ì ìˆ˜ê°€ ì ì–´ ì¶©ë¶„í•œ í† ë¡ ê³¼ ê²€ì¦ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
        
        return risks if risks else ["âœ… íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì†Œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
    
    def _define_success_indicators(self) -> List[str]:
        """ì„±ê³µ ì§€í‘œ ì •ì˜"""
        indicators = []
        
        # ì‹¤í–‰ë¥  ì§€í‘œ
        indicators.append("ğŸ“ˆ ì•¡ì…˜ ì•„ì´í…œ ì™„ë£Œìœ¨ 80% ì´ìƒ ë‹¬ì„±")
        
        # ì°¸ì—¬ë„ ì§€í‘œ
        if self.speaker_profiles:
            indicators.append(f"ğŸ‘¥ {len(self.speaker_profiles)}ëª… ì°¸ì—¬ì ë§Œì¡±ë„ 4.0/5.0 ì´ìƒ")
        
        # ì„±ê³¼ ì§€í‘œ
        if self.topic_clusters:
            indicators.append(f"ğŸ¯ ì£¼ìš” {len(self.topic_clusters[:3])}ê°œ ì£¼ì œë³„ êµ¬ì²´ì  ì„±ê³¼ ì°½ì¶œ")
        
        # í”„ë¡œì„¸ìŠ¤ ì§€í‘œ
        indicators.append("â° í•©ì˜ëœ ì¼ì • ì¤€ìˆ˜ìœ¨ 90% ì´ìƒ")
        
        # í’ˆì§ˆ ì§€í‘œ
        indicators.append("ğŸ“Š í›„ì† ë¯¸íŒ…ì—ì„œ ì°¸ì¡° ìë£Œë¡œ í™œìš©ë¥  70% ì´ìƒ")
        
        return indicators
    
    def _build_stakeholder_map(self) -> Dict[str, List[str]]:
        """ì´í•´ê´€ê³„ì ë§µí•‘"""
        stakeholder_map = {
            "í•µì‹¬ ì˜ì‚¬ê²°ì •ì": [],
            "ì‹¤í–‰ ë‹´ë‹¹ì": [],
            "ê²€í† /ìŠ¹ì¸ì": [],
            "ì •ë³´ ê³µìœ  ëŒ€ìƒ": []
        }
        
        if self.speaker_profiles:
            speakers = sorted(self.speaker_profiles.keys(), key=lambda s: len(self.speaker_profiles[s]), reverse=True)
            
            # ë°œì–¸ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì—­í•  ë¶„ë¥˜
            total_speakers = len(speakers)
            
            if total_speakers >= 4:
                stakeholder_map["í•µì‹¬ ì˜ì‚¬ê²°ì •ì"] = speakers[:2]
                stakeholder_map["ì‹¤í–‰ ë‹´ë‹¹ì"] = speakers[2:4]
                stakeholder_map["ê²€í† /ìŠ¹ì¸ì"] = speakers[4:6] if len(speakers) > 4 else []
                stakeholder_map["ì •ë³´ ê³µìœ  ëŒ€ìƒ"] = speakers[6:] if len(speakers) > 6 else []
            elif total_speakers >= 2:
                stakeholder_map["í•µì‹¬ ì˜ì‚¬ê²°ì •ì"] = speakers[:1]
                stakeholder_map["ì‹¤í–‰ ë‹´ë‹¹ì"] = speakers[1:]
            else:
                stakeholder_map["í•µì‹¬ ì˜ì‚¬ê²°ì •ì"] = speakers
        
        return stakeholder_map

# Streamlit UI
def main():
    st.title("ğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œê¸°")
    st.markdown("**ë³µì¡í•œ ì»¨í¼ëŸ°ìŠ¤ ë‚´ìš©ì„ 3ì¤„ ìš”ì•½ê³¼ 5ê°€ì§€ êµ¬ì²´ì  ì•¡ì…˜ ì•„ì´í…œìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤**")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    conference_name = st.sidebar.text_input("ì»¨í¼ëŸ°ìŠ¤ ì´ë¦„", "my_conference")
    
    # ì¶”ì¶œê¸° ì´ˆê¸°í™”
    extractor = ActionableInsightsExtractor(conference_name)
    
    # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
    if st.button("ğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"):
        with st.spinner("ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                insights = extractor.extract_actionable_insights()
                
                st.success("âœ… ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
                
                # 3ì¤„ ìš”ì•½
                st.markdown("## ğŸ“‹ 3ì¤„ ìš”ì•½")
                summary = insights.three_line_summary
                
                st.markdown("### 1ï¸âƒ£ ë¬´ì—‡ì„ ë…¼ì˜í–ˆëŠ”ê°€?")
                st.info(summary.line1_what)
                
                st.markdown("### 2ï¸âƒ£ ì™œ ì¤‘ìš”í•œê°€?")
                st.info(summary.line2_why)
                
                st.markdown("### 3ï¸âƒ£ ê²°ê³¼/ê²°ë¡ ì€ ë¬´ì—‡ì¸ê°€?")
                st.info(summary.line3_outcome)
                
                st.metric("ğŸ“Š ìš”ì•½ ì‹ ë¢°ë„", f"{summary.confidence:.1%}")
                
                # 5ê°€ì§€ ì•¡ì…˜ ì•„ì´í…œ
                st.markdown("## âœ… 5ê°€ì§€ ì•¡ì…˜ ì•„ì´í…œ")
                
                for i, action in enumerate(insights.action_items, 1):
                    priority_color = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                    priority_icon = priority_color.get(action.priority, "âšª")
                    
                    with st.expander(f"{priority_icon} {i}. {action.title} ({action.priority} ìš°ì„ ìˆœìœ„)"):
                        st.markdown(f"**ì„¤ëª…:** {action.description}")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown(f"**ë‹´ë‹¹ì:** {action.owner or 'ë¯¸ì •'}")
                            st.markdown(f"**ë§ˆê°ì¼:** {action.deadline or 'ë¯¸ì •'}")
                        
                        with col2:
                            st.markdown(f"**ì˜ì¡´ì„±:** {', '.join(action.dependencies) if action.dependencies else 'ì—†ìŒ'}")
                            st.markdown(f"**ê·¼ê±° ìë£Œ:** {len(action.evidence_source)}ê°œ")
                        
                        st.markdown(f"**ì„±ê³µ ê¸°ì¤€:** {action.success_criteria}")
                
                # í•µì‹¬ ë©”íŠ¸ë¦­
                st.markdown("## ğŸ“Š í•µì‹¬ ë©”íŠ¸ë¦­")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ì´ ë¶„ì„ ìë£Œ", insights.key_metrics["total_fragments"])
                    st.metric("ì°¸ì—¬ì ìˆ˜", insights.key_metrics["total_participants"])
                
                with col2:
                    st.metric("ë…¼ì˜ ì£¼ì œ", insights.key_metrics["total_topics"])
                    st.metric("ê³ í’ˆì§ˆ ìë£Œ", insights.key_metrics["high_quality_fragments"])
                
                with col3:
                    st.metric("í‰ê·  ì‹ ë¢°ë„", f"{insights.key_metrics['average_confidence']:.1%}")
                    st.metric("ë¶„ì„ ì™„ì„±ë„", f"{insights.key_metrics['analysis_completeness']:.1%}")
                
                # ë¦¬ìŠ¤í¬ ìš”ì†Œ
                st.markdown("## âš ï¸ ì£¼ì˜ì‚¬í•­")
                for risk in insights.risk_factors:
                    st.markdown(f"- {risk}")
                
                # ì„±ê³µ ì§€í‘œ
                st.markdown("## ğŸ¯ ì„±ê³µ ì§€í‘œ")
                for indicator in insights.success_indicators:
                    st.markdown(f"- {indicator}")
                
                # ì´í•´ê´€ê³„ì ë§µ
                st.markdown("## ğŸ‘¥ ì´í•´ê´€ê³„ì ë§µ")
                for role, members in insights.stakeholder_map.items():
                    if members:
                        st.markdown(f"**{role}:** {', '.join(members)}")
                
                # ìƒì„¸ ì •ë³´
                with st.expander("ğŸ“Š ìƒì„¸ ë¶„ì„ ì •ë³´"):
                    st.json(asdict(insights))
                
            except ValueError as e:
                st.error(f"âŒ {e}")
            except Exception as e:
                st.error(f"âŒ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    st.markdown("---")
    st.markdown("**ğŸ’¡ ì‚¬ìš©ë²•:** ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ì´ ì™„ë£Œëœ í›„ ì´ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()