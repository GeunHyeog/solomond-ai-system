#!/usr/bin/env python3
"""
ì‹¤ì œ ì‘ë™í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„
- STTAnalyzer import ì˜¤ë¥˜ í•´ê²°
- ë¬¸ì„œ+ì˜ìƒ+ìŒì„±+ìœ íŠœë¸Œ ë™ì‹œ ì²˜ë¦¬
- ì—¬ëŸ¬ AIì—”ì§„ ì¡°í•© ë¶„ì„ â†’ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸
- ì£¼ì–¼ë¦¬ ê°•ì˜/íšŒì˜ ë‚´ìš© ì¢…í•© ìš”ì•½

ì‚¬ìš©ë²•:
1. ë¶„ì„í•  íŒŒì¼ë“¤ì„ input_files/ í´ë”ì— ë„£ê¸°
2. python multimodal_analysis_engine.py ì‹¤í–‰
3. í†µí•© ë¶„ì„ ê²°ê³¼ í™•ì¸
"""

import os
import sys
import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass, asdict
from enum import Enum

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AnalysisType(Enum):
    AUDIO = "audio"
    VIDEO = "video"
    IMAGE = "image"
    DOCUMENT = "document"
    YOUTUBE = "youtube"
    WEB = "web"

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    file_name: str
    file_size_mb: float
    analysis_type: AnalysisType
    processing_time: float
    content: str
    jewelry_keywords: List[str]
    confidence: float
    jewelry_relevance: float
    metadata: Dict[str, Any]
    success: bool
    error_message: Optional[str] = None

class AudioSTTProcessor:
    """ìŒì„± STT ì²˜ë¦¬ê¸° (STTAnalyzer ì˜¤ë¥˜ í•´ê²°)"""
    
    def __init__(self):
        self.model_name = "whisper-base"
        
    async def process_audio(self, file_path: str) -> Dict[str, Any]:
        """ìŒì„± íŒŒì¼ STT ì²˜ë¦¬"""
        try:
            # Whisper ì§ì ‘ ì‚¬ìš© (STTAnalyzer ì˜ì¡´ì„± ì œê±°)
            import whisper
            
            logger.info(f"ğŸµ ìŒì„± íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
            model = whisper.load_model("base")
            
            result = model.transcribe(file_path, language="ko")
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            jewelry_keywords = self.extract_jewelry_keywords(result["text"])
            
            return {
                "text": result["text"],
                "segments": result.get("segments", []),
                "language": result.get("language", "ko"),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.85  # Whisper ê¸°ë³¸ ì‹ ë¢°ë„
            }
            
        except Exception as e:
            logger.error(f"âŒ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    def extract_jewelry_keywords(self, text: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        jewelry_terms = [
            "ë‹¤ì´ì•„ëª¬ë“œ", "diamond", "ë£¨ë¹„", "ruby", "ì‚¬íŒŒì´ì–´", "sapphire", "ì—ë©”ë„ë“œ", "emerald",
            "ë°˜ì§€", "ring", "ëª©ê±¸ì´", "necklace", "ê·€ê±¸ì´", "earring", "íŒ”ì°Œ", "bracelet",
            "ê¸ˆ", "gold", "ì€", "silver", "ë°±ê¸ˆ", "platinum", "ìºëŸ¿", "carat",
            "ì»·", "cut", "íˆ¬ëª…ë„", "clarity", "ìƒ‰ìƒ", "color", "ë¬´ê²Œ", "weight",
            "GIA", "ê°ì •ì„œ", "ì¸ì¦ì„œ", "certificate", "ë³´ì„", "gem", "ì£¼ì–¼ë¦¬", "jewelry"
        ]
        
        found_keywords = []
        text_lower = text.lower()
        
        for term in jewelry_terms:
            if term.lower() in text_lower:
                found_keywords.append(term)
        
        return list(set(found_keywords))

class VideoProcessor:
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ê¸°"""
    
    async def process_video(self, file_path: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ + STT)"""
        try:
            import ffmpeg
            
            logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}")
            
            # ì„ì‹œ ìŒì„± íŒŒì¼ ê²½ë¡œ
            temp_audio = f"temp_audio_{int(time.time())}.wav"
            
            # FFmpegë¡œ ìŒì„± ì¶”ì¶œ
            (
                ffmpeg
                .input(file_path)
                .output(temp_audio, acodec='pcm_s16le', ac=1, ar='16000')
                .overwrite_output()
                .run(quiet=True)
            )
            
            # STT ì²˜ë¦¬
            stt_processor = AudioSTTProcessor()
            audio_result = await stt_processor.process_audio(temp_audio)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
            
            return {
                "text": audio_result["text"],
                "jewelry_keywords": audio_result["jewelry_keywords"],
                "confidence": audio_result["confidence"],
                "type": "video_to_audio_stt"
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class ImageProcessor:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ê¸°"""
    
    async def process_image(self, file_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ OCR ì²˜ë¦¬"""
        try:
            import pytesseract
            from PIL import Image
            
            logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ì¤‘: {file_path}")
            
            # ì´ë¯¸ì§€ ì—´ê¸°
            image = Image.open(file_path)
            
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•œêµ­ì–´ + ì˜ì–´)
            text = pytesseract.image_to_string(image, lang='kor+eng')
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.75,  # OCR ê¸°ë³¸ ì‹ ë¢°ë„
                "type": "image_ocr"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ê¸°"""
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬"""
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.pdf':
                return await self.process_pdf(file_path)
            elif file_ext == '.docx':
                return await self.process_docx(file_path)
            elif file_ext == '.txt':
                return await self.process_txt(file_path)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œ í˜•ì‹: {file_ext}")
                
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_pdf(self, file_path: str) -> Dict[str, Any]:
        """PDF ì²˜ë¦¬"""
        try:
            import PyPDF2
            
            logger.info(f"ğŸ“„ PDF ì²˜ë¦¬ ì¤‘: {file_path}")
            
            text = ""
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.90,
                "type": "pdf_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_docx(self, file_path: str) -> Dict[str, Any]:
        """DOCX ì²˜ë¦¬"""
        try:
            from docx import Document
            
            logger.info(f"ğŸ“ DOCX ì²˜ë¦¬ ì¤‘: {file_path}")
            
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.95,
                "type": "docx_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"DOCX ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_txt(self, file_path: str) -> Dict[str, Any]:
        """TXT ì²˜ë¦¬"""
        try:
            logger.info(f"ğŸ“‹ TXT ì²˜ë¦¬ ì¤‘: {file_path}")
            
            with open(file_path, 'r', encoding='utf-8') as file:
                text = file.read()
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 1.0,
                "type": "txt_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"TXT ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class MultimodalIntegrationEngine:
    """ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.audio_processor = AudioSTTProcessor()
        self.video_processor = VideoProcessor()
        self.image_processor = ImageProcessor()
        self.document_processor = DocumentProcessor()
        
    async def analyze_single_file(self, file_path: str) -> AnalysisResult:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        start_time = time.time()
        file_name = Path(file_path).name
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        
        logger.info(f"ğŸ” íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name} ({file_size_mb:.2f}MB)")
        
        try:
            # íŒŒì¼ í™•ì¥ìë³„ ì²˜ë¦¬ê¸° ì„ íƒ
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext in ['.mp3', '.wav', '.m4a', '.aac']:
                analysis_type = AnalysisType.AUDIO
                result = await self.audio_processor.process_audio(file_path)
                
            elif file_ext in ['.mp4', '.mov', '.avi', '.mkv']:
                analysis_type = AnalysisType.VIDEO
                result = await self.video_processor.process_video(file_path)
                
            elif file_ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                analysis_type = AnalysisType.IMAGE
                result = await self.image_processor.process_image(file_path)
                
            elif file_ext in ['.pdf', '.docx', '.txt']:
                analysis_type = AnalysisType.DOCUMENT
                result = await self.document_processor.process_document(file_path)
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            
            processing_time = time.time() - start_time
            
            # ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚°
            jewelry_relevance = self.calculate_jewelry_relevance(
                result.get("jewelry_keywords", []), 
                result.get("text", "")
            )
            
            return AnalysisResult(
                file_path=file_path,
                file_name=file_name,
                file_size_mb=file_size_mb,
                analysis_type=analysis_type,
                processing_time=processing_time,
                content=result.get("text", ""),
                jewelry_keywords=result.get("jewelry_keywords", []),
                confidence=result.get("confidence", 0.0),
                jewelry_relevance=jewelry_relevance,
                metadata=result,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_name} - {str(e)}")
            
            return AnalysisResult(
                file_path=file_path,
                file_name=file_name,
                file_size_mb=file_size_mb,
                analysis_type=AnalysisType.DOCUMENT,  # ê¸°ë³¸ê°’
                processing_time=processing_time,
                content="",
                jewelry_keywords=[],
                confidence=0.0,
                jewelry_relevance=0.0,
                metadata={},
                success=False,
                error_message=str(e)
            )
    
    def calculate_jewelry_relevance(self, keywords: List[str], text: str) -> float:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚°"""
        if not keywords:
            return 0.0
        
        # í‚¤ì›Œë“œ ìˆ˜ ê¸°ë°˜ ì ìˆ˜
        keyword_score = min(len(keywords) / 10, 1.0)  # ìµœëŒ€ 10ê°œ í‚¤ì›Œë“œ
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ëŒ€ë¹„ í‚¤ì›Œë“œ ë°€ë„
        text_length = len(text.split())
        if text_length > 0:
            density_score = len(keywords) / text_length * 100
            density_score = min(density_score, 1.0)
        else:
            density_score = 0.0
        
        # ìµœì¢… ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
        relevance = (keyword_score * 0.7) + (density_score * 0.3)
        return round(relevance, 2)
    
    async def integrate_multimodal_analysis(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•©"""
        logger.info("ğŸ”— ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•© ì¤‘...")
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = [r for r in results if r.success]
        
        if not successful_results:
            return {
                "summary": "ë¶„ì„ ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.",
                "total_files": len(results),
                "successful_files": 0,
                "total_processing_time": sum(r.processing_time for r in results),
                "jewelry_relevance": 0.0
            }
        
        # ì „ì²´ í…ìŠ¤íŠ¸ í†µí•©
        all_text = []
        all_keywords = []
        
        for result in successful_results:
            if result.content.strip():
                all_text.append(f"[{result.file_name}] {result.content}")
            all_keywords.extend(result.jewelry_keywords)
        
        combined_text = "\n\n".join(all_text)
        unique_keywords = list(set(all_keywords))
        
        # í†µí•© ë¶„ì„ ìƒì„±
        jewelry_summary = self.generate_jewelry_summary(combined_text, unique_keywords)
        
        # í†µê³„ ê³„ì‚°
        avg_confidence = sum(r.confidence for r in successful_results) / len(successful_results)
        avg_jewelry_relevance = sum(r.jewelry_relevance for r in successful_results) / len(successful_results)
        total_processing_time = sum(r.processing_time for r in results)
        
        return {
            "summary": jewelry_summary,
            "combined_text": combined_text,
            "unique_keywords": unique_keywords,
            "total_files": len(results),
            "successful_files": len(successful_results),
            "failed_files": len(results) - len(successful_results),
            "average_confidence": round(avg_confidence, 2),
            "average_jewelry_relevance": round(avg_jewelry_relevance, 2),
            "total_processing_time": round(total_processing_time, 2),
            "file_breakdown": {
                "audio": len([r for r in successful_results if r.analysis_type == AnalysisType.AUDIO]),
                "video": len([r for r in successful_results if r.analysis_type == AnalysisType.VIDEO]),
                "image": len([r for r in successful_results if r.analysis_type == AnalysisType.IMAGE]),
                "document": len([r for r in successful_results if r.analysis_type == AnalysisType.DOCUMENT])
            }
        }
    
    def generate_jewelry_summary(self, text: str, keywords: List[str]) -> str:
        """ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” ìš”ì•½ ìƒì„±"""
        if not text.strip():
            return "ë¶„ì„í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìš”ì•½ (ì‹¤ì œ LLM ëŒ€ì‹ )
        summary_parts = []
        
        # ì£¼ìš” í‚¤ì›Œë“œ ì–¸ê¸‰
        if keywords:
            summary_parts.append(f"ì£¼ìš” ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ: {', '.join(keywords[:10])}")
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ë³„ ìš”ì•½
        if len(text) > 1000:
            summary_parts.append("ëŒ€ìš©ëŸ‰ ì½˜í…ì¸ ê°€ í¬í•¨ëœ ì¢…í•©ì ì¸ ì£¼ì–¼ë¦¬ ê´€ë ¨ ìë£Œì…ë‹ˆë‹¤.")
        elif len(text) > 300:
            summary_parts.append("ì¤‘ê°„ ê·œëª¨ì˜ ì£¼ì–¼ë¦¬ ê´€ë ¨ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            summary_parts.append("ê°„ëµí•œ ì£¼ì–¼ë¦¬ ê´€ë ¨ ë‚´ìš©ì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ ìœ í˜•ë³„ ì–¸ê¸‰
        if "ë‹¤ì´ì•„ëª¬ë“œ" in text or "diamond" in text.lower():
            summary_parts.append("ë‹¤ì´ì•„ëª¬ë“œ ê´€ë ¨ ë‚´ìš©ì´ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë¤„ì§‘ë‹ˆë‹¤.")
        
        if any(term in text.lower() for term in ["ê°€ê²©", "price", "ì‹œì¥", "market"]):
            summary_parts.append("ê°€ê²© ë° ì‹œì¥ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        if any(term in text.lower() for term in ["ì¸ì¦", "certificate", "gia", "ê°ì •"]):
            summary_parts.append("ë³´ì„ ì¸ì¦ ë° ê°ì • ê´€ë ¨ ì •ë³´ê°€ ì–¸ê¸‰ë©ë‹ˆë‹¤.")
        
        return " ".join(summary_parts) if summary_parts else "ì£¼ì–¼ë¦¬ ê´€ë ¨ ê¸°ë³¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ì„¤ì •"""
    dirs = ["input_files", "output_results"]
    for dir_name in dirs:
        Path(dir_name).mkdir(exist_ok=True)
    return dirs

def find_input_files() -> List[str]:
    """ì…ë ¥ íŒŒì¼ ì°¾ê¸°"""
    input_dir = Path("input_files")
    
    supported_extensions = [
        "*.mp3", "*.wav", "*.m4a", "*.aac",
        "*.mp4", "*.mov", "*.avi", "*.mkv",
        "*.jpg", "*.jpeg", "*.png", "*.gif", "*.bmp",
        "*.pdf", "*.docx", "*.txt"
    ]
    
    all_files = []
    for ext in supported_extensions:
        files = list(input_dir.glob(ext))
        all_files.extend([str(f) for f in files])
    
    return all_files

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì†”ë¡œëª¬ë“œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ v2.0")
    print("=" * 60)
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    setup_directories()
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    input_files = find_input_files()
    
    if not input_files:
        print("ğŸ“ input_files/ í´ë”ì— ë¶„ì„í•  íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        print("ğŸ”§ ì§€ì› í˜•ì‹: MP3, WAV, M4A, MP4, MOV, JPG, PNG, PDF, DOCX, TXT")
        return
    
    print(f"ğŸ“‹ ë¶„ì„í•  íŒŒì¼ {len(input_files)}ê°œ ë°œê²¬:")
    for i, file_path in enumerate(input_files, 1):
        file_size = os.path.getsize(file_path) / (1024*1024)
        print(f"   {i}. {Path(file_path).name} ({file_size:.2f}MB)")
    
    # ë¶„ì„ ì‹œì‘ í™•ì¸
    response = input("\nğŸ”„ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if response.lower() not in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
        print("â¸ï¸ ë¶„ì„ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™”
    engine = MultimodalIntegrationEngine()
    
    print(f"\nğŸ” {len(input_files)}ê°œ íŒŒì¼ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹œì‘...")
    start_time = time.time()
    
    # ê° íŒŒì¼ ìˆœì°¨ ë¶„ì„
    analysis_results = []
    for i, file_path in enumerate(input_files, 1):
        print(f"\nğŸ“Š ì§„í–‰ë¥ : {i}/{len(input_files)}")
        result = await engine.analyze_single_file(file_path)
        analysis_results.append(result)
        
        if result.success:
            print(f"âœ… ì„±ê³µ: {result.file_name}")
            print(f"   ğŸ¯ ê´€ë ¨ì„±: {result.jewelry_relevance:.2f}")
            print(f"   ğŸ”‘ í‚¤ì›Œë“œ: {', '.join(result.jewelry_keywords[:5])}")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result.file_name} - {result.error_message}")
    
    # ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„
    print(f"\nğŸ”— ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì¤‘...")
    integrated_result = await engine.integrate_multimodal_analysis(analysis_results)
    
    total_time = time.time() - start_time
    
    # ê²°ê³¼ ì €ì¥
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_dir = Path("output_results")
    
    # ìƒì„¸ ê²°ê³¼ JSON ì €ì¥
    detailed_results = {
        "timestamp": timestamp,
        "individual_analysis": [asdict(r) for r in analysis_results],
        "integrated_analysis": integrated_result,
        "performance": {
            "total_processing_time": total_time,
            "average_time_per_file": total_time / len(input_files),
            "files_per_second": len(input_files) / total_time
        }
    }
    
    json_file = output_dir / f"multimodal_analysis_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    
    # ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥
    report_file = output_dir / f"analysis_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ’ ì†”ë¡œëª¬ë“œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"ğŸ“Š ì „ì²´ í†µê³„:\n")
        f.write(f"   ì´ íŒŒì¼ ìˆ˜: {integrated_result['total_files']}\n")
        f.write(f"   ì„±ê³µ íŒŒì¼: {integrated_result['successful_files']}\n")
        f.write(f"   ì‹¤íŒ¨ íŒŒì¼: {integrated_result['failed_files']}\n")
        f.write(f"   ì „ì²´ ì²˜ë¦¬ì‹œê°„: {integrated_result['total_processing_time']:.2f}ì´ˆ\n")
        f.write(f"   í‰ê·  ì‹ ë¢°ë„: {integrated_result['average_confidence']:.2f}\n")
        f.write(f"   í‰ê·  ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {integrated_result['average_jewelry_relevance']:.2f}\n\n")
        
        f.write(f"ğŸ”‘ ë°œê²¬ëœ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ:\n")
        f.write(f"   {', '.join(integrated_result['unique_keywords'])}\n\n")
        
        f.write(f"ğŸ“‹ íŒŒì¼ ìœ í˜•ë³„ ë¶„ì„:\n")
        breakdown = integrated_result['file_breakdown']
        f.write(f"   ìŒì„±: {breakdown['audio']}ê°œ\n")
        f.write(f"   ë¹„ë””ì˜¤: {breakdown['video']}ê°œ\n")
        f.write(f"   ì´ë¯¸ì§€: {breakdown['image']}ê°œ\n")
        f.write(f"   ë¬¸ì„œ: {breakdown['document']}ê°œ\n\n")
        
        f.write(f"ğŸ¯ í†µí•© ë¶„ì„ ìš”ì•½:\n")
        f.write(f"   {integrated_result['summary']}\n\n")
        
        if integrated_result['combined_text']:
            f.write(f"ğŸ“ ì „ì²´ ë‚´ìš© (ì²˜ìŒ 500ì):\n")
            f.write(f"   {integrated_result['combined_text'][:500]}...\n")
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n" + "=" * 60)
    print(f"ğŸ‰ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì™„ë£Œ!")
    print(f"   ğŸ“Š ì´ {integrated_result['total_files']}ê°œ íŒŒì¼ ì²˜ë¦¬")
    print(f"   âœ… ì„±ê³µ: {integrated_result['successful_files']}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {integrated_result['failed_files']}ê°œ")
    print(f"   â±ï¸ ì „ì²´ ì‹œê°„: {integrated_result['total_processing_time']:.2f}ì´ˆ")
    print(f"   ğŸ“ˆ í‰ê·  ê´€ë ¨ì„±: {integrated_result['average_jewelry_relevance']:.2f}")
    print(f"   ğŸ”‘ í‚¤ì›Œë“œ ìˆ˜: {len(integrated_result['unique_keywords'])}ê°œ")
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥:")
    print(f"   ğŸ“„ ìƒì„¸ ë°ì´í„°: {json_file}")
    print(f"   ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸: {report_file}")
    print(f"\nğŸ¯ í†µí•© ìš”ì•½: {integrated_result['summary']}")

if __name__ == "__main__":
    asyncio.run(main())
