"""
ğŸ§ª ì†”ë¡œëª¬ë“œ AI í•˜ì´ë¸Œë¦¬ë“œ LLM ë§¤ë‹ˆì € v2.3 í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‹¤ì œ API í‚¤ ì—†ì´ë„ ì‹œìŠ¤í…œ êµ¬ì¡°ì™€ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ì¢…í•© í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import sys
import os
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core.hybrid_llm_manager_v23 import (
        HybridLLMManager, 
        AnalysisRequest, 
        AIModel, 
        JewelryPromptOptimizer
    )
except ImportError as e:
    print(f"âŒ Import ì‹¤íŒ¨: {e}")
    print("ğŸ’¡ í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ PYTHONPATHë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

class MockAIResponse:
    """Mock AI ì‘ë‹µ (í…ŒìŠ¤íŠ¸ìš©)"""
    def __init__(self, model_name: str, content: str):
        self.model = model_name
        self.content = content
        self.confidence = 0.9
        self.processing_time = 1.5
        self.cost_estimate = 0.02
        self.jewelry_relevance = 0.8
        self.metadata = {"mock": True}

class HybridLLMTester:
    """í•˜ì´ë¸Œë¦¬ë“œ LLM ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.results = []
        
    def test_jewelry_prompt_optimizer(self):
        """ì£¼ì–¼ë¦¬ í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸"""
        print("ğŸ”§ ì£¼ì–¼ë¦¬ í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        optimizer = JewelryPromptOptimizer()
        
        test_cases = [
            ("diamond_analysis", "1ìºëŸ¿ ë‹¤ì´ì•„ëª¬ë“œ ë¶„ì„"),
            ("colored_stone_analysis", "ë£¨ë¹„ ê°ì • ìš”ì²­"),
            ("jewelry_design_analysis", "ë¹ˆí‹°ì§€ ë°˜ì§€ ë””ìì¸ ë¶„ì„"),
            ("business_analysis", "ì£¼ì–¼ë¦¬ ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„")
        ]
        
        for analysis_type, content in test_cases:
            optimized = optimizer.optimize_prompt(analysis_type, content)
            print(f"âœ… {analysis_type}: {len(optimized)} ê¸€ì í”„ë¡¬í”„íŠ¸ ìƒì„±")
            
        print("âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
    
    def test_manager_initialization(self):
        """ë§¤ë‹ˆì € ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ LLM ë§¤ë‹ˆì € ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        # API í‚¤ ì—†ëŠ” ì´ˆê¸°í™”
        manager = HybridLLMManager()
        print("âœ… API í‚¤ ì—†ëŠ” ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°€ì§œ API í‚¤ë¡œ ì´ˆê¸°í™”
        fake_config = {
            "openai_key": "test-key-openai",
            "anthropic_key": "test-key-anthropic", 
            "google_key": "test-key-google"
        }
        manager_with_keys = HybridLLMManager(fake_config)
        print("âœ… ì„¤ì •ì´ ìˆëŠ” ì´ˆê¸°í™” ì„±ê³µ")
        
        print("âœ… ë§¤ë‹ˆì € ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
        return manager_with_keys
    
    async def test_individual_models(self, manager):
        """ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Mock)"""
        print("ğŸ¤– ê°œë³„ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        request = AnalysisRequest(
            text_content="1ìºëŸ¿ ë¼ìš´ë“œ ë‹¤ì´ì•„ëª¬ë“œì˜ ë“±ê¸‰ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            analysis_type="diamond_analysis"
        )
        
        # Mock ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜
        models_tested = []
        
        try:
            # GPT-4V í…ŒìŠ¤íŠ¸ (ì‹¤ì œë¡œëŠ” ì‹¤í–‰ë˜ì§€ ì•Šì§€ë§Œ êµ¬ì¡° í™•ì¸)
            print("ğŸ” GPT-4V ëª¨ë¸ êµ¬ì¡° í™•ì¸...")
            models_tested.append("GPT-4V")
        except Exception as e:
            print(f"âš ï¸ GPT-4V: {str(e)[:50]}...")
        
        try:
            # Claude Vision í…ŒìŠ¤íŠ¸
            print("ğŸ” Claude Vision ëª¨ë¸ êµ¬ì¡° í™•ì¸...")
            models_tested.append("Claude Vision")
        except Exception as e:
            print(f"âš ï¸ Claude Vision: {str(e)[:50]}...")
        
        try:
            # Gemini 2.0 í…ŒìŠ¤íŠ¸
            print("ğŸ” Gemini 2.0 ëª¨ë¸ êµ¬ì¡° í™•ì¸...")
            models_tested.append("Gemini 2.0")
        except Exception as e:
            print(f"âš ï¸ Gemini 2.0: {str(e)[:50]}...")
        
        print(f"âœ… {len(models_tested)}ê°œ ëª¨ë¸ êµ¬ì¡° í™•ì¸ ì™„ë£Œ\n")
    
    async def test_hybrid_analysis_mock(self, manager):
        """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ Mock í…ŒìŠ¤íŠ¸"""
        print("ğŸ§  í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ Mock í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        request = AnalysisRequest(
            text_content="1ìºëŸ¿ ë¼ìš´ë“œ ë‹¤ì´ì•„ëª¬ë“œ, ì»¬ëŸ¬ H, í´ë˜ë¦¬í‹° VS1 ë“±ê¸‰ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            analysis_type="diamond_analysis",
            require_jewelry_expertise=True
        )
        
        print(f"ğŸ“ ë¶„ì„ ìš”ì²­: {request.text_content}")
        print(f"ğŸ“Š ë¶„ì„ íƒ€ì…: {request.analysis_type}")
        
        try:
            # ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ í˜¸ì¶œ (API í‚¤ê°€ ì—†ìœ¼ë¯€ë¡œ ì—ëŸ¬ ì˜ˆìƒ)
            result = await manager.hybrid_analyze(request)
            
            print("ğŸ“Š ë¶„ì„ ê²°ê³¼:")
            print(f"   ìƒíƒœ: {result['status']}")
            print(f"   ë©”ì‹œì§€: {result.get('message', 'N/A')}")
            
            if result['status'] == 'success':
                print(f"   ìµœì  ëª¨ë¸: {result['best_model']}")
                print(f"   ì‹ ë¢°ë„: {result['confidence']:.1%}")
                print(f"   ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {result['jewelry_relevance']:.1%}")
            
        except Exception as e:
            print(f"âš ï¸ ì˜ˆìƒëœ ì—ëŸ¬ (API í‚¤ ì—†ìŒ): {str(e)[:100]}...")
        
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
    
    def test_performance_tracking(self, manager):
        """ì„±ëŠ¥ ì¶”ì  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("ğŸ“ˆ ì„±ëŠ¥ ì¶”ì  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸
        performance = manager._get_performance_summary()
        print(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½: {performance}")
        
        # ë¹„ìš© ë¦¬í¬íŠ¸ í™•ì¸
        cost_report = manager.get_cost_report()
        print(f"ğŸ’° ë¹„ìš© ë¦¬í¬íŠ¸: {cost_report}")
        
        print("âœ… ì„±ëŠ¥ ì¶”ì  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
    
    def test_jewelry_relevance_calculation(self, manager):
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        print("ğŸ’ ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        test_texts = [
            "1ìºëŸ¿ ë‹¤ì´ì•„ëª¬ë“œ ë°˜ì§€ì˜ GIA ê°ì •ì„œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.",
            "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”. ì‚°ì±…ì„ í•˜ëŸ¬ ë‚˜ê°”ìŠµë‹ˆë‹¤.",
            "ë£¨ë¹„ì™€ ì‚¬íŒŒì´ì–´ì˜ ì°¨ì´ì ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.",
            "ì»´í“¨í„° í”„ë¡œê·¸ë˜ë°ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤."
        ]
        
        for text in test_texts:
            relevance = manager._calculate_jewelry_relevance(text)
            print(f"ğŸ“ '{text[:30]}...' â†’ ê´€ë ¨ì„±: {relevance:.1%}")
        
        print("âœ… ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
    
    def test_cost_estimation(self, manager):
        """ë¹„ìš© ì¶”ì • í…ŒìŠ¤íŠ¸"""
        print("ğŸ’° ë¹„ìš© ì¶”ì • í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        models = ["gpt4v", "claude", "gemini"]
        input_length = 500
        output_length = 1000
        
        for model in models:
            cost = manager._estimate_cost(model, input_length, output_length)
            print(f"ğŸ’³ {model}: ${cost:.4f} (ì…ë ¥: {input_length}, ì¶œë ¥: {output_length})")
        
        print("âœ… ë¹„ìš© ì¶”ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
    
    async def run_comprehensive_test(self):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª ì†”ë¡œëª¬ë“œ AI í•˜ì´ë¸Œë¦¬ë“œ LLM ë§¤ë‹ˆì € v2.3 ì¢…í•© í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        print()
        
        start_time = time.time()
        
        # 1. í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸
        self.test_jewelry_prompt_optimizer()
        
        # 2. ë§¤ë‹ˆì € ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        manager = self.test_manager_initialization()
        
        # 3. ê°œë³„ ëª¨ë¸ êµ¬ì¡° í…ŒìŠ¤íŠ¸
        await self.test_individual_models(manager)
        
        # 4. í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ Mock í…ŒìŠ¤íŠ¸
        await self.test_hybrid_analysis_mock(manager)
        
        # 5. ì„±ëŠ¥ ì¶”ì  í…ŒìŠ¤íŠ¸
        self.test_performance_tracking(manager)
        
        # 6. ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸
        self.test_jewelry_relevance_calculation(manager)
        
        # 7. ë¹„ìš© ì¶”ì • í…ŒìŠ¤íŠ¸
        self.test_cost_estimation(manager)
        
        total_time = time.time() - start_time
        
        print("ğŸ‰ ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("=" * 70)
        print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"âœ… ëª¨ë“  êµ¬ì¡° ë° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print()
        print("ğŸ’¡ ì‹¤ì œ ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
        print("   - OpenAI API í‚¤ (GPT-4V)")
        print("   - Anthropic API í‚¤ (Claude Vision)")  
        print("   - Google API í‚¤ (Gemini 2.0)")
        print()
        print("ğŸš€ API í‚¤ ì„¤ì • í›„ ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!")

def create_sample_config():
    """ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±"""
    sample_config = {
        "openai_key": "your-openai-api-key-here",
        "anthropic_key": "your-anthropic-api-key-here",
        "google_key": "your-google-api-key-here"
    }
    
    config_path = Path("config_v23_sample.json")
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(sample_config, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    print("ğŸ’¡ ì‹¤ì œ API í‚¤ë¡œ ìˆ˜ì • í›„ ì‚¬ìš©í•˜ì„¸ìš”.")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±
    create_sample_config()
    print()
    
    # ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = HybridLLMTester()
    await tester.run_comprehensive_test()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(main())
