"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ í†µí•© UI
5GB íŒŒì¼ 50ê°œ ë™ì‹œ ì²˜ë¦¬ + GEMMA ìš”ì•½ + ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”

íŠ¹ì§•:
- ë“œë˜ê·¸&ë“œë¡­ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ
- ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- ê³„ì¸µì  ìš”ì•½ ê²°ê³¼ í‘œì‹œ
- í’ˆì§ˆ í‰ê°€ ë° ì‹ ë¢°ë„ ì§€í‘œ
- ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì¸ì‚¬ì´íŠ¸
"""

import streamlit as st
import asyncio
import json
import time
from typing import Dict, List, Optional
from datetime import datetime
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
import pandas as pd
from pathlib import Path

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ import
try:
    from core.advanced_llm_summarizer_complete import EnhancedLLMSummarizer
    from core.large_file_streaming_engine import LargeFileStreamingEngine, StreamingProgress
    from core.multimodal_integrator import get_multimodal_integrator
    ADVANCED_MODULES_AVAILABLE = True
except ImportError:
    ADVANCED_MODULES_AVAILABLE = False
    st.warning("âš ï¸ ê³ ê¸‰ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ì˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì†”ë¡œëª¬ë“œ AI - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #2a5298;
        margin-bottom: 1rem;
    }
    
    .progress-container {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .quality-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        font-weight: bold;
        margin: 0.25rem;
    }
    
    .quality-excellent { background: #d4edda; color: #155724; }
    .quality-good { background: #d1ecf1; color: #0c5460; }
    .quality-fair { background: #fff3cd; color: #856404; }
    .quality-poor { background: #f8d7da; color: #721c24; }
    
    .file-item {
        background: white;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    
    .streaming-status {
        font-family: 'Courier New', monospace;
        background: #000;
        color: #00ff00;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'processing_session' not in st.session_state:
        st.session_state.processing_session = None
    if 'uploaded_files' not in st.session_state:
        st.session_state.uploaded_files = []
    if 'processing_results' not in st.session_state:
        st.session_state.processing_results = {}
    if 'streaming_progress' not in st.session_state:
        st.session_state.streaming_progress = {}
    if 'llm_summarizer' not in st.session_state:
        if ADVANCED_MODULES_AVAILABLE:
            st.session_state.llm_summarizer = EnhancedLLMSummarizer()
        else:
            st.session_state.llm_summarizer = None
    if 'streaming_engine' not in st.session_state:
        if ADVANCED_MODULES_AVAILABLE:
            st.session_state.streaming_engine = LargeFileStreamingEngine(max_memory_mb=150)
        else:
            st.session_state.streaming_engine = None

def render_header():
    """í—¤ë” ë Œë”ë§"""
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ’ ì†”ë¡œëª¬ë“œ AI - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì‹œìŠ¤í…œ</h1>
        <p>5GB íŒŒì¼ 50ê°œ ë™ì‹œ ì²˜ë¦¬ â€¢ GEMMA í†µí•© ìš”ì•½ â€¢ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°</p>
    </div>
    """, unsafe_allow_html=True)

def render_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ì‹œìŠ¤í…œ ìƒíƒœ",
            "ì˜¨ë¼ì¸" if ADVANCED_MODULES_AVAILABLE else "ëª¨ì˜ëª¨ë“œ",
            delta="GEMMA + ìŠ¤íŠ¸ë¦¬ë°" if ADVANCED_MODULES_AVAILABLE else "ê¸°ë³¸ ëª¨ë“œ"
        )
    
    with col2:
        uploaded_count = len(st.session_state.uploaded_files)
        st.metric("ì—…ë¡œë“œëœ íŒŒì¼", f"{uploaded_count}ê°œ", delta="ìµœëŒ€ 50ê°œ")
    
    with col3:
        total_size = sum(f.size for f in st.session_state.uploaded_files) / (1024*1024)
        st.metric("ì´ íŒŒì¼ í¬ê¸°", f"{total_size:.1f}MB", delta="ìµœëŒ€ 5GB")
    
    with col4:
        processing_status = "ì²˜ë¦¬ì¤‘" if st.session_state.processing_session else "ëŒ€ê¸°"
        st.metric("ì²˜ë¦¬ ìƒíƒœ", processing_status)

def render_file_upload():
    """íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸ“ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "íŒŒì¼ì„ ë“œë˜ê·¸&ë“œë¡­í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš” (mov, m4a, jpg, png, pdf, mp3, wav, mp4)",
        type=['mov', 'm4a', 'jpg', 'jpeg', 'png', 'pdf', 'mp3', 'wav', 'mp4', 'avi'],
        accept_multiple_files=True,
        help="ìµœëŒ€ 50ê°œ íŒŒì¼, ì´ 5GBê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥"
    )
    
    if uploaded_files:
        st.session_state.uploaded_files = uploaded_files
        
        # íŒŒì¼ ëª©ë¡ í‘œì‹œ
        st.subheader("ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
        
        file_data = []
        total_size = 0
        
        for i, file in enumerate(uploaded_files):
            file_size_mb = file.size / (1024 * 1024)
            total_size += file_size_mb
            
            file_data.append({
                "ìˆœë²ˆ": i + 1,
                "íŒŒì¼ëª…": file.name,
                "í¬ê¸°(MB)": f"{file_size_mb:.2f}",
                "íƒ€ì…": Path(file.name).suffix.upper(),
                "ìƒíƒœ": "ì—…ë¡œë“œ ì™„ë£Œ"
            })
        
        # íŒŒì¼ ëª©ë¡ í…Œì´ë¸”
        df = pd.DataFrame(file_data)
        st.dataframe(df, use_container_width=True)
        
        # ìš”ì•½ ì •ë³´
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ íŒŒì¼ ìˆ˜", f"{len(uploaded_files)}ê°œ")
        with col2:
            st.metric("ì´ í¬ê¸°", f"{total_size:.1f}MB")
        with col3:
            max_files = 50
            remaining = max_files - len(uploaded_files)
            st.metric("ë‚¨ì€ ìŠ¬ë¡¯", f"{remaining}ê°œ")
        
        # ê²½ê³  ë° ê¶Œì¥ì‚¬í•­
        if len(uploaded_files) > 50:
            st.error("âš ï¸ íŒŒì¼ ìˆ˜ê°€ 50ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ì„ ìœ„í•´ 50ê°œ ì´í•˜ë¡œ ì œí•œí•´ì£¼ì„¸ìš”.")
        elif total_size > 5000:  # 5GB
            st.error("âš ï¸ ì´ íŒŒì¼ í¬ê¸°ê°€ 5GBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ ì¸í•´ ì²˜ë¦¬ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif total_size > 1000:  # 1GB
            st.warning("âš ï¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ì…ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def render_processing_controls():
    """ì²˜ë¦¬ ì œì–´ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ğŸš€ ì²˜ë¦¬ ì„¤ì • ë° ì‹¤í–‰")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.selectbox(
            "ì²˜ë¦¬ ëª¨ë“œ",
            ["ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ëŒ€ìš©ëŸ‰)", "ë°°ì¹˜ ì²˜ë¦¬ (ì¤‘ê°„)", "ë©”ëª¨ë¦¬ ì²˜ë¦¬ (ì†ŒëŸ‰)"],
            help="íŒŒì¼ í¬ê¸°ì— ë”°ë¼ ìë™ ì„ íƒë©ë‹ˆë‹¤"
        )
        
        st.selectbox(
            "ìš”ì•½ íƒ€ì…",
            ["ì¢…í•© ìš”ì•½", "ê²½ì˜ì§„ ìš”ì•½", "ê¸°ìˆ ì  ìš”ì•½", "ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì•½"],
            help="ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” ìš”ì•½ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col2:
        st.slider("ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)", 50, 500, 150)
        st.slider("ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜", 1, 20, 10)
    
    # ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button(
            "ğŸš€ ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì‹œì‘",
            type="primary",
            use_container_width=True,
            disabled=len(st.session_state.uploaded_files) == 0
        ):
            if len(st.session_state.uploaded_files) > 0:
                start_processing()
            else:
                st.error("ì²˜ë¦¬í•  íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

async def start_processing():
    """ì²˜ë¦¬ ì‹œì‘"""
    st.session_state.processing_session = {
        "start_time": time.time(),
        "status": "processing",
        "files": st.session_state.uploaded_files
    }
    
    with st.spinner("ğŸ”„ ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì²˜ë¦¬ ì¤‘..."):
        try:
            # íŒŒì¼ ë°ì´í„° ì¤€ë¹„
            files_data = []
            for file in st.session_state.uploaded_files:
                files_data.append({
                    "filename": file.name,
                    "size_mb": file.size / (1024 * 1024),
                    "content": file.read(),
                    "processed_text": f"ëª¨ì˜ í…ìŠ¤íŠ¸ ë°ì´í„° for {file.name}..."  # ì‹¤ì œë¡œëŠ” STT/OCR ê²°ê³¼
                })
            
            # LLM ìš”ì•½ ì²˜ë¦¬
            if st.session_state.llm_summarizer:
                result = await st.session_state.llm_summarizer.process_large_batch(files_data)
            else:
                # ëª¨ì˜ ê²°ê³¼
                result = create_mock_processing_result(files_data)
            
            st.session_state.processing_results = result
            st.session_state.processing_session["status"] = "completed"
            
            st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            st.session_state.processing_session["status"] = "error"

def create_mock_processing_result(files_data: List[Dict]) -> Dict:
    """ëª¨ì˜ ì²˜ë¦¬ ê²°ê³¼ ìƒì„±"""
    return {
        "success": True,
        "session_id": f"mock_{int(time.time())}",
        "processing_time": 15.5,
        "files_processed": len(files_data),
        "chunks_processed": len(files_data) * 3,
        "hierarchical_summary": {
            "final_summary": """
            2025ë…„ ì£¼ì–¼ë¦¬ ì‹œì¥ ë¶„ì„ ê²°ê³¼, ë‹¤ì´ì•„ëª¬ë“œ ê°€ê²©ì´ ì „ë…„ ëŒ€ë¹„ 15% ìƒìŠ¹í–ˆìœ¼ë©°, 
            íŠ¹íˆ 1ìºëŸ¿ ì´ìƒ ê³ ê¸‰ ë‹¤ì´ì•„ëª¬ë“œì˜ ìˆ˜ìš”ê°€ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤. 
            GIA ì¸ì¦ì„œì˜ ì¤‘ìš”ì„±ì´ ë”ìš± ê°•ì¡°ë˜ê³  ìˆìœ¼ë©°, 
            4C ë“±ê¸‰ ì¤‘ ì»¬ëŸ¬ì™€ í´ë˜ë¦¬í‹°ê°€ ê°€ê²© ê²°ì •ì— í•µì‹¬ ìš”ì†Œë¡œ ì‘ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.
            """,
            "source_summaries": {
                "audio": {"summary": "ìŒì„± ë¶„ì„ ìš”ì•½...", "chunk_count": 5},
                "video": {"summary": "ë¹„ë””ì˜¤ ë¶„ì„ ìš”ì•½...", "chunk_count": 3},
                "documents": {"summary": "ë¬¸ì„œ ë¶„ì„ ìš”ì•½...", "chunk_count": 7}
            }
        },
        "quality_assessment": {
            "quality_score": 87.5,
            "coverage_ratio": 0.82,
            "compression_ratio": 0.15,
            "jewelry_terms_found": 25,
            "jewelry_terms_total": 30
        },
        "recommendations": [
            "âœ… ìš°ìˆ˜í•œ í’ˆì§ˆì˜ ìš”ì•½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ğŸ’¡ ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì»¤ë²„ë¦¬ì§€ê°€ 82%ë¡œ ì–‘í˜¸í•©ë‹ˆë‹¤.",
            "ğŸ“ ì••ì¶•ë¥ ì´ 15%ë¡œ íš¨ìœ¨ì ì¸ ìš”ì•½ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        ]
    }

def render_processing_results():
    """ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ"""
    if not st.session_state.processing_results:
        return
    
    st.subheader("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
    
    result = st.session_state.processing_results
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result.get('processing_time', 0):.1f}ì´ˆ")
    with col2:
        st.metric("ì²˜ë¦¬ëœ íŒŒì¼", f"{result.get('files_processed', 0)}ê°œ")
    with col3:
        st.metric("ì²˜ë¦¬ëœ ì²­í¬", f"{result.get('chunks_processed', 0)}ê°œ")
    with col4:
        quality_score = result.get('quality_assessment', {}).get('quality_score', 0)
        st.metric("í’ˆì§ˆ ì ìˆ˜", f"{quality_score:.1f}/100")
    
    # í’ˆì§ˆ í‰ê°€ ì‹œê°í™”
    st.subheader("ğŸ¯ í’ˆì§ˆ í‰ê°€")
    
    qa = result.get('quality_assessment', {})
    
    col1, col2 = st.columns(2)
    
    with col1:
        # í’ˆì§ˆ ì ìˆ˜ ê²Œì´ì§€
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = qa.get('quality_score', 0),
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "ì „ì²´ í’ˆì§ˆ ì ìˆ˜"},
            delta = {'reference': 80},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgray"},
                    {'range': [50, 80], 'color': "yellow"},
                    {'range': [80, 100], 'color': "green"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75, 'value': 90
                }
            }
        ))
        
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ìƒì„¸ ë©”íŠ¸ë¦­
        metrics_data = {
            "ë©”íŠ¸ë¦­": ["í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€", "ì••ì¶•ë¥ ", "ìš©ì–´ ë°œê²¬ìœ¨"],
            "ê°’": [
                qa.get('coverage_ratio', 0) * 100,
                qa.get('compression_ratio', 0) * 100,
                (qa.get('jewelry_terms_found', 0) / max(qa.get('jewelry_terms_total', 1), 1)) * 100
            ]
        }
        
        fig = px.bar(
            metrics_data, 
            x="ë©”íŠ¸ë¦­", 
            y="ê°’",
            title="ì„¸ë¶€ í’ˆì§ˆ ì§€í‘œ",
            color="ê°’",
            color_continuous_scale="viridis"
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    # ìµœì¢… ìš”ì•½
    st.subheader("ğŸ“‹ ìµœì¢… í†µí•© ìš”ì•½")
    
    hierarchical = result.get('hierarchical_summary', {})
    final_summary = hierarchical.get('final_summary', 'ìš”ì•½ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.')
    
    st.markdown(f"""
    <div class="metric-card">
        <h4>ğŸ’ ì£¼ì–¼ë¦¬ ì—…ê³„ í†µí•© ë¶„ì„ ìš”ì•½</h4>
        <p>{final_summary}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì†ŒìŠ¤ë³„ ìš”ì•½
    st.subheader("ğŸ” ì†ŒìŠ¤ë³„ ìƒì„¸ ë¶„ì„")
    
    source_summaries = hierarchical.get('source_summaries', {})
    
    for source_type, source_data in source_summaries.items():
        with st.expander(f"ğŸ“‚ {source_type.upper()} ì†ŒìŠ¤ ë¶„ì„"):
            st.write(f"**ìš”ì•½:** {source_data.get('summary', 'N/A')}")
            st.write(f"**ì²˜ë¦¬ëœ ì²­í¬:** {source_data.get('chunk_count', 0)}ê°œ")
    
    # ê¶Œì¥ì‚¬í•­
    st.subheader("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
    
    recommendations = result.get('recommendations', [])
    for rec in recommendations:
        st.markdown(f"- {rec}")

def render_real_time_monitoring():
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
    if st.session_state.processing_session and st.session_state.processing_session["status"] == "processing":
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§")
        
        # ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ (ëª¨ì˜)
        st.markdown("""
        <div class="streaming-status">
        ğŸŒŠ STREAMING PROCESSING STATUS<br>
        ================================<br>
        > Processing chunk 15/47...<br>
        > Memory usage: 89MB / 150MB<br>
        > Speed: 2.3 MB/s<br>
        > ETA: 00:02:15<br>
        ================================<br>
        </div>
        """, unsafe_allow_html=True)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    initialize_session_state()
    
    render_header()
    render_system_status()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
        
        st.subheader("ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        if st.session_state.streaming_engine:
            stats = {"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰": "89MB", "ì²˜ë¦¬ ì†ë„": "2.3MB/s", "í™œì„± ìŠ¤íŠ¸ë¦¼": "3ê°œ"}
        else:
            stats = {"ì‹œìŠ¤í…œ ìƒíƒœ": "ëª¨ì˜ ëª¨ë“œ", "ë©”ëª¨ë¦¬": "ì œí•œ ì—†ìŒ", "ì²˜ë¦¬ ëŠ¥ë ¥": "ê¸°ë³¸"}
        
        for key, value in stats.items():
            st.metric(key, value)
        
        st.subheader("ğŸ”§ ê³ ê¸‰ ì„¤ì •")
        st.checkbox("GEMMA ëª¨ë¸ ì‚¬ìš©", value=ADVANCED_MODULES_AVAILABLE, disabled=True)
        st.checkbox("ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬", value=ADVANCED_MODULES_AVAILABLE, disabled=True)
        st.checkbox("ë©”ëª¨ë¦¬ ìµœì í™”", value=True)
        st.checkbox("ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", value=True)
        
        if st.button("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬", use_container_width=True):
            if st.session_state.streaming_engine:
                st.session_state.streaming_engine.cleanup()
            st.success("ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ!")
    
    # ë©”ì¸ ì½˜í…ì¸ 
    tab1, tab2, tab3 = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸš€ ì²˜ë¦¬ ì‹¤í–‰", "ğŸ“Š ê²°ê³¼ ë¶„ì„"])
    
    with tab1:
        render_file_upload()
    
    with tab2:
        render_processing_controls()
        render_real_time_monitoring()
    
    with tab3:
        render_processing_results()
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ğŸ’ ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ v2.0 - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ íŠ¹í™” ë²„ì „</p>
        <p>Powered by GEMMA + Whisper + ìŠ¤íŠ¸ë¦¬ë° ì—”ì§„</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
