"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ API ì„œë²„
FastAPI ê¸°ë°˜ REST API + WebSocket ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:
- POST /api/v1/analyze/batch - ë°°ì¹˜ ë¶„ì„
- POST /api/v1/analyze/streaming - ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„  
- GET /api/v1/status/{session_id} - ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ
- WebSocket /ws/progress/{session_id} - ì‹¤ì‹œê°„ ì§„í–‰ë¥ 
- GET /api/v1/health - ì‹œìŠ¤í…œ ìƒíƒœ
"""

from fastapi import FastAPI, File, UploadFile, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import asyncio
import json
import time
import uuid
from datetime import datetime
import tempfile
import os
from pathlib import Path
import logging

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ
try:
    from core.advanced_llm_summarizer_complete import EnhancedLLMSummarizer
    from core.large_file_streaming_engine import LargeFileStreamingEngine, StreamingProgress
    from core.multimodal_integrator import get_multimodal_integrator
    MODULES_AVAILABLE = True
except ImportError:
    MODULES_AVAILABLE = False

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="ì†”ë¡œëª¬ë“œ AI - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ API",
    description="ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” ë©€í‹°ëª¨ë‹¬ AI ë¶„ì„ ì‹œìŠ¤í…œ",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
active_sessions: Dict[str, Dict] = {}
websocket_connections: Dict[str, List[WebSocket]] = {}
llm_summarizer: Optional[EnhancedLLMSummarizer] = None
streaming_engine: Optional[LargeFileStreamingEngine] = None

# ë°ì´í„° ëª¨ë¸
class AnalysisRequest(BaseModel):
    session_name: str = Field(..., description="ì„¸ì…˜ ì´ë¦„")
    analysis_type: str = Field("comprehensive", description="ë¶„ì„ íƒ€ì… (comprehensive, executive, technical, business)")
    max_memory_mb: int = Field(150, description="ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)")
    enable_streaming: bool = Field(True, description="ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í™œì„±í™”")
    priority_sources: List[str] = Field(default_factory=list, description="ìš°ì„ ìˆœìœ„ ì†ŒìŠ¤ íƒ€ì…")

class AnalysisResponse(BaseModel):
    success: bool
    session_id: str
    message: str
    processing_started: bool = False
    estimated_time: Optional[float] = None

class StatusResponse(BaseModel):
    session_id: str
    status: str  # pending, processing, completed, error
    progress: float  # 0-100
    files_processed: int
    total_files: int
    processing_time: float
    estimated_remaining: Optional[float] = None
    memory_usage_mb: float
    current_stage: str
    error_message: Optional[str] = None

class ResultResponse(BaseModel):
    session_id: str
    success: bool
    final_summary: str
    quality_score: float
    processing_time: float
    files_processed: int
    recommendations: List[str]
    source_summaries: Dict[str, Any]
    metadata: Dict[str, Any]

class HealthResponse(BaseModel):
    status: str
    timestamp: str
    version: str
    modules_available: bool
    active_sessions: int
    system_info: Dict[str, Any]

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì‹œìŠ¤í…œ ì‹œì‘ì‹œ ì´ˆê¸°í™”"""
    global llm_summarizer, streaming_engine
    
    logging.info("ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ ì‹œì‘ ì¤‘...")
    
    if MODULES_AVAILABLE:
        try:
            llm_summarizer = EnhancedLLMSummarizer()
            streaming_engine = LargeFileStreamingEngine(max_memory_mb=200)
            logging.info("ê³ ê¸‰ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logging.error(f"ëª¨ë“ˆ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    else:
        logging.warning("ê³ ê¸‰ ëª¨ë“ˆ ì—†ìŒ. ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")

@app.on_event("shutdown")
async def shutdown_event():
    """ì‹œìŠ¤í…œ ì¢…ë£Œì‹œ ì •ë¦¬"""
    global streaming_engine
    
    logging.info("ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
    
    if streaming_engine:
        streaming_engine.cleanup()

# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/v1/health", response_model=HealthResponse)
async def health_check():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    import psutil
    
    return HealthResponse(
        status="healthy" if MODULES_AVAILABLE else "limited",
        timestamp=datetime.now().isoformat(),
        version="2.0.0",
        modules_available=MODULES_AVAILABLE,
        active_sessions=len(active_sessions),
        system_info={
            "cpu_percent": psutil.cpu_percent(),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_usage_percent": psutil.disk_usage('/').percent,
            "python_version": "3.11+"
        }
    )

@app.post("/api/v1/analyze/batch", response_model=AnalysisResponse)
async def analyze_batch(
    background_tasks: BackgroundTasks,
    request: AnalysisRequest,
    files: List[UploadFile] = File(...)
):
    """ë°°ì¹˜ ë¶„ì„ ì‹œì‘"""
    
    # íŒŒì¼ ìˆ˜ ì œí•œ ê²€ì¦
    if len(files) > 50:
        raise HTTPException(status_code=400, detail="íŒŒì¼ ìˆ˜ëŠ” 50ê°œë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ì´ í¬ê¸° ê²€ì¦
    total_size = sum(file.size for file in files if file.size)
    if total_size > 5 * 1024 * 1024 * 1024:  # 5GB
        raise HTTPException(status_code=400, detail="ì´ íŒŒì¼ í¬ê¸°ëŠ” 5GBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ì„¸ì…˜ ìƒì„±
    session_id = str(uuid.uuid4())
    session_data = {
        "session_id": session_id,
        "session_name": request.session_name,
        "status": "pending",
        "progress": 0.0,
        "files": [],
        "created_at": time.time(),
        "analysis_type": request.analysis_type,
        "total_files": len(files),
        "files_processed": 0,
        "processing_time": 0.0,
        "memory_usage_mb": 0.0,
        "current_stage": "íŒŒì¼ ì—…ë¡œë“œ ì¤‘",
        "result": None,
        "error_message": None
    }
    
    active_sessions[session_id] = session_data
    
    # íŒŒì¼ ë°ì´í„° ì¤€ë¹„
    files_data = []
    temp_dir = tempfile.mkdtemp(prefix=f"solomond_{session_id}_")
    
    try:
        for i, file in enumerate(files):
            # íŒŒì¼ ì €ì¥
            file_path = os.path.join(temp_dir, file.filename)
            content = await file.read()
            
            with open(file_path, 'wb') as f:
                f.write(content)
            
            files_data.append({
                "filename": file.filename,
                "file_path": file_path,
                "size_mb": len(content) / (1024 * 1024),
                "content": content,
                "processed_text": ""  # STT/OCR ê²°ê³¼ê°€ ë“¤ì–´ê°ˆ ìë¦¬
            })
            
            session_data["files"].append({
                "filename": file.filename,
                "size_mb": len(content) / (1024 * 1024),
                "status": "uploaded"
            })
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì‹œì‘
        background_tasks.add_task(
            process_batch_analysis,
            session_id,
            files_data,
            request,
            temp_dir
        )
        
        # ì²˜ë¦¬ ì‹œê°„ ì¶”ì •
        estimated_time = estimate_processing_time(files_data, request.analysis_type)
        
        return AnalysisResponse(
            success=True,
            session_id=session_id,
            message=f"{len(files)}ê°œ íŒŒì¼ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            processing_started=True,
            estimated_time=estimated_time
        )
        
    except Exception as e:
        if session_id in active_sessions:
            del active_sessions[session_id]
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")

@app.post("/api/v1/analyze/streaming", response_model=AnalysisResponse)
async def analyze_streaming(
    background_tasks: BackgroundTasks,
    request: AnalysisRequest,
    files: List[UploadFile] = File(...)
):
    """ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‹œì‘"""
    
    if not MODULES_AVAILABLE or not streaming_engine:
        raise HTTPException(status_code=503, detail="ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    # ë°°ì¹˜ ë¶„ì„ê³¼ ë™ì¼í•œ ìœ íš¨ì„± ê²€ì‚¬
    if len(files) > 50:
        raise HTTPException(status_code=400, detail="íŒŒì¼ ìˆ˜ëŠ” 50ê°œë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session_id = str(uuid.uuid4())
    session_data = {
        "session_id": session_id,
        "session_name": request.session_name,
        "status": "pending",
        "progress": 0.0,
        "files": [],
        "created_at": time.time(),
        "analysis_type": request.analysis_type,
        "total_files": len(files),
        "files_processed": 0,
        "processing_time": 0.0,
        "memory_usage_mb": 0.0,
        "current_stage": "ìŠ¤íŠ¸ë¦¬ë° ì¤€ë¹„ ì¤‘",
        "result": None,
        "error_message": None,
        "streaming_mode": True
    }
    
    active_sessions[session_id] = session_data
    
    # íŒŒì¼ ì¤€ë¹„ ë° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹œì‘
    files_data = []
    temp_dir = tempfile.mkdtemp(prefix=f"solomond_stream_{session_id}_")
    
    try:
        for file in files:
            file_path = os.path.join(temp_dir, file.filename)
            content = await file.read()
            
            with open(file_path, 'wb') as f:
                f.write(content)
            
            files_data.append({
                "filename": file.filename,
                "file_path": file_path,
                "size_mb": len(content) / (1024 * 1024),
                "file_type": detect_file_type(file.filename)
            })
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹œì‘
        background_tasks.add_task(
            process_streaming_analysis,
            session_id,
            files_data,
            request,
            temp_dir
        )
        
        return AnalysisResponse(
            success=True,
            session_id=session_id,
            message=f"ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ ({len(files)}ê°œ íŒŒì¼)",
            processing_started=True,
            estimated_time=estimate_processing_time(files_data, request.analysis_type) * 0.8  # ìŠ¤íŠ¸ë¦¬ë°ì´ ë” ë¹ ë¦„
        )
        
    except Exception as e:
        if session_id in active_sessions:
            del active_sessions[session_id]
        raise HTTPException(status_code=500, detail=f"ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")

@app.get("/api/v1/status/{session_id}", response_model=StatusResponse)
async def get_analysis_status(session_id: str):
    """ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
    
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session = active_sessions[session_id]
    current_time = time.time()
    processing_time = current_time - session["created_at"]
    
    # ë‚¨ì€ ì‹œê°„ ì¶”ì •
    estimated_remaining = None
    if session["progress"] > 0 and session["status"] == "processing":
        estimated_total = processing_time / (session["progress"] / 100)
        estimated_remaining = max(0, estimated_total - processing_time)
    
    return StatusResponse(
        session_id=session_id,
        status=session["status"],
        progress=session["progress"],
        files_processed=session["files_processed"],
        total_files=session["total_files"],
        processing_time=processing_time,
        estimated_remaining=estimated_remaining,
        memory_usage_mb=session["memory_usage_mb"],
        current_stage=session["current_stage"],
        error_message=session.get("error_message")
    )

@app.get("/api/v1/result/{session_id}", response_model=ResultResponse)
async def get_analysis_result(session_id: str):
    """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session = active_sessions[session_id]
    
    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail="ë¶„ì„ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    result = session.get("result", {})
    
    return ResultResponse(
        session_id=session_id,
        success=result.get("success", False),
        final_summary=result.get("hierarchical_summary", {}).get("final_summary", ""),
        quality_score=result.get("quality_assessment", {}).get("quality_score", 0),
        processing_time=session["processing_time"],
        files_processed=session["files_processed"],
        recommendations=result.get("recommendations", []),
        source_summaries=result.get("hierarchical_summary", {}).get("source_summaries", {}),
        metadata={
            "session_name": session.get("session_name", ""),
            "analysis_type": session.get("analysis_type", ""),
            "total_files": session["total_files"],
            "created_at": session["created_at"],
            "completed_at": session.get("completed_at", time.time())
        }
    )

@app.delete("/api/v1/session/{session_id}")
async def delete_session(session_id: str):
    """ì„¸ì…˜ ì‚­ì œ"""
    
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # WebSocket ì—°ê²° ì •ë¦¬
    if session_id in websocket_connections:
        for ws in websocket_connections[session_id]:
            try:
                await ws.close()
            except:
                pass
        del websocket_connections[session_id]
    
    # ì„¸ì…˜ ë°ì´í„° ì‚­ì œ
    del active_sessions[session_id]
    
    return {"message": "ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤", "session_id": session_id}

@app.get("/api/v1/sessions")
async def list_sessions():
    """í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
    
    sessions_info = []
    for session_id, session in active_sessions.items():
        sessions_info.append({
            "session_id": session_id,
            "session_name": session.get("session_name", ""),
            "status": session["status"],
            "progress": session["progress"],
            "created_at": session["created_at"],
            "total_files": session["total_files"],
            "files_processed": session["files_processed"]
        })
    
    return {"sessions": sessions_info, "total": len(sessions_info)}

# WebSocket ì—”ë“œí¬ì¸íŠ¸
@app.websocket("/ws/progress/{session_id}")
async def websocket_progress(websocket: WebSocket, session_id: str):
    """ì‹¤ì‹œê°„ ì§„í–‰ë¥  WebSocket"""
    
    await websocket.accept()
    
    # ì—°ê²° ê´€ë¦¬
    if session_id not in websocket_connections:
        websocket_connections[session_id] = []
    websocket_connections[session_id].append(websocket)
    
    try:
        while True:
            # ì„¸ì…˜ ìƒíƒœ í™•ì¸
            if session_id in active_sessions:
                session = active_sessions[session_id]
                
                progress_data = {
                    "session_id": session_id,
                    "status": session["status"],
                    "progress": session["progress"],
                    "current_stage": session["current_stage"],
                    "files_processed": session["files_processed"],
                    "total_files": session["total_files"],
                    "memory_usage_mb": session["memory_usage_mb"],
                    "timestamp": time.time()
                }
                
                await websocket.send_text(json.dumps(progress_data))
                
                # ì™„ë£Œë˜ë©´ ì—°ê²° ì¢…ë£Œ
                if session["status"] in ["completed", "error"]:
                    break
            else:
                # ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ì—°ê²° ì¢…ë£Œ
                await websocket.send_text(json.dumps({"error": "Session not found"}))
                break
            
            await asyncio.sleep(1)  # 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            
    except WebSocketDisconnect:
        pass
    finally:
        # ì—°ê²° ì •ë¦¬
        if session_id in websocket_connections:
            websocket_connections[session_id].remove(websocket)
            if not websocket_connections[session_id]:
                del websocket_connections[session_id]

# ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
async def process_batch_analysis(session_id: str, files_data: List[Dict], request: AnalysisRequest, temp_dir: str):
    """ë°°ì¹˜ ë¶„ì„ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬"""
    
    session = active_sessions[session_id]
    session["status"] = "processing"
    session["current_stage"] = "íŒŒì¼ ë¶„ì„ ì¤‘"
    
    start_time = time.time()
    
    try:
        # LLM ì²˜ë¦¬
        if llm_summarizer:
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            session["progress"] = 10
            await notify_websocket_clients(session_id, session)
            
            result = await llm_summarizer.process_large_batch(files_data)
            
            session["progress"] = 90
            session["current_stage"] = "ê²°ê³¼ ìƒì„± ì¤‘"
            await notify_websocket_clients(session_id, session)
            
        else:
            # ëª¨ì˜ ì²˜ë¦¬
            for i in range(len(files_data)):
                await asyncio.sleep(0.5)
                session["files_processed"] = i + 1
                session["progress"] = (i + 1) / len(files_data) * 90
                await notify_websocket_clients(session_id, session)
            
            result = create_mock_result(files_data)
        
        # ì™„ë£Œ ì²˜ë¦¬
        session["status"] = "completed"
        session["progress"] = 100
        session["current_stage"] = "ì™„ë£Œ"
        session["result"] = result
        session["processing_time"] = time.time() - start_time
        session["completed_at"] = time.time()
        session["files_processed"] = len(files_data)
        
        await notify_websocket_clients(session_id, session)
        
    except Exception as e:
        session["status"] = "error"
        session["error_message"] = str(e)
        session["processing_time"] = time.time() - start_time
        
        await notify_websocket_clients(session_id, session)
        
        logging.error(f"ë°°ì¹˜ ë¶„ì„ ì˜¤ë¥˜ (ì„¸ì…˜ {session_id}): {e}")
    
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            import shutil
            shutil.rmtree(temp_dir)
        except:
            pass

async def process_streaming_analysis(session_id: str, files_data: List[Dict], request: AnalysisRequest, temp_dir: str):
    """ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬"""
    
    session = active_sessions[session_id]
    session["status"] = "processing"
    session["current_stage"] = "ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘"
    
    start_time = time.time()
    
    try:
        processed_results = []
        
        for i, file_data in enumerate(files_data):
            session["current_stage"] = f"íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_data['filename']}"
            
            if streaming_engine:
                # ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                result = await streaming_engine.process_large_file(
                    file_data["file_path"],
                    file_data["file_type"]
                )
                processed_results.append(result)
            else:
                # ëª¨ì˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                await asyncio.sleep(0.3)
                processed_results.append({"success": True, "filename": file_data["filename"]})
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            session["files_processed"] = i + 1
            session["progress"] = (i + 1) / len(files_data) * 80
            await notify_websocket_clients(session_id, session)
        
        # ê²°ê³¼ í†µí•©
        session["current_stage"] = "ê²°ê³¼ í†µí•© ì¤‘"
        session["progress"] = 85
        await notify_websocket_clients(session_id, session)
        
        # LLM ìš”ì•½
        if llm_summarizer:
            # ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•  í˜•íƒœë¡œ ë³€í™˜
            llm_input = []
            for result in processed_results:
                if result.get("success"):
                    llm_input.append({
                        "filename": result.get("filename", "unknown"),
                        "processed_text": result.get("result", {}).get("processed_text", ""),
                        "size_mb": 1.0  # ì˜ˆì‹œ
                    })
            
            final_result = await llm_summarizer.process_large_batch(llm_input)
        else:
            final_result = create_mock_result(files_data)
        
        # ì™„ë£Œ ì²˜ë¦¬
        session["status"] = "completed"
        session["progress"] = 100
        session["current_stage"] = "ì™„ë£Œ"
        session["result"] = final_result
        session["processing_time"] = time.time() - start_time
        session["completed_at"] = time.time()
        
        await notify_websocket_clients(session_id, session)
        
    except Exception as e:
        session["status"] = "error"
        session["error_message"] = str(e)
        session["processing_time"] = time.time() - start_time
        
        await notify_websocket_clients(session_id, session)
        
        logging.error(f"ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì˜¤ë¥˜ (ì„¸ì…˜ {session_id}): {e}")
    
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            import shutil
            shutil.rmtree(temp_dir)
        except:
            pass

async def notify_websocket_clients(session_id: str, session_data: Dict):
    """WebSocket í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ì—…ë°ì´íŠ¸ ì „ì†¡"""
    
    if session_id in websocket_connections:
        progress_data = {
            "session_id": session_id,
            "status": session_data["status"],
            "progress": session_data["progress"],
            "current_stage": session_data["current_stage"],
            "files_processed": session_data["files_processed"],
            "total_files": session_data["total_files"],
            "timestamp": time.time()
        }
        
        # ì—°ê²°ëœ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
        disconnected_clients = []
        for websocket in websocket_connections[session_id]:
            try:
                await websocket.send_text(json.dumps(progress_data))
            except:
                disconnected_clients.append(websocket)
        
        # ëŠì–´ì§„ ì—°ê²° ì •ë¦¬
        for ws in disconnected_clients:
            websocket_connections[session_id].remove(ws)

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def detect_file_type(filename: str) -> str:
    """íŒŒì¼ íƒ€ì… ê°ì§€"""
    ext = Path(filename).suffix.lower()
    
    if ext in ['.mp3', '.wav', '.m4a', '.aac']:
        return 'audio'
    elif ext in ['.mp4', '.avi', '.mov', '.mkv']:
        return 'video'
    elif ext in ['.pdf', '.docx', '.txt']:
        return 'document'
    elif ext in ['.jpg', '.jpeg', '.png', '.gif']:
        return 'image'
    else:
        return 'unknown'

def estimate_processing_time(files_data: List[Dict], analysis_type: str) -> float:
    """ì²˜ë¦¬ ì‹œê°„ ì¶”ì •"""
    base_time_per_mb = 2.0  # ì´ˆ/MB
    
    total_mb = sum(f.get("size_mb", 0) for f in files_data)
    base_time = total_mb * base_time_per_mb
    
    # ë¶„ì„ íƒ€ì…ë³„ ê°€ì¤‘ì¹˜
    type_multiplier = {
        "comprehensive": 1.5,
        "executive": 1.0,
        "technical": 1.2,
        "business": 1.1
    }
    
    multiplier = type_multiplier.get(analysis_type, 1.0)
    return base_time * multiplier

def create_mock_result(files_data: List[Dict]) -> Dict:
    """ëª¨ì˜ ê²°ê³¼ ìƒì„±"""
    return {
        "success": True,
        "session_id": str(uuid.uuid4()),
        "processing_time": 15.5,
        "files_processed": len(files_data),
        "chunks_processed": len(files_data) * 3,
        "hierarchical_summary": {
            "final_summary": "ì£¼ì–¼ë¦¬ ì‹œì¥ ë¶„ì„ ê²°ê³¼, ë‹¤ì´ì•„ëª¬ë“œ ê°€ê²© ìƒìŠ¹ì„¸ì™€ GIA ì¸ì¦ì„œ ì¤‘ìš”ì„± ì¦ëŒ€ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "source_summaries": {
                "audio": {"summary": "ìŒì„± ë¶„ì„ ìš”ì•½", "chunk_count": 5},
                "documents": {"summary": "ë¬¸ì„œ ë¶„ì„ ìš”ì•½", "chunk_count": 7}
            }
        },
        "quality_assessment": {
            "quality_score": 87.5,
            "coverage_ratio": 0.82,
            "compression_ratio": 0.15
        },
        "recommendations": [
            "ìš°ìˆ˜í•œ í’ˆì§ˆì˜ ìš”ì•½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì»¤ë²„ë¦¬ì§€ê°€ ì–‘í˜¸í•©ë‹ˆë‹¤."
        ]
    }

# ì˜ˆì™¸ ì²˜ë¦¬
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content={"error": exc.detail, "status_code": exc.status_code}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logging.error(f"API ì˜¤ë¥˜: {exc}")
    return JSONResponse(
        status_code=500,
        content={"error": "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "status_code": 500}
    )

# ê°œë°œìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import uvicorn
    
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸš€ ì†”ë¡œëª¬ë“œ AI API ì„œë²„ ì‹œì‘")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸŒ WebSocket: ws://localhost:8000/ws/progress/{session_id}")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
