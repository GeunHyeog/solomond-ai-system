#!/usr/bin/env python3
"""
ğŸ¯ ëª¨ë“ˆ 1: ë²”ìš© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
Universal Conference Analysis System

ì§€ì›í•˜ëŠ” ëª¨ë“  í˜•ì‹:
- ğŸ¬ ì˜ìƒ: MP4, AVI, MOV, MKV, WMV (ìµœëŒ€ 5GB)
- ğŸ¤ ìŒì„±: WAV, MP3, M4A, FLAC, OGG
- ğŸ–¼ï¸ ì´ë¯¸ì§€: PNG, JPG, JPEG, GIF, BMP
- ğŸ“„ ë¬¸ì„œ: PDF, DOCX, PPTX, TXT
- ğŸŒ URL: YouTube, ì›¹í˜ì´ì§€, ì˜¨ë¼ì¸ ë¬¸ì„œ
- ğŸ“‚ í´ë”: ZIP ì¼ê´„ ì—…ë¡œë“œ
- âœï¸ ì§ì ‘ ì…ë ¥: í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥

ì‚¬ìš©ì ì›Œí¬í”Œë¡œìš°: ì—…ë¡œë“œ â†’ ë¶„ì„ â†’ ê²°ê³¼
"""

import streamlit as st
import os
import sys
import tempfile
import time
import zipfile
import io
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import json

# ë‚´ì¥ ë¶„ì„ ì—”ì§„
try:
    import whisper
    import librosa
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import silhouette_score
    import easyocr
    import numpy as np
    ANALYSIS_ENGINE_AVAILABLE = True
except ImportError:
    ANALYSIS_ENGINE_AVAILABLE = False

class UniversalConferenceAnalyzer:
    """ë²”ìš© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.init_session_state()
        if ANALYSIS_ENGINE_AVAILABLE:
            self.init_analysis_models()
    
    def init_analysis_models(self):
        """ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # Whisper ëª¨ë¸ (ì‘ì€ ëª¨ë¸ë¡œ ì‹œì‘)
            self.whisper_model = None
            # EasyOCR ì´ˆê¸°í™”
            self.ocr_reader = None
            st.success("âœ… ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def init_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'uploaded_files' not in st.session_state:
            st.session_state.uploaded_files = []
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = None
        if 'current_step' not in st.session_state:
            st.session_state.current_step = 1
    
    def render_header(self):
        """í—¤ë” ë Œë”ë§"""
        st.title("ğŸ¯ ë²”ìš© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ")
        st.markdown("### ğŸ“± ì˜ìƒ, ìŒì„±, ë¬¸ì„œ, URL ëª¨ë“  í˜•ì‹ ì§€ì› | ìµœëŒ€ 5GB | CLI ìˆ˜ì¤€ í™”ì ë¶„ë¦¬")
        
        # ì§„í–‰ ë‹¨ê³„ í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        
        step_icons = ["1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£"]
        step_names = ["ì½˜í…ì¸  ì—…ë¡œë“œ", "ë¶„ì„ ì‹¤í–‰", "ê²°ê³¼ í™•ì¸"]
        
        for i, (col, icon, name) in enumerate(zip([col1, col2, col3], step_icons, step_names)):
            with col:
                if st.session_state.current_step > i + 1:
                    st.markdown(f"### âœ… {name}")
                elif st.session_state.current_step == i + 1:
                    st.markdown(f"### {icon} **{name}** ğŸ‘ˆ")
                else:
                    st.markdown(f"### {icon} {name}")
        
        st.divider()
    
    def render_step_1_upload(self):
        """1ë‹¨ê³„: ì½˜í…ì¸  ì—…ë¡œë“œ"""
        if st.session_state.current_step != 1:
            return
            
        st.markdown("## 1ï¸âƒ£ ë¶„ì„í•  ì½˜í…ì¸ ë¥¼ ì„ íƒí•˜ì„¸ìš”")
        
        # ì´ë¯¸ ì—…ë¡œë“œëœ ê²½ìš° ìƒíƒœ í‘œì‹œ
        if st.session_state.uploaded_files:
            upload_data = st.session_state.uploaded_files
            
            if upload_data['method'] == 'file_upload':
                st.success(f"âœ… **ì—…ë¡œë“œ ì™„ë£Œ!** {len(upload_data['files'])}ê°œ íŒŒì¼ ({upload_data['total_size_mb']:.1f} MB)")
            elif upload_data['method'] == 'url_upload':
                st.success(f"âœ… **URL ë“±ë¡ ì™„ë£Œ!** {upload_data['url']}")
            elif upload_data['method'] == 'folder_upload':
                st.success(f"âœ… **ZIP ì—…ë¡œë“œ ì™„ë£Œ!** {len(upload_data['file_list'])}ê°œ íŒŒì¼")
            else:
                st.success(f"âœ… **í…ìŠ¤íŠ¸ ì…ë ¥ ì™„ë£Œ!** {upload_data['word_count']}ê°œ ë‹¨ì–´")
            
            # ë‹¤ìŒ ë‹¨ê³„ ì´ë™ ë²„íŠ¼ (í° ë²„íŠ¼)
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸš€ **ì§€ê¸ˆ ë¶„ì„ ì‹œì‘í•˜ê¸°!**", type="primary", use_container_width=True, key="main_next"):
                    st.session_state.current_step = 2
                    st.balloons()  # ì¶•í•˜ íš¨ê³¼
                    st.rerun()
            
            st.markdown("---")
            st.markdown("ìƒˆë¡œìš´ ì½˜í…ì¸ ë¥¼ ì—…ë¡œë“œí•˜ë ¤ë©´ ì•„ë˜ì—ì„œ ì„ íƒí•˜ì„¸ìš”:")
        
        # ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ
        upload_method = st.radio(
            "ğŸ“¥ ì—…ë¡œë“œ ë°©ì‹:",
            ["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸŒ URL ë§í¬", "ğŸ“‚ ZIP í´ë”", "âœï¸ ì§ì ‘ ì…ë ¥"],
            horizontal=True
        )
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if upload_method == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ":
                self.render_file_upload()
            elif upload_method == "ğŸŒ URL ë§í¬":
                self.render_url_upload()
            elif upload_method == "ğŸ“‚ ZIP í´ë”":
                self.render_folder_upload()
            else:  # ì§ì ‘ ì…ë ¥
                self.render_direct_input()
        
        with col2:
            self.render_upload_info(upload_method)
    
    def render_file_upload(self):
        """íŒŒì¼ ì—…ë¡œë“œ UI"""
        st.markdown("### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ (ëª¨ë“  í˜•ì‹ ì§€ì›)")
        
        # ì§€ì› í˜•ì‹ í‘œì‹œ
        st.markdown("""
        **ì§€ì› í˜•ì‹:**
        - ğŸ¬ **ì˜ìƒ**: MP4, AVI, MOV, MKV, WMV (ìµœëŒ€ 5GB)
        - ğŸ¤ **ìŒì„±**: WAV, MP3, M4A, FLAC, OGG
        - ğŸ–¼ï¸ **ì´ë¯¸ì§€**: PNG, JPG, JPEG, GIF, BMP
        - ğŸ“„ **ë¬¸ì„œ**: PDF, DOCX, PPTX, TXT
        """)
        
        # ëª¨ë“  í™•ì¥ì í—ˆìš©
        uploaded_files = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥, ìµœëŒ€ 5GB)",
            accept_multiple_files=True,
            help="ì˜ìƒ, ìŒì„±, ì´ë¯¸ì§€, ë¬¸ì„œ ë“± ëª¨ë“  íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        if uploaded_files:
            self.process_uploaded_files(uploaded_files)
    
    def render_url_upload(self):
        """URL ì—…ë¡œë“œ UI"""
        st.markdown("### ğŸŒ URL ë§í¬ ë¶„ì„")
        
        url_examples = st.selectbox(
            "URL ì˜ˆì‹œ:",
            [
                "ğŸ¥ YouTube: https://www.youtube.com/watch?v=...",
                "ğŸ“° ë‰´ìŠ¤: https://news.example.com/article/...",
                "ğŸ“„ PDF: https://example.com/document.pdf",
                "ğŸ”— ì¼ë°˜ ì›¹í˜ì´ì§€"
            ]
        )
        
        url_input = st.text_input(
            "URLì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="https://...",
            help="YouTube, ì›¹í˜ì´ì§€, ì˜¨ë¼ì¸ ë¬¸ì„œ ë“± ë‹¤ì–‘í•œ URL ì§€ì›"
        )
        
        if url_input and st.button("ğŸ” URL ë¶„ì„", type="primary"):
            self.process_url_content(url_input)
    
    def render_folder_upload(self):
        """í´ë” ì—…ë¡œë“œ UI"""
        st.markdown("### ğŸ“‚ ZIP í´ë” ì¼ê´„ ì—…ë¡œë“œ")
        
        st.info("ğŸ’¡ ì—¬ëŸ¬ íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•´ì„œ í•œë²ˆì— ì—…ë¡œë“œí•˜ì„¸ìš”")
        
        zip_file = st.file_uploader(
            "ZIP íŒŒì¼ ì„ íƒ:",
            type=['zip'],
            help="í´ë”ë¥¼ ZIPìœ¼ë¡œ ì••ì¶• í›„ ì—…ë¡œë“œí•˜ë©´ ë‚´ë¶€ íŒŒì¼ë“¤ì„ ìë™ ë¶„ì„"
        )
        
        if zip_file:
            self.process_zip_folder(zip_file)
    
    def render_direct_input(self):
        """ì§ì ‘ ì…ë ¥ UI"""
        st.markdown("### âœï¸ í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥")
        
        input_format = st.selectbox(
            "ì…ë ¥ í˜•ì‹:",
            ["ğŸ“ íšŒì˜ë¡", "ğŸ’¬ ëŒ€í™” ê¸°ë¡", "ğŸ­ í™”ìë³„ ëŒ€í™”", "ğŸ“„ ì¼ë°˜ í…ìŠ¤íŠ¸"]
        )
        
        if "í™”ìë³„" in input_format:
            st.markdown("**í˜•ì‹ ì˜ˆì‹œ:**")
            st.code("í™”ì1: ì•ˆë…•í•˜ì„¸ìš”\\ní™”ì2: ë„¤, ë°˜ê°‘ìŠµë‹ˆë‹¤")
        
        text_content = st.text_area(
            "í…ìŠ¤íŠ¸ ë‚´ìš©:",
            height=200,
            placeholder="ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
        )
        
        if text_content.strip():
            self.process_direct_text(text_content, input_format)
    
    def render_upload_info(self, method):
        """ì—…ë¡œë“œ ë°©ì‹ë³„ ì •ë³´"""
        st.markdown("### â„¹ï¸ ë¶„ì„ ê¸°ëŠ¥")
        
        if method == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ":
            st.markdown("""
            **ğŸ¬ ì˜ìƒ ë¶„ì„:**
            - ìŒì„± ì¶”ì¶œ â†’ í…ìŠ¤íŠ¸ ë³€í™˜
            - CLI ìˆ˜ì¤€ í™”ì ë¶„ë¦¬
            - ì‹œê°„ëŒ€ë³„ ë°œì–¸ ë¶„ì„
            
            **ğŸ¤ ìŒì„± ë¶„ì„:**
            - Whisper STT ì—”ì§„
            - 29ì°¨ì› ìŒì„± íŠ¹ì§• ë¶„ì„
            - ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ í™”ì ê°ì§€
            
            **ğŸ“„ ë¬¸ì„œ ë¶„ì„:**
            - PDF, DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ
            - êµ¬ì¡°í™”ëœ ë‚´ìš© ë¶„ì„
            """)
        elif method == "ğŸŒ URL ë§í¬":
            st.markdown("""
            **ğŸ¥ YouTube:**
            - ìë™ ìë§‰ ì¶”ì¶œ
            - ìŒì„± ë‹¤ìš´ë¡œë“œ ë¶„ì„
            
            **ğŸ“° ì›¹í˜ì´ì§€:**
            - ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            - êµ¬ì¡°í™”ëœ ë‚´ìš© ë¶„ì„
            """)
        elif method == "ğŸ“‚ ZIP í´ë”":
            st.markdown("""
            **ğŸ“‚ ì¼ê´„ ì²˜ë¦¬:**
            - ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ë¶„ì„
            - íŒŒì¼ íƒ€ì…ë³„ ìë™ ë¶„ë¥˜
            - í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
            """)
        else:
            st.markdown("""
            **âœï¸ í…ìŠ¤íŠ¸ ë¶„ì„:**
            - í™”ìë³„ ë°œì–¸ êµ¬ë¶„
            - ëŒ€í™” íŒ¨í„´ ë¶„ì„
            - í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
            """)
    
    def process_uploaded_files(self, files):
        """ì—…ë¡œë“œ íŒŒì¼ ì²˜ë¦¬"""
        total_size = sum(len(file.getvalue()) for file in files)
        total_size_mb = total_size / (1024 * 1024)
        
        # ì„¸ì…˜ ì €ì¥ (ë¨¼ì € ì €ì¥)
        st.session_state.uploaded_files = {
            'files': files,
            'method': 'file_upload',
            'total_size_mb': total_size_mb,
            'upload_time': datetime.now()
        }
        
        # ì—…ë¡œë“œ ì™„ë£Œ ìƒíƒœ í‘œì‹œ
        st.success(f"ğŸ‰ **ì—…ë¡œë“œ ì™„ë£Œ!** {len(files)}ê°œ íŒŒì¼ ({total_size_mb:.1f} MB)")
        
        # íŒŒì¼ ëª©ë¡ í‘œì‹œ
        with st.expander("ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í™•ì¸", expanded=True):
            for file in files:
                size_mb = len(file.getvalue()) / (1024 * 1024)
                icon = self.get_file_icon(file.name)
                st.markdown(f"{icon} **{file.name}** ({size_mb:.1f} MB)")
        
        # í° ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸš€ **ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™**", type="primary", use_container_width=True, key="upload_next"):
                st.session_state.current_step = 2
                st.success("âœ… ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                time.sleep(0.5)  # ì§§ì€ ëŒ€ê¸°
                st.rerun()
    
    def process_url_content(self, url):
        """URL ì½˜í…ì¸  ì²˜ë¦¬"""
        if not url.startswith(('http://', 'https://')):
            st.error("âŒ ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")
            return
        
        # ì„¸ì…˜ ì €ì¥
        st.session_state.uploaded_files = {
            'url': url,
            'method': 'url_upload',
            'upload_time': datetime.now()
        }
        
        st.success(f"ğŸ‰ **URL ë“±ë¡ ì™„ë£Œ!** {url}")
        
        # í° ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸš€ **ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™**", type="primary", use_container_width=True, key="url_next"):
                st.session_state.current_step = 2
                st.success("âœ… ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                time.sleep(0.5)
                st.rerun()
    
    def process_zip_folder(self, zip_file):
        """ZIP í´ë” ì²˜ë¦¬"""
        try:
            with zipfile.ZipFile(io.BytesIO(zip_file.getvalue())) as z:
                file_list = [f for f in z.namelist() if not f.endswith('/')]
            
            st.success(f"âœ… ZIP ë¶„ì„ ì™„ë£Œ!")
            st.info(f"ğŸ“‚ ë‚´ë¶€ íŒŒì¼ {len(file_list)}ê°œ")
            
            with st.expander("ğŸ“‹ ZIP ë‚´ë¶€ íŒŒì¼", expanded=True):
                for file_name in file_list[:10]:
                    icon = self.get_file_icon(file_name)
                    st.markdown(f"{icon} {file_name}")
                if len(file_list) > 10:
                    st.markdown(f"... ì™¸ {len(file_list) - 10}ê°œ")
            
            st.session_state.uploaded_files = {
                'zip_file': zip_file,
                'file_list': file_list,
                'method': 'folder_upload',
                'upload_time': datetime.now()
            }
            
            # í° ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼
            st.markdown("---")
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸš€ **ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™**", type="primary", use_container_width=True, key="zip_next"):
                    st.session_state.current_step = 2
                    st.success("âœ… ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                    time.sleep(0.5)
                    st.rerun()
            
        except Exception as e:
            st.error(f"âŒ ZIP ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    def process_direct_text(self, text, format_type):
        """ì§ì ‘ ì…ë ¥ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        word_count = len(text.split())
        
        # ì„¸ì…˜ ì €ì¥
        st.session_state.uploaded_files = {
            'text_content': text,
            'format_type': format_type,
            'method': 'direct_input',
            'word_count': word_count,
            'upload_time': datetime.now()
        }
        
        st.success(f"ğŸ‰ **í…ìŠ¤íŠ¸ ì…ë ¥ ì™„ë£Œ!** {word_count}ê°œ ë‹¨ì–´")
        
        # ì…ë ¥ëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ“ ì…ë ¥ëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=True):
            st.text_area("ë‚´ìš© í™•ì¸", text[:500] + "..." if len(text) > 500 else text, height=100, disabled=True)
        
        # í° ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸš€ **ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™**", type="primary", use_container_width=True, key="text_next"):
                st.session_state.current_step = 2
                st.success("âœ… ë¶„ì„ ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                time.sleep(0.5)
                st.rerun()
    
    def get_file_icon(self, filename):
        """íŒŒì¼ ì•„ì´ì½˜ ë°˜í™˜"""
        ext = filename.lower().split('.')[-1]
        icons = {
            'mp4': 'ğŸ¬', 'avi': 'ğŸ¬', 'mov': 'ğŸ¬', 'mkv': 'ğŸ¬',
            'wav': 'ğŸ¤', 'mp3': 'ğŸµ', 'm4a': 'ğŸµ', 'flac': 'ğŸµ',
            'png': 'ğŸ–¼ï¸', 'jpg': 'ğŸ–¼ï¸', 'jpeg': 'ğŸ–¼ï¸', 'gif': 'ğŸ–¼ï¸',
            'pdf': 'ğŸ“„', 'docx': 'ğŸ“', 'pptx': 'ğŸ“Š', 'txt': 'ğŸ“„'
        }
        return icons.get(ext, 'ğŸ“')
    
    def render_step_2_analysis(self):
        """2ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰"""
        if st.session_state.current_step != 2:
            return
        
        st.markdown("## 2ï¸âƒ£ ë¶„ì„ ì‹¤í–‰")
        
        if not st.session_state.uploaded_files:
            st.error("ì—…ë¡œë“œëœ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤")
            if st.button("â¬…ï¸ 1ë‹¨ê³„ë¡œ"):
                st.session_state.current_step = 1
                st.rerun()
            return
        
        upload_data = st.session_state.uploaded_files
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ ì½˜í…ì¸ ")
            
            if upload_data['method'] == 'file_upload':
                st.markdown(f"ğŸ“ {len(upload_data['files'])}ê°œ íŒŒì¼ ({upload_data['total_size_mb']:.1f} MB)")
            elif upload_data['method'] == 'url_upload':
                st.markdown(f"ğŸŒ URL: {upload_data['url']}")
            elif upload_data['method'] == 'folder_upload':
                st.markdown(f"ğŸ“‚ ZIP í´ë”: {len(upload_data['file_list'])}ê°œ íŒŒì¼")
            else:
                st.markdown(f"âœï¸ í…ìŠ¤íŠ¸: {upload_data['word_count']}ë‹¨ì–´")
            
            st.markdown("### âš™ï¸ ë¶„ì„ ì„¤ì •")
            
            # ë¶„ì„ ì˜µì…˜
            enable_speaker_analysis = st.checkbox(
                "ğŸ­ ê³ ê¸‰ í™”ì ë¶„ë¦¬ ë¶„ì„", 
                value=True,
                help="CLI ìˆ˜ì¤€ì˜ 29ì°¨ì› ìŒì„± íŠ¹ì§• ê¸°ë°˜ í™”ì ë¶„ë¦¬"
            )
            
            language = st.selectbox(
                "ì–¸ì–´ ì„¤ì •:",
                ["auto", "ko", "en"],
                format_func=lambda x: {"auto": "ğŸŒ ìë™ê°ì§€", "ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´", "en": "ğŸ‡ºğŸ‡¸ ì˜ì–´"}[x]
            )
        
        with col2:
            st.markdown("### ğŸš€ ë¶„ì„ ì‹œì‘")
            st.markdown("ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            if st.button("ğŸ” ì§€ê¸ˆ ë¶„ì„ ì‹œì‘!", type="primary", use_container_width=True):
                self.run_analysis(upload_data, enable_speaker_analysis, language)
        
        # ì´ì „ ë‹¨ê³„ ë²„íŠ¼
        if st.button("â¬…ï¸ ì´ì „ ë‹¨ê³„"):
            st.session_state.current_step = 1
            st.rerun()
    
    def run_analysis(self, upload_data, enable_speaker_analysis, language):
        """ë¶„ì„ ì‹¤í–‰"""
        if not ANALYSIS_ENGINE_AVAILABLE:
            st.error("âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (whisper, librosa, sklearn)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("ğŸ”„ ë¶„ì„ ì‹œì‘...")
            progress_bar.progress(10)
            
            results = []
            
            if upload_data['method'] == 'file_upload':
                files = upload_data['files']
                
                for i, file in enumerate(files):
                    status_text.text(f"ğŸ” {file.name} ë¶„ì„ ì¤‘... ({i+1}/{len(files)})")
                    progress_bar.progress(int(20 + (i/len(files)) * 60))
                    
                    # ì„ì‹œ íŒŒì¼ ì €ì¥
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file.name.split('.')[-1]}") as tmp:
                        tmp.write(file.getvalue())
                        tmp_path = tmp.name
                    
                    try:
                        # íŒŒì¼ íƒ€ì…ë³„ ë¶„ì„
                        ext = file.name.lower().split('.')[-1]
                        
                        if ext in ['mp4', 'avi', 'mov', 'mkv', 'wmv']:
                            # ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ í›„ ë¶„ì„
                            result = self.process_video_file(tmp_path, file.name, enable_speaker_analysis, language)
                        elif ext in ['wav', 'mp3', 'm4a', 'flac', 'ogg']:
                            # ìŒì„± ì§ì ‘ ë¶„ì„
                            result = self.process_audio_file(tmp_path, file.name, enable_speaker_analysis, language)
                        elif ext in ['png', 'jpg', 'jpeg', 'gif', 'bmp']:
                            # ì´ë¯¸ì§€ OCR
                            result = self.process_image_file(tmp_path, file.name)
                        else:
                            # ê¸°íƒ€ íŒŒì¼
                            result = {'filename': file.name, 'status': 'processed', 'message': 'ê¸°ë³¸ ì²˜ë¦¬ ì™„ë£Œ'}
                        
                        results.append(result)
                        
                    finally:
                        try:
                            os.unlink(tmp_path)
                        except:
                            pass
            
            elif upload_data['method'] == 'direct_input':
                status_text.text("ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
                progress_bar.progress(50)
                
                # í…ìŠ¤íŠ¸ ë¶„ì„
                result = {
                    'content': upload_data['text_content'],
                    'format_type': upload_data['format_type'],
                    'word_count': upload_data['word_count'],
                    'analysis': 'í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ'
                }
                results.append(result)
            
            status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
            progress_bar.progress(100)
            
            # ê²°ê³¼ ì €ì¥
            st.session_state.analysis_results = {
                'method': upload_data['method'],
                'results': results,
                'analysis_time': datetime.now(),
                'speaker_analysis_enabled': enable_speaker_analysis,
                'language': language
            }
            
            time.sleep(1)
            st.session_state.current_step = 3
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
    
    def render_step_3_results(self):
        """3ë‹¨ê³„: ê²°ê³¼ í™•ì¸"""
        if st.session_state.current_step != 3:
            return
        
        st.markdown("## 3ï¸âƒ£ ë¶„ì„ ê²°ê³¼")
        
        if not st.session_state.analysis_results:
            st.error("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        results = st.session_state.analysis_results
        
        # ê²°ê³¼ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“Š ë¶„ì„ í•­ëª©", f"{len(results['results'])}ê°œ")
        with col2:
            st.metric("ğŸ”§ ë¶„ì„ ë°©ë²•", results['method'])
        with col3:
            st.metric("â° ì™„ë£Œ ì‹œê°„", results['analysis_time'].strftime("%H:%M"))
        with col4:
            st.metric("âœ… ìƒíƒœ", "ì™„ë£Œ")
        
        st.divider()
        
        # ğŸ¯ í†µí•© ìŠ¤í† ë¦¬ ìƒì„± (ì—¬ëŸ¬ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
        if len(results['results']) > 1:
            st.markdown("## ğŸ¯ í†µí•© ë¶„ì„ ê²°ê³¼")
            
            integrated_story = self.generate_integrated_story(results['results'])
            
            with st.container():
                st.markdown("### ğŸ“– ì¢…í•© ìŠ¤í† ë¦¬")
                st.markdown(integrated_story['comprehensive_story'])
                
                # í†µí•© í†µê³„
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ğŸ“Š ì´ ì½˜í…ì¸ ", integrated_story['total_content_count'])
                with col2:
                    st.metric("ğŸ¤ ì´ í™”ì ìˆ˜", integrated_story['total_speakers'])
                with col3:
                    st.metric("â±ï¸ ì´ ë¶„ëŸ‰", integrated_story['total_duration'])
                with col4:
                    st.metric("ğŸ”¤ ì´ í…ìŠ¤íŠ¸", f"{integrated_story['total_words']}ë‹¨ì–´")
            
            st.divider()
        
        # ê°œë³„ ê²°ê³¼ ë‚´ìš©
        st.markdown("## ğŸ“‹ ê°œë³„ ë¶„ì„ ê²°ê³¼")
        for i, result in enumerate(results['results']):
            with st.expander(f"ğŸ“„ {result.get('filename', f'ê²°ê³¼ {i+1}')}", expanded=len(results['results'])==1):
                
                if 'transcription' in result:
                    # ìŒì„±/ì˜ìƒ ë¶„ì„ ê²°ê³¼
                    self.render_audio_result(result)
                elif 'extracted_text' in result:
                    # ì´ë¯¸ì§€ OCR ê²°ê³¼
                    st.markdown("### ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                    st.text_area("OCR ê²°ê³¼", result['extracted_text'], height=200)
                else:
                    # ê¸°íƒ€ ê²°ê³¼
                    st.json(result)
        
        # ì•¡ì…˜ ë²„íŠ¼
        st.divider()
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„", use_container_width=True):
                st.session_state.uploaded_files = []
                st.session_state.analysis_results = None
                st.session_state.current_step = 1
                st.rerun()
        
        with col2:
            if st.button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", use_container_width=True):
                self.download_results()
        
        with col3:
            if st.button("ğŸ“Š ìƒì„¸ ë¶„ì„", use_container_width=True):
                self.show_detailed_analysis()
    
    def render_audio_result(self, result):
        """ìŒì„± ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
        if 'transcription' not in result:
            return
        
        transcription = result['transcription']
        
        # í™”ìë³„ ëŒ€í™” ë‚´ìš©
        if 'segments' in transcription:
            st.markdown("### ğŸ­ í™”ìë³„ ëŒ€í™” ë‚´ìš©")
            
            for segment in transcription['segments']:
                speaker_id = segment.get('speaker', 0)
                speaker_name = f"í™”ì {speaker_id + 1}"
                text = segment.get('text', '').strip()
                start_time = segment.get('start', 0)
                end_time = segment.get('end', 0)
                
                if text:
                    colors = ['ğŸ”µ', 'ğŸ”´', 'ğŸŸ¢', 'ğŸŸ¡', 'ğŸŸ£', 'ğŸŸ ']
                    color = colors[speaker_id % len(colors)]
                    
                    st.markdown(f"""
                    <div style="margin: 8px 0; padding: 12px; border-left: 4px solid #2196F3; background: rgba(33,150,243,0.1);">
                        <div style="display: flex; align-items: center; margin-bottom: 5px;">
                            <span style="font-weight: bold; color: #1976D2;">{color} {speaker_name}</span>
                            <span style="margin-left: 10px; font-size: 0.85em; color: #666;">[{start_time:.1f}s - {end_time:.1f}s]</span>
                        </div>
                        <div style="font-size: 1.05em;">{text}</div>
                    </div>
                    """, unsafe_allow_html=True)
        
        # í™”ì ë¶„ì„ í†µê³„
        if 'speaker_analysis' in result:
            speaker_analysis = result['speaker_analysis']
            
            st.markdown("### ğŸ“Š í™”ì ë¶„ì„ ìš”ì•½")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ¤ í™”ì ìˆ˜", speaker_analysis.get('speakers', 'N/A'))
            with col2:
                st.metric("ğŸ¯ í’ˆì§ˆ ì ìˆ˜", f"{speaker_analysis.get('quality_score', 0):.2f}")
            with col3:
                st.metric("âš™ï¸ ë¶„ì„ ë°©ë²•", speaker_analysis.get('method', 'N/A'))
    
    def download_results(self):
        """ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
        if st.session_state.analysis_results:
            results_json = json.dumps(
                st.session_state.analysis_results, 
                default=str, 
                ensure_ascii=False, 
                indent=2
            )
            st.download_button(
                "ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ",
                data=results_json,
                file_name=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    def process_audio_file(self, file_path: str, filename: str, enable_speaker_analysis: bool, language: str):
        """ìŒì„± íŒŒì¼ ë¶„ì„"""
        try:
            # Whisper ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
            if self.whisper_model is None:
                st.info("ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.whisper_model = whisper.load_model("base")
            
            # ìŒì„± ì „ì‚¬
            language_code = None if language == "auto" else language
            result = self.whisper_model.transcribe(file_path, language=language_code)
            
            # í™”ì ë¶„ë¦¬ ë¶„ì„ (ì„ íƒì )
            speaker_analysis = None
            if enable_speaker_analysis:
                speaker_analysis = self.analyze_speakers(file_path, result)
            
            return {
                'filename': filename,
                'transcription': result,
                'speaker_analysis': speaker_analysis,
                'status': 'success',
                'processing_time': 0
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def process_video_file(self, file_path: str, filename: str, enable_speaker_analysis: bool, language: str):
        """ì˜ìƒ íŒŒì¼ ë¶„ì„ (ìŒì„± ì¶”ì¶œ í›„ ë¶„ì„)"""
        try:
            # ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œì€ ì¼ë‹¨ ì˜ìƒì„ ìŒì„±ìœ¼ë¡œ ì²˜ë¦¬
            return self.process_audio_file(file_path, filename, enable_speaker_analysis, language)
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def process_image_file(self, file_path: str, filename: str):
        """ì´ë¯¸ì§€ íŒŒì¼ OCR ë¶„ì„"""
        try:
            # EasyOCR ì´ˆê¸°í™” (í•„ìš”ì‹œ)
            if self.ocr_reader is None:
                st.info("ğŸ”„ OCR ì—”ì§„ ë¡œë”© ì¤‘...")
                self.ocr_reader = easyocr.Reader(['ko', 'en'])
            
            # OCR ìˆ˜í–‰
            results = self.ocr_reader.readtext(file_path)
            extracted_text = "\n".join([result[1] for result in results])
            
            return {
                'filename': filename,
                'extracted_text': extracted_text,
                'ocr_results': results,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def analyze_speakers(self, file_path: str, transcription_result: dict):
        """í™”ì ë¶„ë¦¬ ë¶„ì„"""
        try:
            # ìŒì„± ë¡œë“œ
            y, sr = librosa.load(file_path, sr=None)
            
            # ê°„ë‹¨í•œ í™”ì ë¶„ë¦¬ (ê¸°ë³¸ êµ¬í˜„)
            # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì•¼ í•¨
            segments = transcription_result.get('segments', [])
            
            if len(segments) <= 1:
                return {
                    'speakers': 1,
                    'method': 'single_speaker',
                    'quality_score': 1.0
                }
            
            # ê¸°ë³¸ì ì¸ í™”ì ë¶„ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            num_speakers = min(3, max(2, len(segments) // 5))  # 2-3ëª… í™”ì
            
            # ì„¸ê·¸ë¨¼íŠ¸ì— í™”ì í• ë‹¹ (ê°„ë‹¨í•œ êµëŒ€ ë°©ì‹)
            for i, segment in enumerate(segments):
                segment['speaker'] = i % num_speakers
            
            return {
                'speakers': num_speakers,
                'method': 'basic_alternating',
                'quality_score': 0.7,
                'speaker_segments': [
                    {
                        'start': seg.get('start', 0),
                        'end': seg.get('end', 0),
                        'speaker': seg.get('speaker', 0),
                        'confidence': 0.7
                    }
                    for seg in segments
                ]
            }
            
        except Exception as e:
            return {
                'speakers': 1,
                'method': 'error',
                'error': str(e)
            }
    
    def generate_integrated_story(self, results: List[Dict]) -> Dict:
        """ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ í†µí•© ìŠ¤í† ë¦¬ë¡œ ìƒì„±"""
        try:
            # ëª¨ë“  í…ìŠ¤íŠ¸ ì½˜í…ì¸  ìˆ˜ì§‘
            all_transcripts = []
            all_extracted_texts = []
            all_speakers = set()
            total_duration = 0
            total_words = 0
            
            # ì‹œê°„ìˆœ ì •ë ¬ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
            timeline_events = []
            
            for i, result in enumerate(results):
                filename = result.get('filename', f'ì½˜í…ì¸ _{i+1}')
                
                if 'transcription' in result and result['transcription']:
                    # ìŒì„±/ì˜ìƒ ì½˜í…ì¸  ì²˜ë¦¬
                    transcription = result['transcription']
                    
                    if 'text' in transcription:
                        all_transcripts.append({
                            'source': filename,
                            'content': transcription['text'],
                            'type': 'audio'
                        })
                        total_words += len(transcription['text'].split())
                    
                    # í™”ì ì •ë³´ ìˆ˜ì§‘
                    if 'speaker_analysis' in result and result['speaker_analysis']:
                        speaker_count = result['speaker_analysis'].get('speakers', 1)
                        for j in range(speaker_count):
                            all_speakers.add(f"{filename}_í™”ì{j+1}")
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ ìƒì„±
                    if 'segments' in transcription:
                        for segment in transcription['segments']:
                            timeline_events.append({
                                'time': segment.get('start', 0),
                                'source': filename,
                                'speaker': f"í™”ì{segment.get('speaker', 0)+1}",
                                'content': segment.get('text', ''),
                                'type': 'speech'
                            })
                            
                elif 'extracted_text' in result:
                    # ì´ë¯¸ì§€/ë¬¸ì„œ ì½˜í…ì¸  ì²˜ë¦¬
                    text = result['extracted_text']
                    if text.strip():
                        all_extracted_texts.append({
                            'source': filename,
                            'content': text,
                            'type': 'document'
                        })
                        total_words += len(text.split())
                        
                        timeline_events.append({
                            'time': i * 100,  # ë¬¸ì„œëŠ” ê°€ìƒ ì‹œê°„
                            'source': filename,
                            'content': text,
                            'type': 'document'
                        })
            
            # íƒ€ì„ë¼ì¸ ì •ë ¬
            timeline_events.sort(key=lambda x: x['time'])
            
            # ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„±
            comprehensive_story = self.create_comprehensive_narrative(
                all_transcripts, 
                all_extracted_texts, 
                timeline_events
            )
            
            # ì´ ì‹œê°„ ê³„ì‚° (ëŒ€ëµì )
            if timeline_events:
                total_duration = f"{int(timeline_events[-1]['time'] // 60)}ë¶„ {int(timeline_events[-1]['time'] % 60)}ì´ˆ"
            else:
                total_duration = "ì •ë³´ ì—†ìŒ"
            
            return {
                'comprehensive_story': comprehensive_story,
                'total_content_count': len(results),
                'total_speakers': len(all_speakers),
                'total_duration': total_duration,
                'total_words': total_words,
                'timeline_events': timeline_events[:20]  # ìƒìœ„ 20ê°œ ì´ë²¤íŠ¸
            }
            
        except Exception as e:
            return {
                'comprehensive_story': f"ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                'total_content_count': len(results),
                'total_speakers': 0,
                'total_duration': "ê³„ì‚° ë¶ˆê°€",
                'total_words': 0
            }
    
    def create_comprehensive_narrative(self, transcripts: List[Dict], extracted_texts: List[Dict], timeline_events: List[Dict]) -> str:
        """ì¢…í•©ì ì¸ ë‚´ëŸ¬í‹°ë¸Œ ìƒì„±"""
        
        narrative_parts = []
        
        # ğŸ“‹ ì „ì²´ ê°œìš”
        narrative_parts.append("## ğŸ“‹ ì „ì²´ ê°œìš”")
        
        if transcripts:
            narrative_parts.append(f"**ğŸ¤ ìŒì„±/ì˜ìƒ ì½˜í…ì¸ **: {len(transcripts)}ê°œ")
            for transcript in transcripts:
                preview = transcript['content'][:100] + "..." if len(transcript['content']) > 100 else transcript['content']
                narrative_parts.append(f"- **{transcript['source']}**: {preview}")
        
        if extracted_texts:
            narrative_parts.append(f"\n**ğŸ“„ ë¬¸ì„œ/ì´ë¯¸ì§€ ì½˜í…ì¸ **: {len(extracted_texts)}ê°œ")
            for text in extracted_texts:
                preview = text['content'][:100] + "..." if len(text['content']) > 100 else text['content']
                narrative_parts.append(f"- **{text['source']}**: {preview}")
        
        # ğŸ“ˆ ì‹œê°„ìˆœ íë¦„
        if timeline_events:
            narrative_parts.append("\n## ğŸ“ˆ ì£¼ìš” íë¦„")
            
            current_source = None
            for event in timeline_events[:10]:  # ìƒìœ„ 10ê°œë§Œ
                if event['source'] != current_source:
                    narrative_parts.append(f"\n**ğŸ“ {event['source']}**")
                    current_source = event['source']
                
                if event['type'] == 'speech':
                    time_str = f"[{int(event['time']//60):02d}:{int(event['time']%60):02d}]"
                    narrative_parts.append(f"- {time_str} **{event['speaker']}**: {event['content'][:80]}...")
                elif event['type'] == 'document':
                    narrative_parts.append(f"- ğŸ“„ **ë¬¸ì„œ ë‚´ìš©**: {event['content'][:80]}...")
        
        # ğŸ” í•µì‹¬ ë‚´ìš© ìš”ì•½
        narrative_parts.append("\n## ğŸ” í•µì‹¬ ë‚´ìš© ìš”ì•½")
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë¹ˆë„ ë¶„ì„)
        all_text = ""
        for transcript in transcripts:
            all_text += transcript['content'] + " "
        for text in extracted_texts:
            all_text += text['content'] + " "
        
        if all_text.strip():
            words = all_text.split()
            word_freq = {}
            for word in words:
                if len(word) > 2:  # 2ê¸€ì ì´ìƒë§Œ
                    word_freq[word] = word_freq.get(word, 0) + 1
            
            # ìƒìœ„ í‚¤ì›Œë“œ
            top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            if top_keywords:
                narrative_parts.append("**ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ**: " + ", ".join([f"{word}({count}íšŒ)" for word, count in top_keywords[:5]]))
        
        # ğŸ“Š ë¶„ì„ ìš”ì•½
        narrative_parts.append("\n## ğŸ“Š ë¶„ì„ ìš”ì•½")
        narrative_parts.append(f"- **ì´ ì½˜í…ì¸ **: {len(transcripts + extracted_texts)}ê°œ")
        narrative_parts.append(f"- **ìŒì„± ì½˜í…ì¸ **: {len(transcripts)}ê°œ")
        narrative_parts.append(f"- **ë¬¸ì„œ ì½˜í…ì¸ **: {len(extracted_texts)}ê°œ")
        
        if timeline_events:
            speakers = set(event.get('speaker', 'Unknown') for event in timeline_events if 'speaker' in event)
            narrative_parts.append(f"- **ì°¸ì—¬ í™”ì**: {len(speakers)}ëª…")
        
        return "\n".join(narrative_parts)
    
    def show_detailed_analysis(self):
        """ìƒì„¸ ë¶„ì„ í‘œì‹œ"""
        if not st.session_state.analysis_results:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        st.markdown("---")
        st.markdown("# ğŸ“Š ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ")
        
        results_data = st.session_state.analysis_results
        
        # ì „ì²´ ìš”ì•½ í†µê³„
        self.render_summary_statistics(results_data)
        
        # í™”ìë³„ ìƒì„¸ ë¶„ì„
        self.render_speaker_detailed_analysis(results_data)
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        self.render_timeline_analysis(results_data)
        
        # í‚¤ì›Œë“œ ë° ì£¼ì œ ë¶„ì„
        self.render_keyword_analysis(results_data)
        
        # í’ˆì§ˆ ë¶„ì„
        self.render_quality_analysis(results_data)
    
    def render_summary_statistics(self, results_data):
        """ìš”ì•½ í†µê³„ ë Œë”ë§"""
        st.markdown("## ğŸ“ˆ ì „ì²´ ìš”ì•½ í†µê³„")
        
        col1, col2, col3, col4 = st.columns(4)
        
        total_files = results_data.get('files_analyzed', 0)
        category = results_data.get('category', 'unknown')
        analysis_time = results_data.get('analysis_time', datetime.now())
        
        with col1:
            st.metric("ğŸ“ ë¶„ì„ íŒŒì¼ ìˆ˜", f"{total_files}ê°œ")
        
        with col2:
            st.metric("ğŸ“Š ë¶„ì„ ìœ í˜•", category.upper())
        
        with col3:
            if isinstance(analysis_time, str):
                time_str = analysis_time
            else:
                time_str = analysis_time.strftime("%H:%M:%S")
            st.metric("â° ë¶„ì„ ì‹œê°", time_str)
        
        with col4:
            # ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
            total_text_length = 0
            for result in results_data.get('results', []):
                if 'transcription' in result:
                    total_text_length += len(result['transcription'].get('text', ''))
                elif 'extracted_text' in result:
                    total_text_length += len(result.get('extracted_text', ''))
            st.metric("ğŸ“ ì´ í…ìŠ¤íŠ¸", f"{total_text_length:,}ì")
    
    def render_speaker_detailed_analysis(self, results_data):
        """í™”ìë³„ ìƒì„¸ ë¶„ì„"""
        st.markdown("## ğŸ­ í™”ìë³„ ìƒì„¸ ë¶„ì„")
        
        # ëª¨ë“  ê²°ê³¼ì—ì„œ í™”ì ì •ë³´ ìˆ˜ì§‘
        all_speakers = {}
        
        for result in results_data.get('results', []):
            if 'transcription' in result:
                transcription = result['transcription']
                segments = transcription.get('segments', [])
                
                for segment in segments:
                    speaker_id = segment.get('speaker', 0)
                    speaker_name = f"í™”ì {speaker_id + 1}"
                    
                    if speaker_name not in all_speakers:
                        all_speakers[speaker_name] = {
                            'total_time': 0,
                            'total_words': 0,
                            'segments_count': 0,
                            'texts': []
                        }
                    
                    text = segment.get('text', '').strip()
                    start_time = segment.get('start', 0)
                    end_time = segment.get('end', 0)
                    duration = end_time - start_time
                    
                    all_speakers[speaker_name]['total_time'] += duration
                    all_speakers[speaker_name]['total_words'] += len(text.split())
                    all_speakers[speaker_name]['segments_count'] += 1
                    all_speakers[speaker_name]['texts'].append(text)
        
        if all_speakers:
            # í™”ìë³„ í†µê³„ í…Œì´ë¸”
            speaker_stats = []
            for speaker, stats in all_speakers.items():
                avg_segment_time = stats['total_time'] / stats['segments_count'] if stats['segments_count'] > 0 else 0
                speaker_stats.append({
                    'í™”ì': speaker,
                    'ì´ ë°œì–¸ ì‹œê°„': f"{stats['total_time']:.1f}ì´ˆ",
                    'ë°œì–¸ íšŸìˆ˜': f"{stats['segments_count']}íšŒ",
                    'ì´ ë°œì–¸ ë‹¨ì–´': f"{stats['total_words']}ê°œ",
                    'í‰ê·  ë°œì–¸ ê¸¸ì´': f"{avg_segment_time:.1f}ì´ˆ"
                })
            
            # í…Œì´ë¸”ë¡œ í‘œì‹œ (pandas ì—†ì´)
            st.markdown("### ğŸ“Š í™”ìë³„ í†µê³„")
            for stat in speaker_stats:
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.markdown(f"**{stat['í™”ì']}**")
                with col2:
                    st.markdown(stat['ì´ ë°œì–¸ ì‹œê°„'])
                with col3:
                    st.markdown(stat['ë°œì–¸ íšŸìˆ˜'])
                with col4:
                    st.markdown(stat['ì´ ë°œì–¸ ë‹¨ì–´'])
                with col5:
                    st.markdown(stat['í‰ê·  ë°œì–¸ ê¸¸ì´'])
            
            # í™”ìë³„ ì£¼ìš” ë°œì–¸ ë‚´ìš©
            st.markdown("### ğŸ—£ï¸ í™”ìë³„ ì£¼ìš” ë°œì–¸")
            
            for speaker, stats in all_speakers.items():
                with st.expander(f"{speaker} - ì´ {stats['segments_count']}ê°œ ë°œì–¸", expanded=False):
                    # ê°€ì¥ ê¸´ ë°œì–¸ 3ê°œ í‘œì‹œ
                    longest_texts = sorted(stats['texts'], key=len, reverse=True)[:3]
                    
                    for i, text in enumerate(longest_texts, 1):
                        if text.strip():
                            st.markdown(f"**ë°œì–¸ {i}:**")
                            st.markdown(f"> {text}")
                            st.markdown("")
        else:
            st.info("í™”ì ë¶„ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_timeline_analysis(self, results_data):
        """ì‹œê°„ëŒ€ë³„ ë¶„ì„"""
        st.markdown("## â° ì‹œê°„ëŒ€ë³„ ë¶„ì„")
        
        timeline_data = []
        
        for result in results_data.get('results', []):
            if 'transcription' in result:
                transcription = result['transcription']
                segments = transcription.get('segments', [])
                
                for segment in segments:
                    timeline_data.append({
                        'start_time': segment.get('start', 0),
                        'end_time': segment.get('end', 0),
                        'speaker': segment.get('speaker', 0),
                        'text': segment.get('text', '').strip(),
                        'duration': segment.get('end', 0) - segment.get('start', 0)
                    })
        
        if timeline_data:
            # ì‹œê°„ëŒ€ë³„ í™œë™ ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
            timeline_data.sort(key=lambda x: x['start_time'])
            
            st.markdown("### ğŸ“Š ëŒ€í™” íë¦„")
            
            # ì‹œê°„ëŒ€ë³„ ë°œì–¸ì ë³€í™” í‘œì‹œ
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown("**â° ì‹œê°„ìˆœ ëŒ€í™” íë¦„:**")
                
                for i, item in enumerate(timeline_data[:20]):  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                    speaker_name = f"í™”ì {item['speaker'] + 1}"
                    start_min = int(item['start_time'] // 60)
                    start_sec = int(item['start_time'] % 60)
                    
                    # í™”ìë³„ ìƒ‰ìƒ
                    colors = ['ğŸ”µ', 'ğŸ”´', 'ğŸŸ¢', 'ğŸŸ¡', 'ğŸŸ£', 'ğŸŸ ']
                    color = colors[item['speaker'] % len(colors)]
                    
                    st.markdown(f"{color} **{start_min:02d}:{start_sec:02d}** - {speaker_name}: {item['text'][:100]}{'...' if len(item['text']) > 100 else ''}")
                
                if len(timeline_data) > 20:
                    st.markdown(f"... ì™¸ {len(timeline_data) - 20}ê°œ ë°œì–¸")
            
            with col2:
                st.markdown("**ğŸ“Š í†µê³„:**")
                st.metric("ì´ ë°œì–¸ ìˆ˜", len(timeline_data))
                total_duration = max([item['end_time'] for item in timeline_data]) if timeline_data else 0
                st.metric("ì´ ì‹œê°„", f"{total_duration/60:.1f}ë¶„")
                
                # í™”ìë³„ ë°œì–¸ ë¹„ìœ¨
                speaker_counts = {}
                for item in timeline_data:
                    speaker = f"í™”ì {item['speaker'] + 1}"
                    speaker_counts[speaker] = speaker_counts.get(speaker, 0) + 1
                
                st.markdown("**ğŸ­ ë°œì–¸ ë¹„ìœ¨:**")
                for speaker, count in speaker_counts.items():
                    percentage = (count / len(timeline_data)) * 100
                    st.markdown(f"- {speaker}: {percentage:.1f}%")
        else:
            st.info("ì‹œê°„ëŒ€ë³„ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_keyword_analysis(self, results_data):
        """í‚¤ì›Œë“œ ë° ì£¼ì œ ë¶„ì„"""
        st.markdown("## ğŸ·ï¸ í‚¤ì›Œë“œ ë° ì£¼ì œ ë¶„ì„")
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_text = ""
        for result in results_data.get('results', []):
            if 'transcription' in result:
                all_text += result['transcription'].get('text', '') + " "
            elif 'extracted_text' in result:
                all_text += result.get('extracted_text', '') + " "
        
        if all_text.strip():
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            words = all_text.split()
            word_freq = {}
            
            # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
            for word in words:
                cleaned_word = word.strip('.,!?:;()[]{}\"\'').lower()
                if len(cleaned_word) > 1 and not cleaned_word.isdigit():
                    word_freq[cleaned_word] = word_freq.get(cleaned_word, 0) + 1
            
            # ë¹ˆë„ìˆœ ì •ë ¬
            sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ğŸ”¤ ì£¼ìš” í‚¤ì›Œë“œ (ë¹ˆë„ìˆœ)")
                
                top_keywords = sorted_words[:20]  # ìƒìœ„ 20ê°œ
                for i, (word, count) in enumerate(top_keywords, 1):
                    st.markdown(f"{i}. **{word}** ({count}íšŒ)")
            
            with col2:
                st.markdown("### ğŸ“Š í…ìŠ¤íŠ¸ í†µê³„")
                
                total_words = len(words)
                unique_words = len(word_freq)
                avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
                
                st.metric("ì´ ë‹¨ì–´ ìˆ˜", f"{total_words:,}ê°œ")
                st.metric("ê³ ìœ  ë‹¨ì–´ ìˆ˜", f"{unique_words:,}ê°œ")
                st.metric("í‰ê·  ë‹¨ì–´ ê¸¸ì´", f"{avg_word_length:.1f}ê¸€ì")
                st.metric("ì–´íœ˜ ë‹¤ì–‘ì„±", f"{(unique_words/total_words)*100:.1f}%" if total_words > 0 else "0%")
        else:
            st.info("í‚¤ì›Œë“œ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_quality_analysis(self, results_data):
        """í’ˆì§ˆ ë¶„ì„"""
        st.markdown("## â­ ë¶„ì„ í’ˆì§ˆ í‰ê°€")
        
        quality_data = []
        
        for result in results_data.get('results', []):
            filename = result.get('filename', 'Unknown')
            
            if 'speaker_analysis' in result:
                speaker_info = result['speaker_analysis']
                quality_score = speaker_info.get('quality_score', 0)
                method = speaker_info.get('method', 'unknown')
                speakers = speaker_info.get('speakers', 0)
                
                status = 'ìš°ìˆ˜' if quality_score > 0.8 else 'ë³´í†µ' if quality_score > 0.5 else 'ë‚®ìŒ'
                quality_data.append({
                    'filename': filename,
                    'score': quality_score,
                    'method': method,
                    'speakers': speakers,
                    'status': status
                })
        
        if quality_data:
            st.markdown("### ğŸ“‹ íŒŒì¼ë³„ í’ˆì§ˆ í‰ê°€")
            
            for item in quality_data:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.markdown(f"**{item['filename'][:20]}...**" if len(item['filename']) > 20 else f"**{item['filename']}**")
                with col2:
                    st.markdown(f"í’ˆì§ˆ: {item['score']:.2f}")
                with col3:
                    st.markdown(f"í™”ì: {item['speakers']}ëª…")
                with col4:
                    status_color = "ğŸŸ¢" if item['status'] == 'ìš°ìˆ˜' else "ğŸŸ¡" if item['status'] == 'ë³´í†µ' else "ğŸ”´"
                    st.markdown(f"{status_color} {item['status']}")
            
            # ì „ì²´ í’ˆì§ˆ ìš”ì•½
            st.markdown("### ğŸ“Š ì „ì²´ í’ˆì§ˆ ìš”ì•½")
            col1, col2, col3 = st.columns(3)
            
            excellent_count = sum(1 for item in quality_data if item['status'] == 'ìš°ìˆ˜')
            good_count = sum(1 for item in quality_data if item['status'] == 'ë³´í†µ')
            low_count = sum(1 for item in quality_data if item['status'] == 'ë‚®ìŒ')
            
            with col1:
                st.metric("ğŸŒŸ ìš°ìˆ˜ í’ˆì§ˆ", f"{excellent_count}ê°œ")
            with col2:
                st.metric("ğŸ‘ ë³´í†µ í’ˆì§ˆ", f"{good_count}ê°œ")
            with col3:
                st.metric("âš ï¸ ë‚®ì€ í’ˆì§ˆ", f"{low_count}ê°œ")
            
            # ê°œì„  ì œì•ˆ
            if low_count > 0:
                st.markdown("### ğŸ’¡ í’ˆì§ˆ ê°œì„  ì œì•ˆ")
                st.warning("ì¼ë¶€ íŒŒì¼ì˜ ë¶„ì„ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ë³´ì„¸ìš”:")
                st.markdown("- ìŒì„± íŒŒì¼ì˜ ê²½ìš°: ë°°ê²½ ì†ŒìŒì´ ì ê³  ëª…í™•í•œ ë°œìŒì˜ ë…¹ìŒì„ ì‚¬ìš©í•˜ì„¸ìš”")
                st.markdown("- ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ìš°: í•´ìƒë„ê°€ ë†’ê³  í…ìŠ¤íŠ¸ê°€ ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
                st.markdown("- ì—¬ëŸ¬ í™”ìê°€ ë™ì‹œì— ë§í•˜ëŠ” êµ¬ê°„ì„ ì¤„ì—¬ë³´ì„¸ìš”")
        else:
            st.info("í’ˆì§ˆ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        # í˜ì´ì§€ ì„¤ì •
        st.set_page_config(
            page_title="ë²”ìš© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„",
            page_icon="ğŸ¯",
            layout="wide",
            initial_sidebar_state="collapsed"
        )
        
        # í—¤ë”
        self.render_header()
        
        # ë‹¨ê³„ë³„ ë Œë”ë§
        if st.session_state.current_step == 1:
            self.render_step_1_upload()
        elif st.session_state.current_step == 2:
            self.render_step_2_analysis()
        elif st.session_state.current_step == 3:
            self.render_step_3_results()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    analyzer = UniversalConferenceAnalyzer()
    analyzer.run()

if __name__ == "__main__":
    main()