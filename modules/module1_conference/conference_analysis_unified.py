#!/usr/bin/env python3
"""
ğŸ† ëª¨ë“ˆ 1: í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
Unified Conference Analysis System

ğŸ¯ ë‹¨ì¼ ì‹œìŠ¤í…œ, ë‹¤ì¤‘ ëª¨ë“œ:
- ğŸ† ê¶ê·¹ ëª¨ë“œ: ëª¨ë“  ê¸°ëŠ¥ + ìµœê³  ì„±ëŠ¥
- âš–ï¸ ê· í˜• ëª¨ë“œ: í•µì‹¬ ê¸°ëŠ¥ + ì•ˆì •ì„±
- ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ê¸°ë³¸ ê¸°ëŠ¥ + ìµœëŒ€ ì•ˆì •ì„±

âœ¨ ëª¨ë“  ê¸°ëŠ¥ í†µí•©:
- ğŸ”¥ í„°ë³´ ì—…ë¡œë“œ (3ê°€ì§€ ì†ë„)
- ğŸŒ URL ë‹¤ìš´ë¡œë“œ ì§€ì›
- ğŸ¬ ë¹„ë””ì˜¤ í™”ë©´ ì¸ì‹
- ğŸ’¾ ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ
- ğŸ›¡ï¸ ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±
- ğŸ“Š 10GB íŒŒì¼ ì§€ì›
- âš¡ GPU/CPU ìë™ ìµœì í™”
- ğŸ­ ê³ í’ˆì§ˆ í™”ì ë¶„ë¦¬
- ğŸ“ˆ ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¶”ì 
"""

import streamlit as st
import os
import sys
import tempfile
import time
import hashlib
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import json
import pickle
import gzip
import io
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import subprocess
import sys
import os

# Ollama ì¸í„°í˜ì´ìŠ¤ ì„í¬íŠ¸
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
try:
    from shared.ollama_interface import OllamaInterface
    OLLAMA_AVAILABLE = True
    print("Ollama interface loaded successfully")
except ImportError as e:
    OLLAMA_AVAILABLE = False
    print(f"Ollama interface load failed: {e}")

# AI ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import whisper
    import librosa
    from sklearn.cluster import KMeans, MiniBatchKMeans  
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    from sklearn.metrics import silhouette_score
    import easyocr
    import numpy as np
    import torch
    import cv2
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

# URL ë‹¤ìš´ë¡œë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import yt_dlp
    import pytube
    URL_DOWNLOAD_AVAILABLE = True
except ImportError:
    URL_DOWNLOAD_AVAILABLE = False

class UnifiedConferenceAnalyzer:
    """í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ê¸° - ëª¨ë“  ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ"""
    
    def __init__(self):
        # Ollama AI ì´ˆê¸°í™”
        self.ollama = None
        if OLLAMA_AVAILABLE:
            try:
                self.ollama = OllamaInterface()
                print("Ollama AI connected successfully")
            except Exception as e:
                print(f"Ollama AI connection failed: {e}")
        
        self.analysis_modes = {
            "ultimate": {
                "name": "ğŸ† ê¶ê·¹ ëª¨ë“œ",
                "description": "ğŸ¤– AI ì§€ëŠ¥ë¶„ì„ + ëª¨ë“  ê¸°ëŠ¥ + ìµœê³  ì„±ëŠ¥ (ê¶Œì¥)",
                "upload_speed": "turbo",      # 10ë°° ë¹ ë¦„
                "chunk_size": 10 * 1024 * 1024,  # 10MB
                "parallel_workers": 8,
                "network_stability": "balanced",
                "features": ["audio", "video", "image", "text", "url", "cache", "gpu", "ai_analysis"],
                "quality": "high",
                "color": "#FFD700"
            },
            "balanced": {
                "name": "âš–ï¸ ê· í˜• ëª¨ë“œ", 
                "description": "ğŸ¤– AI ê¸°ë³¸ë¶„ì„ + í•µì‹¬ ê¸°ëŠ¥ + ì•ˆì •ì„± (ì¼ë°˜ ì‚¬ìš©)",
                "upload_speed": "fast",       # 5ë°° ë¹ ë¦„
                "chunk_size": 5 * 1024 * 1024,   # 5MB
                "parallel_workers": 4,
                "network_stability": "high",
                "features": ["audio", "video", "image", "text", "cache", "ai_analysis"],
                "quality": "medium",
                "color": "#4CAF50"
            },
            "safe": {
                "name": "ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ",
                "description": "ê¸°ë³¸ ê¸°ëŠ¥ + ìµœëŒ€ ì•ˆì •ì„± (ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì •ì‹œ)",
                "upload_speed": "normal",     # ê¸°ë³¸ ì†ë„
                "chunk_size": 1 * 1024 * 1024,   # 1MB
                "parallel_workers": 2,
                "network_stability": "maximum",
                "features": ["audio", "image", "text"],
                "quality": "stable",
                "color": "#2196F3"
            }
        }
        
        self.current_mode = "ultimate"  # ê¸°ë³¸ ëª¨ë“œ
        self.cache_dir = Path("cache/conference_analysis")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # AI ëª¨ë¸ ì´ˆê¸°í™” ìƒíƒœ
        self.models_loaded = {
            "whisper": None,
            "easyocr": None
        }
        
    def render_mode_selector(self):
        """ë¶„ì„ ëª¨ë“œ ì„ íƒ UI"""
        st.markdown("## ğŸ¯ ë¶„ì„ ëª¨ë“œ ì„ íƒ")
        
        # ëª¨ë“œ ì„ íƒ
        mode_options = []
        for mode_key, config in self.analysis_modes.items():
            mode_options.append(f"{config['name']} - {config['description']}")
        
        selected_option = st.selectbox(
            "ì›í•˜ëŠ” ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            mode_options,
            index=0,  # ê¶ê·¹ ëª¨ë“œê°€ ê¸°ë³¸
            help="ë„¤íŠ¸ì›Œí¬ê°€ ë¶ˆì•ˆì •í•˜ë©´ ì•ˆì „ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”."
        )
        
        # ì„ íƒëœ ëª¨ë“œ ì¶”ì¶œ
        if "ê¶ê·¹" in selected_option:
            self.current_mode = "ultimate"
        elif "ê· í˜•" in selected_option:
            self.current_mode = "balanced"
        elif "ì•ˆì „" in selected_option:
            self.current_mode = "safe"
        
        # ì„ íƒëœ ëª¨ë“œ ì •ë³´ í‘œì‹œ
        config = self.analysis_modes[self.current_mode]
        
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, {config['color']}20, {config['color']}05);
            border: 2px solid {config['color']};
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
        ">
            <h3 style="color: {config['color']}; margin: 0;">
                {config['name']} ì„ íƒë¨
            </h3>
            <p style="margin: 10px 0;"><strong>ì„¤ëª…:</strong> {config['description']}</p>
            <p style="margin: 5px 0;"><strong>ì—…ë¡œë“œ ì†ë„:</strong> {config['upload_speed']}</p>
            <p style="margin: 5px 0;"><strong>ì²­í¬ í¬ê¸°:</strong> {config['chunk_size'] // 1024 // 1024}MB</p>
            <p style="margin: 5px 0;"><strong>ë³‘ë ¬ ì²˜ë¦¬:</strong> {config['parallel_workers']}ê°œ ìŠ¤ë ˆë“œ</p>
            <p style="margin: 5px 0;"><strong>ì§€ì› ê¸°ëŠ¥:</strong> {', '.join(config['features'])}</p>
        </div>
        """, unsafe_allow_html=True)
        
        return self.current_mode
    
    def render_upload_system(self):
        """í†µí•© ì—…ë¡œë“œ ì‹œìŠ¤í…œ"""
        st.markdown("## ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
        
        config = self.analysis_modes[self.current_mode]
        
        # ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ
        upload_method = st.radio(
            "ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ:",
            ["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸŒ URL ë‹¤ìš´ë¡œë“œ", "ğŸ“ í…ìŠ¤íŠ¸ ì…ë ¥", "ğŸ“‚ í´ë” ì—…ë¡œë“œ"],
            horizontal=True
        )
        
        uploaded_files = []
        
        if upload_method == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ":
            uploaded_files = self.render_file_upload(config)
        elif upload_method == "ğŸŒ URL ë‹¤ìš´ë¡œë“œ":
            uploaded_files = self.render_url_download(config)
        elif upload_method == "ğŸ“ í…ìŠ¤íŠ¸ ì…ë ¥":
            uploaded_files = self.render_text_input(config)
        elif upload_method == "ğŸ“‚ í´ë” ì—…ë¡œë“œ":
            uploaded_files = self.render_folder_upload(config)
        
        return uploaded_files
    
    def render_file_upload(self, config):
        """íŒŒì¼ ì—…ë¡œë“œ UI"""
        # ëª¨ë“œë³„ ì—…ë¡œë“œ ì„¤ì • í‘œì‹œ
        st.info(f"ğŸš€ {config['name']} - {config['chunk_size']//1024//1024}MB ì²­í¬, {config['parallel_workers']}ê°œ ë³‘ë ¬ ì²˜ë¦¬")
        
        uploaded_files = st.file_uploader(
            f"ë¶„ì„í•  íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” ({config['upload_speed']} ëª¨ë“œ)",
            type=['mp4', 'avi', 'mov', 'mp3', 'wav', 'm4a', 'jpg', 'png', 'pdf', 'txt', 'docx'],
            accept_multiple_files=True,
            help=f"ìµœëŒ€ 10GB íŒŒì¼ ì§€ì› | {config['upload_speed']} ì†ë„ ëª¨ë“œ",
            key=f"upload_{self.current_mode}"
        )
        
        if uploaded_files:
            # í„°ë³´ ì—…ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ
            self.render_upload_progress(uploaded_files, config)
        
        return uploaded_files
    
    def render_upload_progress(self, files, config):
        """ì—…ë¡œë“œ ì§„í–‰ë¥  ë° í†µê³„ í‘œì‹œ"""
        st.markdown("### ğŸ“Š ì—…ë¡œë“œ ì§„í–‰ ìƒí™©")
        
        # ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        
        total_size = sum(len(file.getvalue()) for file in files)
        total_size_gb = total_size / (1024**3)
        
        with col1:
            st.metric("ğŸ“ íŒŒì¼ ìˆ˜", f"{len(files)}ê°œ")
        with col2:
            st.metric("ğŸ“Š ì´ ìš©ëŸ‰", f"{total_size_gb:.2f} GB")
        with col3:
            # ì˜ˆìƒ ì†ë„ ê³„ì‚°
            if config['upload_speed'] == 'turbo':
                estimated_speed = 50
            elif config['upload_speed'] == 'fast':
                estimated_speed = 25
            else:
                estimated_speed = 10
            st.metric("âš¡ ì˜ˆìƒ ì†ë„", f"{estimated_speed} MB/s")
        with col4:
            estimated_time = (total_size / (1024**2)) / estimated_speed
            st.metric("â±ï¸ ì˜ˆìƒ ì‹œê°„", f"{estimated_time:.1f}ì´ˆ")
        
        # ì„±ëŠ¥ íŒ
        if config['upload_speed'] == 'turbo':
            st.success(f"ğŸš€ í„°ë³´ ëª¨ë“œ: {config['parallel_workers']}ê°œ ë³‘ë ¬ ìŠ¤ë ˆë“œë¡œ ìµœê³  ì†ë„!")
        elif config['upload_speed'] == 'fast':
            st.info(f"âš¡ ê³ ì† ëª¨ë“œ: {config['parallel_workers']}ê°œ ìŠ¤ë ˆë“œë¡œ ë¹ ë¥¸ ì²˜ë¦¬!")
        else:
            st.info(f"ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: {config['parallel_workers']}ê°œ ìŠ¤ë ˆë“œë¡œ ì•ˆì •ì  ì²˜ë¦¬!")
    
    def render_url_download(self, config):
        """URL ë‹¤ìš´ë¡œë“œ UI"""
        if not URL_DOWNLOAD_AVAILABLE:
            st.warning("âš ï¸ URL ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ yt-dlpë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install yt-dlp")
            return []
        
        st.info(f"ğŸŒ {config['name']} - URLì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ")
        
        url = st.text_input(
            "ë‹¤ìš´ë¡œë“œí•  URLì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="https://www.youtube.com/watch?v=... ë˜ëŠ” ì›¹í˜ì´ì§€ URL",
            help="YouTube, ì›¹í˜ì´ì§€, ë¬¸ì„œ URL ì§€ì›"
        )
        
        if url and st.button("ğŸš€ ë‹¤ìš´ë¡œë“œ ì‹œì‘"):
            with st.spinner("URLì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                downloaded_files = self.download_from_url(url, config)
                if downloaded_files:
                    st.success(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(downloaded_files)}ê°œ íŒŒì¼")
                    return downloaded_files
        
        return []
    
    def render_text_input(self, config):
        """í…ìŠ¤íŠ¸ ì…ë ¥ UI"""
        st.info(f"ğŸ“ {config['name']} - í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥")
        
        text_content = st.text_area(
            "ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
            height=200,
            placeholder="íšŒì˜ ë‚´ìš©, ê°•ì—° ìŠ¤í¬ë¦½íŠ¸, ëŒ€í™” ë‚´ìš© ë“±ì„ ì…ë ¥í•˜ì„¸ìš”...",
            help="ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ ë¶„ì„í•©ë‹ˆë‹¤"
        )
        
        if text_content and st.button("ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘"):
            # í…ìŠ¤íŠ¸ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ë³€í™˜
            text_file = io.StringIO(text_content)
            text_file.name = f"text_input_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            return [text_file]
        
        return []
    
    def render_folder_upload(self, config):
        """í´ë” ì—…ë¡œë“œ UI (ì—¬ëŸ¬ íŒŒì¼ í•œë²ˆì—)"""
        st.info(f"ğŸ“‚ {config['name']} - ì—¬ëŸ¬ íŒŒì¼ í•œë²ˆì— ì—…ë¡œë“œ")
        st.warning("âš ï¸ ë¸Œë¼ìš°ì € ì œí•œìœ¼ë¡œ í´ë” ì—…ë¡œë“œëŠ” íŒŒì¼ ì„ íƒ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
        
        # ë‹¤ì¤‘ íŒŒì¼ ì„ íƒìœ¼ë¡œ í´ë” ì—…ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜
        uploaded_files = st.file_uploader(
            "í´ë”ì˜ ëª¨ë“  íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (Ctrl+í´ë¦­ìœ¼ë¡œ ë‹¤ì¤‘ ì„ íƒ)",
            type=['mp4', 'avi', 'mov', 'mp3', 'wav', 'm4a', 'jpg', 'png', 'pdf', 'txt', 'docx'],
            accept_multiple_files=True,
            help="ê°™ì€ í´ë”ì˜ íŒŒì¼ë“¤ì„ ëª¨ë‘ ì„ íƒí•˜ì—¬ ë°°ì¹˜ ì—…ë¡œë“œ",
            key=f"folder_upload_{self.current_mode}"
        )
        
        if uploaded_files:
            st.success(f"ğŸ“‚ ë°°ì¹˜ ì—…ë¡œë“œ: {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")
            self.render_upload_progress(uploaded_files, config)
        
        return uploaded_files
    
    def render_analysis_button(self, files):
        """ë¶„ì„ ì‹œì‘ ë²„íŠ¼"""
        if not files:
            return False
        
        config = self.analysis_modes[self.current_mode]
        
        st.markdown("---")
        st.markdown("## ğŸš€ ë¶„ì„ ì‹œì‘")
        
        # ë¶„ì„ ì„¤ì • ìš”ì•½
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            **ì„ íƒëœ ëª¨ë“œ:** {config['name']}  
            **íŒŒì¼ ìˆ˜:** {len(files)}ê°œ  
            **ì§€ì› ê¸°ëŠ¥:** {', '.join(config['features'][:3])}...
            """)
        
        with col2:
            st.markdown(f"""
            **ì²˜ë¦¬ ì†ë„:** {config['upload_speed']}  
            **ì•ˆì •ì„±:** {config['network_stability']}  
            **í’ˆì§ˆ:** {config['quality']}
            """)
        
        # ë¶„ì„ ì‹œì‘ ë²„íŠ¼ (ëª¨ë“œë³„ ìƒ‰ìƒ)
        button_color = config['color']
        
        if st.button(
            f"ğŸš€ {config['name']} ë¶„ì„ ì‹œì‘",
            type="primary",
            help=f"ì„ íƒëœ {len(files)}ê°œ íŒŒì¼ì„ {config['name']}ë¡œ ë¶„ì„í•©ë‹ˆë‹¤"
        ):
            return True
        
        return False
    
    def execute_unified_analysis(self, files):
        """í†µí•© ë¶„ì„ ì‹¤í–‰"""
        config = self.analysis_modes[self.current_mode]
        
        st.markdown(f"## ğŸ”„ {config['name']} ë¶„ì„ ì§„í–‰ ì¤‘...")
        
        # ì „ì²´ ì§„í–‰ë¥ 
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ê²°ê³¼ ì €ì¥
        analysis_results = {
            "mode": self.current_mode,
            "config": config,
            "files_processed": 0,
            "total_files": len(files),
            "results": [],
            "start_time": datetime.now(),
            "errors": []
        }
        
        # ìˆœì°¨ ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í™•ë³´ (ThreadPoolExecutor ì œê±°)
        for i, file in enumerate(files):
            try:
                status_text.text(f"ğŸ”„ ë¶„ì„ ì¤‘: {file.name} ({i+1}/{len(files)})")
                
                file_result = self.analyze_single_file(file, config)
                analysis_results["results"].append(file_result)
                analysis_results["files_processed"] += 1
                
                progress = (i + 1) / len(files)
                progress_bar.progress(progress)
                
            except Exception as e:
                error_info = {
                    "file": file.name,
                    "error": str(e),
                    "timestamp": datetime.now()
                }
                analysis_results["errors"].append(error_info)
                st.error(f"âŒ {file.name} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ë¶„ì„ ì™„ë£Œ
        analysis_results["end_time"] = datetime.now()
        analysis_results["duration"] = (analysis_results["end_time"] - analysis_results["start_time"]).total_seconds()
        
        # ì¢…í•© ë¶„ì„ ìˆ˜í–‰ (ìƒˆë¡œ ì¶”ê°€)
        if analysis_results["files_processed"] > 0:
            status_text.text("ğŸ”„ ì¢…í•© ë¶„ì„ ìƒì„± ì¤‘...")
            
            # ê²°ê³¼ë¥¼ íŒŒì¼ëª… ê¸°ì¤€ìœ¼ë¡œ ì •ë¦¬
            file_results = {}
            for result in analysis_results["results"]:
                if "filename" in result:
                    file_results[result["filename"]] = result
            
            # ì¢…í•© ë¶„ì„ ì‹¤í–‰
            comprehensive_summary = self.generate_comprehensive_summary(file_results)
            analysis_results["comprehensive_summary"] = comprehensive_summary
        
        progress_bar.progress(1.0)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        
        return analysis_results
    
    def analyze_single_file(self, file, config):
        """ê°œë³„ íŒŒì¼ ë¶„ì„"""
        file_extension = Path(file.name).suffix.lower()
        
        result = {
            "filename": file.name,
            "type": file_extension,
            "size": len(file.getvalue()) if hasattr(file, 'getvalue') else 0,
            "analysis": {},
            "timestamp": datetime.now()
        }
        
        # ìºì‹œ í™•ì¸
        if "cache" in config["features"]:
            cached_result = self.check_cache(file)
            if cached_result:
                st.info(f"ğŸ“„ ìºì‹œì—ì„œ ë¡œë“œ: {file.name}")
                return cached_result
        
        # íŒŒì¼ íƒ€ì…ë³„ ë¶„ì„
        if file_extension in ['.mp3', '.wav', '.m4a'] and "audio" in config["features"]:
            result["analysis"] = self.analyze_audio(file, config)
        elif file_extension in ['.mp4', '.avi', '.mov'] and "video" in config["features"]:
            result["analysis"] = self.analyze_video(file, config)
        elif file_extension in ['.jpg', '.png', '.jpeg'] and "image" in config["features"]:
            result["analysis"] = self.analyze_image(file, config)
        elif file_extension in ['.txt', '.pdf', '.docx'] and "text" in config["features"]:
            result["analysis"] = self.analyze_text(file, config)
        else:
            result["analysis"] = {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}"}
        
        # ìºì‹œ ì €ì¥
        if "cache" in config["features"]:
            self.save_cache(file, result)
        
        return result
    
    def analyze_audio(self, file, config):
        """ì˜¤ë””ì˜¤ ë¶„ì„ (í™”ì ë¶„ë¦¬ + STT)"""
        if not AI_AVAILABLE:
            return {"error": "AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # Whisper STT
            if self.models_loaded["whisper"] is None:
                self.models_loaded["whisper"] = whisper.load_model("base")
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_path = tmp_file.name
            
            # STT ì‹¤í–‰
            result = self.models_loaded["whisper"].transcribe(tmp_path)
            
            # í™”ì ë¶„ë¦¬ (ê¶ê·¹ ëª¨ë“œë§Œ)
            speakers = {}
            if config["quality"] == "high":
                speakers = self.perform_speaker_diarization(tmp_path)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_path)
            
            return {
                "transcription": result["text"],
                "language": result.get("language", "unknown"),
                "speakers": speakers,
                "confidence": "high" if config["quality"] == "high" else "medium"
            }
            
        except Exception as e:
            return {"error": f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    def analyze_video(self, file, config):
        """ë¹„ë””ì˜¤ ë¶„ì„ (ìŒì„± + í™”ë©´)"""
        # ë¹„ë””ì˜¤ëŠ” ì˜¤ë””ì˜¤ ì¶”ì¶œ í›„ ë¶„ì„
        return {
            "type": "video",
            "note": "ë¹„ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ êµ¬í˜„ ì˜ˆì •",
            "audio_extracted": False
        }
    
    def analyze_image(self, file, config):
        """ì´ë¯¸ì§€ ë¶„ì„ (OCR)"""
        if not AI_AVAILABLE:
            return {"error": "AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # EasyOCR
            if self.models_loaded["easyocr"] is None:
                self.models_loaded["easyocr"] = easyocr.Reader(['ko', 'en'])
            
            # ì´ë¯¸ì§€ ì½ê¸°
            image_bytes = file.getvalue()
            nparr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            # OCR ì‹¤í–‰
            results = self.models_loaded["easyocr"].readtext(image)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = []
            for (bbox, text, confidence) in results:
                if confidence > 0.5:  # ì‹ ë¢°ë„ í•„í„°
                    extracted_text.append({
                        "text": text,
                        "confidence": confidence,
                        "bbox": bbox
                    })
            
            return {
                "extracted_text": extracted_text,
                "total_text_blocks": len(extracted_text),
                "avg_confidence": np.mean([item["confidence"] for item in extracted_text]) if extracted_text else 0
            }
            
        except Exception as e:
            return {"error": f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    def analyze_text(self, file, config):
        """í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            if hasattr(file, 'getvalue'):
                content = file.getvalue().decode('utf-8')
            else:
                content = file.read()
            
            # ê¸°ë³¸ í…ìŠ¤íŠ¸ í†µê³„
            lines = content.split('\n')
            words = content.split()
            
            return {
                "content": content[:1000] + "..." if len(content) > 1000 else content,
                "stats": {
                    "characters": len(content),
                    "words": len(words),
                    "lines": len(lines)
                },
                "preview": content[:200] + "..." if len(content) > 200 else content
            }
            
        except Exception as e:
            return {"error": f"í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    def perform_speaker_diarization(self, audio_path):
        """ê³ í’ˆì§ˆ í™”ì ë¶„ë¦¬ (ê¶ê·¹ ëª¨ë“œ ì „ìš©)"""
        try:
            # ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            y, sr = librosa.load(audio_path, sr=16000)
            
            # MFCC íŠ¹ì§• ì¶”ì¶œ
            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            
            # ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì§•
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)
            
            # í¬ë¡œë§ˆ íŠ¹ì§•
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            
            # RMS ì—ë„ˆì§€
            rms = librosa.feature.rms(y=y)
            
            # ëª¨ë“  íŠ¹ì§• ê²°í•© (29ì°¨ì›)
            features = np.vstack([
                mfcc,                    # 13ì°¨ì›
                spectral_centroids,      # 1ì°¨ì›
                spectral_rolloff,        # 1ì°¨ì›  
                spectral_bandwidth,      # 1ì°¨ì›
                chroma,                  # 12ì°¨ì›
                rms                      # 1ì°¨ì›
            ])
            
            # íŠ¹ì§• ì •ê·œí™”
            features = features.T  # ì‹œê°„ ì¶•ìœ¼ë¡œ transpose
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features)
            
            # PCA ì°¨ì› ì¶•ì†Œ
            pca = PCA(n_components=0.95)  # 95% ë¶„ì‚° ìœ ì§€
            features_pca = pca.fit_transform(features_scaled)
            
            # ìµœì  í™”ì ìˆ˜ ì°¾ê¸° (ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ ê¸°ë°˜)
            best_n_speakers = 2
            best_score = -1
            
            for n in range(2, min(7, len(features_pca) // 10)):
                kmeans = KMeans(n_clusters=n, random_state=42, n_init=10)
                labels = kmeans.fit_predict(features_pca)
                score = silhouette_score(features_pca, labels)
                
                if score > best_score:
                    best_score = score
                    best_n_speakers = n
            
            # ìµœì¢… í´ëŸ¬ìŠ¤í„°ë§
            kmeans = KMeans(n_clusters=best_n_speakers, random_state=42, n_init=10)
            speaker_labels = kmeans.fit_predict(features_pca)
            
            # í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            speakers = {}
            hop_length = 512
            frame_duration = hop_length / sr
            
            for i, label in enumerate(speaker_labels):
                speaker_id = f"í™”ì_{label + 1}"
                if speaker_id not in speakers:
                    speakers[speaker_id] = []
                
                start_time = i * frame_duration
                end_time = (i + 1) * frame_duration
                
                speakers[speaker_id].append({
                    "start": start_time,
                    "end": end_time,
                    "confidence": best_score
                })
            
            return {
                "speaker_count": best_n_speakers,
                "silhouette_score": best_score,
                "speakers": speakers,
                "method": "29D_features_silhouette_optimized"
            }
            
        except Exception as e:
            return {"error": f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {str(e)}"}
    
    def check_cache(self, file):
        """ìºì‹œ í™•ì¸"""
        try:
            # íŒŒì¼ í•´ì‹œ ìƒì„±
            file_hash = hashlib.md5(file.getvalue()).hexdigest()
            cache_file = self.cache_dir / f"{file_hash}.pkl.gz"
            
            if cache_file.exists():
                with gzip.open(cache_file, 'rb') as f:
                    return pickle.load(f)
            
        except Exception:
            pass
    
    def generate_comprehensive_summary(self, all_results):
        """ì¢…í•© ë¶„ì„ ìš”ì•½ ìƒì„± - ì—¬ëŸ¬ íŒŒì¼ì„ í•˜ë‚˜ì˜ ìŠ¤í† ë¦¬ë¡œ í†µí•© (AI ê°•í™”)"""
        try:
            # ë¶„ì„ ê²°ê³¼ ì •ë¦¬
            audio_results = []
            video_results = []
            image_results = []
            text_results = []
            
            for file_name, result in all_results.items():
                if result.get('type') == 'audio':
                    audio_results.append(result)
                elif result.get('type') == 'video':
                    video_results.append(result)
                elif result.get('type') == 'image':
                    image_results.append(result)
                elif result.get('type') == 'text':
                    text_results.append(result)
            
            # ì „ì‚¬ í…ìŠ¤íŠ¸ í†µí•©
            all_transcripts = []
            speaker_contents = {}
            
            for result in audio_results + video_results:
                if 'transcript' in result:
                    all_transcripts.append(result['transcript'])
                
                # í™”ìë³„ ë‚´ìš© í†µí•©
                if 'speaker_diarization' in result:
                    for speaker_id, segments in result['speaker_diarization'].get('speakers', {}).items():
                        if speaker_id not in speaker_contents:
                            speaker_contents[speaker_id] = []
                        
                        # í•´ë‹¹ í™”ìì˜ ì‹œê°„ëŒ€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        transcript = result.get('transcript', '')
                        for segment in segments:
                            # ê°„ë‹¨í•œ ì‹œê°„ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë§¤í•‘ (ê°œì„  í•„ìš”)
                            start_char = int(segment['start'] * 10)  # ëŒ€ëµì  ë§¤í•‘
                            end_char = int(segment['end'] * 10)
                            speaker_text = transcript[start_char:end_char] if transcript else "ìŒì„± ê°ì§€ë¨"
                            if speaker_text.strip():
                                speaker_contents[speaker_id].append(speaker_text.strip())
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œë„ í™”ì ë‚´ìš© ì¶”ì¶œ (ì¤‘ìš”!)
            for result in text_results:
                if 'content' in result and result['content']:
                    content = result['content']
                    all_transcripts.append(content)
                    
                    # ê°„ë‹¨í•œ í™”ì êµ¬ë¶„ (í™”ì1:, í™”ì2: ë“±ìœ¼ë¡œ êµ¬ë¶„)
                    lines = content.split('\n')
                    current_speaker = None
                    for line in lines:
                        if 'í™”ì' in line and ':' in line:
                            # í™”ì ID ì¶”ì¶œ
                            if 'í™”ì1' in line or 'í™”ì_1' in line:
                                current_speaker = 'í™”ì_1'
                            elif 'í™”ì2' in line or 'í™”ì_2' in line:
                                current_speaker = 'í™”ì_2' 
                            elif 'í™”ì3' in line or 'í™”ì_3' in line:
                                current_speaker = 'í™”ì_3'
                            
                            if current_speaker:
                                if current_speaker not in speaker_contents:
                                    speaker_contents[current_speaker] = []
                                
                                # ì½œë¡  ë’¤ì˜ ë‚´ìš© ì¶”ì¶œ
                                speaker_text = line.split(':', 1)[-1].strip()
                                if speaker_text:
                                    speaker_contents[current_speaker].append(speaker_text)
            
            # ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í†µí•©
            all_image_texts = []
            for result in image_results:
                if 'text_content' in result:
                    all_image_texts.append(result['text_content'])
            
            # ì „ì²´ ìƒí™© ì¢…í•© ë¶„ì„
            combined_text = "\n".join(all_transcripts + all_image_texts + [r.get('content', '') for r in text_results])
            
            # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
            words = combined_text.lower().split()
            word_freq = {}
            for word in words:
                if len(word) > 3:  # 3ê¸€ì ì´ìƒë§Œ
                    word_freq[word] = word_freq.get(word, 0) + 1
            
            top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # AI ê¸°ë°˜ ì§€ëŠ¥ì  ë¶„ì„ ì¶”ê°€
            ai_enhanced_analysis = self._generate_ai_enhanced_analysis(combined_text, speaker_contents, all_image_texts)
            
            # ì¢…í•© ìš”ì•½ ìƒì„±
            summary = {
                "ë¶„ì„_ê°œìš”": {
                    "ì´_íŒŒì¼_ìˆ˜": len(all_results),
                    "ì˜¤ë””ì˜¤_íŒŒì¼": len(audio_results),
                    "ë¹„ë””ì˜¤_íŒŒì¼": len(video_results), 
                    "ì´ë¯¸ì§€_íŒŒì¼": len(image_results),
                    "í…ìŠ¤íŠ¸_íŒŒì¼": len(text_results),
                    "ë¶„ì„_ì‹œê°„": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                },
                "í™”ì_ë¶„ì„": {
                    "ê°ì§€ëœ_í™”ì_ìˆ˜": len(speaker_contents),
                    "í™”ìë³„_ë°œì–¸_ë‚´ìš©": {
                        speaker_id: {
                            "ë°œì–¸_íšŸìˆ˜": len(contents),
                            "ì£¼ìš”_ë°œì–¸": contents[:3] if contents else ["ë°œì–¸ ë‚´ìš© ì—†ìŒ"],
                            "ì „ì²´_ë°œì–¸": contents,
                            "AI_ì˜ë¯¸_ë¶„ì„": ai_enhanced_analysis.get("í™”ì_ì˜ë¯¸_ë¶„ì„", {}).get(speaker_id, "ë¶„ì„ ì¤‘...")
                        }
                        for speaker_id, contents in speaker_contents.items()
                    }
                },
                "ì£¼ìš”_ë‚´ìš©": {
                    "í•µì‹¬_í‚¤ì›Œë“œ": [{"ë‹¨ì–´": word, "ë¹ˆë„": freq} for word, freq in top_keywords],
                    "ì „ì²´_ì „ì‚¬_í…ìŠ¤íŠ¸": combined_text[:1000] + "..." if len(combined_text) > 1000 else combined_text,
                    "ì´ë¯¸ì§€_í…ìŠ¤íŠ¸": all_image_texts
                },
                "í†µí•©_ìŠ¤í† ë¦¬": self._generate_integrated_story(combined_text, speaker_contents, all_image_texts),
                "AI_ìƒí™©_ë¶„ì„": ai_enhanced_analysis,  # AI ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                "ì‚¬ìš©ëœ_ì œì›": {
                    "ìŒì„±_ì¸ì‹": "OpenAI Whisper",
                    "í™”ì_ë¶„ë¦¬": "29ì°¨ì› íŠ¹ì§• + K-means í´ëŸ¬ìŠ¤í„°ë§", 
                    "ì´ë¯¸ì§€_OCR": "EasyOCR",
                    "íŠ¹ì§•_ì¶”ì¶œ": "MFCC, ìŠ¤í™íŠ¸ëŸ´, í¬ë¡œë§ˆ, RMS",
                    "ìµœì í™”": "ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ ê¸°ë°˜ í™”ì ìˆ˜ ìë™ ê²°ì •",
                    "AI_ë¶„ì„": f"Ollama {ai_enhanced_analysis.get('ì‚¬ìš©ëœ_ëª¨ë¸', 'qwen2.5:7b')}" if self.ollama else "ë¯¸ì‚¬ìš©"
                }
            }
            
            return summary
            
        except Exception as e:
            return {"error": f"ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    def _generate_integrated_story(self, combined_text, speaker_contents, image_texts):
        """í†µí•© ìŠ¤í† ë¦¬ ìƒì„±"""
        try:
            story_parts = []
            
            # ìƒí™© ê°œìš”
            if combined_text:
                story_parts.append(f"ğŸ“‹ **ì „ì²´ ìƒí™©**: {combined_text[:200]}...")
            
            # í™”ìë³„ ì£¼ìš” ë°œì–¸
            if speaker_contents:
                story_parts.append("ğŸ­ **í™”ìë³„ ì£¼ìš” ë°œì–¸**:")
                for speaker_id, contents in speaker_contents.items():
                    if contents:
                        main_content = " | ".join(contents[:2])  # ì£¼ìš” ë°œì–¸ 2ê°œ
                        story_parts.append(f"  - {speaker_id}: {main_content}")
            
            # ì‹œê°ì  ì •ë³´
            if image_texts:
                story_parts.append("ğŸ–¼ï¸ **ì‹œê°ì  ì •ë³´**:")
                for i, text in enumerate(image_texts[:3]):  # ìµœëŒ€ 3ê°œ
                    if text.strip():
                        story_parts.append(f"  - ì´ë¯¸ì§€ {i+1}: {text[:100]}...")
            
            # ê²°ë¡ 
            story_parts.append("ğŸ“Š **ì¢…í•© ê²°ë¡ **: ë‹¤ê°ë„ ë¶„ì„ì„ í†µí•´ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ì „ì²´ ìƒí™©ì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.")
            
            return "\n".join(story_parts)
            
        except Exception as e:
            return f"ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def _generate_ai_enhanced_analysis(self, combined_text, speaker_contents, image_texts):
        """AI ê¸°ë°˜ ì§€ëŠ¥ì  ìƒí™© ë¶„ì„"""
        if not self.ollama:
            return {"error": "Ollama AIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        # ë””ë²„ê¹…: ë°›ì€ ë°ì´í„° í™•ì¸
        print(f"DEBUG: combined_text length: {len(combined_text) if combined_text else 0}")
        print(f"DEBUG: speaker_contents: {speaker_contents}")
        print(f"DEBUG: image_texts: {image_texts}")
        
        try:
            # ìƒí™©ë³„ ìµœì  ëª¨ë¸ ì„ íƒ
            selected_model = self._select_optimal_model(combined_text, len(speaker_contents))
            
            # 1. ì „ì²´ ìƒí™© ë¶„ì„
            situation_analysis = self._analyze_overall_situation(combined_text, selected_model)
            
            # 2. í™”ìë³„ ì˜ë¯¸ ë¶„ì„  
            speaker_meanings = self._analyze_speaker_meanings(speaker_contents, selected_model)
            
            # 3. íšŒì˜ ë§¥ë½ ë° ê²°ë¡  ë¶„ì„
            context_analysis = self._analyze_meeting_context(combined_text, selected_model)
            
            return {
                "ì‚¬ìš©ëœ_ëª¨ë¸": selected_model,
                "ì „ì²´_ìƒí™©_ë¶„ì„": situation_analysis,
                "í™”ì_ì˜ë¯¸_ë¶„ì„": speaker_meanings,
                "íšŒì˜_ë§¥ë½_ë¶„ì„": context_analysis,
                "AI_ì¢…í•©_ê²°ë¡ ": self._generate_ai_conclusion(situation_analysis, context_analysis, selected_model)
            }
            
        except Exception as e:
            return {"error": f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    def _select_optimal_model(self, text, speaker_count):
        """ìƒí™©ë³„ ìµœì  ëª¨ë¸ ì„ íƒ"""
        text_length = len(text)
        
        # ë³µì¡ë„ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
        if text_length > 5000 or speaker_count > 4:
            # ë³µì¡í•œ ìƒí™© - ê°•ë ¥í•œ ëª¨ë¸ í•„ìš”
            return "qwen2.5:14b" if "qwen2.5:14b" in self.ollama.available_models else "qwen2.5:7b"
        elif text_length > 2000 or speaker_count > 2:
            # ì¤‘ê°„ ë³µì¡ë„ - ê· í˜•ì¡íŒ ëª¨ë¸
            return "qwen2.5:7b"
        else:
            # ê°„ë‹¨í•œ ìƒí™© - ë¹ ë¥¸ ëª¨ë¸
            return "llama3.2:3b" if "llama3.2:3b" in self.ollama.available_models else "qwen2.5:7b"
    
    def _analyze_overall_situation(self, text, model):
        """ì „ì²´ ìƒí™© AI ë¶„ì„"""
        if not text.strip():
            return "ë¶„ì„í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
        
        prompt = f"""ë‹¤ìŒì€ íšŒì˜/ì»¨í¼ëŸ°ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤. ì „ì²´ ìƒí™©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‚´ìš©:
{text[:2000]}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. íšŒì˜ ì£¼ì œ: 
2. ì°¸ì—¬ì ì—­í• :
3. ì£¼ìš” ë…¼ì˜ì‚¬í•­:
4. í•µì‹¬ ê²°ì •ì‚¬í•­:
5. ì¤‘ìš”ë„ (ìƒ/ì¤‘/í•˜):
6. íšŒì˜ ë¶„ìœ„ê¸°:"""

        try:
            response = self.ollama.generate_response(
                prompt=prompt,
                model=model,
            )
            return response
        except Exception as e:
            return f"ì „ì²´ ìƒí™© ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
    
    def _analyze_speaker_meanings(self, speaker_contents, model):
        """í™”ìë³„ ë°œì–¸ ì˜ë¯¸ ë¶„ì„"""
        meanings = {}
        
        for speaker_id, contents in speaker_contents.items():
            if not contents:
                meanings[speaker_id] = "ë°œì–¸ ë‚´ìš© ì—†ìŒ"
                continue
            
            # ë°œì–¸ ë‚´ìš© í†µí•©
            combined_speech = " ".join(contents[:5])  # ìµœëŒ€ 5ê°œ ë°œì–¸
            
            prompt = f"""í™”ìì˜ ë°œì–¸ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ ì˜ë¯¸ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”.

{speaker_id} ë°œì–¸:
{combined_speech}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„:
- ì£¼ìš” ì˜ë„:
- ê°ì • ìƒíƒœ:
- í•µì‹¬ ë©”ì‹œì§€:
- ìš”ì²­ì‚¬í•­:"""

            try:
                response = self.ollama.generate_response(
                    prompt=prompt,
                    model=model,
                    )
                meanings[speaker_id] = response
            except Exception as e:
                meanings[speaker_id] = f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        
        return meanings
    
    def _analyze_meeting_context(self, text, model):
        """íšŒì˜ ë§¥ë½ ë° ê²°ë¡  ë¶„ì„"""
        if not text.strip():
            return "ë¶„ì„í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
        
        prompt = f"""íšŒì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë§¥ë½ê³¼ ê²°ë¡ ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‚´ìš©:
{text[:1500]}

ë¶„ì„ í•­ëª©:
1. íšŒì˜ ëª©ì :
2. ë‹¬ì„±ëœ ëª©í‘œ:
3. ë¯¸í•´ê²° ì´ìŠˆ:
4. ë‹¤ìŒ ë‹¨ê³„:
5. ì „ì²´ì  í‰ê°€:"""

        try:
            response = self.ollama.generate_response(
                prompt=prompt,
                model=model,
            )
            return response
        except Exception as e:
            return f"ë§¥ë½ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
    
    def _generate_ai_conclusion(self, situation, context, model):
        """AI ì¢…í•© ê²°ë¡  ìƒì„±"""
        prompt = f"""ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ê²°ë¡ ì„ ë‚´ë ¤ì£¼ì„¸ìš”.

ì „ì²´ ìƒí™©: {situation[:500]}
íšŒì˜ ë§¥ë½: {context[:500]}

í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì¢…í•© ê²°ë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        try:
            response = self.ollama.generate_response(
                prompt=prompt,
                model=model,
            )
            return response
        except Exception as e:
            return f"ì¢…í•© ê²°ë¡  ìƒì„± ì‹¤íŒ¨: {str(e)}"
        
        return None
    
    def save_cache(self, file, result):
        """ìºì‹œ ì €ì¥"""
        try:
            # íŒŒì¼ í•´ì‹œ ìƒì„±
            file_hash = hashlib.md5(file.getvalue()).hexdigest()
            cache_file = self.cache_dir / f"{file_hash}.pkl.gz"
            
            with gzip.open(cache_file, 'wb') as f:
                pickle.dump(result, f)
                
        except Exception:
            pass
    
    def download_from_url(self, url, config):
        """URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        # URL ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ êµ¬í˜„ (í–¥í›„ í™•ì¥)
        return []
    
    def render_comprehensive_summary(self, summary):
        """ì¢…í•© ë¶„ì„ ìš”ì•½ í‘œì‹œ"""
        st.markdown("## ğŸ¯ ì¢…í•© ë¶„ì„ ìš”ì•½")
        
        if "error" in summary:
            st.error(f"ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {summary['error']}")
            return
        
        # íƒ­ìœ¼ë¡œ êµ¬ì„± - AI ë¶„ì„ íƒ­ ì¶”ê°€
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“‹ ì „ì²´ ê°œìš”", "ğŸ­ í™”ì ë¶„ì„", "ğŸ“Š ì£¼ìš” ë‚´ìš©", "ğŸ¤– AI ìƒí™©ë¶„ì„", "âš™ï¸ ì‚¬ìš©ëœ ì œì›"])
        
        with tab1:
            # ë¶„ì„ ê°œìš”
            if "ë¶„ì„_ê°œìš”" in summary:
                overview = summary["ë¶„ì„_ê°œìš”"]
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ íŒŒì¼ ìˆ˜", overview.get("ì´_íŒŒì¼_ìˆ˜", 0))
                with col2:
                    st.metric("ì˜¤ë””ì˜¤ íŒŒì¼", overview.get("ì˜¤ë””ì˜¤_íŒŒì¼", 0))
                with col3:
                    st.metric("ì´ë¯¸ì§€ íŒŒì¼", overview.get("ì´ë¯¸ì§€_íŒŒì¼", 0))
                
                st.info(f"ğŸ“… ë¶„ì„ ì‹œê°„: {overview.get('ë¶„ì„_ì‹œê°„', 'N/A')}")
            
            # í†µí•© ìŠ¤í† ë¦¬
            if "í†µí•©_ìŠ¤í† ë¦¬" in summary:
                st.markdown("### ğŸ“– í†µí•© ìŠ¤í† ë¦¬")
                st.markdown(summary["í†µí•©_ìŠ¤í† ë¦¬"])
        
        with tab2:
            # í™”ì ë¶„ì„
            if "í™”ì_ë¶„ì„" in summary:
                speaker_analysis = summary["í™”ì_ë¶„ì„"]
                st.metric("ê°ì§€ëœ í™”ì ìˆ˜", speaker_analysis.get("ê°ì§€ëœ_í™”ì_ìˆ˜", 0))
                
                if "í™”ìë³„_ë°œì–¸_ë‚´ìš©" in speaker_analysis:
                    st.markdown("### ğŸ¤ í™”ìë³„ ë°œì–¸ ë‚´ìš©")
                    
                    for speaker_id, content in speaker_analysis["í™”ìë³„_ë°œì–¸_ë‚´ìš©"].items():
                        with st.container():
                            st.markdown(f"#### {speaker_id}")
                            col1, col2 = st.columns([1, 3])
                            with col1:
                                st.metric("ë°œì–¸ íšŸìˆ˜", content.get("ë°œì–¸_íšŸìˆ˜", 0))
                            with col2:
                                if content.get("ì£¼ìš”_ë°œì–¸"):
                                    st.markdown("**ì£¼ìš” ë°œì–¸:**")
                                    for j, statement in enumerate(content["ì£¼ìš”_ë°œì–¸"][:3], 1):
                                        st.markdown(f"{j}. {statement}")
                                
                                # ì „ì²´ ë°œì–¸ ë³´ê¸° (ì ‘ì„ ìˆ˜ ìˆê²Œ)
                                if content.get("ì „ì²´_ë°œì–¸") and len(content["ì „ì²´_ë°œì–¸"]) > 3:
                                    with st.expander(f"{speaker_id} ì „ì²´ ë°œì–¸ ë³´ê¸°"):
                                        for k, statement in enumerate(content["ì „ì²´_ë°œì–¸"], 1):
                                            st.markdown(f"{k}. {statement}")
        
        with tab3:
            # ì£¼ìš” ë‚´ìš©
            if "ì£¼ìš”_ë‚´ìš©" in summary:
                main_content = summary["ì£¼ìš”_ë‚´ìš©"]
                
                # í•µì‹¬ í‚¤ì›Œë“œ
                if "í•µì‹¬_í‚¤ì›Œë“œ" in main_content:
                    st.markdown("### ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ")
                    keywords = main_content["í•µì‹¬_í‚¤ì›Œë“œ"][:10]  # ìƒìœ„ 10ê°œ
                    if keywords:
                        for i, kw in enumerate(keywords, 1):
                            st.markdown(f"{i}. **{kw.get('ë‹¨ì–´', 'N/A')}** (ë¹ˆë„: {kw.get('ë¹ˆë„', 0)})")
                
                # ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸
                if "ì „ì²´_ì „ì‚¬_í…ìŠ¤íŠ¸" in main_content:
                    st.markdown("### ğŸ“ ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸")
                    with st.expander("ì „ì‚¬ í…ìŠ¤íŠ¸ ë³´ê¸°"):
                        st.text(main_content["ì „ì²´_ì „ì‚¬_í…ìŠ¤íŠ¸"])
                
                # ì´ë¯¸ì§€ í…ìŠ¤íŠ¸
                if "ì´ë¯¸ì§€_í…ìŠ¤íŠ¸" in main_content and main_content["ì´ë¯¸ì§€_í…ìŠ¤íŠ¸"]:
                    st.markdown("### ğŸ–¼ï¸ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                    for i, img_text in enumerate(main_content["ì´ë¯¸ì§€_í…ìŠ¤íŠ¸"], 1):
                        if img_text.strip():
                            st.markdown(f"**ì´ë¯¸ì§€ {i}**: {img_text}")
        
        with tab4:
            # AI ìƒí™© ë¶„ì„ (ìƒˆë¡œ ì¶”ê°€ëœ í•µì‹¬ ê¸°ëŠ¥)
            if "AI_ìƒí™©_ë¶„ì„" in summary:
                ai_analysis = summary["AI_ìƒí™©_ë¶„ì„"]
                
                if "error" in ai_analysis:
                    st.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {ai_analysis['error']}")
                else:
                    # ì‚¬ìš©ëœ ëª¨ë¸ í‘œì‹œ
                    if "ì‚¬ìš©ëœ_ëª¨ë¸" in ai_analysis:
                        st.success(f"ğŸ¤– ì‚¬ìš©ëœ AI ëª¨ë¸: **{ai_analysis['ì‚¬ìš©ëœ_ëª¨ë¸']}**")
                    
                    # ì „ì²´ ìƒí™© ë¶„ì„
                    if "ì „ì²´_ìƒí™©_ë¶„ì„" in ai_analysis:
                        st.markdown("### ğŸ” AI ì „ì²´ ìƒí™© ë¶„ì„")
                        st.markdown(ai_analysis["ì „ì²´_ìƒí™©_ë¶„ì„"])
                    
                    # í™”ìë³„ ì˜ë¯¸ ë¶„ì„
                    if "í™”ì_ì˜ë¯¸_ë¶„ì„" in ai_analysis:
                        st.markdown("### ğŸ­ AI í™”ì ì˜ë¯¸ ë¶„ì„")
                        for speaker_id, meaning in ai_analysis["í™”ì_ì˜ë¯¸_ë¶„ì„"].items():
                            with st.expander(f"ğŸ¤ {speaker_id} ë°œì–¸ ì˜ë¯¸"):
                                st.markdown(meaning)
                    
                    # íšŒì˜ ë§¥ë½ ë¶„ì„
                    if "íšŒì˜_ë§¥ë½_ë¶„ì„" in ai_analysis:
                        st.markdown("### ğŸ“‹ AI íšŒì˜ ë§¥ë½ ë¶„ì„")
                        st.markdown(ai_analysis["íšŒì˜_ë§¥ë½_ë¶„ì„"])
                    
                    # AI ì¢…í•© ê²°ë¡ 
                    if "AI_ì¢…í•©_ê²°ë¡ " in ai_analysis:
                        st.markdown("### ğŸ¯ AI ì¢…í•© ê²°ë¡ ")
                        st.info(ai_analysis["AI_ì¢…í•©_ê²°ë¡ "])
            else:
                st.warning("AI ìƒí™© ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        with tab5:
            # ì‚¬ìš©ëœ ì œì›
            if "ì‚¬ìš©ëœ_ì œì›" in summary:
                specs = summary["ì‚¬ìš©ëœ_ì œì›"]
                st.markdown("### âš™ï¸ ë¶„ì„ì— ì‚¬ìš©ëœ ê¸°ìˆ  ì œì›")
                
                for key, value in specs.items():
                    st.markdown(f"- **{key.replace('_', ' ').title()}**: {value}")
    
    def render_results(self, results):
        """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        if not results or not results.get("results"):
            st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        config = self.analysis_modes[results["mode"]]
        
        st.markdown(f"## ğŸ“Š {config['name']} ë¶„ì„ ê²°ê³¼")
        
        # ì „ì²´ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼", f"{results['files_processed']}ê°œ")
        with col2:
            st.metric("â±ï¸ ì†Œìš” ì‹œê°„", f"{results['duration']:.1f}ì´ˆ")
        with col3:
            st.metric("ğŸ¯ ì„±ê³µë¥ ", f"{(results['files_processed']/(results['total_files']*1.0)*100):.1f}%")
        with col4:
            st.metric("âŒ ì˜¤ë¥˜", f"{len(results['errors'])}ê°œ")
        
        # ì¢…í•© ë¶„ì„ ê²°ê³¼ ë¨¼ì € í‘œì‹œ (í•µì‹¬)  
        if "comprehensive_summary" in results:
            st.divider()
            self.render_comprehensive_summary(results["comprehensive_summary"])
        
        # íŒŒì¼ë³„ ê²°ê³¼
        st.divider()
        st.markdown("### ğŸ“‹ ê°œë³„ íŒŒì¼ ë¶„ì„ ê²°ê³¼")
        
        for i, result in enumerate(results["results"]):
            with st.expander(f"ğŸ“„ {result['filename']} ({result['type']})"):
                
                if "error" in result["analysis"]:
                    st.error(f"âŒ ì˜¤ë¥˜: {result['analysis']['error']}")
                    continue
                
                # ë¶„ì„ íƒ€ì…ë³„ ê²°ê³¼ í‘œì‹œ
                if "transcription" in result["analysis"]:
                    st.markdown("**ğŸ™ï¸ ìŒì„± ì¸ì‹ ê²°ê³¼:**")
                    st.write(result["analysis"]["transcription"])
                    
                    if "speakers" in result["analysis"] and result["analysis"]["speakers"]:
                        st.markdown("**ğŸ‘¥ í™”ì ë¶„ë¦¬ ê²°ê³¼:**")
                        speakers = result["analysis"]["speakers"]
                        st.write(f"ê°ì§€ëœ í™”ì ìˆ˜: {speakers.get('speaker_count', 0)}ëª…")
                        st.write(f"ë¶„ë¦¬ í’ˆì§ˆ: {speakers.get('silhouette_score', 0):.3f}")
                
                elif "extracted_text" in result["analysis"]:
                    st.markdown("**ğŸ” ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ:**")
                    for text_item in result["analysis"]["extracted_text"]:
                        st.write(f"- {text_item['text']} (ì‹ ë¢°ë„: {text_item['confidence']:.2f})")
                
                elif "content" in result["analysis"]:
                    st.markdown("**ğŸ“ í…ìŠ¤íŠ¸ ë‚´ìš©:**")
                    st.write(result["analysis"]["preview"])
                    
                    stats = result["analysis"]["stats"]
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ë¬¸ì", f"{stats['characters']:,}")
                    with col2:
                        st.metric("ë‹¨ì–´", f"{stats['words']:,}")
                    with col3:
                        st.metric("ì¤„", f"{stats['lines']:,}")
        
        # ì˜¤ë¥˜ ë‚´ì—­
        if results["errors"]:
            st.markdown("### âŒ ì˜¤ë¥˜ ë‚´ì—­")
            for error in results["errors"]:
                st.error(f"ğŸ“ {error['file']}: {error['error']}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    st.set_page_config(
        page_title="ğŸ† í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ",
        page_icon="ğŸ†",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # í—¤ë”
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    ">
        <h1 style="margin: 0; font-size: 2.5rem;">ğŸ† í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ</h1>
        <h3 style="margin: 0.5rem 0; opacity: 0.9;">í•˜ë‚˜ì˜ ì‹œìŠ¤í…œ, ë‹¤ì–‘í•œ ëª¨ë“œ</h3>
        <p style="margin: 0; font-size: 1.1rem; opacity: 0.8;">
            ê¶ê·¹/ê· í˜•/ì•ˆì „ ëª¨ë“œ ì¤‘ ì„ íƒí•˜ì—¬ ìµœì ì˜ ë¶„ì„ì„ ê²½í—˜í•˜ì„¸ìš”
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = UnifiedConferenceAnalyzer()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = None
    
    # 1ë‹¨ê³„: ëª¨ë“œ ì„ íƒ
    selected_mode = analyzer.render_mode_selector()
    
    st.divider()
    
    # 2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = analyzer.render_upload_system()
    
    # 3ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰
    if analyzer.render_analysis_button(uploaded_files):
        with st.spinner(f"ğŸ”„ {analyzer.analysis_modes[selected_mode]['name']} ë¶„ì„ ì¤‘..."):
            st.session_state.analysis_results = analyzer.execute_unified_analysis(uploaded_files)
    
    # 4ë‹¨ê³„: ê²°ê³¼ í‘œì‹œ
    if st.session_state.analysis_results:
        st.divider()
        analyzer.render_results(st.session_state.analysis_results)
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; margin-top: 2rem;">
        ğŸ† í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ v1.0<br>
        í•˜ë‚˜ì˜ ì‹œìŠ¤í…œìœ¼ë¡œ ëª¨ë“  ë¶„ì„ ëª¨ë“œ ì§€ì›
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()