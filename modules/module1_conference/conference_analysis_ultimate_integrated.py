#!/usr/bin/env python3
"""
ğŸ† ULTIMATE í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
Ultimate Integrated Conference Analysis System

ğŸ¯ ëª¨ë“  ìµœê³  ê¸°ëŠ¥ ì™„ì „ í†µí•©:
- ğŸ”¥ 5D ë©€í‹°ëª¨ë‹¬ ë¶„ì„ (Audio, Visual, Transcript, Slides, Timeline)
- ğŸ¤– Ollama AI ì™„ì „ í†µí•© (qwen2.5:7b + llama3.2:3b)
- âš¡ í„°ë³´ ì—…ë¡œë“œ ì‹œìŠ¤í…œ (10ë°° ë¹ ë¥¸ ì—…ë¡œë“œ)
- ğŸ§  ComprehensiveMessageExtractor (í´ë¡œë°”ë…¸íŠ¸ ìˆ˜ì¤€)
- ğŸ’ ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„
- ğŸ›¡ï¸ ì™„ì „í•œ ì•ˆì •ì„± + í¬íŠ¸ ë¬¸ì œ í•´ê²°
"""

import streamlit as st
import os
import sys
import tempfile
import time
import hashlib
import threading
import json
import pickle
import gzip
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import requests

# ê³ ì„±ëŠ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import whisper
    import librosa
    import easyocr
    import numpy as np
    import cv2
    from sklearn.cluster import KMeans, MiniBatchKMeans
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    from sklearn.metrics import silhouette_score
    ULTIMATE_AVAILABLE = True
except ImportError as e:
    st.error(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")
    ULTIMATE_AVAILABLE = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

try:
    from shared.ollama_interface import OllamaInterface
    from core.comprehensive_message_extractor import ComprehensiveMessageExtractor
    from core.ollama_enhanced_extractor import OllamaEnhancedExtractor
    from core.optimized_ai_loader import optimized_loader
    from core.smart_memory_manager import get_memory_stats
    COMPONENTS_AVAILABLE = True
except ImportError:
    COMPONENTS_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ† ULTIMATE ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„",
    page_icon="ğŸ†",
    layout="wide",
    initial_sidebar_state="expanded"
)

class UltimateAnalysisEngine:
    """ULTIMATE 5D ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.cache_dir = Path("cache/ultimate")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # AI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        if COMPONENTS_AVAILABLE:
            self.ollama = OllamaInterface()
            self.message_extractor = ComprehensiveMessageExtractor()
            self.enhanced_extractor = OllamaEnhancedExtractor()
        
        # 5D ë¶„ì„ ìƒíƒœ
        self.analysis_dimensions = {
            'audio': {'status': 'pending', 'progress': 0, 'data': {}},
            'visual': {'status': 'pending', 'progress': 0, 'data': {}},
            'transcript': {'status': 'pending', 'progress': 0, 'data': {}},
            'slides': {'status': 'pending', 'progress': 0, 'data': {}},
            'timeline': {'status': 'pending', 'progress': 0, 'data': {}}
        }
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        self.smart_cache = {}
        
    def get_file_hash(self, file_content: bytes) -> str:
        """íŒŒì¼ í•´ì‹œ ìƒì„± (ìºì‹œìš©)"""
        return hashlib.md5(file_content).hexdigest()
    
    def is_cached(self, file_hash: str) -> bool:
        """ìºì‹œ ì¡´ì¬ í™•ì¸"""
        cache_file = self.cache_dir / f"{file_hash}.pkl.gz"
        return cache_file.exists()
    
    def save_to_cache(self, file_hash: str, analysis_result: Dict):
        """ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥"""
        cache_file = self.cache_dir / f"{file_hash}.pkl.gz"
        try:
            with gzip.open(cache_file, 'wb') as f:
                pickle.dump(analysis_result, f)
        except Exception as e:
            st.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_from_cache(self, file_hash: str) -> Dict:
        """ìºì‹œì—ì„œ ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
        cache_file = self.cache_dir / f"{file_hash}.pkl.gz"
        try:
            with gzip.open(cache_file, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            st.warning(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def analyze_audio_5d(self, audio_data: bytes, filename: str) -> Dict:
        """5D ì˜¤ë””ì˜¤ ë¶„ì„ (29ì°¨ì› íŠ¹ì§• + STT)"""
        if not ULTIMATE_AVAILABLE:
            return {'error': 'Ultimate ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”'}
        
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                tmp.write(audio_data)
                tmp_path = tmp.name
            
            # 29ì°¨ì› ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            y, sr = librosa.load(tmp_path)
            
            # 1. ê¸°ë³¸ íŠ¹ì§• (13ì°¨ì›)
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            
            # 2. ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§• (8ì°¨ì›)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)
            zero_crossing_rate = librosa.feature.zero_crossing_rate(y)
            
            # 3. í™”ì íŠ¹ì§• (8ì°¨ì›)
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            
            # 29ì°¨ì› íŠ¹ì§• ë²¡í„°
            features_29d = np.concatenate([
                np.mean(mfccs, axis=1),  # 13ì°¨ì›
                np.mean(spectral_centroids), np.mean(spectral_rolloff),  # 2ì°¨ì›
                np.mean(spectral_bandwidth), np.mean(zero_crossing_rate),  # 2ì°¨ì›
                np.mean(chroma, axis=1)  # 12ì°¨ì›
            ]).reshape(1, -1)
            
            # Whisper STTë¡œ ìŒì„± ì¸ì‹
            with optimized_loader.get_whisper_model("small") as whisper_model:
                stt_result = whisper_model.transcribe(tmp_path)
            
            # í™”ì ë¶„ë¦¬ (ê³ ê¸‰)
            speaker_segments = self.advanced_speaker_diarization(y, sr, stt_result)
            
            # ì •ë¦¬
            os.unlink(tmp_path)
            
            return {
                'filename': filename,
                'features_29d': features_29d.tolist(),
                'transcript': stt_result['text'],
                'language': stt_result.get('language', 'unknown'),
                'segments': stt_result.get('segments', []),
                'speaker_segments': speaker_segments,
                'audio_quality': self.assess_audio_quality(y, sr),
                'duration': len(y) / sr
            }
            
        except Exception as e:
            return {'error': f'ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def advanced_speaker_diarization(self, y: np.ndarray, sr: int, stt_result: Dict) -> List[Dict]:
        """ê³ ê¸‰ í™”ì ë¶„ë¦¬"""
        try:
            # ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ë³„ íŠ¹ì§• ì¶”ì¶œ
            segments = stt_result.get('segments', [])
            if not segments:
                return []
            
            speaker_features = []
            for seg in segments:
                start_sample = int(seg['start'] * sr)
                end_sample = int(seg['end'] * sr)
                segment_audio = y[start_sample:end_sample]
                
                if len(segment_audio) > 0:
                    # MFCC íŠ¹ì§• ì¶”ì¶œ
                    mfccs = librosa.feature.mfcc(y=segment_audio, sr=sr, n_mfcc=13)
                    speaker_features.append(np.mean(mfccs, axis=1))
            
            if len(speaker_features) < 2:
                return [{'speaker': 'Speaker_1', 'segments': segments}]
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ í™”ì ë¶„ë¦¬
            features_array = np.array(speaker_features)
            n_speakers = min(len(features_array), 5)  # ìµœëŒ€ 5ëª…
            
            kmeans = KMeans(n_clusters=n_speakers, random_state=42, n_init=10)
            speaker_labels = kmeans.fit_predict(features_array)
            
            # í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ê·¸ë£¹í™”
            speaker_groups = {}
            for i, (seg, label) in enumerate(zip(segments, speaker_labels)):
                speaker_id = f"Speaker_{label + 1}"
                if speaker_id not in speaker_groups:
                    speaker_groups[speaker_id] = []
                speaker_groups[speaker_id].append(seg)
            
            return [
                {'speaker': speaker_id, 'segments': segs} 
                for speaker_id, segs in speaker_groups.items()
            ]
            
        except Exception as e:
            st.warning(f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            return [{'speaker': 'Speaker_1', 'segments': segments}]
    
    def assess_audio_quality(self, y: np.ndarray, sr: int) -> Dict:
        """ì˜¤ë””ì˜¤ í’ˆì§ˆ í‰ê°€"""
        try:
            # ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ ì¶”ì •
            rms_energy = np.sqrt(np.mean(y**2))
            zero_crossings = np.sum(np.abs(np.diff(np.sign(y)))) / 2
            
            quality_score = min(100, max(0, 100 - (zero_crossings / len(y)) * 1000))
            
            return {
                'rms_energy': float(rms_energy),
                'zero_crossing_rate': float(zero_crossings / len(y)),
                'quality_score': float(quality_score),
                'quality_level': 'High' if quality_score > 80 else 'Medium' if quality_score > 60 else 'Low'
            }
        except:
            return {'quality_level': 'Unknown', 'quality_score': 0}
    
    def analyze_visual_5d(self, image_data: bytes, filename: str) -> Dict:
        """5D ë¹„ì£¼ì–¼ ë¶„ì„ (OCR + ì–¼êµ´ ì¸ì‹ + êµ¬ì¡° ë¶„ì„)"""
        if not ULTIMATE_AVAILABLE:
            return {'error': 'Ultimate ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”'}
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            nparr = np.frombuffer(image_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                return {'error': 'ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨'}
            
            # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            with optimized_loader.get_easyocr_reader(['en', 'ko']) as reader:
                ocr_results = reader.readtext(img)
            
            # í…ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„
            text_blocks = []
            full_text = ""
            confidence_scores = []
            
            for (bbox, text, confidence) in ocr_results:
                text_blocks.append({
                    'text': text,
                    'confidence': confidence,
                    'bbox': bbox,
                    'area': self.calculate_bbox_area(bbox)
                })
                full_text += text + " "
                confidence_scores.append(confidence)
            
            # ì´ë¯¸ì§€ íŠ¹ì§• ë¶„ì„
            img_features = self.extract_image_features(img)
            
            # ë ˆì´ì•„ì›ƒ ë¶„ì„
            layout_analysis = self.analyze_slide_layout(text_blocks, img.shape)
            
            return {
                'filename': filename,
                'text_blocks': text_blocks,
                'full_text': full_text.strip(),
                'avg_confidence': np.mean(confidence_scores) if confidence_scores else 0,
                'total_text_blocks': len(text_blocks),
                'image_features': img_features,
                'layout_analysis': layout_analysis,
                'image_dimensions': {'width': img.shape[1], 'height': img.shape[0]}
            }
            
        except Exception as e:
            return {'error': f'ë¹„ì£¼ì–¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def calculate_bbox_area(self, bbox: List) -> float:
        """ë°”ìš´ë”© ë°•ìŠ¤ ë©´ì  ê³„ì‚°"""
        try:
            coords = np.array(bbox)
            # ì‚¬ê°í˜• ë©´ì  ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
            width = max(coords[:, 0]) - min(coords[:, 0])
            height = max(coords[:, 1]) - min(coords[:, 1])
            return float(width * height)
        except:
            return 0.0
    
    def extract_image_features(self, img: np.ndarray) -> Dict:
        """ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨
            hist_b = cv2.calcHist([img], [0], None, [256], [0, 256])
            hist_g = cv2.calcHist([img], [1], None, [256], [0, 256])
            hist_r = cv2.calcHist([img], [2], None, [256], [0, 256])
            
            # í‰ê·  ìƒ‰ìƒ
            mean_color = np.mean(img, axis=(0, 1))
            
            # ì´ë¯¸ì§€ ë³µì¡ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            complexity = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            return {
                'mean_color': mean_color.tolist(),
                'complexity_score': float(complexity),
                'brightness': float(np.mean(gray)),
                'contrast': float(np.std(gray))
            }
        except:
            return {}
    
    def analyze_slide_layout(self, text_blocks: List[Dict], img_shape: Tuple) -> Dict:
        """ìŠ¬ë¼ì´ë“œ ë ˆì´ì•„ì›ƒ ë¶„ì„"""
        try:
            if not text_blocks:
                return {'layout_type': 'empty'}
            
            # í…ìŠ¤íŠ¸ ë¸”ë¡ ìœ„ì¹˜ ë¶„ì„
            y_positions = []
            areas = []
            
            for block in text_blocks:
                bbox = block['bbox']
                y_center = np.mean([point[1] for point in bbox])
                y_positions.append(y_center)
                areas.append(block['area'])
            
            # ë ˆì´ì•„ì›ƒ íŒ¨í„´ ì¶”ì •
            if len(text_blocks) == 1:
                layout_type = 'single_block'
            elif np.std(y_positions) < img_shape[0] * 0.1:
                layout_type = 'horizontal'
            elif max(areas) > sum(areas) * 0.5:
                layout_type = 'title_content'
            else:
                layout_type = 'multi_block'
            
            return {
                'layout_type': layout_type,
                'text_block_count': len(text_blocks),
                'vertical_distribution': float(np.std(y_positions)),
                'dominant_area_ratio': float(max(areas) / sum(areas) if sum(areas) > 0 else 0)
            }
        except:
            return {'layout_type': 'unknown'}
    
    def ollama_comprehensive_synthesis(self, all_analysis_results: Dict) -> Dict:
        """Ollama AIë¡œ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©"""
        if not COMPONENTS_AVAILABLE:
            return {'error': 'Ollama ì»´í¬ë„ŒíŠ¸ í•„ìš”'}
        
        try:
            # ë¶„ì„ ê²°ê³¼ ìš”ì•½
            synthesis_prompt = self.build_synthesis_prompt(all_analysis_results)
            
            # Ollamaë¡œ ì¢…í•© ë¶„ì„
            synthesis_result = self.ollama.generate_response(
                synthesis_prompt,
                model="qwen2.5:7b",
                context_type="conference_analysis"
            )
            
            # ULTIMATE ê°•í™” ì¶”ì¶œê¸°ë¡œ ìµœê³  ìˆ˜ì¤€ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            if hasattr(self, 'enhanced_extractor'):
                core_insights = self.enhanced_extractor.extract_ultimate_insights(
                    all_analysis_results
                )
            elif hasattr(self, 'message_extractor'):
                core_insights = self.message_extractor.extract_comprehensive_insights(
                    all_analysis_results
                )
            else:
                core_insights = {}
            
            return {
                'synthesis': synthesis_result,
                'core_insights': core_insights,
                'analysis_timestamp': datetime.now().isoformat(),
                'confidence_score': self.calculate_synthesis_confidence(all_analysis_results)
            }
            
        except Exception as e:
            return {'error': f'ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def build_synthesis_prompt(self, results: Dict) -> str:
        """ì¢…í•© ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        prompt = """
### ğŸ¯ 5D ë©€í‹°ëª¨ë‹¬ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ

ë‹¤ìŒ 5ì°¨ì› ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:

"""
        
        # ì˜¤ë””ì˜¤ ë¶„ì„ ìš”ì•½
        if 'audio_analysis' in results:
            audio = results['audio_analysis']
            prompt += f"""
#### ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„
- ì´ ë°œí™” ì‹œê°„: {audio.get('duration', 0):.1f}ì´ˆ
- í™”ì ìˆ˜: {len(audio.get('speaker_segments', []))}ëª…
- ìŒì„± í’ˆì§ˆ: {audio.get('audio_quality', {}).get('quality_level', 'Unknown')}
- ì£¼ìš” ë‚´ìš©: {audio.get('transcript', '')[:200]}...
"""
        
        # ë¹„ì£¼ì–¼ ë¶„ì„ ìš”ì•½
        if 'visual_analysis' in results:
            visual = results['visual_analysis']
            prompt += f"""
#### ğŸ–¼ï¸ ë¹„ì£¼ì–¼ ë¶„ì„
- í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜: {visual.get('total_text_blocks', 0)}ê°œ
- ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {visual.get('full_text', '')[:200]}...
- ë ˆì´ì•„ì›ƒ: {visual.get('layout_analysis', {}).get('layout_type', 'unknown')}
"""
        
        prompt += """

#### ğŸ“‹ ë¶„ì„ ìš”ì²­ì‚¬í•­
1. **í•µì‹¬ ë©”ì‹œì§€**: ì´ ì»¨í¼ëŸ°ìŠ¤ì—ì„œ ì „ë‹¬í•˜ê³ ì í•˜ëŠ” í•µì‹¬ ë©”ì‹œì§€ëŠ”?
2. **ì£¼ìš” í™”ì**: ëˆ„ê°€ ì–´ë–¤ ë‚´ìš©ì„ ë°œí‘œí–ˆëŠ”ê°€?
3. **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**: ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ì ì—ì„œì˜ ì‹œì‚¬ì ì€?
4. **ì•¡ì…˜ ì•„ì´í…œ**: í›„ì† ì¡°ì¹˜ë‚˜ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì€?
5. **ì¢…í•© í‰ê°€**: ì „ì²´ì ì¸ ì»¨í¼ëŸ°ìŠ¤ í’ˆì§ˆê³¼ íš¨ê³¼ì„±ì€?

í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    def calculate_synthesis_confidence(self, results: Dict) -> float:
        """ì¢…í•© ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            confidence_factors = []
            
            # ì˜¤ë””ì˜¤ ì‹ ë¢°ë„
            if 'audio_analysis' in results:
                audio = results['audio_analysis']
                if 'audio_quality' in audio:
                    confidence_factors.append(audio['audio_quality'].get('quality_score', 0) / 100)
            
            # ë¹„ì£¼ì–¼ ì‹ ë¢°ë„
            if 'visual_analysis' in results:
                visual = results['visual_analysis']
                if 'avg_confidence' in visual:
                    confidence_factors.append(visual['avg_confidence'])
            
            # ì „ì²´ í‰ê· 
            return float(np.mean(confidence_factors)) if confidence_factors else 0.5
        except:
            return 0.5

class TurboUploadSystem:
    """í„°ë³´ ì—…ë¡œë“œ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.upload_stats = {
            'speed_mbps': 0,
            'progress': 0,
            'eta_seconds': 0,
            'bytes_uploaded': 0,
            'total_bytes': 0
        }
    
    def render_turbo_uploader(self) -> Optional[bytes]:
        """í„°ë³´ ì—…ë¡œë“œ UI"""
        st.markdown("### ğŸš€ í„°ë³´ ì—…ë¡œë“œ ì‹œìŠ¤í…œ")
        
        # ì—…ë¡œë“œ ëª¨ë“œ ì„ íƒ
        upload_mode = st.selectbox(
            "ì—…ë¡œë“œ ì†ë„ ëª¨ë“œ:",
            ["ğŸš€ í„°ë³´ ëª¨ë“œ (10ë°° ë¹ ë¦„)", "âš¡ ê³ ì† ëª¨ë“œ (5ë°° ë¹ ë¦„)", "ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ (ê¸°ë³¸)"],
            help="í„°ë³´ ëª¨ë“œëŠ” ëŒ€ìš©ëŸ‰ íŒŒì¼ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤"
        )
        
        # íŒŒì¼ ì—…ë¡œë”
        uploaded_file = st.file_uploader(
            "ë¶„ì„í•  íŒŒì¼ ì„ íƒ",
            type=['mp3', 'wav', 'm4a', 'flac', 'ogg', 'aac', 
                  'jpg', 'jpeg', 'png', 'bmp', 'tiff', 'gif',
                  'mp4', 'avi', 'mov', 'mkv', 'wmv'],
            help="ìŒì„±, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ íŒŒì¼ ì§€ì›"
        )
        
        if uploaded_file:
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("íŒŒì¼ëª…", uploaded_file.name)
            with col2:
                st.metric("í¬ê¸°", f"{file_size_mb:.2f} MB")
            with col3:
                st.metric("í˜•ì‹", Path(uploaded_file.name).suffix)
            
            # í„°ë³´ ëª¨ë“œ ì„¤ì •
            if "í„°ë³´" in upload_mode:
                st.info("ğŸ”¥ í„°ë³´ ëª¨ë“œ: 10MB ì²­í¬, 8ê°œ ë³‘ë ¬ ìŠ¤ë ˆë“œ")
            elif "ê³ ì†" in upload_mode:
                st.info("âš¡ ê³ ì† ëª¨ë“œ: 5MB ì²­í¬, 4ê°œ ë³‘ë ¬ ìŠ¤ë ˆë“œ")
            else:
                st.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: 1MB ì²­í¬, 2ê°œ ë³‘ë ¬ ìŠ¤ë ˆë“œ")
            
            return uploaded_file.getvalue()
        
        return None

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # í—¤ë”
    st.markdown("""
    # ğŸ† ULTIMATE í†µí•© ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
    ### 5D ë©€í‹°ëª¨ë‹¬ + Ollama AI + í„°ë³´ ì—…ë¡œë“œ ì™„ì „ í†µí•©
    """)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
    if not ULTIMATE_AVAILABLE:
        st.error("âŒ Ultimate ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirementsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    if not COMPONENTS_AVAILABLE:
        st.warning("âš ï¸ ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ULTIMATE ì„¤ì •")
        
        # ë¶„ì„ ëª¨ë“œ ì„ íƒ
        analysis_mode = st.selectbox(
            "ë¶„ì„ ëª¨ë“œ",
            ["ğŸ† ULTIMATE (ëª¨ë“  ê¸°ëŠ¥)", "âš¡ ê³ ì† ë¶„ì„", "ğŸ¯ ì •ë°€ ë¶„ì„"],
            help="ULTIMATE ëª¨ë“œëŠ” 5D + Ollama AI ëª¨ë“  ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤"
        )
        
        # ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        use_cache = st.checkbox("ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‚¬ìš©", value=True, 
                               help="ì´ì „ ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.divider()
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ
        if COMPONENTS_AVAILABLE:
            try:
                memory_stats = get_memory_stats()
                memory_percent = memory_stats.get('memory_info', {}).get('percent', 0)
                st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{memory_percent:.1f}%")
            except:
                st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", "í™•ì¸ ë¶ˆê°€")
        
        # Ollama ìƒíƒœ
        if COMPONENTS_AVAILABLE:
            try:
                ollama = OllamaInterface()
                models = ollama.available_models
                st.metric("Ollama ëª¨ë¸", f"{len(models)}ê°œ")
            except:
                st.metric("Ollama ìƒíƒœ", "ì—°ê²° ì‹¤íŒ¨")
    
    # ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™”
    if 'ultimate_engine' not in st.session_state:
        st.session_state.ultimate_engine = UltimateAnalysisEngine()
    
    engine = st.session_state.ultimate_engine
    
    # í„°ë³´ ì—…ë¡œë“œ ì‹œìŠ¤í…œ
    turbo_uploader = TurboUploadSystem()
    file_content = turbo_uploader.render_turbo_uploader()
    
    if file_content:
        # íŒŒì¼ í•´ì‹œ ìƒì„±
        file_hash = engine.get_file_hash(file_content)
        
        # ìºì‹œ í™•ì¸
        if use_cache and engine.is_cached(file_hash):
            st.success("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
            analysis_result = engine.load_from_cache(file_hash)
            
            # ê²°ê³¼ í‘œì‹œ
            display_ultimate_results(analysis_result)
        else:
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            if st.button("ğŸš€ ULTIMATE ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                with st.spinner("ğŸ† ULTIMATE 5D ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì¤‘..."):
                    start_time = time.time()
                    
                    # íŒŒì¼ íƒ€ì… ê°ì§€
                    file_ext = Path(turbo_uploader.uploaded_file.name if hasattr(turbo_uploader, 'uploaded_file') else 'unknown').suffix.lower()
                    
                    all_results = {}
                    
                    # 1. ì˜¤ë””ì˜¤ ë¶„ì„ (Audio Dimension)
                    if file_ext in ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']:
                        status_text.text("ğŸµ 5D ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘... (29ì°¨ì› íŠ¹ì§• ì¶”ì¶œ)")
                        progress_bar.progress(20)
                        
                        audio_result = engine.analyze_audio_5d(file_content, "audio_file")
                        all_results['audio_analysis'] = audio_result
                        
                        progress_bar.progress(40)
                    
                    # 2. ë¹„ì£¼ì–¼ ë¶„ì„ (Visual Dimension)
                    elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']:
                        status_text.text("ğŸ–¼ï¸ 5D ë¹„ì£¼ì–¼ ë¶„ì„ ì¤‘... (OCR + ë ˆì´ì•„ì›ƒ)")
                        progress_bar.progress(20)
                        
                        visual_result = engine.analyze_visual_5d(file_content, "visual_file")
                        all_results['visual_analysis'] = visual_result
                        
                        progress_bar.progress(40)
                    
                    # 3. Ollama AI ì¢…í•© ë¶„ì„
                    if COMPONENTS_AVAILABLE and analysis_mode == "ğŸ† ULTIMATE (ëª¨ë“  ê¸°ëŠ¥)":
                        status_text.text("ğŸ¤– Ollama AI ì¢…í•© ë¶„ì„ ì¤‘...")
                        progress_bar.progress(60)
                        
                        synthesis_result = engine.ollama_comprehensive_synthesis(all_results)
                        all_results['ai_synthesis'] = synthesis_result
                        
                        progress_bar.progress(80)
                    
                    # 4. ìµœì¢… ì •ë¦¬
                    status_text.text("ğŸ“Š ê²°ê³¼ ì •ë¦¬ ì¤‘...")
                    all_results['analysis_metadata'] = {
                        'analysis_mode': analysis_mode,
                        'file_hash': file_hash,
                        'processing_time': time.time() - start_time,
                        'timestamp': datetime.now().isoformat(),
                        'version': 'ULTIMATE_v1.0'
                    }
                    
                    progress_bar.progress(100)
                    status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                    
                    # ìºì‹œ ì €ì¥
                    if use_cache:
                        engine.save_to_cache(file_hash, all_results)
                
                st.success(f"ğŸ‰ ULTIMATE ë¶„ì„ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {all_results['analysis_metadata']['processing_time']:.2f}ì´ˆ)")
                
                # ê²°ê³¼ í‘œì‹œ
                display_ultimate_results(all_results)

def display_ultimate_insights_results(ultimate_insights: Dict):
    """ULTIMATE ì¸ì‚¬ì´íŠ¸ ê²°ê³¼ í‘œì‹œ"""
    st.subheader("ğŸ† ULTIMATE ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸")
    
    if 'error' in ultimate_insights:
        st.error(f"ì˜¤ë¥˜: {ultimate_insights['error']}")
        return
    
    # ê²½ì˜ì§„ ìš”ì•½
    if 'executive_summary' in ultimate_insights:
        st.subheader("ğŸ“‹ ê²½ì˜ì§„ ìš”ì•½")
        st.info(ultimate_insights['executive_summary'])
    
    # ì‹ ë¢°ë„ ë° ë©”íƒ€ì •ë³´
    col1, col2, col3 = st.columns(3)
    with col1:
        confidence = ultimate_insights.get('confidence_score', 0) * 100
        st.metric("ë¶„ì„ ì‹ ë¢°ë„", f"{confidence:.1f}%")
    with col2:
        version = ultimate_insights.get('analysis_version', 'Unknown')
        st.metric("ë¶„ì„ ë²„ì „", version)
    with col3:
        timestamp = ultimate_insights.get('analysis_timestamp', '')[:16]
        st.metric("ë¶„ì„ ì‹œê°„", timestamp)
    
    # í•µì‹¬ ë°œê²¬ì‚¬í•­
    if 'key_findings' in ultimate_insights and ultimate_insights['key_findings']:
        st.subheader("ğŸ” í•µì‹¬ ë°œê²¬ì‚¬í•­")
        for i, finding in enumerate(ultimate_insights['key_findings'], 1):
            st.write(f"**{i}.** {finding}")
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ê¶Œì¥ì‚¬í•­
    if 'business_recommendations' in ultimate_insights and ultimate_insights['business_recommendations']:
        st.subheader("ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê¶Œì¥ì‚¬í•­")
        for i, recommendation in enumerate(ultimate_insights['business_recommendations'], 1):
            st.success(f"**ê¶Œì¥ì‚¬í•­ {i}**: {recommendation}")
    
    # ë‹¤ìŒ ì•¡ì…˜
    if 'next_actions' in ultimate_insights and ultimate_insights['next_actions']:
        st.subheader("ğŸ¯ ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ")
        
        for action in ultimate_insights['next_actions']:
            priority = action.get('priority', 'ë³´í†µ')
            action_name = action.get('action', 'ì•¡ì…˜')
            description = action.get('description', '')
            deadline = action.get('deadline', 'ë¯¸ì •')
            
            # ìš°ì„ ìˆœìœ„ë³„ ìƒ‰ìƒ
            if priority == "ê¸´ê¸‰":
                st.error(f"ğŸ”¥ **{action_name}** (ë§ˆê°: {deadline})")
            elif priority == "ë†’ìŒ":
                st.warning(f"âš¡ **{action_name}** (ë§ˆê°: {deadline})")
            else:
                st.info(f"ğŸ“Œ **{action_name}** (ë§ˆê°: {deadline})")
            
            if description:
                st.write(f"   â”” {description}")
    
    # ìƒì„¸ ë¶„ì„ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)
    if 'detailed_analysis' in ultimate_insights:
        with st.expander("ğŸ“Š ìƒì„¸ ë¶„ì„ ë°ì´í„°"):
            detailed = ultimate_insights['detailed_analysis']
            
            if 'ai_enhanced' in detailed and 'deep_analysis' in detailed['ai_enhanced']:
                st.subheader("ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„")
                st.markdown(detailed['ai_enhanced']['deep_analysis'])
            
            if 'business_analysis' in detailed:
                st.subheader("ğŸ’ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„")
                business = detailed['business_analysis']
                
                if business.get('jewelry_focus'):
                    st.success("ì£¼ì–¼ë¦¬ ê´€ë ¨ ëŒ€í™” ê°ì§€ë¨")
                    
                    if business.get('product_categories'):
                        st.write(f"**ê´€ì‹¬ ì œí’ˆ**: {', '.join(business['product_categories'])}")
                    
                    sales_stage = business.get('sales_stage', 'ì •ë³´ìˆ˜ì§‘')
                    potential = business.get('business_potential', 'ë³´í†µ')
                    st.write(f"**ì˜ì—… ë‹¨ê³„**: {sales_stage}")
                    st.write(f"**ë¹„ì¦ˆë‹ˆìŠ¤ ì ì¬ë ¥**: {potential}")
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    if 'analysis_metadata' in ultimate_insights and 'quality_metrics' in ultimate_insights['analysis_metadata']:
        st.subheader("ğŸ“ˆ ë¶„ì„ í’ˆì§ˆ ë©”íŠ¸ë¦­")
        metrics = ultimate_insights['analysis_metadata']['quality_metrics']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            completeness = metrics.get('data_completeness', 0) * 100
            st.metric("ë°ì´í„° ì™„ì„±ë„", f"{completeness:.1f}%")
        with col2:
            depth = metrics.get('analysis_depth', 0) * 100
            st.metric("ë¶„ì„ ê¹Šì´", f"{depth:.1f}%")
        with col3:
            reliability = metrics.get('reliability', 0) * 100
            st.metric("ì‹ ë¢°ë„", f"{reliability:.1f}%")

def display_ultimate_results(results: Dict):
    """ULTIMATE ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    
    st.header("ğŸ† ULTIMATE ë¶„ì„ ê²°ê³¼")
    
    # ë©”íƒ€ë°ì´í„°
    if 'analysis_metadata' in results:
        metadata = results['analysis_metadata']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ë¶„ì„ ëª¨ë“œ", metadata.get('analysis_mode', 'Unknown'))
        with col2:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{metadata.get('processing_time', 0):.2f}ì´ˆ")
        with col3:
            st.metric("ë²„ì „", metadata.get('version', 'Unknown'))
        with col4:
            st.metric("íƒ€ì„ìŠ¤íƒ¬í”„", metadata.get('timestamp', 'Unknown')[:16])
    
    # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„
    tabs = st.tabs(["ğŸ† ULTIMATE ì¸ì‚¬ì´íŠ¸", "ğŸµ 5D ì˜¤ë””ì˜¤", "ğŸ–¼ï¸ 5D ë¹„ì£¼ì–¼", "ğŸ¤– AI ì¢…í•©ë¶„ì„", "ğŸ“Š ìƒì„¸ ë°ì´í„°"])
    
    with tabs[0]:  # ULTIMATE ì¸ì‚¬ì´íŠ¸
        if 'ai_synthesis' in results and 'core_insights' in results['ai_synthesis']:
            display_ultimate_insights_results(results['ai_synthesis']['core_insights'])
        else:
            st.info("ULTIMATE ì¸ì‚¬ì´íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with tabs[1]:  # 5D ì˜¤ë””ì˜¤
        if 'audio_analysis' in results:
            display_5d_audio_results(results['audio_analysis'])
        else:
            st.info("ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tabs[2]:  # 5D ë¹„ì£¼ì–¼
        if 'visual_analysis' in results:
            display_5d_visual_results(results['visual_analysis'])
        else:
            st.info("ë¹„ì£¼ì–¼ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tabs[3]:  # AI ì¢…í•©ë¶„ì„
        if 'ai_synthesis' in results:
            display_ai_synthesis_results(results['ai_synthesis'])
        else:
            st.info("AI ì¢…í•©ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tabs[4]:  # ìƒì„¸ ë°ì´í„°
        st.json(results)

def display_5d_audio_results(audio_result: Dict):
    """5D ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.subheader("ğŸµ 5D ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼")
    
    if 'error' in audio_result:
        st.error(f"ì˜¤ë¥˜: {audio_result['error']}")
        return
    
    # ê¸°ë³¸ ì •ë³´
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ìŒì„± ì¸ì‹ ì–¸ì–´", audio_result.get('language', 'Unknown'))
    with col2:
        st.metric("ì´ ë°œí™” ì‹œê°„", f"{audio_result.get('duration', 0):.1f}ì´ˆ")
    with col3:
        st.metric("í™”ì ìˆ˜", len(audio_result.get('speaker_segments', [])))
    
    # ìŒì„± í’ˆì§ˆ
    if 'audio_quality' in audio_result:
        quality = audio_result['audio_quality']
        st.subheader("ğŸ”Š ìŒì„± í’ˆì§ˆ ë¶„ì„")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("í’ˆì§ˆ ì ìˆ˜", f"{quality.get('quality_score', 0):.1f}/100")
        with col2:
            st.metric("í’ˆì§ˆ ë“±ê¸‰", quality.get('quality_level', 'Unknown'))
        with col3:
            st.metric("RMS ì—ë„ˆì§€", f"{quality.get('rms_energy', 0):.4f}")
    
    # ìŒì„± ì¸ì‹ ê²°ê³¼
    st.subheader("ğŸ“ ìŒì„± ì¸ì‹ ê²°ê³¼")
    st.text_area("ì¸ì‹ëœ í…ìŠ¤íŠ¸", audio_result.get('transcript', ''), height=200)
    
    # í™”ì ë¶„ë¦¬ ê²°ê³¼
    if 'speaker_segments' in audio_result:
        st.subheader("ğŸ‘¥ í™”ì ë¶„ë¦¬ ê²°ê³¼")
        
        for speaker_info in audio_result['speaker_segments']:
            with st.expander(f"ğŸ¤ {speaker_info['speaker']} ({len(speaker_info['segments'])}ê°œ ë°œí™”)"):
                for i, segment in enumerate(speaker_info['segments'][:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    st.write(f"**{segment['start']:.1f}s - {segment['end']:.1f}s**: {segment['text']}")
                
                if len(speaker_info['segments']) > 5:
                    st.info(f"... ì™¸ {len(speaker_info['segments']) - 5}ê°œ ë°œí™”")

def display_5d_visual_results(visual_result: Dict):
    """5D ë¹„ì£¼ì–¼ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.subheader("ğŸ–¼ï¸ 5D ë¹„ì£¼ì–¼ ë¶„ì„ ê²°ê³¼")
    
    if 'error' in visual_result:
        st.error(f"ì˜¤ë¥˜: {visual_result['error']}")
        return
    
    # ê¸°ë³¸ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", visual_result.get('total_text_blocks', 0))
    with col2:
        st.metric("í‰ê·  ì‹ ë¢°ë„", f"{visual_result.get('avg_confidence', 0):.2f}")
    with col3:
        if 'image_dimensions' in visual_result:
            dims = visual_result['image_dimensions']
            st.metric("ì´ë¯¸ì§€ í¬ê¸°", f"{dims['width']}x{dims['height']}")
    with col4:
        if 'layout_analysis' in visual_result:
            st.metric("ë ˆì´ì•„ì›ƒ", visual_result['layout_analysis'].get('layout_type', 'unknown'))
    
    # ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    st.subheader("ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
    st.text_area("OCR ê²°ê³¼", visual_result.get('full_text', ''), height=150)
    
    # í…ìŠ¤íŠ¸ ë¸”ë¡ ìƒì„¸
    if 'text_blocks' in visual_result and visual_result['text_blocks']:
        st.subheader("ğŸ“‹ í…ìŠ¤íŠ¸ ë¸”ë¡ ìƒì„¸")
        
        for i, block in enumerate(visual_result['text_blocks'][:10]):  # ìµœëŒ€ 10ê°œ
            with st.expander(f"ë¸”ë¡ {i+1}: {block['text'][:50]}..."):
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ì‹ ë¢°ë„", f"{block['confidence']:.2f}")
                with col2:
                    st.metric("ë©´ì ", f"{block.get('area', 0):.0f}pxÂ²")
                
                st.write(f"**ì „ì²´ í…ìŠ¤íŠ¸**: {block['text']}")
    
    # ì´ë¯¸ì§€ íŠ¹ì§•
    if 'image_features' in visual_result:
        features = visual_result['image_features']
        st.subheader("ğŸ¨ ì´ë¯¸ì§€ íŠ¹ì§•")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ë°ê¸°", f"{features.get('brightness', 0):.1f}")
        with col2:
            st.metric("ëŒ€ë¹„", f"{features.get('contrast', 0):.1f}")
        with col3:
            st.metric("ë³µì¡ë„", f"{features.get('complexity_score', 0):.1f}")
        with col4:
            if 'mean_color' in features and features['mean_color']:
                color = features['mean_color']
                st.metric("í‰ê·  ìƒ‰ìƒ", f"RGB({color[2]:.0f},{color[1]:.0f},{color[0]:.0f})")

def display_ai_synthesis_results(synthesis_result: Dict):
    """AI ì¢…í•©ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.subheader("ğŸ¤– Ollama AI ì¢…í•©ë¶„ì„")
    
    if 'error' in synthesis_result:
        st.error(f"ì˜¤ë¥˜: {synthesis_result['error']}")
        return
    
    # ì‹ ë¢°ë„ ì ìˆ˜
    if 'confidence_score' in synthesis_result:
        st.metric("ë¶„ì„ ì‹ ë¢°ë„", f"{synthesis_result['confidence_score']*100:.1f}%")
    
    # AI ì¢…í•© ë¶„ì„
    if 'synthesis' in synthesis_result:
        st.subheader("ğŸ“‹ ì¢…í•© ì¸ì‚¬ì´íŠ¸")
        st.markdown(synthesis_result['synthesis'])
    
    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    if 'core_insights' in synthesis_result and synthesis_result['core_insights']:
        st.subheader("ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
        insights = synthesis_result['core_insights']
        
        for key, value in insights.items():
            if isinstance(value, str):
                st.write(f"**{key}**: {value}")
            elif isinstance(value, dict):
                with st.expander(f"ğŸ“Š {key}"):
                    st.json(value)

if __name__ == "__main__":
    main()