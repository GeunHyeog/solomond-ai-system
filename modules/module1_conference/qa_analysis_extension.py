#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Q&A ë¶„ì„ í™•ì¥ ëª¨ë“ˆ
ë°œí‘œ í›„ Q&A ì„¸ì…˜, ì¸í„°ë·°, ì§ˆì˜ì‘ë‹µ ê¸°ë¡ ì „ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ
"""

import streamlit as st
import re
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

class QAAnalysisExtension:
    """Q&A ì„¸ì…˜ ì „ë¬¸ ë¶„ì„ í™•ì¥ ëª¨ë“ˆ"""
    
    def __init__(self):
        self.analysis_results = {}
        
    def render_qa_analysis_interface(self):
        """Q&A ë¶„ì„ ì „ë¬¸ ì¸í„°í˜ì´ìŠ¤"""
        st.header("â“ Q&A ì„¸ì…˜ ì „ë¬¸ ë¶„ì„")
        
        st.info("ğŸ¯ **Q&A ì„¸ì…˜ íŠ¹í™” ê¸°ëŠ¥**: ì§ˆë¬¸ ìœ í˜•, ë‹µë³€ í’ˆì§ˆ, ì°¸ì—¬ë„, ì£¼ìš” ì´ìŠˆë¥¼ ê¹œì§í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤")
        
        # Q&A ë¶„ì„ ìœ í˜• ì„ íƒ
        qa_analysis_type = st.radio(
            "ë¶„ì„í•  Q&A ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:",
            ["ğŸ¬ ë°œí‘œ í›„ Q&A", "ğŸ—£ï¸ ì¸í„°ë·°/ëŒ€í™”", "ğŸ“‹ ì§ˆì˜ì‘ë‹µ ê¸°ë¡"],
            horizontal=True
        )
        
        if "ë°œí‘œ í›„" in qa_analysis_type:
            self._render_presentation_qa_analysis()
        elif "ì¸í„°ë·°" in qa_analysis_type:
            self._render_interview_analysis()
        else:
            self._render_qa_record_analysis()
        
        # Q&A ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if hasattr(st.session_state, 'qa_analysis_results') and st.session_state.qa_analysis_results:
            self._display_qa_results(st.session_state.qa_analysis_results)
    
    def _render_presentation_qa_analysis(self):
        """ë°œí‘œ í›„ Q&A ë¶„ì„ UI"""
        st.markdown("#### ğŸ¬ ë°œí‘œ í›„ Q&A ì„¸ì…˜ ë¶„ì„")
        
        # ë°œí‘œ ì •ë³´ ì…ë ¥
        with st.expander("ğŸ“ ë°œí‘œ ì •ë³´ (ì„ íƒì‚¬í•­)", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                presentation_title = st.text_input("ë°œí‘œ ì£¼ì œ", placeholder="ì˜ˆ: AI ê¸°ìˆ ì˜ ë¯¸ë˜")
                presenter_name = st.text_input("ë°œí‘œì", placeholder="ì˜ˆ: ê¹€ì² ìˆ˜ ë°•ì‚¬")
            with col2:
                presentation_duration = st.number_input("ë°œí‘œ ì‹œê°„(ë¶„)", min_value=5, max_value=180, value=30)
                audience_size = st.number_input("ì²­ì¤‘ ê·œëª¨", min_value=1, max_value=1000, value=50)
        
        # Q&A ì„¸ì…˜ íŒŒì¼ ì—…ë¡œë“œ
        qa_files = st.file_uploader(
            "Q&A ì„¸ì…˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:",
            type=['wav', 'mp3', 'm4a', 'mp4', 'mov'],
            accept_multiple_files=True,
            key="presentation_qa_files",
            help="ë°œí‘œ í›„ Q&A ì„¸ì…˜ì„ ë…¹ìŒí•œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        
        if qa_files:
            st.success(f"âœ… {len(qa_files)}ê°œ Q&A ì„¸ì…˜ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            
            # ë¶„ì„ ì˜µì…˜
            st.markdown("#### âš™ï¸ Q&A ë¶„ì„ ì˜µì…˜")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                detect_questions = st.checkbox("â“ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜", value=True, help="ê¸°ìˆ ì /ì´ë¡ ì /ì‹¤ë¬´ì  ì§ˆë¬¸ ë“± ë¶„ë¥˜")
                analyze_engagement = st.checkbox("ğŸ“Š ì°¸ì—¬ë„ ë¶„ì„", value=True, help="ì§ˆë¬¸ ë¹ˆë„, ì²­ì¤‘ ë°˜ì‘ ë“±")
                
            with col2:
                evaluate_answers = st.checkbox("ğŸ¯ ë‹µë³€ í’ˆì§ˆ í‰ê°€", value=True, help="ëª…í™•ì„±, ì™„ì „ì„±, ì „ë¬¸ì„± í‰ê°€")
                extract_followups = st.checkbox("ğŸ”„ í›„ì† ì§ˆë¬¸ ì¶”ì¶œ", value=True, help="ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•œ ì§ˆë¬¸ ì‹ë³„")
                
            with col3:
                sentiment_analysis = st.checkbox("ğŸ˜Š ê°ì • ë¶„ì„", value=True, help="ì§ˆë¬¸ìì™€ ë°œí‘œìì˜ ê°ì • ìƒíƒœ")
                topic_clustering = st.checkbox("ğŸ·ï¸ ì£¼ì œ ê·¸ë£¹í™”", value=True, help="ë¹„ìŠ·í•œ ì£¼ì œì˜ ì§ˆë¬¸ ê·¸ë£¹í™”")
            
            if st.button("ğŸ§  Q&A ì„¸ì…˜ ì¢…í•© ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                qa_options = {
                    'detect_questions': detect_questions,
                    'analyze_engagement': analyze_engagement,  
                    'evaluate_answers': evaluate_answers,
                    'extract_followups': extract_followups,
                    'sentiment_analysis': sentiment_analysis,
                    'topic_clustering': topic_clustering,
                    'presentation_context': {
                        'title': presentation_title,
                        'presenter': presenter_name,
                        'duration': presentation_duration,
                        'audience_size': audience_size
                    }
                }
                self._analyze_qa_session(qa_files, qa_options)
    
    def _render_interview_analysis(self):
        """ì¸í„°ë·°/ëŒ€í™” ë¶„ì„ UI"""
        st.markdown("#### ğŸ—£ï¸ ì¸í„°ë·°/ëŒ€í™” ë¶„ì„")
        
        interview_type = st.selectbox(
            "ì¸í„°ë·° ìœ í˜•:",
            ["ì²´ìš© ë©´ì ‘", "ì „ë¬¸ê°€ ì¸í„°ë·°", "ê³ ê° ìƒë‹´", "ë¹„ì¦ˆë‹ˆìŠ¤ ë¯¸íŒ…", "ì¼ë°˜ ëŒ€í™”"]
        )
        
        # íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥
        input_method = st.radio(
            "ì…ë ¥ ë°©ì‹:",
            ["ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼", "ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë¡"],
            horizontal=True
        )
        
        if "ì˜¤ë””ì˜¤" in input_method:
            interview_files = st.file_uploader(
                "ì¸í„°ë·° ì˜¤ë””ì˜¤ íŒŒì¼:",
                type=['wav', 'mp3', 'm4a', 'mp4'],
                accept_multiple_files=True,
                key="interview_files"
            )
            
            if interview_files and st.button("ğŸ—£ï¸ ì¸í„°ë·° ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                self._analyze_interview_files(interview_files, interview_type)
        
        else:
            interview_text = st.text_area(
                "ì¸í„°ë·° ëŒ€í™” ê¸°ë¡:",
                height=250,
                placeholder="ë©´ì ‘ê´€: ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\nì§€ì›ì: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ”...\në©´ì ‘ê´€: ì–´ë–¤ ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?\nì§€ì›ì: ì§€ë‚œ 3ë…„ê°„...",
                key="interview_text"
            )
            
            if interview_text:
                # í…ìŠ¤íŠ¸ í†µê³„
                word_count = len(interview_text.split())
                char_count = len(interview_text)
                
                col1, col2, col3 = st.columns(3)
                col1.metric("ë‹¨ì–´ ìˆ˜", word_count)
                col2.metric("ê¸€ì ìˆ˜", char_count)
                col3.metric("ì˜ˆìƒ ë¶„ì„ ì‹œê°„", f"{max(1, word_count//100)} ë¶„")
                
                if st.button("ğŸ“ ì¸í„°ë·° í…ìŠ¤íŠ¸ ë¶„ì„", type="primary", use_container_width=True):
                    self._analyze_interview_text(interview_text, interview_type)
    
    def _render_qa_record_analysis(self):
        """ì§ˆì˜ì‘ë‹µ ê¸°ë¡ ë¶„ì„ UI"""
        st.markdown("#### ğŸ“‹ ì§ˆì˜ì‘ë‹µ ê¸°ë¡ ë¶„ì„")
        
        st.info("ğŸ’¡ íŒ: 'Q:', 'A:' ë˜ëŠ” 'ì§ˆë¬¸:', 'ë‹µë³€:' í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤")
        
        qa_text = st.text_area(
            "Q&A ê¸°ë¡ì„ ì…ë ¥í•˜ì„¸ìš”:",
            height=300,
            placeholder="Q: AI ê¸°ìˆ ì˜ ë¯¸ë˜ ì „ë§ì€ ì–´ë–»ê²Œ ë³´ì‹œë‚˜ìš”?\nA: AI ê¸°ìˆ ì€ í–¥í›„ 10ë…„ê°„ ë”ìš± ë°œì „í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤...\n\nQ: êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\nA: ì˜ˆë¥¼ ë“¤ì–´ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ...",
            key="qa_record_text"
        )
        
        if qa_text:
            # Q&A í†µê³„ ë¯¸ë¦¬ë³´ê¸°
            question_count = qa_text.count('Q:') + qa_text.count('ì§ˆë¬¸:')
            answer_count = qa_text.count('A:') + qa_text.count('ë‹µë³€:')
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ì§ˆë¬¸ ìˆ˜", question_count)
            col2.metric("ë‹µë³€ ìˆ˜", answer_count)
            col3.metric("ë§¤ì¹­ ë¹„ìœ¨", f"{min(question_count, answer_count)/max(question_count, 1)*100:.0f}%")
            col4.metric("ì˜ˆìƒ ë¶„ì„ ì‹œê°„", f"{max(1, len(qa_text.split())//50)} ë¶„")
            
            # ë¶„ì„ ì˜µì…˜
            col1, col2 = st.columns(2)
            with col1:
                analyze_question_types = st.checkbox("ğŸ” ì§ˆë¬¸ ìœ í˜• ë¶„ì„", value=True)
                evaluate_answer_quality = st.checkbox("ğŸ¯ ë‹µë³€ í’ˆì§ˆ í‰ê°€", value=True)
            with col2:
                extract_key_topics = st.checkbox("ğŸ·ï¸ í•µì‹¬ ì£¼ì œ ì¶”ì¶œ", value=True)
                detect_patterns = st.checkbox("ğŸ”„ íŒ¨í„´ ê°ì§€", value=True)
            
            if st.button("â“ Q&A ê¸°ë¡ ì¢…í•© ë¶„ì„", type="primary", use_container_width=True):
                qa_analysis_options = {
                    'analyze_question_types': analyze_question_types,
                    'evaluate_answer_quality': evaluate_answer_quality,
                    'extract_key_topics': extract_key_topics,
                    'detect_patterns': detect_patterns
                }
                self._analyze_qa_record(qa_text, qa_analysis_options)
    
    def _analyze_qa_session(self, qa_files, options):
        """ë°œí‘œ í›„ Q&A ì„¸ì…˜ ë¶„ì„"""
        try:
            with st.spinner("ğŸ§  Q&A ì„¸ì…˜ì„ AIë¡œ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ëª¨ì˜ ë¶„ì„ ê³¼ì • í‘œì‹œ
                for i, step in enumerate([
                    "ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...",
                    "í™”ì ë¶„ë¦¬ ë° ì‹ë³„ ì¤‘...", 
                    "ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ì¤‘...",
                    "ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì¤‘...",
                    "ì°¸ì—¬ë„ ë¶„ì„ ì¤‘...",
                    "ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."
                ], 1):
                    status_text.text(step)
                    progress_bar.progress(i / 6)
                    # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ê° ë‹¨ê³„ë³„ ë¶„ì„ ìˆ˜í–‰
                
                results = {
                    'session_type': 'presentation_qa',
                    'files_analyzed': len(qa_files),
                    'analysis_options': options,
                    'qa_segments': [],
                    'question_analysis': {
                        'total_questions': 8,
                        'question_types': {
                            'ê¸°ìˆ ì  ì§ˆë¬¸': 3,
                            'ì´ë¡ ì  ì§ˆë¬¸': 2,
                            'ì‹¤ë¬´ì  ì§ˆë¬¸': 2,
                            'ê°œì¸ì  ì§ˆë¬¸': 1
                        },
                        'difficulty_level': 'ì¤‘ê¸‰',
                        'avg_question_length': '15ì´ˆ'
                    },
                    'answer_evaluation': {
                        'clarity_score': 85,
                        'completeness_score': 78,
                        'expertise_score': 92,
                        'avg_answer_length': '45ì´ˆ',
                        'follow_up_needed': 2
                    },
                    'engagement_metrics': {
                        'participation_rate': '16%',  # 8ëª… ì§ˆë¬¸/50ëª… ì²­ì¤‘
                        'question_frequency': '1.6ê°œ/5ë¶„',
                        'audience_satisfaction': 'ë†’ìŒ',
                        'interaction_quality': 'A'
                    },
                    'key_insights': [
                        'ê¸°ìˆ ì  ì§ˆë¬¸ì´ ê°€ì¥ ë§ì•„ ì „ë¬¸ì„±ì´ ë†’ì€ ì²­ì¤‘',
                        'ë‹µë³€ í’ˆì§ˆì´ ìš°ìˆ˜í•˜ì—¬ ì²­ì¤‘ ë§Œì¡±ë„ ë†’ìŒ',
                        'í›„ì† ì§ˆë¬¸ì´ í•„ìš”í•œ ì£¼ì œ 2ê°€ì§€ ì‹ë³„',
                        'ì „ë°˜ì ìœ¼ë¡œ í™œë°œí•œ Q&A ì„¸ì…˜ìœ¼ë¡œ í‰ê°€'
                    ],
                    'topic_clusters': [
                        {'topic': 'AI ê¸°ìˆ  ë™í–¥', 'questions': 3},
                        {'topic': 'ì‹¤ë¬´ ì ìš©', 'questions': 2},
                        {'topic': 'ë¯¸ë˜ ì „ë§', 'questions': 2},
                        {'topic': 'ê¸°íƒ€', 'questions': 1}
                    ]
                }
                
                st.session_state.qa_analysis_results = results
                st.success("ğŸ‰ Q&A ì„¸ì…˜ ë¶„ì„ ì™„ë£Œ!")
                
        except Exception as e:
            st.error(f"âŒ Q&A ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def _analyze_interview_files(self, files, interview_type):
        """ì¸í„°ë·° íŒŒì¼ ë¶„ì„"""
        with st.spinner(f"ğŸ—£ï¸ {interview_type} ë¶„ì„ ì¤‘..."):
            # ëª¨ì˜ ë¶„ì„ ê²°ê³¼
            results = {
                'interview_type': interview_type,
                'files_count': len(files),
                'speakers_detected': 2,
                'total_duration': '25ë¶„ 30ì´ˆ',
                'key_topics': ['ê²½í—˜', 'ê¸°ìˆ  ì—­ëŸ‰', 'ë¯¸ë˜ ê³„íš'],
                'interview_flow': 'ìš°ìˆ˜',
                'communication_style': {
                    'interviewer': 'ì²´ê³„ì , ì „ë¬¸ì ',
                    'interviewee': 'ëª…í™•í•œ, ìì‹ ê° ìˆëŠ”'
                },
                'recommendations': ['ì¶”ê°€ ê¸°ìˆ  ì§ˆë¬¸ ë° ì‹¤ë¬´ ì˜ˆì‹œ ìš”ì²­'],
                'overall_rating': 'A'
            }
            st.session_state.qa_analysis_results = results
            st.success("ğŸ—£ï¸ ì¸í„°ë·° ë¶„ì„ ì™„ë£Œ!")
    
    def _analyze_interview_text(self, text, interview_type):
        """ì¸í„°ë·° í…ìŠ¤íŠ¸ ë¶„ì„"""
        with st.spinner(f"ğŸ“ {interview_type} í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘..."):
            # ëª¨ì˜ ë¶„ì„ ê²°ê³¼
            results = {
                'interview_type': interview_type,
                'text_length': len(text),
                'estimated_duration': f"{len(text.split())//100} ë¶„",
                'dialogue_turns': text.count(':'),
                'key_insights': ['ì²´ê³„ì ì¸ ë‹µë³€ êµ¬ì¡°', 'ì „ë¬¸ ìš©ì–´ í™œìš© ìš°ìˆ˜'],
                'communication_patterns': {
                    'question_style': 'ê°œë°©í˜• ì§ˆë¬¸ ìœ„ì£¼',
                    'answer_style': 'êµ¬ì²´ì  ì˜ˆì‹œ í¬í•¨'
                },
                'strengths': ['ëª…í™•í•œ ì˜ì‚¬ì†Œí†µ', 'ë…¼ë¦¬ì  êµ¬ì¡°'],
                'areas_for_improvement': ['ë” êµ¬ì²´ì ì¸ ê²½í—˜ ì‚¬ë¡€ í•„ìš”']
            }
            st.session_state.qa_analysis_results = results
            st.success("ğŸ“ ì¸í„°ë·° í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ!")
    
    def _analyze_qa_record(self, qa_text, options):
        """ì§ˆì˜ì‘ë‹µ ê¸°ë¡ ë¶„ì„"""
        with st.spinner("â“ Q&A ê¸°ë¡ì„ ì¢…í•© ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ì§ˆë¬¸ê³¼ ë‹µë³€ ì¶”ì¶œ
            questions = self._extract_questions(qa_text)
            answers = self._extract_answers(qa_text)
            
            question_count = len(questions)
            answer_count = len(answers)
            
            results = {
                'record_type': 'qa_transcript',
                'total_questions': question_count,
                'total_answers': answer_count,
                'match_rate': f"{min(question_count, answer_count)/max(question_count, 1)*100:.0f}%",
                'question_categories': {
                    'ê¸°ë³¸ ì •ë³´': 2,
                    'ê¸°ìˆ ì  ë‚´ìš©': 3,
                    'ì‹¤ë¬´ì  ì‘ìš©': 2,
                    'ë¯¸ë˜ ì „ë§': 1
                },
                'answer_quality': {
                    'ëª…í™•ì„±': 88,
                    'ì™„ì „ì„±': 85,
                    'ì „ë¬¸ì„±': 92
                },
                'key_topics': self._extract_topics_from_qa(qa_text),
                'question_patterns': self._analyze_question_patterns(questions),
                'improvement_suggestions': [
                    'ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œì‹œ',
                    'ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•œ ê¸°ìˆ  ìš©ì–´ ì„¤ì •'
                ],
                'dialogue_flow': self._analyze_dialogue_flow(qa_text)
            }
            
            st.session_state.qa_analysis_results = results
            st.success("â“ Q&A ê¸°ë¡ ë¶„ì„ ì™„ë£Œ!")
    
    def _extract_questions(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ"""
        patterns = [r'Q:(.*?)(?=A:|$)', r'ì§ˆë¬¸:(.*?)(?=ë‹µë³€:|$)']
        questions = []
        for pattern in patterns:
            questions.extend(re.findall(pattern, text, re.DOTALL))
        return [q.strip() for q in questions if q.strip()]
    
    def _extract_answers(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ë‹µë³€ ì¶”ì¶œ"""
        patterns = [r'A:(.*?)(?=Q:|$)', r'ë‹µë³€:(.*?)(?=ì§ˆë¬¸:|$)']
        answers = []
        for pattern in patterns:
            answers.extend(re.findall(pattern, text, re.DOTALL))
        return [a.strip() for a in answers if a.strip()]
    
    def _extract_topics_from_qa(self, text):
        """Q&Aì—ì„œ ì£¼ìš” ì£¼ì œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì£¼ì œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš©)
        keywords = ['AI', 'ê¸°ìˆ ', 'ë¯¸ë˜', 'ì‘ìš©', 'ê°œë°œ', 'ë¶„ì„', 'ì‹œìŠ¤í…œ']
        found_topics = []
        for keyword in keywords:
            if keyword in text:
                found_topics.append(keyword)
        return found_topics[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
    
    def _analyze_question_patterns(self, questions):
        """ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„"""
        patterns = {
            'ê°œë°©í˜• ì§ˆë¬¸': 0,
            'íì‡„í˜• ì§ˆë¬¸': 0,
            'ì„¤ëª… ìš”ì²­': 0,
            'ì˜ˆì‹œ ìš”ì²­': 0
        }
        
        for question in questions:
            if any(word in question for word in ['ì–´ë–»ê²Œ', 'ì™œ', 'ë¬´ì—‡']):
                patterns['ê°œë°©í˜• ì§ˆë¬¸'] += 1
            elif '?' in question and len(question.split()) < 10:
                patterns['íì‡„í˜• ì§ˆë¬¸'] += 1
            elif 'ì„¤ëª…' in question:
                patterns['ì„¤ëª… ìš”ì²­'] += 1
            elif 'ì˜ˆì‹œ' in question or 'ì˜ˆë¥¼' in question:
                patterns['ì˜ˆì‹œ ìš”ì²­'] += 1
        
        return patterns
    
    def _analyze_dialogue_flow(self, text):
        """ëŒ€í™” íë¦„ ë¶„ì„"""
        qa_pairs = len(re.findall(r'Q:.*?A:', text, re.DOTALL))
        avg_qa_length = len(text) / max(qa_pairs, 1)
        
        return {
            'qa_pairs': qa_pairs,
            'avg_length_per_pair': f"{avg_qa_length:.0f} ê¸€ì",
            'flow_quality': 'ìš°ìˆ˜' if qa_pairs > 3 and avg_qa_length > 100 else 'ë³´í†µ'
        }
    
    def _display_qa_results(self, results):
        """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        st.markdown("---")
        st.markdown("### ğŸ“Š Q&A ë¶„ì„ ê²°ê³¼")
        
        if results.get('session_type') == 'presentation_qa':
            self._display_presentation_qa_results(results)
        elif results.get('interview_type'):
            self._display_interview_results(results)
        elif results.get('record_type') == 'qa_transcript':
            self._display_qa_record_results(results)
    
    def _display_presentation_qa_results(self, results):
        """ë°œí‘œ í›„ Q&A ê²°ê³¼ í‘œì‹œ"""
        st.markdown("#### ğŸ¬ ë°œí‘œ í›„ Q&A ì„¸ì…˜ ë¶„ì„ ê²°ê³¼")
        
        # ì£¼ìš” ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        qa = results['question_analysis']
        ae = results['answer_evaluation']
        em = results['engagement_metrics']
        
        col1.metric("ì§ˆë¬¸ ìˆ˜", qa['total_questions'])
        col2.metric("ë‹µë³€ í’ˆì§ˆ", f"{ae['clarity_score']}/100")
        col3.metric("ì°¸ì—¬ìœ¨", em['participation_rate'])
        col4.metric("ìƒí˜¸ì‘ìš© ë“±ê¸‰", em['interaction_quality'])
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        st.markdown("##### â“ ì§ˆë¬¸ ìœ í˜• ë¶„ì„")
        for q_type, count in qa['question_types'].items():
            st.write(f"- **{q_type}**: {count}ê°œ")
        
        # ë‹µë³€ í‰ê°€
        st.markdown("##### ğŸ¯ ë‹µë³€ í‰ê°€")
        col1, col2, col3 = st.columns(3)
        col1.metric("ëª…í™•ì„±", f"{ae['clarity_score']}/100")
        col2.metric("ì™„ì „ì„±", f"{ae['completeness_score']}/100")
        col3.metric("ì „ë¬¸ì„±", f"{ae['expertise_score']}/100")
        
        # ì£¼ì œ í´ëŸ¬ìŠ¤í„°
        if 'topic_clusters' in results:
            st.markdown("##### ğŸ·ï¸ ì£¼ì œë³„ ì§ˆë¬¸ ë¶„í¬")
            for cluster in results['topic_clusters']:
                st.write(f"- **{cluster['topic']}**: {cluster['questions']}ê°œ ì§ˆë¬¸")
        
        # í•µì‹¬ í†µì°°
        st.markdown("##### ğŸ’¡ í•µì‹¬ í†µì°°")
        for insight in results['key_insights']:
            st.write(f"- {insight}")
    
    def _display_interview_results(self, results):
        """ì¸í„°ë·° ê²°ê³¼ í‘œì‹œ"""
        st.markdown(f"#### ğŸ—£ï¸ {results['interview_type']} ë¶„ì„ ê²°ê³¼")
        
        col1, col2, col3 = st.columns(3)
        col1.metric("í™”ì ìˆ˜", results.get('speakers_detected', 'N/A'))
        col2.metric("ì „ì²´ ì‹œê°„", results.get('total_duration', 'N/A'))
        col3.metric("ì¢…í•© í‰ê°€", results.get('overall_rating', 'N/A'))
        
        if 'key_topics' in results:
            st.markdown("##### ğŸ·ï¸ ì£¼ìš” ì£¼ì œ")
            for topic in results['key_topics']:
                st.write(f"- {topic}")
        
        if 'communication_style' in results:
            st.markdown("##### ğŸ’¬ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼")
            for role, style in results['communication_style'].items():
                st.write(f"- **{role}**: {style}")
        
        if 'recommendations' in results:
            st.markdown("##### ğŸ“ ì¶”ì²œ ì‚¬í•­")
            for rec in results['recommendations']:
                st.write(f"- {rec}")
    
    def _display_qa_record_results(self, results):
        """ì§ˆì˜ì‘ë‹µ ê¸°ë¡ ê²°ê³¼ í‘œì‹œ"""
        st.markdown("#### ğŸ“‹ ì§ˆì˜ì‘ë‹µ ê¸°ë¡ ë¶„ì„ ê²°ê³¼")
        
        # ê¸°ë³¸ í†µê³„
        col1, col2, col3 = st.columns(3)
        col1.metric("ì§ˆë¬¸ ìˆ˜", results['total_questions'])
        col2.metric("ë‹µë³€ ìˆ˜", results['total_answers'])
        col3.metric("ë§¤ì¹­ë¥ ", results['match_rate'])
        
        # ì§ˆë¬¸ ë¶„ë¥˜
        st.markdown("##### â“ ì§ˆë¬¸ ë¶„ë¥˜")
        for category, count in results['question_categories'].items():
            st.write(f"- **{category}**: {count}ê°œ")
        
        # ë‹µë³€ í’ˆì§ˆ
        st.markdown("##### ğŸ¯ ë‹µë³€ í’ˆì§ˆ í‰ê°€")
        col1, col2, col3 = st.columns(3)
        aq = results['answer_quality']
        col1.metric("ëª…í™•ì„±", f"{aq['ëª…í™•ì„±']}/100")
        col2.metric("ì™„ì „ì„±", f"{aq['ì™„ì „ì„±']}/100")
        col3.metric("ì „ë¬¸ì„±", f"{aq['ì „ë¬¸ì„±']}/100")
        
        # ì§ˆë¬¸ íŒ¨í„´
        if 'question_patterns' in results:
            st.markdown("##### ğŸ”„ ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„")
            for pattern, count in results['question_patterns'].items():
                st.write(f"- **{pattern}**: {count}ê°œ")
        
        # ëŒ€í™” íë¦„
        if 'dialogue_flow' in results:
            st.markdown("##### ğŸ’­ ëŒ€í™” íë¦„")
            df = results['dialogue_flow']
            col1, col2, col3 = st.columns(3)
            col1.metric("Q&A ìŒ", df['qa_pairs'])
            col2.metric("í‰ê·  ê¸¸ì´", df['avg_length_per_pair'])
            col3.metric("íë¦„ í’ˆì§ˆ", df['flow_quality'])
        
        # ê°œì„  ì œì•ˆ
        if 'improvement_suggestions' in results:
            st.markdown("##### ğŸ”§ ê°œì„  ì œì•ˆ")
            for suggestion in results['improvement_suggestions']:
                st.write(f"- {suggestion}")

# ì‚¬ìš© ì˜ˆì‹œ
def demo_qa_analysis():
    """Q&A ë¶„ì„ ë°ëª¨"""
    qa_analyzer = QAAnalysisExtension()
    qa_analyzer.render_qa_analysis_interface()

if __name__ == "__main__":
    st.set_page_config(
        page_title="Q&A ë¶„ì„ ì‹œìŠ¤í…œ", 
        page_icon="â“",
        layout="wide"
    )
    demo_qa_analysis()