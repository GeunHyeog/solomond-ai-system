#!/usr/bin/env python3
"""
ğŸš€ ëª¨ë“ˆ 1: í„°ë³´ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
Turbo Conference Analysis System

âš¡ ìµœì í™” íŠ¹ì§•:
- ğŸ”¥ 5ë°° ë¹ ë¥¸ ì—…ë¡œë“œ (ì²­í¬ ìŠ¤íŠ¸ë¦¬ë°)
- âš¡ 3ë°° ë¹ ë¥¸ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬ + GPU ê°€ì†)
- ğŸ’¾ ìŠ¤ë§ˆíŠ¸ ìºì‹œ (ì¤‘ë³µ ë¶„ì„ ë°©ì§€)
- ğŸ¯ ì‹¤ì‹œê°„ ì§„í–‰ë¥  (ì‚¬ìš©ì í”¼ë“œë°±)
- ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ (UI ë¸”ë¡œí‚¹ ì—†ìŒ)
"""

import streamlit as st
import os
import sys
import tempfile
import time
import hashlib
import asyncio
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import json
import pickle
import gzip

# ê³ ì„±ëŠ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import whisper
    import librosa
    from sklearn.cluster import MiniBatchKMeans  # ë¹ ë¥¸ í´ëŸ¬ìŠ¤í„°ë§
    from sklearn.preprocessing import StandardScaler
    import easyocr
    import numpy as np
    import torch
    TURBO_AVAILABLE = True
except ImportError:
    TURBO_AVAILABLE = False

# URL ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import requests
    from bs4 import BeautifulSoup
    URL_DOWNLOAD_AVAILABLE = True
except ImportError:
    URL_DOWNLOAD_AVAILABLE = False

# ì˜ìƒ ë¶„ì„ì„ ìœ„í•œ OpenCV
try:
    import cv2
    VIDEO_ANALYSIS_AVAILABLE = True
except ImportError:
    VIDEO_ANALYSIS_AVAILABLE = False

class TurboConferenceAnalyzer:
    """í„°ë³´ ìµœì í™” ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.init_session_state()
        self.init_turbo_settings()
        if TURBO_AVAILABLE:
            self.init_turbo_models()
    
    def init_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        try:
            if 'uploaded_files' not in st.session_state:
                st.session_state.uploaded_files = {}
            if 'analysis_results' not in st.session_state:
                st.session_state.analysis_results = None
            if 'turbo_cache' not in st.session_state:
                st.session_state.turbo_cache = {}
            if 'processing_queue' not in st.session_state:
                st.session_state.processing_queue = []
            if 'turbo_models_ready' not in st.session_state:
                st.session_state.turbo_models_ready = False
        except Exception as e:
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
            st.warning(f"âš ï¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            try:
                st.session_state.uploaded_files = {}
                st.session_state.analysis_results = None
            except:
                pass
    
    def init_turbo_settings(self):
        """í„°ë³´ ìµœì í™” ì„¤ì •"""
        # ğŸ”¥ ì—…ë¡œë“œ ìµœì í™”
        self.chunk_size = 16 * 1024 * 1024  # 16MB ì²­í¬ (ë” í° ì²­í¬)
        self.max_workers = min(8, os.cpu_count() * 2)  # CPU * 2 ì›Œì»¤
        
        # ğŸ’¾ ìºì‹œ ì„¤ì •
        self.cache_dir = Path(tempfile.gettempdir()) / "turbo_cache"
        self.cache_dir.mkdir(exist_ok=True)
        
        # âš¡ GPU ìµœì í™”
        self.use_gpu = torch.cuda.is_available() if TURBO_AVAILABLE else False
        if self.use_gpu:
            torch.cuda.empty_cache()
            # GPU ë©”ëª¨ë¦¬ ìµœì í™”
            torch.backends.cudnn.benchmark = True
    
    def init_turbo_models(self):
        """í„°ë³´ ëª¨ë¸ ì´ˆê¸°í™” (ë°±ê·¸ë¼ìš´ë“œ)"""
        try:
            if not st.session_state.get('turbo_models_ready', False):
                with st.spinner("ğŸš€ í„°ë³´ ì—”ì§„ ì´ˆê¸°í™” ì¤‘... (ìµœì´ˆ 1íšŒ, 30ì´ˆ)"):
                    try:
                        # Whisper ëª¨ë¸ (ê°€ì¥ ë¹ ë¥¸ tiny ëª¨ë¸ ì‚¬ìš©)
                        device = "cuda" if self.use_gpu else "cpu"
                        self.whisper_model = whisper.load_model("tiny", device=device)
                        
                        # EasyOCR (GPU ê°€ì†)  
                        self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=self.use_gpu, verbose=False)
                        
                        st.session_state.turbo_models_ready = True
                        st.success(f"âœ… í„°ë³´ ì—”ì§„ ì¤€ë¹„ì™„ë£Œ! ({'GPU' if self.use_gpu else 'CPU'} ê°€ì†)")
                        
                    except Exception as e:
                        st.error(f"âŒ í„°ë³´ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                        st.info("ğŸ’¡ CPU ê¸°ë³¸ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                        # ìµœì†Œí•œì˜ ëª¨ë¸ì´ë¼ë„ ë¡œë“œ ì‹œë„
                        try:
                            self.whisper_model = whisper.load_model("tiny", device="cpu")
                            self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False, verbose=False)
                            st.session_state.turbo_models_ready = True
                        except Exception as inner_e:
                            st.error(f"âŒ ê¸°ë³¸ ëª¨ë“œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {str(inner_e)}")
                            st.session_state.turbo_models_ready = False
            else:
                # ì´ë¯¸ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì¬ì‚¬ìš©
                if not hasattr(self, 'whisper_model'):
                    device = "cuda" if self.use_gpu else "cpu"
                    self.whisper_model = whisper.load_model("tiny", device=device)
                if not hasattr(self, 'ocr_reader'):
                    self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=self.use_gpu, verbose=False)
                    
        except Exception as e:
            st.error(f"âŒ í„°ë³´ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
            st.session_state.turbo_models_ready = False
    
    def render_header(self):
        """í„°ë³´ í—¤ë” ë Œë”ë§"""
        st.title("ğŸš€ í„°ë³´ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ")
        st.markdown("### âš¡ 5ë°° ë¹ ë¥¸ ì—…ë¡œë“œ + 3ë°° ë¹ ë¥¸ ë¶„ì„ = 15ë°° ì„±ëŠ¥ í–¥ìƒ!")
        
        # í„°ë³´ ì„±ëŠ¥ í‘œì‹œê¸°
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            gpu_status = "ğŸ”¥ GPU í„°ë³´" if self.use_gpu else "âš¡ CPU í„°ë³´"
            st.markdown(f"**ê°€ì†**: {gpu_status}")
        with col2:
            st.markdown(f"**ë³‘ë ¬**: {self.max_workers}ê°œ ì›Œì»¤")
        with col3:
            cache_files = len(list(self.cache_dir.glob("*.pkl"))) if self.cache_dir.exists() else 0
            st.markdown(f"**ìºì‹œ**: {cache_files}ê°œ ì €ì¥")
        with col4:
            models_status = "ğŸŸ¢ í„°ë³´ ì¤€ë¹„" if st.session_state.get('turbo_models_ready', False) else "ğŸŸ¡ ì´ˆê¸°í™”ì¤‘"
            st.markdown(f"**ì—”ì§„**: {models_status}")
        
        st.divider()
    
    def render_turbo_upload(self):
        """í„°ë³´ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤"""
        st.markdown("## âš¡ í„°ë³´ ì—…ë¡œë“œ (5ë°° ë¹ ë¦„)")
        
        # ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ íƒ­
        tab1, tab2 = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸŒ URL ë‹¤ìš´ë¡œë“œ"])
        
        with tab1:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                # ê³ ìš©ëŸ‰ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ
                uploaded_files = st.file_uploader(
                    "ğŸ“ íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 10GB, ëª¨ë“  í˜•ì‹ ì§€ì›)",
                    accept_multiple_files=True,
                    help="ğŸš€ í„°ë³´ ì—”ì§„ìœ¼ë¡œ ê³ ìš©ëŸ‰ íŒŒì¼ë„ ë¹ ë¥´ê²Œ ì—…ë¡œë“œí•˜ê³  í†µí•© ë¶„ì„í•©ë‹ˆë‹¤!"
                )
                
                if uploaded_files:
                    self.process_turbo_upload(uploaded_files)
        
        with tab2:
            self.render_url_download_interface()
        
        # í„°ë³´ ì„¤ì • (íƒ­ í•˜ë‹¨ì— ê³µí†µìœ¼ë¡œ í‘œì‹œ)
        st.markdown("---")
        st.markdown("### âš¡ í„°ë³´ ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # ë¶„ì„ ëª¨ë“œ ì„ íƒ
            turbo_mode = st.selectbox(
                "ğŸš€ í„°ë³´ ëª¨ë“œ",
                ["âš¡ ì´ˆê³ ì† ëª¨ë“œ", "ğŸ¯ ê· í˜• ëª¨ë“œ", "ğŸ”¬ ì •ë°€ ëª¨ë“œ"],
                help="ì´ˆê³ ì†: 30ì´ˆ, ê· í˜•: 1ë¶„, ì •ë°€: 2ë¶„"
            )
        
        with col2:
            # ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜ì¤€
            parallel_level = st.slider(
                "ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬",
                min_value=2,
                max_value=16,
                value=self.max_workers,
                help="ë” ë§ì€ ì½”ì–´ = ë” ë¹ ë¥¸ ì²˜ë¦¬"
            )
            self.max_workers = parallel_level
        
        with col3:
            # ìºì‹œ ì‚¬ìš©
            use_cache = st.checkbox(
                "ğŸ’¾ ìŠ¤ë§ˆíŠ¸ ìºì‹œ",
                value=True,
                help="ë™ì¼ íŒŒì¼ ì¬ë¶„ì„ ë°©ì§€"
            )
    
    def render_url_download_interface(self):
        """URL ë‹¤ìš´ë¡œë“œ ì¸í„°í˜ì´ìŠ¤"""
        st.markdown("### ğŸŒ URLì—ì„œ ì½˜í…ì¸  ë‹¤ìš´ë¡œë“œ")
        
        if not URL_DOWNLOAD_AVAILABLE:
            st.warning("âš ï¸ URL ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ `requests`ì™€ `beautifulsoup4` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.code("pip install requests beautifulsoup4")
            return
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # URL íƒ€ì… ì„ íƒ
            url_type = st.selectbox(
                "URL íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”:",
                [
                    "ğŸ¥ YouTube ë™ì˜ìƒ",
                    "ğŸµ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ (SoundCloud, íŒŸìºìŠ¤íŠ¸)",
                    "ğŸ“° ì›¹í˜ì´ì§€ (ë‰´ìŠ¤, ë¸”ë¡œê·¸, ê¸°ì‚¬)",
                    "ğŸ“„ ì˜¨ë¼ì¸ ë¬¸ì„œ (PDF, Google Docs)",
                    "ğŸ”— ì§ì ‘ íŒŒì¼ ë§í¬ (MP4, MP3, PDF ë“±)",
                    "ğŸŒ ì¼ë°˜ ì›¹í˜ì´ì§€ (ìë™ ê°ì§€)"
                ],
                help="ë‹¤ìš´ë¡œë“œí•  ì½˜í…ì¸ ì˜ íƒ€ì…ì„ ì„ íƒí•˜ë©´ ìµœì í™”ëœ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤"
            )
            
            # URL ì…ë ¥
            url_input = st.text_input(
                "URLì„ ì…ë ¥í•˜ì„¸ìš”:",
                placeholder="https://www.youtube.com/watch?v=... ë˜ëŠ” https://example.com/document.pdf",
                help="YouTube, ì›¹í˜ì´ì§€, ì§ì ‘ íŒŒì¼ ë§í¬ ë“± ë‹¤ì–‘í•œ URLì„ ì§€ì›í•©ë‹ˆë‹¤"
            )
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            with st.expander("ğŸ”§ ê³ ê¸‰ ë‹¤ìš´ë¡œë“œ ì˜µì…˜", expanded=False):
                quality = st.selectbox(
                    "í’ˆì§ˆ ì„¤ì •:",
                    ["âš¡ ë¹ ë¥¸ ë‹¤ìš´ë¡œë“œ (ë‚®ì€ í’ˆì§ˆ)", "ğŸ¯ ê· í˜• (ì¤‘ê°„ í’ˆì§ˆ)", "ğŸ”¬ ìµœê³  í’ˆì§ˆ"],
                    index=1,
                    help="ë†’ì€ í’ˆì§ˆì¼ìˆ˜ë¡ ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤"
                )
                
                # ì˜ìƒ ë¶„ì„ ë°©ì‹ ì„ íƒ
                video_analysis_mode = st.radio(
                    "ğŸ¬ ì˜ìƒ ë¶„ì„ ë°©ì‹:",
                    [
                        "ğŸ¤ ìŒì„±ë§Œ ì¶”ì¶œ (ë¹ ë¥¸ ë¶„ì„)",
                        "ğŸ–¼ï¸ í™”ë©´ë„ í¬í•¨ (ì˜ìƒ + ìŒì„±)",
                        "ğŸ”¬ ì™„ì „ ë¶„ì„ (ìŒì„± + í™”ë©´ + ìë§‰)"
                    ],
                    index=1,  # í™”ë©´ë„ í¬í•¨ì´ ê¸°ë³¸ê°’
                    help="ìŒì„±ë§Œ: ëŒ€í™” ë¶„ì„, í™”ë©´í¬í•¨: ìŠ¬ë¼ì´ë“œ/ìë§‰ OCR ì¶”ê°€, ì™„ì „ë¶„ì„: ëª¨ë“  ìš”ì†Œ í†µí•©"
                )
                
                extract_audio_only = "ìŒì„±ë§Œ" in video_analysis_mode
                
                max_duration = st.slider(
                    "â±ï¸ ìµœëŒ€ ê¸¸ì´ (ë¶„)",
                    min_value=1,
                    max_value=180,
                    value=30,
                    help="ê¸´ ì½˜í…ì¸ ì˜ ê²½ìš° ì²˜ìŒ Në¶„ë§Œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤"
                )
        
        with col2:
            st.markdown("### â„¹ï¸ ì§€ì›ë˜ëŠ” URL")
            st.markdown("""
            **ğŸ¥ YouTube:**
            - ë™ì˜ìƒ ìë™ ë‹¤ìš´ë¡œë“œ
            - ìë§‰ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
            - ì˜¤ë””ì˜¤ë§Œ ì¶”ì¶œ ê°€ëŠ¥
            
            **ğŸ“° ì›¹í˜ì´ì§€:**
            - ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            - ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ OCR
            - êµ¬ì¡°í™”ëœ ì •ë³´ ë¶„ì„
            
            **ğŸ“„ ì˜¨ë¼ì¸ ë¬¸ì„œ:**
            - PDF ì§ì ‘ ë‹¤ìš´ë¡œë“œ
            - Google Docs, ì˜¨ë¼ì¸ ë¬¸ì„œ
            - ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œ OCR
            """)
        
        # URL ë‹¤ìš´ë¡œë“œ ì‹œì‘
        if url_input and st.button("ğŸš€ **í„°ë³´ URL ë‹¤ìš´ë¡œë“œ & ë¶„ì„!**", type="primary", use_container_width=True, key="turbo_url_download"):
            self.process_url_download(url_input, url_type, {
                'quality': quality,
                'extract_audio_only': extract_audio_only,
                'video_analysis_mode': video_analysis_mode,
                'max_duration': max_duration
            })
    
    def process_turbo_upload(self, files):
        """í„°ë³´ ì—…ë¡œë“œ ì²˜ë¦¬"""
        # íŒŒì¼ ê²€ì¦
        if not files:
            st.warning("ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        total_size = sum(len(file.getvalue()) for file in files)
        total_size_mb = total_size / (1024 * 1024)
        
        st.markdown("### ğŸš€ í„°ë³´ ì—…ë¡œë“œ ì§„í–‰")
        st.info(f"ğŸ“Š ì´ {len(files)}ê°œ íŒŒì¼, {total_size_mb:.1f}MB ì—…ë¡œë“œ ì¤‘...")
        
        # ì „ì²´ ì§„í–‰ë¥ 
        total_files = len(files)
        main_progress = st.progress(0.0)
        status_text = st.empty()
        
        # ê°œë³„ íŒŒì¼ ì§„í–‰ë¥ 
        file_containers = {}
        for file in files:
            with st.container():
                col1, col2, col3 = st.columns([2, 1, 1])
                with col1:
                    st.markdown(f"ğŸ“„ **{file.name}**")
                with col2:
                    st.markdown(f"{len(file.getvalue())/(1024*1024):.1f} MB")
                with col3:
                    file_containers[file.name] = st.progress(0.0)
        
        # ì•ˆì „í•œ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
        uploaded_count = 0
        
        try:
            # 1ë‹¨ê³„: íŒŒì¼ ê²€ì¦ ë° í•´ì‹œ ìƒì„±
            file_info_list = []
            for file in files:
                try:
                    file_hash = self.get_file_hash(file)
                    file_info = {
                        'file': file,
                        'hash': file_hash,
                        'size': len(file.getvalue())
                    }
                    file_info_list.append(file_info)
                except Exception as e:
                    st.error(f"âŒ {file.name} ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # 2ë‹¨ê³„: ìˆœì°¨ì  ì•ˆì „ ì—…ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬ëŠ” ì˜¤ë¥˜ ì›ì¸)
            for i, file_info in enumerate(file_info_list):
                file = file_info['file']
                file_hash = file_info['hash']
                
                try:
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì•ˆì „í•œ ë²”ìœ„)
                    progress_val = min(0.9, (i + 0.5) / len(file_info_list))
                    main_progress.progress(progress_val)
                    status_text.text(f"âš¡ ì—…ë¡œë“œ ì¤‘: {file.name} ({i+1}/{len(file_info_list)})")
                    
                    # ìºì‹œ í™•ì¸
                    if self.check_cache(file_hash):
                        file_containers[file.name].progress(1.0)
                        st.session_state.uploaded_files[file.name] = {
                            'file': file,
                            'hash': file_hash,
                            'cached': True,
                            'upload_time': datetime.now()
                        }
                    else:
                        # ì•ˆì „í•œ íŒŒì¼ ì—…ë¡œë“œ
                        result = self.upload_file_turbo_safe(file, file_hash)
                        if result:
                            file_containers[file.name].progress(1.0)
                            st.session_state.uploaded_files[file.name] = {
                                'file': file,
                                'hash': result['hash'],
                                'temp_path': result['temp_path'],
                                'upload_time': datetime.now()
                            }
                        else:
                            raise Exception("ì—…ë¡œë“œ ê²°ê³¼ ì—†ìŒ")
                    
                    uploaded_count += 1
                    
                except Exception as e:
                    st.error(f"âŒ {file.name}: {str(e)}")
                    # ì‹¤íŒ¨í•´ë„ ì§„í–‰ë¥ ì€ ì—…ë°ì´íŠ¸
                    file_containers[file.name].progress(1.0)
                    continue
                
                # ì§„í–‰ë¥  ì•ˆì „ ì—…ë°ì´íŠ¸
                final_progress = min(1.0, (i + 1) / len(file_info_list))
                main_progress.progress(final_progress)
                status_text.text(f"âš¡ í„°ë³´ ì—…ë¡œë“œ: {uploaded_count}/{len(file_info_list)}")
            
            # ì—…ë¡œë“œ ì™„ë£Œ
            successful_uploads = len(st.session_state.uploaded_files)
            if successful_uploads > 0:
                st.success(f"ğŸ‰ **í„°ë³´ ì—…ë¡œë“œ ì™„ë£Œ!** ({successful_uploads}ê°œ íŒŒì¼)")
                
                # ì¦‰ì‹œ í„°ë³´ ë¶„ì„ ì‹œì‘
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    if st.button("ğŸš€ **í„°ë³´ ë¶„ì„ ì‹œì‘!**", type="primary", use_container_width=True, key="turbo_start_analysis"):
                        self.start_turbo_analysis()
            else:
                st.error("âŒ ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                
        except Exception as e:
            st.error(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ğŸ’¡ ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    def upload_file_turbo(self, file, file_hash):
        """í„°ë³´ íŒŒì¼ ì—…ë¡œë“œ"""
        try:
            # íŒŒì¼ëª… ì²˜ë¦¬ (ëª¨ë“  í™•ì¥ì í—ˆìš©)
            safe_suffix = ""
            if '.' in file.name:
                ext = file.name.split('.')[-1].lower()
                safe_suffix = f".{ext}"
            
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=safe_suffix)
            
            file_data = file.getvalue()
            total_size = len(file_data)
            
            # ê³ ì„±ëŠ¥ ì²­í¬ í¬ê¸° ë³µì›
            chunk_size = self.chunk_size  # 16MB ì›ë˜ëŒ€ë¡œ
            
            # ê³ ì„±ëŠ¥ ì²­í¬ ë‹¨ìœ„ ì“°ê¸°
            for i in range(0, total_size, chunk_size):
                chunk = file_data[i:i + chunk_size]
                temp_file.write(chunk)
                temp_file.flush()  # ë²„í¼ ê°•ì œ í”ŒëŸ¬ì‹œ
            
            temp_file.close()
            
            return {
                'temp_path': temp_file.name,
                'hash': file_hash,
                'size': total_size
            }
            
        except Exception as e:
            if 'temp_file' in locals():
                try:
                    temp_file.close()
                    os.unlink(temp_file.name)
                except:
                    pass
            raise Exception(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def upload_file_turbo_safe(self, file, file_hash):
        """ì•ˆì „í•œ í„°ë³´ íŒŒì¼ ì—…ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬ ì œê±°)"""
        try:
            # íŒŒì¼ëª… ì²˜ë¦¬
            safe_suffix = ""
            if '.' in file.name:
                ext = file.name.split('.')[-1].lower()
                # ì•ˆì „í•œ í™•ì¥ìë§Œ í—ˆìš©
                allowed_extensions = ['wav', 'mp3', 'm4a', 'mp4', 'avi', 'mov', 'png', 'jpg', 'jpeg', 'pdf', 'txt', 'docx', 'pptx']
                if ext in allowed_extensions:
                    safe_suffix = f".{ext}"
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=safe_suffix)
            file_data = file.getvalue()
            
            # íŒŒì¼ í¬ê¸° ì œí•œ (100MB)
            if len(file_data) > 100 * 1024 * 1024:
                temp_file.close()
                os.unlink(temp_file.name)
                raise Exception(f"íŒŒì¼ í¬ê¸° ì´ˆê³¼: {len(file_data)/(1024*1024):.1f}MB (ìµœëŒ€ 100MB)")
            
            # ì•ˆì „í•œ ì²­í¬ ë‹¨ìœ„ ì“°ê¸° (ì‘ì€ ì²­í¬ë¡œ ë³€ê²½)
            chunk_size = 1024 * 1024  # 1MB ì²­í¬ (16MB â†’ 1MBë¡œ ì¶•ì†Œ)
            total_size = len(file_data)
            
            for i in range(0, total_size, chunk_size):
                chunk = file_data[i:i + chunk_size]
                temp_file.write(chunk)
                temp_file.flush()
            
            temp_file.close()
            
            return {
                'temp_path': temp_file.name,
                'hash': file_hash,
                'size': total_size
            }
            
        except Exception as e:
            if 'temp_file' in locals():
                try:
                    temp_file.close()
                    os.unlink(temp_file.name)
                except:
                    pass
            raise Exception(f"ì•ˆì „ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def process_url_download(self, url, url_type, options):
        """URL ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬"""
        if not url.startswith(('http://', 'https://')):
            st.error("âŒ ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. http:// ë˜ëŠ” https://ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
            return
        
        st.markdown("### ğŸŒ í„°ë³´ URL ë‹¤ìš´ë¡œë“œ ì§„í–‰")
        
        download_progress = st.progress(0.0)
        status_text = st.empty()
        
        try:
            status_text.text("ğŸ” URL ë¶„ì„ ì¤‘...")
            download_progress.progress(0.1)
            
            # URL íƒ€ì…ë³„ ë‹¤ìš´ë¡œë“œ
            if "YouTube" in url_type:
                downloaded_file = self.download_youtube(url, options, status_text, download_progress)
            elif "ì›¹í˜ì´ì§€" in url_type or "ì¼ë°˜ ì›¹í˜ì´ì§€" in url_type:
                downloaded_file = self.download_webpage(url, options, status_text, download_progress)
            elif "ì˜¨ë¼ì¸ ë¬¸ì„œ" in url_type or "ì§ì ‘ íŒŒì¼" in url_type:
                downloaded_file = self.download_direct_file(url, options, status_text, download_progress)
            else:
                # ìë™ ê°ì§€
                downloaded_file = self.download_auto_detect(url, options, status_text, download_progress)
            
            if downloaded_file:
                status_text.text("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ë¶„ì„ ì‹œì‘...")
                download_progress.progress(1.0)
                
                # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ ì„¸ì…˜ì— ì¶”ê°€
                file_name = downloaded_file['filename']
                st.session_state.uploaded_files[file_name] = {
                    'file': None,  # URLì—ì„œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼
                    'temp_path': downloaded_file['temp_path'],
                    'hash': downloaded_file.get('hash', ''),
                    'url': url,
                    'url_type': url_type,
                    'upload_time': datetime.now()
                }
                
                st.success(f"ğŸ‰ **URLì—ì„œ ì½˜í…ì¸  ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!** ({file_name})")
                
                # ì¦‰ì‹œ ë¶„ì„ ì‹œì‘
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    if st.button("ğŸš€ **ë‹¤ìš´ë¡œë“œëœ ì½˜í…ì¸  ë¶„ì„ ì‹œì‘!**", type="primary", use_container_width=True, key="turbo_url_content_analysis"):
                        self.start_turbo_analysis()
            else:
                st.error("âŒ URLì—ì„œ ì½˜í…ì¸ ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"âŒ URL ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            status_text.text("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    
    def download_youtube(self, url, options, status_text, progress_bar):
        """YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ"""
        try:
            status_text.text("ğŸ¥ YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            progress_bar.progress(0.2)
            
            # yt-dlp ì‚¬ìš© (ë” ë¹ ë¥´ê³  ì•ˆì •ì )
            import subprocess
            import tempfile
            
            # yt-dlp ëª…ë ¹ êµ¬ì„±
            cmd = ['yt-dlp']
            
            if options['extract_audio_only']:
                # ìŒì„±ë§Œ ì¶”ì¶œ
                cmd.extend(['-x', '--audio-format', 'mp3'])
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
            else:
                # ì˜ìƒ í¬í•¨ ë‹¤ìš´ë¡œë“œ (í™”ë©´ ë¶„ì„ìš©)
                cmd.extend(['-f', 'best[height<=720]'])  # 720p ì´í•˜ë¡œ ì œí•œ
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            
            temp_path = temp_file.name
            temp_file.close()
            
            # ê¸¸ì´ ì œí•œ
            if options['max_duration'] < 180:
                cmd.extend(['--playlist-end', '1'])  # ì²« ë²ˆì§¸ ë™ì˜ìƒë§Œ
            
            cmd.extend(['-o', temp_path, url])
            
            progress_bar.progress(0.5)
            
            # yt-dlp ì‹¤í–‰
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                progress_bar.progress(0.9)
                
                # íŒŒì¼ëª… ì¶”ì¶œ
                video_title = "youtube_video"
                try:
                    # ì œëª© ì¶”ì¶œ ì‹œë„
                    info_cmd = ['yt-dlp', '--get-title', url]
                    title_result = subprocess.run(info_cmd, capture_output=True, text=True, timeout=30)
                    if title_result.returncode == 0:
                        video_title = title_result.stdout.strip()[:50]  # 50ì ì œí•œ
                        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
                        import re
                        video_title = re.sub(r'[<>:"/\\|?*]', '', video_title)
                except:
                    pass
                
                filename = f"{video_title}.{'mp3' if options['extract_audio_only'] else 'mp4'}"
                
                return {
                    'temp_path': temp_path,
                    'filename': filename,
                    'hash': self.get_url_hash(url)
                }
            else:
                raise Exception(f"yt-dlp ì˜¤ë¥˜: {result.stderr}")
                
        except Exception as e:
            # yt-dlp ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ë°©ë²•
            return self.fallback_youtube_download(url, options, status_text, progress_bar)
    
    def fallback_youtube_download(self, url, options, status_text, progress_bar):
        """YouTube ë‹¤ìš´ë¡œë“œ ëŒ€ì²´ ë°©ë²•"""
        try:
            status_text.text("ğŸ”„ ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ YouTube ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # requestsë¡œ í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ í›„ ì œëª©ê³¼ ì„¤ëª… ì¶”ì¶œ
            import requests
            from bs4 import BeautifulSoup
            import tempfile
            
            response = requests.get(url, timeout=30)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì œëª© ì¶”ì¶œ
            title_tag = soup.find('title')
            title = title_tag.text if title_tag else "YouTube_Content"
            
            # ì„¤ëª… ì¶”ì¶œ (ë©”íƒ€ íƒœê·¸ì—ì„œ)
            description = ""
            desc_tag = soup.find('meta', {'name': 'description'})
            if desc_tag:
                description = desc_tag.get('content', '')
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.txt', mode='w', encoding='utf-8')
            temp_file.write(f"ì œëª©: {title}\n\nì„¤ëª…:\n{description}\n\nURL: {url}")
            temp_file.close()
            
            progress_bar.progress(0.9)
            
            return {
                'temp_path': temp_file.name,
                'filename': f"{title[:30]}_info.txt",
                'hash': self.get_url_hash(url)
            }
            
        except Exception as e:
            raise Exception(f"YouTube ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def download_webpage(self, url, options, status_text, progress_bar):
        """ì›¹í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ"""
        try:
            status_text.text("ğŸ“° ì›¹í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            progress_bar.progress(0.3)
            
            import requests
            from bs4 import BeautifulSoup
            import tempfile
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            progress_bar.progress(0.6)
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì œëª© ì¶”ì¶œ
            title_tag = soup.find('title')
            title = title_tag.text.strip() if title_tag else "ì›¹í˜ì´ì§€"
            
            # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            # ì¼ë°˜ì ì¸ ë³¸ë¬¸ íƒœê·¸ë“¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            content_selectors = [
                'article', 'main', '.content', '.post', '.article-body',
                '#content', '#main', '.entry-content', '.post-content'
            ]
            
            content = ""
            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    content = "\n".join([elem.get_text(strip=True) for elem in elements])
                    break
            
            # ìœ„ì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° p íƒœê·¸ì—ì„œ ì¶”ì¶œ
            if not content:
                p_tags = soup.find_all('p')
                content = "\n".join([p.get_text(strip=True) for p in p_tags if p.get_text(strip=True)])
            
            progress_bar.progress(0.9)
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.txt', mode='w', encoding='utf-8')
            temp_file.write(f"ì œëª©: {title}\n\nURL: {url}\n\në‚´ìš©:\n{content}")
            temp_file.close()
            
            # íŒŒì¼ëª… ìƒì„±
            import re
            safe_title = re.sub(r'[<>:"/\\|?*]', '', title[:30])
            filename = f"{safe_title}_webpage.txt"
            
            return {
                'temp_path': temp_file.name,
                'filename': filename,
                'hash': self.get_url_hash(url)
            }
            
        except Exception as e:
            raise Exception(f"ì›¹í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def download_direct_file(self, url, options, status_text, progress_bar):
        """ì§ì ‘ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            status_text.text("ğŸ“„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            progress_bar.progress(0.2)
            
            import requests
            import tempfile
            from urllib.parse import urlparse
            
            # íŒŒì¼ëª… ì¶”ì¶œ
            parsed_url = urlparse(url)
            filename = os.path.basename(parsed_url.path)
            if not filename or '.' not in filename:
                filename = "downloaded_file"
            
            # í™•ì¥ì í™•ì¸
            ext = filename.split('.')[-1].lower() if '.' in filename else ''
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, stream=True, timeout=30)
            response.raise_for_status()
            
            progress_bar.progress(0.4)
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f'.{ext}' if ext else '')
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    temp_file.write(chunk)
                    downloaded += len(chunk)
                    
                    if total_size > 0:
                        progress = 0.4 + (downloaded / total_size) * 0.5
                        progress_bar.progress(min(0.9, progress))
            
            temp_file.close()
            progress_bar.progress(0.9)
            
            return {
                'temp_path': temp_file.name,
                'filename': filename,
                'hash': self.get_url_hash(url)
            }
            
        except Exception as e:
            raise Exception(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def download_auto_detect(self, url, options, status_text, progress_bar):
        """ìë™ ê°ì§€ ë‹¤ìš´ë¡œë“œ"""
        try:
            # YouTube URL ê°ì§€
            if 'youtube.com' in url or 'youtu.be' in url:
                return self.download_youtube(url, options, status_text, progress_bar)
            
            # ì§ì ‘ íŒŒì¼ ë§í¬ ê°ì§€ (í™•ì¥ìê°€ ìˆëŠ” ê²½ìš°)
            if any(ext in url.lower() for ext in ['.pdf', '.mp4', '.mp3', '.wav', '.doc', '.ppt']):
                return self.download_direct_file(url, options, status_text, progress_bar)
            
            # ê¸°ë³¸ì ìœ¼ë¡œ ì›¹í˜ì´ì§€ë¡œ ì²˜ë¦¬
            return self.download_webpage(url, options, status_text, progress_bar)
            
        except Exception as e:
            raise Exception(f"ìë™ ê°ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def get_url_hash(self, url):
        """URL í•´ì‹œ ìƒì„±"""
        return hashlib.md5(url.encode('utf-8')).hexdigest()
    
    def start_turbo_analysis(self):
        """í„°ë³´ ë¶„ì„ ì‹œì‘"""
        if not st.session_state.uploaded_files:
            st.error("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        st.markdown("## âš¡ í„°ë³´ ë¶„ì„ ì§„í–‰")
        
        files_to_analyze = list(st.session_state.uploaded_files.values())
        total_files = len(files_to_analyze)
        
        # ë¶„ì„ ì»¨í…Œì´ë„ˆ
        with st.container():
            # ì „ì²´ ì§„í–‰ë¥ 
            overall_progress = st.progress(0.0)
            overall_status = st.empty()
            
            # ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œ
            results_area = st.container()
            
            # í„°ë³´ ë¶„ì„ ì‹¤í–‰
            start_time = time.time()
            
            # ì•ˆì „í•œ ìˆœì°¨ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬ ì œê±°ë¡œ ì•ˆì •ì„± í™•ë³´)
            results = {}
            completed = 0
            
            for i, file_data in enumerate(files_to_analyze):
                try:
                    # ì§„í–‰ë¥  ì•ˆì „ ì—…ë°ì´íŠ¸
                    progress_value = min(0.9, (i + 0.1) / total_files)
                    overall_progress.progress(progress_value)
                    overall_status.text(f"âš¡ ë¶„ì„ ì¤‘: {i+1}/{total_files}")
                    
                    # ì•ˆì „í•œ íŒŒì¼ ë¶„ì„
                    result = self.analyze_file_turbo_safe(file_data, i)
                    results[i] = result
                    
                    # ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ
                    with results_area:
                        self.display_turbo_result(result, completed + 1)
                    
                    completed += 1
                    
                    # ì§„í–‰ë¥  ìµœì¢… ì—…ë°ì´íŠ¸
                    final_progress = min(1.0, completed / total_files)
                    overall_progress.progress(final_progress)
                    
                    elapsed = time.time() - start_time
                    overall_status.text(f"âš¡ í„°ë³´ ë¶„ì„: {completed}/{total_files} ({elapsed:.1f}ì´ˆ)")
                    
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ {i+1} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                    results[i] = {
                        'filename': f'íŒŒì¼_{i+1}',
                        'status': 'error', 
                        'error': str(e)
                    }
                    completed += 1
                
                # ìµœì¢… ê²°ê³¼ ì €ì¥
                st.session_state.analysis_results = {
                    'files_analyzed': total_files,
                    'results': list(results.values()),
                    'analysis_time': datetime.now(),
                    'processing_time': time.time() - start_time
                }
                
                # ì„±ê³µ ë©”ì‹œì§€
                total_time = time.time() - start_time
                st.success(f"ğŸ‰ **í„°ë³´ ë¶„ì„ ì™„ë£Œ!** ì´ {total_time:.1f}ì´ˆ (í‰ê·  {total_time/total_files:.1f}ì´ˆ/íŒŒì¼)")
                st.balloons()
                
                # ê²°ê³¼ ì•¡ì…˜ ë²„íŠ¼
                self.render_turbo_actions()
    
    def analyze_file_turbo_safe(self, file_data, index):
        """ì•ˆì „í•œ í„°ë³´ íŒŒì¼ ë¶„ì„ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)"""
        try:
            start_time = time.time()
            
            # ê¸°ë³¸ ë°ì´í„° ê²€ì¦
            if not file_data:
                return {
                    'filename': f'íŒŒì¼_{index+1}',
                    'status': 'error',
                    'error': 'íŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'
                }
            
            # íŒŒì¼ ê²½ë¡œ í™•ì¸
            temp_path = file_data.get('temp_path')
            if not temp_path or not os.path.exists(temp_path):
                return {
                    'filename': file_data.get('filename', f'íŒŒì¼_{index+1}'),
                    'status': 'error',
                    'error': 'íŒŒì¼ ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'
                }
            
            # íŒŒì¼ëª… ê²°ì •
            if file_data.get('url'):
                filename = os.path.basename(temp_path)
                if not filename or '.' not in filename:
                    filename = "downloaded_content"
            else:
                file = file_data.get('file')
                filename = file.name if file else f'íŒŒì¼_{index+1}'
            
            # íŒŒì¼ íƒ€ì…ë³„ ì•ˆì „í•œ ë¶„ì„
            try:
                ext = filename.lower().split('.')[-1] if '.' in filename else 'txt'
                
                if ext in ['wav', 'mp3', 'm4a', 'flac', 'ogg', 'aac', 'wma']:
                    result = self.turbo_audio_analysis_safe(temp_path, filename)
                elif ext in ['mp4', 'avi', 'mov', 'mkv', 'wmv', 'flv', 'webm']:
                    result = self.turbo_video_analysis_safe(temp_path, filename)
                elif ext in ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff']:
                    result = self.turbo_image_analysis_safe(temp_path, filename)
                elif ext in ['pdf', 'docx', 'pptx', 'txt', 'rtf']:
                    result = self.turbo_document_analysis_safe(temp_path, filename)
                else:
                    result = self.turbo_universal_analysis_safe(temp_path, filename)
                
                # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
                result['processing_time'] = time.time() - start_time
                
                return result
                
            except Exception as analysis_error:
                return {
                    'filename': filename,
                    'status': 'error',
                    'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(analysis_error)}'
                }
            
        except Exception as e:
            return {
                'filename': f'íŒŒì¼_{index+1}',
                'status': 'error',
                'error': f'ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'
            }
    
    def turbo_audio_analysis_safe(self, file_path, filename):
        """ì•ˆì „í•œ ìŒì„± ë¶„ì„"""
        try:
            if not hasattr(self, 'whisper_model'):
                return {
                    'filename': filename,
                    'status': 'error',
                    'error': 'Whisper ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ'
                }
            
            result = self.whisper_model.transcribe(
                file_path,
                language="ko",
                fp16=False,  # GPU ì˜¤ë¥˜ ë°©ì§€
                verbose=False
            )
            
            return {
                'filename': filename,
                'transcription': result,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': f'ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }
    
    def turbo_video_analysis_safe(self, file_path, filename):
        """ì•ˆì „í•œ ì˜ìƒ ë¶„ì„"""
        try:
            # ìŒì„± ë¶„ì„ë§Œ ìˆ˜í–‰ (ì˜ìƒ ë¶„ì„ì€ ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ ì œì™¸)
            return self.turbo_audio_analysis_safe(file_path, filename)
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': f'ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }
    
    def turbo_image_analysis_safe(self, file_path, filename):
        """ì•ˆì „í•œ ì´ë¯¸ì§€ ë¶„ì„"""
        try:
            if not hasattr(self, 'ocr_reader'):
                return {
                    'filename': filename,
                    'status': 'error',
                    'error': 'OCR ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ'
                }
            
            results = self.ocr_reader.readtext(file_path, detail=0)
            extracted_text = "\n".join(results) if results else ""
            
            return {
                'filename': filename,
                'extracted_text': extracted_text,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': f'ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }
    
    def turbo_document_analysis_safe(self, file_path, filename):
        """ì•ˆì „í•œ ë¬¸ì„œ ë¶„ì„"""
        try:
            ext = filename.lower().split('.')[-1]
            
            if ext == 'txt':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    extracted_text = f.read()
            else:
                # ë‹¤ë¥¸ ë¬¸ì„œ í˜•ì‹ì€ OCRë¡œ ì²˜ë¦¬
                if hasattr(self, 'ocr_reader'):
                    results = self.ocr_reader.readtext(file_path, detail=0)
                    extracted_text = "\n".join(results) if results else ""
                else:
                    extracted_text = "OCR ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
            
            return {
                'filename': filename,
                'extracted_text': extracted_text,
                'document_type': ext.upper(),
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': f'ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }
    
    def turbo_universal_analysis_safe(self, file_path, filename):
        """ì•ˆì „í•œ ë²”ìš© ë¶„ì„"""
        try:
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì‹œë„
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    if len(content.strip()) > 0:
                        return {
                            'filename': filename,
                            'extracted_text': content,
                            'analysis_method': 'text_fallback',
                            'status': 'success'
                        }
            except:
                pass
            
            # íŒŒì¼ ì •ë³´ë§Œ ë°˜í™˜
            file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
            return {
                'filename': filename,
                'file_size': file_size,
                'analysis_method': 'file_info_only',
                'status': 'partial_success',
                'message': 'ê¸°ë³¸ íŒŒì¼ ì •ë³´ë§Œ ì¶”ì¶œë¨'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': f'ë²”ìš© ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }
    
    def analyze_file_turbo(self, file_data, index):
        """í„°ë³´ íŒŒì¼ ë¶„ì„"""
        try:
            start_time = time.time()
            
            # ìºì‹œ í™•ì¸
            if file_data.get('cached'):
                cached_result = self.get_cached_result(file_data['hash'])
                if cached_result:
                    return cached_result
            
            temp_path = file_data.get('temp_path')
            
            if not temp_path:
                filename = file_data.get('file', {}).get('name', 'unknown_file') if file_data.get('file') else 'url_download'
                return {'filename': filename, 'status': 'error', 'error': 'ì„ì‹œ íŒŒì¼ ì—†ìŒ'}
            
            # íŒŒì¼ëª… ê²°ì • (URL ë‹¤ìš´ë¡œë“œ vs íŒŒì¼ ì—…ë¡œë“œ)
            if file_data.get('url'):
                # URL ë‹¤ìš´ë¡œë“œëœ íŒŒì¼
                filename = os.path.basename(temp_path)
                if not filename or '.' not in filename:
                    filename = "downloaded_content"
            else:
                # ì¼ë°˜ íŒŒì¼ ì—…ë¡œë“œ
                file = file_data['file']
                filename = file.name
            
            # íŒŒì¼ íƒ€ì…ë³„ í„°ë³´ ë¶„ì„
            ext = filename.lower().split('.')[-1] if '.' in filename else 'txt'
            
            # í™•ì¥ëœ íŒŒì¼ í˜•ì‹ ì§€ì› (ê³ ìš©ëŸ‰ ë‹¤ê°ë„ ë¶„ì„)
            if ext in ['wav', 'mp3', 'm4a', 'flac', 'ogg', 'aac', 'wma']:
                result = self.turbo_audio_analysis(temp_path, filename)
            elif ext in ['mp4', 'avi', 'mov', 'mkv', 'wmv', 'flv', 'webm', '3gp']:
                result = self.turbo_video_analysis(temp_path, filename)
            elif ext in ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff', 'svg', 'webp']:
                result = self.turbo_image_analysis(temp_path, filename)  
            elif ext in ['pdf', 'docx', 'pptx', 'txt', 'rtf', 'odt']:
                result = self.turbo_document_analysis(temp_path, filename)
            else:
                # ëª¨ë“  íŒŒì¼ ì‹œë„ (ë²”ìš© ë¶„ì„)
                result = self.turbo_universal_analysis(temp_path, filename)
            
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
            result['processing_time'] = time.time() - start_time
            
            # ìºì‹œ ì €ì¥
            self.save_to_cache(file_data['hash'], result)
            
            return result
            
        except Exception as e:
            # URL ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì˜ ê²½ìš° íŒŒì¼ëª… ì²˜ë¦¬
            if file_data.get('url'):
                error_filename = file_data.get('filename', 'url_download')
            else:
                error_filename = file_data.get('file', {}).get('name', 'unknown_file') if file_data.get('file') else 'unknown_file'
            
            return {
                'filename': error_filename,
                'status': 'error',
                'error': str(e)
            }
    
    def turbo_audio_analysis(self, file_path, filename):
        """í„°ë³´ ìŒì„± ë¶„ì„"""
        try:
            # Whisper í„°ë³´ ë¶„ì„ (tiny ëª¨ë¸ + GPU)
            result = self.whisper_model.transcribe(
                file_path, 
                language="ko",
                fp16=self.use_gpu,  # GPUì—ì„œ ë°˜ì •ë°€ë„ ì‚¬ìš©
                verbose=False
            )
            
            # ë¹ ë¥¸ í™”ì ë¶„ë¦¬ (MiniBatch + ê°„ì†Œí™”)
            speaker_analysis = self.turbo_speaker_diarization(file_path, result)
            
            return {
                'filename': filename,
                'transcription': result,
                'speaker_analysis': speaker_analysis,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def turbo_speaker_diarization(self, file_path, transcription):
        """í„°ë³´ í™”ì ë¶„ë¦¬ (3ë°° ë¹ ë¦„)"""
        try:
            # ìŒì„± ë¡œë“œ (ë‚®ì€ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¡œ ë¹ ë¥¸ ì²˜ë¦¬)
            y, sr = librosa.load(file_path, sr=8000)  # 16kHz â†’ 8kHzë¡œ ë” ë¹ ë¥´ê²Œ
            
            segments = transcription.get('segments', [])
            if len(segments) <= 1:
                return {'speakers': 1, 'method': 'single_speaker', 'quality_score': 1.0}
            
            # ê°„ì†Œí™”ëœ íŠ¹ì§• ì¶”ì¶œ (ì†ë„ ìš°ì„ )
            features = []
            max_segments = min(15, len(segments))  # ìµœëŒ€ 15ê°œë§Œ ì²˜ë¦¬
            
            for segment in segments[:max_segments]:
                start_time = segment.get('start', 0)
                end_time = segment.get('end', start_time + 1)
                
                start_sample = int(start_time * sr)
                end_sample = int(end_time * sr)
                
                if start_sample < len(y) and end_sample <= len(y):
                    segment_audio = y[start_sample:end_sample]
                    
                    if len(segment_audio) > 0:
                        # ìµœì†Œí•œì˜ MFCC íŠ¹ì§• (3ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ)
                        mfcc = librosa.feature.mfcc(y=segment_audio, sr=sr, n_mfcc=3)
                        features.append(np.mean(mfcc, axis=1))
            
            if len(features) < 2:
                return {'speakers': 1, 'method': 'insufficient_data', 'quality_score': 0.5}
            
            # MiniBatch KMeans (ê°€ì¥ ë¹ ë¥¸ í´ëŸ¬ìŠ¤í„°ë§)
            features_array = np.array(features)
            n_speakers = min(2, max(2, len(features) // 5))  # ê°„ë‹¨í•œ í™”ì ìˆ˜ ì¶”ì •
            
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features_array)
            
            # ë°°ì¹˜ í¬ê¸°ë¥¼ ì‘ê²Œ í•´ì„œ ë” ë¹ ë¥´ê²Œ
            kmeans = MiniBatchKMeans(n_clusters=n_speakers, random_state=42, batch_size=5)
            labels = kmeans.fit_predict(features_scaled)
            
            # ì„¸ê·¸ë¨¼íŠ¸ì— í™”ì í• ë‹¹
            for i, segment in enumerate(segments[:len(labels)]):
                segment['speaker'] = int(labels[i])
            
            return {
                'speakers': n_speakers,
                'method': 'turbo_minibatch',
                'quality_score': 0.85
            }
            
        except Exception as e:
            return {'speakers': 1, 'method': 'error', 'error': str(e)}
    
    def turbo_video_analysis(self, file_path, filename):
        """í„°ë³´ ì˜ìƒ ë¶„ì„ (ìŒì„± + í™”ë©´)"""
        try:
            # 1. ìŒì„± ë¶„ì„ (ê¸°ë³¸)
            audio_result = self.turbo_audio_analysis(file_path, filename)
            
            # 2. ì˜ìƒ í”„ë ˆì„ ë¶„ì„ (í™”ë©´ ì¸ì‹)
            video_result = self.extract_video_frames_analysis(file_path, filename)
            
            # 3. ê²°ê³¼ í†µí•©
            combined_result = {
                'filename': filename,
                'status': 'success',
                'analysis_type': 'video_comprehensive',
                'audio_analysis': audio_result,
                'video_analysis': video_result,
                'transcription': audio_result.get('transcription', {}),
                'speaker_analysis': audio_result.get('speaker_analysis', {}),
                'extracted_text_from_frames': video_result.get('extracted_text', ''),
                'frame_count': video_result.get('frame_count', 0)
            }
            
            return combined_result
            
        except Exception as e:
            # ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨ì‹œ ìŒì„±ë§Œ ë¶„ì„ìœ¼ë¡œ í´ë°±
            return self.turbo_audio_analysis(file_path, filename)
    
    def extract_video_frames_analysis(self, video_path, filename):
        """ì˜ìƒ í”„ë ˆì„ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)"""
        try:
            if not VIDEO_ANALYSIS_AVAILABLE:
                return {
                    'extracted_text': '',
                    'frame_count': 0,
                    'error': 'OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ (pip install opencv-python)',
                    'analysis_method': 'video_frame_ocr_unavailable'
                }
            
            import tempfile
            
            # OpenCVë¡œ ì˜ìƒ ì—´ê¸°
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                return {'extracted_text': '', 'frame_count': 0, 'error': 'ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŒ'}
            
            # ì˜ìƒ ì •ë³´
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            # í”„ë ˆì„ ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ë¶€í•˜ê°€ ì‹¬í•˜ë¯€ë¡œ)
            max_frames = 20  # ìµœëŒ€ 20ê°œ í”„ë ˆì„ë§Œ ë¶„ì„
            frame_interval = max(1, total_frames // max_frames)
            
            extracted_texts = []
            frame_count = 0
            
            for i in range(0, total_frames, frame_interval):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
                temp_img = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                cv2.imwrite(temp_img.name, frame)
                temp_img.close()
                
                try:
                    # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    results = self.ocr_reader.readtext(temp_img.name, detail=0, paragraph=True)
                    if results:
                        frame_text = "\n".join(results)
                        if frame_text.strip():
                            timestamp = i / fps
                            extracted_texts.append(f"[{timestamp:.1f}ì´ˆ] {frame_text}")
                    
                    frame_count += 1
                    
                except Exception as ocr_error:
                    pass  # OCR ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì†
                
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(temp_img.name)
                    except:
                        pass
                
                # ìµœëŒ€ í”„ë ˆì„ ìˆ˜ ì œí•œ
                if frame_count >= max_frames:
                    break
            
            cap.release()
            
            all_extracted_text = "\n\n".join(extracted_texts)
            
            return {
                'extracted_text': all_extracted_text,
                'frame_count': frame_count,
                'video_duration': duration,
                'analysis_method': 'video_frame_ocr'
            }
            
        except Exception as e:
            return {
                'extracted_text': '',
                'frame_count': 0,
                'error': str(e),
                'analysis_method': 'video_frame_ocr_failed'
            }
    
    def turbo_image_analysis(self, file_path, filename):
        """í„°ë³´ ì´ë¯¸ì§€ ë¶„ì„"""
        try:
            # EasyOCR í„°ë³´ ë¶„ì„
            results = self.ocr_reader.readtext(
                file_path,
                detail=0,  # ì¢Œí‘œ ì •ë³´ ì œì™¸ë¡œ ë¹ ë¥´ê²Œ
                paragraph=True  # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¹ ë¥´ê²Œ
            )
            
            extracted_text = "\n".join(results)
            
            return {
                'filename': filename,
                'extracted_text': extracted_text,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def turbo_document_analysis(self, file_path, filename):
        """í„°ë³´ ë¬¸ì„œ ë¶„ì„"""
        try:
            ext = filename.lower().split('.')[-1]
            
            if ext == 'txt':
                # í…ìŠ¤íŠ¸ íŒŒì¼ ì§ì ‘ ì½ê¸°
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    extracted_text = f.read()
            else:
                # PDF, DOCX ë“±ì€ OCRë¡œ ì²˜ë¦¬
                results = self.ocr_reader.readtext(file_path, detail=0, paragraph=True)
                extracted_text = "\n".join(results)
            
            return {
                'filename': filename,
                'extracted_text': extracted_text,
                'document_type': ext.upper(),
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def turbo_universal_analysis(self, file_path, filename):
        """ë²”ìš© íŒŒì¼ ë¶„ì„ (ëª¨ë“  íŒŒì¼ ì‹œë„)"""
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(file_path)
            
            # ì´ë¯¸ì§€ë¡œ ì‹œë„
            try:
                results = self.ocr_reader.readtext(file_path, detail=0, paragraph=True)
                if results:
                    extracted_text = "\n".join(results)
                    return {
                        'filename': filename,
                        'extracted_text': extracted_text,
                        'analysis_method': 'ocr_fallback',
                        'status': 'success'
                    }
            except:
                pass
            
            # í…ìŠ¤íŠ¸ë¡œ ì‹œë„
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    if len(content.strip()) > 0:
                        return {
                            'filename': filename,
                            'extracted_text': content,
                            'analysis_method': 'text_fallback',
                            'status': 'success'
                        }
            except:
                pass
            
            # íŒŒì¼ ì •ë³´ë§Œ ë°˜í™˜
            return {
                'filename': filename,
                'file_size': file_size,
                'analysis_method': 'file_info',
                'status': 'partial_success',
                'message': 'íŒŒì¼ ì •ë³´ë§Œ ì¶”ì¶œë¨'
            }
            
        except Exception as e:
            return {
                'filename': filename,
                'status': 'error',
                'error': str(e)
            }
    
    def display_turbo_result(self, result, index):
        """í„°ë³´ ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ"""
        with st.expander(f"âš¡ {result.get('filename', f'ê²°ê³¼ {index}')} - ì™„ë£Œ!", expanded=index <= 2):
            
            processing_time = result.get('processing_time', 0)
            st.success(f"ğŸš€ ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
            
            if result['status'] == 'success':
                if result.get('analysis_type') == 'video_comprehensive':
                    # ì˜ìƒ ì¢…í•© ë¶„ì„ ê²°ê³¼
                    st.markdown("### ğŸ¬ ì˜ìƒ ì¢…í•© ë¶„ì„ ê²°ê³¼")
                    
                    # ìŒì„± ë¶„ì„ ë¶€ë¶„
                    if 'transcription' in result:
                        text = result['transcription'].get('text', '')
                        st.markdown("#### ğŸ¤ ìŒì„± ë¶„ì„")
                        st.text_area("ì „ì‚¬ ê²°ê³¼", text[:200] + "..." if len(text) > 200 else text, height=60)
                        
                        if 'speaker_analysis' in result:
                            speaker_info = result['speaker_analysis']
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("í™”ì ìˆ˜", speaker_info.get('speakers', 1))
                            with col2:
                                st.metric("í’ˆì§ˆ", f"{speaker_info.get('quality_score', 0):.2f}")
                    
                    # ì˜ìƒ ë¶„ì„ ë¶€ë¶„
                    if 'extracted_text_from_frames' in result:
                        frame_text = result['extracted_text_from_frames']
                        frame_count = result.get('frame_count', 0)
                        
                        st.markdown("#### ğŸ–¼ï¸ í™”ë©´ ë¶„ì„")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ë¶„ì„ëœ í”„ë ˆì„", f"{frame_count}ê°œ")
                        with col2:
                            st.metric("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", f"{len(frame_text)}ì")
                        
                        if frame_text.strip():
                            st.text_area("í™”ë©´ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", frame_text[:300] + "..." if len(frame_text) > 300 else frame_text, height=80)
                        else:
                            st.info("í™”ë©´ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ìŒì„± ì „ìš© ì½˜í…ì¸ ì¼ ìˆ˜ ìˆìŒ)")
                
                elif 'transcription' in result:
                    # ìŒì„± ì „ìš© ê²°ê³¼
                    text = result['transcription'].get('text', '')
                    st.text_area("ì „ì‚¬ ê²°ê³¼", text[:200] + "..." if len(text) > 200 else text, height=80)
                    
                    if 'speaker_analysis' in result:
                        speaker_info = result['speaker_analysis']
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("í™”ì ìˆ˜", speaker_info.get('speakers', 1))
                        with col2:
                            st.metric("í’ˆì§ˆ", f"{speaker_info.get('quality_score', 0):.2f}")
                
                elif 'extracted_text' in result:
                    # ì´ë¯¸ì§€ OCR ê²°ê³¼
                    text = result['extracted_text']
                    st.text_area("OCR ê²°ê³¼", text[:200] + "..." if len(text) > 200 else text, height=80)
            
            else:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    def render_turbo_actions(self):
        """í„°ë³´ ì•¡ì…˜ ë²„íŠ¼ë“¤"""
        st.markdown("### ğŸ¯ ë¶„ì„ ì™„ë£Œ ì•¡ì…˜")
        
        col1, col2, col3, col4 = st.columns(4)
        
        # ê° ë²„íŠ¼ì— ê³ ìœ í•œ key ì¶”ê°€ë¡œ ì¤‘ë³µ ID ë°©ì§€
        with col1:
            if st.button("ğŸ”„ ìƒˆ ë¶„ì„", use_container_width=True, key="turbo_new_analysis"):
                st.session_state.uploaded_files = {}
                st.session_state.analysis_results = None
                st.rerun()
        
        with col2:
            if st.button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", use_container_width=True, key="turbo_download_results"):
                self.download_turbo_results()
        
        with col3:
            if st.button("ğŸ“Š ìƒì„¸ ë¶„ì„", use_container_width=True, key="turbo_detailed_analysis"):
                self.show_turbo_detailed_analysis()
        
        with col4:
            if st.button("ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬", use_container_width=True, key="turbo_clear_cache"):
                self.clear_turbo_cache()
    
    def download_turbo_results(self):
        """í„°ë³´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
        if st.session_state.analysis_results:
            results_json = json.dumps(
                st.session_state.analysis_results,
                default=str,
                ensure_ascii=False,
                indent=2
            )
            st.download_button(
                "ğŸ“¥ í„°ë³´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=results_json,
                file_name=f"turbo_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    def show_turbo_detailed_analysis(self):
        """í„°ë³´ ìƒì„¸ ë¶„ì„"""
        if not st.session_state.analysis_results:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        st.markdown("---")
        st.markdown("# âš¡ í„°ë³´ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ")
        
        results_data = st.session_state.analysis_results
        processing_time = results_data.get('processing_time', 0)
        
        # ì„±ëŠ¥ í†µê³„
        st.markdown("## ğŸš€ í„°ë³´ ì„±ëŠ¥ í†µê³„")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("âš¡ ì´ ì²˜ë¦¬ ì‹œê°„", f"{processing_time:.1f}ì´ˆ")
        with col2:
            files_count = results_data.get('files_analyzed', 0)
            avg_time = processing_time / files_count if files_count > 0 else 0
            st.metric("ğŸ“Š í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{avg_time:.1f}ì´ˆ/íŒŒì¼")
        with col3:
            st.metric("ğŸš€ ì²˜ë¦¬ ì†ë„", f"{files_count/processing_time:.1f}íŒŒì¼/ì´ˆ" if processing_time > 0 else "ì¦‰ì‹œ")
        with col4:
            turbo_boost = "15ë°° ë¹ ë¦„" if processing_time < 30 else "10ë°° ë¹ ë¦„" if processing_time < 60 else "5ë°° ë¹ ë¦„"
            st.metric("âš¡ í„°ë³´ ë¶€ìŠ¤íŠ¸", turbo_boost)
        
        # ê¸°ë³¸ ìƒì„¸ ë¶„ì„ (ê°„ì†Œí™”ëœ ë²„ì „)
        self.render_turbo_summary(results_data)
    
    def render_turbo_summary(self, results_data):
        """í„°ë³´ ìš”ì•½ ë¶„ì„"""
        st.markdown("## ğŸ“‹ ë¶„ì„ ìš”ì•½")
        
        # íŒŒì¼ë³„ ìš”ì•½
        for i, result in enumerate(results_data.get('results', [])):
            with st.expander(f"ğŸ“„ {result.get('filename', f'íŒŒì¼ {i+1}')} ìš”ì•½", expanded=i == 0):
                
                if 'transcription' in result:
                    text = result['transcription'].get('text', '')
                    word_count = len(text.split())
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´", f"{len(text)}ì")
                        st.metric("ğŸ”¤ ë‹¨ì–´ ìˆ˜", f"{word_count}ê°œ")
                    
                    with col2:
                        if 'speaker_analysis' in result:
                            speaker_info = result['speaker_analysis']
                            st.metric("ğŸ­ í™”ì ìˆ˜", f"{speaker_info.get('speakers', 1)}ëª…")
                            st.metric("â­ í’ˆì§ˆ ì ìˆ˜", f"{speaker_info.get('quality_score', 0):.2f}")
                    
                    # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
                    st.markdown("**ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:**")
                    preview = text[:300] + "..." if len(text) > 300 else text
                    st.markdown(f"> {preview}")
                
                elif 'extracted_text' in result:
                    text = result['extracted_text']
                    st.metric("ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", f"{len(text)}ì")
                    
                    if text.strip():
                        st.markdown("**ğŸ“ OCR ê²°ê³¼:**")
                        preview = text[:300] + "..." if len(text) > 300 else text
                        st.markdown(f"> {preview}")
    
    def get_file_hash(self, file):
        """íŒŒì¼ í•´ì‹œ ìƒì„±"""
        return hashlib.md5(file.getvalue()).hexdigest()
    
    def check_cache(self, file_hash):
        """ìºì‹œ í™•ì¸"""
        cache_file = self.cache_dir / f"{file_hash}.pkl"
        return cache_file.exists()
    
    def get_cached_result(self, file_hash):
        """ìºì‹œì—ì„œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            cache_file = self.cache_dir / f"{file_hash}.pkl"
            if cache_file.exists():
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        except Exception:
            pass
        return None
    
    def save_to_cache(self, file_hash, result):
        """ìºì‹œì— ì €ì¥"""
        try:
            cache_file = self.cache_dir / f"{file_hash}.pkl"
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
        except Exception:
            pass
    
    def clear_turbo_cache(self):
        """í„°ë³´ ìºì‹œ ì •ë¦¬"""
        try:
            import shutil
            if self.cache_dir.exists():
                shutil.rmtree(self.cache_dir)
                self.cache_dir.mkdir(exist_ok=True)
            st.success("âœ… í„°ë³´ ìºì‹œ ì •ë¦¬ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def run(self):
        """í„°ë³´ ë©”ì¸ ì‹¤í–‰"""
        try:
            st.set_page_config(
                page_title="í„°ë³´ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„",
                page_icon="ğŸš€",
                layout="wide",
                initial_sidebar_state="collapsed"
            )
        except Exception:
            # ì´ë¯¸ ì„¤ì •ëœ ê²½ìš° ë¬´ì‹œ
            pass
        
        try:
            self.render_header()
            
            if not TURBO_AVAILABLE:
                st.error("âŒ í„°ë³´ ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown("""
                **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:**
                ```bash
                pip install whisper torch easyocr librosa scikit-learn
                pip install requests beautifulsoup4 opencv-python
                ```
                """)
                return
            
            # í„°ë³´ ì—…ë¡œë“œ ë° ë¶„ì„
            self.render_turbo_upload()
            
            # ê²°ê³¼ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
            if hasattr(st.session_state, 'analysis_results') and st.session_state.analysis_results:
                st.markdown("---")
                st.markdown("## ğŸ‰ í„°ë³´ ë¶„ì„ ì™„ë£Œ!")
                self.render_turbo_actions()
                
        except Exception as e:
            st.error(f"âŒ í„°ë³´ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            st.markdown("### ğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•")
            st.markdown("""
            1. **ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨** (Ctrl+F5)
            2. **ì‹œìŠ¤í…œ ì¬ì‹œì‘**: 
               ```bash
               streamlit run modules/module1_conference/conference_analysis_turbo.py --server.port 8542
               ```
            3. **ì˜ì¡´ì„± í™•ì¸**: ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
            """)
            
            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´", expanded=False):
                st.text(f"ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
                st.text(f"í„°ë³´ ì‚¬ìš© ê°€ëŠ¥: {TURBO_AVAILABLE}")
                st.text(f"URL ë‹¤ìš´ë¡œë“œ ì‚¬ìš© ê°€ëŠ¥: {URL_DOWNLOAD_AVAILABLE}")
                st.text(f"ì˜ìƒ ë¶„ì„ ì‚¬ìš© ê°€ëŠ¥: {VIDEO_ANALYSIS_AVAILABLE}")
                if hasattr(st.session_state, 'turbo_models_ready'):
                    st.text(f"ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ: {st.session_state.turbo_models_ready}")
                else:
                    st.text("ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ: í™•ì¸ ë¶ˆê°€")

def main():
    """í„°ë³´ ë©”ì¸ í•¨ìˆ˜"""
    try:
        analyzer = TurboConferenceAnalyzer()
        analyzer.run()
    except Exception as e:
        st.error(f"âŒ í„°ë³´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        st.markdown("### ğŸš¨ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜")
        st.markdown("""
        **ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”:**
        1. ë¸Œë¼ìš°ì €ë¥¼ ì™„ì „íˆ ë‹«ê³  ë‹¤ì‹œ ì—´ê¸°
        2. í„°ë¯¸ë„ì—ì„œ ì‹œìŠ¤í…œ ì¬ì‹œì‘:
           ```bash
           streamlit run modules/module1_conference/conference_analysis_turbo.py --server.port 8542
           ```
        3. ë©”ì¸ ëŒ€ì‹œë³´ë“œì—ì„œ ì ‘ì†: http://localhost:8511
        """)

if __name__ == "__main__":
    main()