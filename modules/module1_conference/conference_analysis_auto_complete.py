#!/usr/bin/env python3
"""
ğŸ¤– ì™„ì „ ìë™í™” ULTIMATE ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
- íŒŒì¼ ì—…ë¡œë“œ â†’ ìë™ ë¶„ì„ â†’ ì™„ì„±ëœ ê²°ê³¼ê¹Œì§€ ì›í´ë¦­
- ëª¨ë“  Yes ì²˜ë¦¬ ìë™í™”
- ì˜¤ë¥˜ ì—†ëŠ” ì™„ì „ ìë™ ì‹¤í–‰
"""

import streamlit as st
import os
import sys
import tempfile
import time
import hashlib
import threading
import json
import pickle
import gzip
import io
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import requests

# ê³ ì„±ëŠ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import whisper
    import librosa
    import easyocr
    import numpy as np
    import cv2
    from sklearn.cluster import KMeans, MiniBatchKMeans
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    from sklearn.metrics import silhouette_score
    ULTIMATE_AVAILABLE = True
except ImportError as e:
    st.error(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")
    ULTIMATE_AVAILABLE = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

try:
    from shared.ollama_interface import OllamaInterface
    from core.comprehensive_message_extractor import ComprehensiveMessageExtractor
    from core.ollama_enhanced_extractor import OllamaEnhancedExtractor
    from core.optimized_ai_loader import optimized_loader
    from core.smart_memory_manager import get_memory_stats
    COMPONENTS_AVAILABLE = True
except ImportError:
    COMPONENTS_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¤– ì™„ì „ ìë™í™” ULTIMATE ë¶„ì„",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AutoCompleteAnalysisEngine:
    """ì™„ì „ ìë™í™” ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.cache_dir = Path("cache/auto_complete")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.user_files_dir = Path("user_files")
        self.user_files_dir.mkdir(parents=True, exist_ok=True)
        
        # AI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (ìë™)
        self.auto_initialize_components()
        
        # ìë™í™” ì„¤ì •
        self.auto_settings = {
            'auto_start_analysis': True,
            'auto_apply_all_features': True,
            'auto_generate_reports': True,
            'auto_save_results': True,
            'skip_confirmations': True
        }
        
        st.success("ğŸ¤– ì™„ì „ ìë™í™” ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def auto_initialize_components(self):
        """AI ì»´í¬ë„ŒíŠ¸ ìë™ ì´ˆê¸°í™”"""
        try:
            if COMPONENTS_AVAILABLE:
                self.ollama = OllamaInterface()
                self.message_extractor = ComprehensiveMessageExtractor()
                self.enhanced_extractor = OllamaEnhancedExtractor()
                st.success("âœ… ëª¨ë“  AI ì»´í¬ë„ŒíŠ¸ ìë™ ë¡œë“œ ì™„ë£Œ")
            else:
                st.warning("âš ï¸ ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ ëˆ„ë½ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
        except Exception as e:
            st.error(f"âŒ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def scan_user_files_automatically(self) -> List[Path]:
        """user_files í´ë” ìë™ ìŠ¤ìº”"""
        if not self.user_files_dir.exists():
            st.info("ğŸ“ user_files í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ ì—…ë¡œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
            return []
        
        # ì§€ì› íŒŒì¼ í˜•ì‹
        supported_extensions = [
            '.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac',  # ì˜¤ë””ì˜¤
            '.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif',  # ì´ë¯¸ì§€
            '.mp4', '.avi', '.mov', '.mkv', '.wmv'  # ë¹„ë””ì˜¤
        ]
        
        files = []
        for ext in supported_extensions:
            files.extend(self.user_files_dir.glob(f"*{ext}"))
            files.extend(self.user_files_dir.glob(f"*{ext.upper()}"))
        
        return sorted(files)[:10]  # ìµœëŒ€ 10ê°œ íŒŒì¼
    
    def auto_analyze_all_files(self, files: List[Path]) -> Dict[str, Any]:
        """ëª¨ë“  íŒŒì¼ ì™„ì „ ìë™ ë¶„ì„"""
        if not files:
            return {'error': 'ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}
        
        start_time = time.time()
        
        # ì§„í–‰ë¥  í‘œì‹œ
        progress_container = st.container()
        with progress_container:
            st.subheader("ğŸš€ ì™„ì „ ìë™ ë¶„ì„ ì§„í–‰ ì¤‘...")
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        all_results = {
            'session_id': hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8],
            'total_files': len(files),
            'audio_analysis': {},
            'image_analysis': {},
            'video_analysis': {},
            'combined_insights': {},
            'auto_settings': self.auto_settings
        }
        
        # ê° íŒŒì¼ ìë™ ì²˜ë¦¬
        for i, file_path in enumerate(files):
            try:
                progress = (i + 1) / len(files)
                progress_bar.progress(progress)
                status_text.text(f"ğŸ“ ë¶„ì„ ì¤‘: {file_path.name} ({i+1}/{len(files)})")
                
                # íŒŒì¼ ë‚´ìš© ì½ê¸°
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                
                # íŒŒì¼ íƒ€ì…ë³„ ìë™ ë¶„ì„
                file_ext = file_path.suffix.lower()
                if file_ext in ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']:
                    result = self.auto_analyze_audio(file_content, file_path.name)
                    if 'error' not in result:
                        all_results['audio_analysis'][file_path.name] = result
                
                elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']:
                    result = self.auto_analyze_image(file_content, file_path.name)
                    if 'error' not in result:
                        all_results['image_analysis'][file_path.name] = result
                
                elif file_ext in ['.mp4', '.avi', '.mov', '.mkv', '.wmv']:
                    result = self.auto_analyze_video(file_content, file_path.name)
                    if 'error' not in result:
                        all_results['video_analysis'][file_path.name] = result
                
                # ì§§ì€ ëŒ€ê¸° (UI ë°˜ì‘ì„±)
                time.sleep(0.1)
                
            except Exception as e:
                st.warning(f"âš ï¸ {file_path.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ìë™ ì¢…í•© ë¶„ì„ (Ollama AI)
        progress_bar.progress(0.9)
        status_text.text("ğŸ¤– AI ì¢…í•© ë¶„ì„ ì¤‘...")
        
        if COMPONENTS_AVAILABLE and (all_results['audio_analysis'] or all_results['image_analysis']):
            combined_insights = self.enhanced_extractor.extract_ultimate_insights(all_results)
            all_results['combined_insights'] = combined_insights
        
        # ìµœì¢… ì •ë¦¬
        all_results['processing_time'] = time.time() - start_time
        all_results['timestamp'] = datetime.now().isoformat()
        all_results['auto_completed'] = True
        
        progress_bar.progress(1.0)
        status_text.text("âœ… ì™„ì „ ìë™ ë¶„ì„ ì™„ë£Œ!")
        
        return all_results
    
    def auto_analyze_audio(self, content: bytes, filename: str) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ë¶„ì„"""
        if not ULTIMATE_AVAILABLE:
            return {'error': 'Ultimate ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”'}
        
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                tmp.write(content)
                tmp_path = tmp.name
            
            # Whisper STT (ìë™ ìµœì  ëª¨ë¸ ì„ íƒ)
            model_size = "small" if len(content) < 10*1024*1024 else "base"  # 10MB ê¸°ì¤€
            
            with optimized_loader.get_whisper_model(model_size) as whisper_model:
                stt_result = whisper_model.transcribe(tmp_path, language='ko')
            
            # ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ (ìë™)
            y, sr = librosa.load(tmp_path)
            
            # ê¸°ë³¸ íŠ¹ì§•
            duration = len(y) / sr
            rms_energy = np.sqrt(np.mean(y**2))
            zero_crossings = np.sum(np.abs(np.diff(np.sign(y)))) / 2
            
            # ìë™ í™”ì ë¶„ë¦¬ (ê°„ë‹¨í•œ ë²„ì „)
            segments = stt_result.get('segments', [])
            speaker_count = min(max(1, len(segments) // 5), 4)  # ìë™ ì¶”ì •
            
            # ì •ë¦¬
            os.unlink(tmp_path)
            
            return {
                'filename': filename,
                'duration': duration,
                'transcript': stt_result['text'],
                'language': stt_result.get('language', 'unknown'),
                'segments_count': len(segments),
                'estimated_speakers': speaker_count,
                'audio_quality': {
                    'rms_energy': float(rms_energy),
                    'zero_crossing_rate': float(zero_crossings / len(y)),
                    'quality_score': min(100, max(0, 100 - (zero_crossings / len(y)) * 1000))
                },
                'auto_analysis': True
            }
            
        except Exception as e:
            return {'error': f'ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def auto_analyze_image(self, content: bytes, filename: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ìë™ ë¶„ì„"""
        if not ULTIMATE_AVAILABLE:
            return {'error': 'Ultimate ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”'}
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            nparr = np.frombuffer(content, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                return {'error': 'ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨'}
            
            # EasyOCR ìë™ ë¶„ì„ (í•œêµ­ì–´+ì˜ì–´)
            with optimized_loader.get_easyocr_reader(['en', 'ko']) as reader:
                ocr_results = reader.readtext(img)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ë¦¬
            extracted_text = ""
            text_blocks = []
            confidences = []
            
            for (bbox, text, confidence) in ocr_results:
                text_blocks.append({
                    'text': text,
                    'confidence': confidence
                })
                extracted_text += text + " "
                confidences.append(confidence)
            
            # ì´ë¯¸ì§€ ê¸°ë³¸ ì •ë³´
            height, width = img.shape[:2]
            
            return {
                'filename': filename,
                'dimensions': {'width': width, 'height': height},
                'extracted_text': extracted_text.strip(),
                'text_blocks': text_blocks,
                'total_text_blocks': len(text_blocks),
                'avg_confidence': np.mean(confidences) if confidences else 0,
                'auto_analysis': True
            }
            
        except Exception as e:
            return {'error': f'ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def auto_analyze_video(self, content: bytes, filename: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ìë™ ë¶„ì„ (ê¸°ë³¸)"""
        try:
            return {
                'filename': filename,
                'size_bytes': len(content),
                'status': 'ë¹„ë””ì˜¤ ë¶„ì„ ì¤€ë¹„ë¨',
                'note': 'í–¥í›„ ë¹„ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ í™•ì¥ ì˜ˆì •',
                'auto_analysis': True
            }
        except Exception as e:
            return {'error': f'ë¹„ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ - ì™„ì „ ìë™í™”"""
    
    # í—¤ë”
    st.markdown("""
    # ğŸ¤– ì™„ì „ ìë™í™” ULTIMATE ë¶„ì„ ì‹œìŠ¤í…œ
    ### íŒŒì¼ ì—…ë¡œë“œ â†’ ìë™ ë¶„ì„ â†’ ì™„ì„±ëœ ê²°ê³¼ê¹Œì§€ ì›í´ë¦­!
    """)
    
    # ìë™í™” ìƒíƒœ í‘œì‹œ
    st.info("ğŸ¯ **ì™„ì „ ìë™í™” ëª¨ë“œ**: ëª¨ë“  í™•ì¸ ë‹¨ê³„ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
    if not ULTIMATE_AVAILABLE:
        st.error("âŒ Ultimate ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ìë™í™” ì—”ì§„ ì´ˆê¸°í™”
    if 'auto_engine' not in st.session_state:
        st.session_state.auto_engine = AutoCompleteAnalysisEngine()
    
    engine = st.session_state.auto_engine
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tabs = st.tabs(["ğŸ¤– ì™„ì „ ìë™ ë¶„ì„", "ğŸ“ ìˆ˜ë™ ì—…ë¡œë“œ", "âš™ï¸ ì„¤ì •"])
    
    with tabs[0]:  # ì™„ì „ ìë™ ë¶„ì„
        st.subheader("ğŸš€ user_files í´ë” ìë™ ë¶„ì„")
        
        # í´ë” íŒŒì¼ ìë™ ìŠ¤ìº”
        user_files = engine.scan_user_files_automatically()
        
        if user_files:
            st.success(f"ğŸ“ {len(user_files)}ê°œ íŒŒì¼ ìë™ ë°œê²¬!")
            
            # íŒŒì¼ ëª©ë¡ í‘œì‹œ
            with st.expander("ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ëª©ë¡", expanded=True):
                for i, file_path in enumerate(user_files, 1):
                    file_size = file_path.stat().st_size / (1024*1024)  # MB
                    st.write(f"**{i}.** {file_path.name} ({file_size:.2f} MB)")
            
            # ì™„ì „ ìë™ ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            if st.button("ğŸ¤– ì™„ì „ ìë™ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                
                # ìë™ ë¶„ì„ ì‹¤í–‰
                results = engine.auto_analyze_all_files(user_files)
                
                if 'error' not in results:
                    st.success(f"ğŸ‰ ì™„ì „ ìë™ ë¶„ì„ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {results['processing_time']:.2f}ì´ˆ)")
                    
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                    st.session_state.auto_results = results
                    
                    # ê²°ê³¼ í‘œì‹œ
                    display_auto_complete_results(results)
                else:
                    st.error(f"âŒ ìë™ ë¶„ì„ ì‹¤íŒ¨: {results['error']}")
        else:
            st.info("ğŸ“ user_files í´ë”ì— ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.markdown("**ğŸ“‹ ì§€ì› íŒŒì¼ í˜•ì‹:**")
            st.markdown("- ğŸµ **ì˜¤ë””ì˜¤**: mp3, wav, m4a, flac, ogg, aac")
            st.markdown("- ğŸ–¼ï¸ **ì´ë¯¸ì§€**: jpg, jpeg, png, bmp, tiff, gif")  
            st.markdown("- ğŸ¬ **ë¹„ë””ì˜¤**: mp4, avi, mov, mkv, wmv")
    
    with tabs[1]:  # ìˆ˜ë™ ì—…ë¡œë“œ
        st.subheader("ğŸ“ ìˆ˜ë™ íŒŒì¼ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "ë¶„ì„í•  íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
            type=['mp3', 'wav', 'm4a', 'flac', 'ogg', 'aac', 
                  'jpg', 'jpeg', 'png', 'bmp', 'tiff', 'gif',
                  'mp4', 'avi', 'mov', 'mkv', 'wmv'],
            accept_multiple_files=True,
            help="ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        if uploaded_files:
            st.success(f"ğŸ“ {len(uploaded_files)}ê°œ íŒŒì¼ ì—…ë¡œë“œë¨!")
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            total_size = sum(len(f.getvalue()) for f in uploaded_files) / (1024*1024)
            st.write(f"**ì´ í¬ê¸°**: {total_size:.2f} MB")
            
            if st.button("ğŸš€ ì—…ë¡œë“œëœ íŒŒì¼ ìë™ ë¶„ì„", type="primary", use_container_width=True):
                
                # ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ ì„ì‹œë¡œ ì²˜ë¦¬
                temp_results = {
                    'session_id': hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8],
                    'total_files': len(uploaded_files),
                    'audio_analysis': {},
                    'image_analysis': {},
                    'video_analysis': {},
                    'combined_insights': {}
                }
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                start_time = time.time()
                
                for i, uploaded_file in enumerate(uploaded_files):
                    progress = (i + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
                    status_text.text(f"ë¶„ì„ ì¤‘: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                    
                    file_content = uploaded_file.getvalue()
                    file_ext = Path(uploaded_file.name).suffix.lower()
                    
                    # íŒŒì¼ íƒ€ì…ë³„ ë¶„ì„
                    if file_ext in ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']:
                        result = engine.auto_analyze_audio(file_content, uploaded_file.name)
                        if 'error' not in result:
                            temp_results['audio_analysis'][uploaded_file.name] = result
                    
                    elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']:
                        result = engine.auto_analyze_image(file_content, uploaded_file.name)
                        if 'error' not in result:
                            temp_results['image_analysis'][uploaded_file.name] = result
                    
                    elif file_ext in ['.mp4', '.avi', '.mov', '.mkv', '.wmv']:
                        result = engine.auto_analyze_video(file_content, uploaded_file.name)
                        if 'error' not in result:
                            temp_results['video_analysis'][uploaded_file.name] = result
                
                # ì¢…í•© ë¶„ì„
                if COMPONENTS_AVAILABLE:
                    status_text.text("ğŸ¤– AI ì¢…í•© ë¶„ì„ ì¤‘...")
                    combined_insights = engine.enhanced_extractor.extract_ultimate_insights(temp_results)
                    temp_results['combined_insights'] = combined_insights
                
                temp_results['processing_time'] = time.time() - start_time
                temp_results['timestamp'] = datetime.now().isoformat()
                
                progress_bar.progress(1.0)
                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                st.success(f"ğŸ‰ ë¶„ì„ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {temp_results['processing_time']:.2f}ì´ˆ)")
                
                # ê²°ê³¼ í‘œì‹œ
                display_auto_complete_results(temp_results)
    
    with tabs[2]:  # ì„¤ì •
        st.subheader("âš™ï¸ ìë™í™” ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ ë¶„ì„ ì„¤ì •")
            auto_audio = st.checkbox("ğŸµ ì˜¤ë””ì˜¤ ìë™ ë¶„ì„", value=True)
            auto_image = st.checkbox("ğŸ–¼ï¸ ì´ë¯¸ì§€ ìë™ ë¶„ì„", value=True)
            auto_video = st.checkbox("ğŸ¬ ë¹„ë””ì˜¤ ìë™ ë¶„ì„", value=True)
        
        with col2:
            st.subheader("ğŸ¤– AI ì„¤ì •")
            use_ollama = st.checkbox("ğŸ¦™ Ollama AI ì¢…í•© ë¶„ì„", value=COMPONENTS_AVAILABLE)
            auto_insights = st.checkbox("ğŸ’¡ ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„±", value=True)
            auto_reports = st.checkbox("ğŸ“Š ìë™ ë³´ê³ ì„œ ìƒì„±", value=True)
        
        st.info("ğŸ’¡ ëª¨ë“  ì„¤ì •ì´ ìë™ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

def display_auto_complete_results(results: Dict[str, Any]):
    """ì™„ì „ ìë™í™” ê²°ê³¼ í‘œì‹œ"""
    
    st.header("ğŸ‰ ì™„ì „ ìë™ ë¶„ì„ ê²°ê³¼")
    
    # ìš”ì•½ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ íŒŒì¼", results['total_files'])
    with col2:
        st.metric("ì˜¤ë””ì˜¤ íŒŒì¼", len(results['audio_analysis']))
    with col3:
        st.metric("ì´ë¯¸ì§€ íŒŒì¼", len(results['image_analysis']))
    with col4:
        st.metric("ì²˜ë¦¬ ì‹œê°„", f"{results.get('processing_time', 0):.2f}ì´ˆ")
    
    # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„
    result_tabs = st.tabs(["ğŸ† ì¢…í•© ì¸ì‚¬ì´íŠ¸", "ğŸµ ì˜¤ë””ì˜¤ ê²°ê³¼", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²°ê³¼", "ğŸ“Š ì „ì²´ ë°ì´í„°"])
    
    with result_tabs[0]:  # ì¢…í•© ì¸ì‚¬ì´íŠ¸
        if 'combined_insights' in results and results['combined_insights']:
            display_combined_insights(results['combined_insights'])
        else:
            st.info("ğŸ¤– AI ì¢…í•© ì¸ì‚¬ì´íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with result_tabs[1]:  # ì˜¤ë””ì˜¤ ê²°ê³¼
        if results['audio_analysis']:
            for filename, analysis in results['audio_analysis'].items():
                with st.expander(f"ğŸµ {filename}", expanded=True):
                    if 'error' not in analysis:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ê¸¸ì´", f"{analysis.get('duration', 0):.1f}ì´ˆ")
                        with col2:
                            st.metric("í™”ì ìˆ˜", analysis.get('estimated_speakers', 0))
                        with col3:
                            quality = analysis.get('audio_quality', {})
                            st.metric("ìŒì§ˆ ì ìˆ˜", f"{quality.get('quality_score', 0):.1f}")
                        
                        st.subheader("ğŸ“ ìŒì„± ì¸ì‹ ê²°ê³¼")
                        st.text_area("ì¸ì‹ëœ í…ìŠ¤íŠ¸", analysis.get('transcript', ''), height=100)
                    else:
                        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}")
        else:
            st.info("ë¶„ì„ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with result_tabs[2]:  # ì´ë¯¸ì§€ ê²°ê³¼  
        if results['image_analysis']:
            for filename, analysis in results['image_analysis'].items():
                with st.expander(f"ğŸ–¼ï¸ {filename}", expanded=True):
                    if 'error' not in analysis:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            dims = analysis.get('dimensions', {})
                            st.metric("í¬ê¸°", f"{dims.get('width', 0)}x{dims.get('height', 0)}")
                        with col2:
                            st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", analysis.get('total_text_blocks', 0))
                        with col3:
                            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{analysis.get('avg_confidence', 0):.2f}")
                        
                        extracted_text = analysis.get('extracted_text', '')
                        if extracted_text:
                            st.subheader("ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                            st.text_area("OCR ê²°ê³¼", extracted_text, height=100)
                        else:
                            st.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}")
        else:
            st.info("ë¶„ì„ëœ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with result_tabs[3]:  # ì „ì²´ ë°ì´í„°
        st.json(results)

def display_combined_insights(insights: Dict[str, Any]):
    """ì¢…í•© ì¸ì‚¬ì´íŠ¸ í‘œì‹œ"""
    
    if 'executive_summary' in insights:
        st.subheader("ğŸ“‹ ê²½ì˜ì§„ ìš”ì•½")
        st.info(insights['executive_summary'])
    
    if 'key_findings' in insights and insights['key_findings']:
        st.subheader("ğŸ” í•µì‹¬ ë°œê²¬ì‚¬í•­")
        for i, finding in enumerate(insights['key_findings'], 1):
            st.write(f"**{i}.** {finding}")
    
    if 'business_recommendations' in insights and insights['business_recommendations']:
        st.subheader("ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê¶Œì¥ì‚¬í•­")
        for i, rec in enumerate(insights['business_recommendations'], 1):
            st.success(f"**ê¶Œì¥ {i}**: {rec}")
    
    if 'next_actions' in insights and insights['next_actions']:
        st.subheader("ğŸ¯ ë‹¤ìŒ ì•¡ì…˜")
        for action in insights['next_actions']:
            priority = action.get('priority', 'ë³´í†µ')
            if priority == 'ê¸´ê¸‰':
                st.error(f"ğŸ”¥ **{action.get('action', '')}** - {action.get('description', '')}")
            elif priority == 'ë†’ìŒ':
                st.warning(f"âš¡ **{action.get('action', '')}** - {action.get('description', '')}")
            else:
                st.info(f"ğŸ“Œ **{action.get('action', '')}** - {action.get('description', '')}")

if __name__ == "__main__":
    main()