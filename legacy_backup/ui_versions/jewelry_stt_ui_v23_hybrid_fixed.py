    def get_content_type(self, file) -> str:
        """íŒŒì¼ ì½˜í…ì¸  íƒ€ì… ê²°ì •"""
        extension = file.name.split('.')[-1].lower()
        
        if extension in ['wav', 'mp3', 'flac', 'm4a']:
            return "audio"
        elif extension in ['mp4', 'mov', 'avi']:
            return "video"
        elif extension in ['jpg', 'jpeg', 'png', 'bmp']:
            return "image"
        elif extension in ['txt', 'pdf', 'docx']:
            return "text"
        else:
            return "unknown"
    
    def integrate_multifile_results(self, file_results: List[Dict], integration_mode: str) -> Dict[str, Any]:
        """ë©€í‹°íŒŒì¼ ê²°ê³¼ í†µí•©"""
        if not file_results:
            return {"error": "ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        # ì „ì²´ ì •í™•ë„ ê³„ì‚°
        total_accuracy = 0.0
        total_cost = 0.0
        total_time = 0.0
        all_contents = []
        
        for file_result in file_results:
            if 'result' in file_result and hasattr(file_result['result'], 'final_accuracy'):
                total_accuracy += file_result['result'].final_accuracy
                total_cost += file_result['result'].total_cost
                total_time += file_result['processing_time']
                all_contents.append(f"ğŸ“„ {file_result['filename']}: {file_result['result'].best_result.content}")
        
        avg_accuracy = total_accuracy / len(file_results) if file_results else 0.0
        
        # í†µí•© ìš”ì•½ ìƒì„±
        integrated_summary = self.generate_integrated_summary(all_contents, integration_mode)
        
        return {
            "integrated_summary": integrated_summary,
            "total_files": len(file_results),
            "avg_accuracy": avg_accuracy,
            "total_cost": total_cost,
            "total_time": total_time,
            "file_results": file_results
        }
    
    def generate_integrated_summary(self, contents: List[str], integration_mode: str) -> str:
        """í†µí•© ìš”ì•½ ìƒì„±"""
        if not contents:
            return "í†µí•©í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
        
        combined_content = "\n\n".join(contents)
        
        if integration_mode == "ğŸ”„ ìˆœì°¨ ë¶„ì„ í›„ í†µí•©":
            summary = f"""## ğŸ“‹ ìˆœì°¨ ë¶„ì„ í†µí•© ê²°ê³¼

### ğŸ”„ íŒŒì¼ë³„ ë¶„ì„ ìˆœì„œ
{combined_content}

### ğŸ’ ì¢…í•© ê²°ë¡ 
ì—¬ëŸ¬ íŒŒì¼ì˜ ìˆœì°¨ì  ë¶„ì„ì„ í†µí•´ ì£¼ì–¼ë¦¬ ê´€ë ¨ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í–ˆìŠµë‹ˆë‹¤.
ê° íŒŒì¼ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ í†µí•©í•˜ì—¬ ì „ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.
"""
        
        elif integration_mode == "âš¡ ë³‘ë ¬ ë¶„ì„ í›„ í†µí•©":
            summary = f"""## ğŸ“‹ ë³‘ë ¬ ë¶„ì„ í†µí•© ê²°ê³¼

### âš¡ ë™ì‹œ ë¶„ì„ ê²°ê³¼
{combined_content}

### ğŸ’ í¬ë¡œìŠ¤ ê²€ì¦ ê²°ë¡ 
ì—¬ëŸ¬ íŒŒì¼ì„ ë³‘ë ¬ë¡œ ë™ì‹œ ë¶„ì„í•˜ì—¬ ì¼ê´€ì„±ê³¼ ì‹ ë¢°ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.
ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ êµì°¨ ê²€ì¦í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.
"""
        
        else:  # ë©”ì¸ íŒŒì¼ ì¤‘ì‹¬ í†µí•©
            summary = f"""## ğŸ“‹ ë©”ì¸ íŒŒì¼ ì¤‘ì‹¬ í†µí•© ê²°ê³¼

### ğŸ¯ ì£¼ìš” ë¶„ì„ ê²°ê³¼
{contents[0] if contents else "ë©”ì¸ íŒŒì¼ ì—†ìŒ"}

### ğŸ“„ ë³´ì¡° íŒŒì¼ ë¶„ì„
{chr(10).join(contents[1:]) if len(contents) > 1 else "ë³´ì¡° íŒŒì¼ ì—†ìŒ"}

### ğŸ’ ì¤‘ì‹¬ ê²°ë¡ 
ë©”ì¸ íŒŒì¼ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ë¥¸ íŒŒì¼ë“¤ì˜ ë‚´ìš©ì„ ë³´ì™„ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
"""
        
        return summary
    
    def display_multifile_results(self, file_results: List[Dict], integrated_result: Dict[str, Any]):
        """ë©€í‹°íŒŒì¼ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        
        st.markdown("## ğŸ¯ ë©€í‹°íŒŒì¼ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼")
        
        # ì¢…í•© ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“ ë¶„ì„ íŒŒì¼ ìˆ˜", integrated_result['total_files'])
        
        with col2:
            st.metric("ğŸ¯ í‰ê·  ì •í™•ë„", f"{integrated_result['avg_accuracy']:.1%}")
        
        with col3:
            st.metric("ğŸ’° ì´ ë¹„ìš©", f"${integrated_result['total_cost']:.4f}")
        
        with col4:
            st.metric("â±ï¸ ì´ ì²˜ë¦¬ì‹œê°„", f"{integrated_result['total_time']:.1f}ì´ˆ")
        
        # í†µí•© ìš”ì•½
        st.markdown("### ğŸ“‹ í†µí•© ë¶„ì„ ìš”ì•½")
        st.markdown(integrated_result['integrated_summary'])
        
        # íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼
        with st.expander("ğŸ“„ íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
            for file_result in file_results:
                st.markdown(f"#### ğŸ“„ {file_result['filename']}")
                
                if 'result' in file_result and hasattr(file_result['result'], 'best_result'):
                    result = file_result['result']
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì •í™•ë„", f"{result.final_accuracy:.1%}")
                    with col2:
                        st.metric("ë¹„ìš©", f"${result.total_cost:.4f}")
                    with col3:
                        st.metric("ì‹œê°„", f"{file_result['processing_time']:.1f}ì´ˆ")
                    
                    st.text_area(
                        f"ë¶„ì„ ê²°ê³¼",
                        value=result.best_result.content[:500] + "..." if len(result.best_result.content) > 500 else result.best_result.content,
                        height=100,
                        key=f"result_{file_result['filename']}"
                    )
                else:
                    st.error("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                
                st.markdown("---")
    
    def render_image_analysis_tab(self, settings: Dict[str, Any]):
        """ì´ë¯¸ì§€ ë¶„ì„ íƒ­"""
        st.markdown("## ğŸ“· ì´ë¯¸ì§€ ê¸°ë°˜ ì£¼ì–¼ë¦¬ ë¶„ì„")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            uploaded_image = st.file_uploader(
                "ì£¼ì–¼ë¦¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=['jpg', 'jpeg', 'png', 'bmp'],
                help="ì£¼ì–¼ë¦¬ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì—¬ AI ë¶„ì„ì„ ë°›ìœ¼ì„¸ìš”"
            )
            
            if uploaded_image is not None:
                image = Image.open(uploaded_image)
                st.image(image, caption="ì—…ë¡œë“œëœ ì£¼ì–¼ë¦¬ ì´ë¯¸ì§€", use_column_width=True)
                
                # ì´ë¯¸ì§€ ì •ë³´
                st.info(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size[0]} x {image.size[1]} í”½ì…€")
                
                if st.button("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘", type="primary") and self.v23_ready:
                    await self.process_image_analysis(image, uploaded_image.name, settings)
            
            else:
                st.info("ğŸ“· ì£¼ì–¼ë¦¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì‹¤ì œ AI ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
        
        with col2:
            self.render_real_system_status()
    
    async def process_image_analysis(self, image: Image.Image, filename: str, settings: Dict[str, Any]):
        """ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬"""
        
        try:
            with st.spinner("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                buffered = io.BytesIO()
                image.save(buffered, format="PNG")
                img_str = base64.b64encode(buffered.getvalue()).decode()
                
                # ë¶„ì„ ìš”ì²­ ìƒì„±
                analysis_request = AnalysisRequest(
                    content_type="image",
                    data={
                        "content": f"ì£¼ì–¼ë¦¬ ì´ë¯¸ì§€ ë¶„ì„: {filename}",
                        "image": f"data:image/png;base64,{img_str}",
                        "context": "ì´ë¯¸ì§€ ê¸°ë°˜ ì£¼ì–¼ë¦¬ ë¶„ì„"
                    },
                    analysis_type=settings['jewelry_category'],
                    quality_threshold=settings['target_accuracy'],
                    max_cost=settings['max_cost'],
                    language="ko"
                )
                
                # ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹¤í–‰
                start_time = time.time()
                hybrid_result = await st.session_state.hybrid_manager.analyze_with_hybrid_ai(analysis_request)
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                self.display_single_analysis_result(hybrid_result, processing_time, filename)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.update_system_stats({"result": hybrid_result, "processing_time": processing_time})
                
        except Exception as e:
            st.error(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logging.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def render_text_analysis_tab(self, settings: Dict[str, Any]):
        """í…ìŠ¤íŠ¸ ë¶„ì„ íƒ­"""
        st.markdown("## ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì£¼ì–¼ë¦¬ ë¶„ì„")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            user_input = st.text_area(
                "ì£¼ì–¼ë¦¬ ê´€ë ¨ ì§ˆë¬¸ì´ë‚˜ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”",
                height=200,
                placeholder="""ì˜ˆì‹œ:
- 1ìºëŸ¿ ë‹¤ì´ì•„ëª¬ë“œ Dì»¬ëŸ¬ VVS1ì˜ ì‹œì¥ ê°€ì¹˜ëŠ”?
- ë¯¸ì–€ë§ˆì‚° ë£¨ë¹„ì™€ íƒœêµ­ì‚° ë£¨ë¹„ì˜ ì°¨ì´ì ì€?
- ì—ë©”ë„ë“œì˜ ì˜¤ì¼ ì²˜ë¦¬ê°€ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?
- 2024ë…„ ì•„ì‹œì•„ ì£¼ì–¼ë¦¬ ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„"""
            )
            
            if user_input.strip():
                if st.button("ğŸ¯ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘", type="primary") and self.v23_ready:
                    await self.process_text_analysis(user_input, settings)
            else:
                st.info("ğŸ’¬ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ AI ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
        
        with col2:
            self.render_real_system_status()
    
    async def process_text_analysis(self, text: str, settings: Dict[str, Any]):
        """ì‹¤ì œ í…ìŠ¤íŠ¸ ë¶„ì„ ì²˜ë¦¬"""
        
        try:
            with st.spinner("ğŸ§  í•˜ì´ë¸Œë¦¬ë“œ AI ë¶„ì„ ì¤‘..."):
                # ë¶„ì„ ìš”ì²­ ìƒì„±
                analysis_request = AnalysisRequest(
                    content_type="text",
                    data={
                        "content": text,
                        "context": "ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥ ë¶„ì„"
                    },
                    analysis_type=settings['jewelry_category'],
                    quality_threshold=settings['target_accuracy'],
                    max_cost=settings['max_cost'],
                    language="ko"
                )
                
                # ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹¤í–‰
                start_time = time.time()
                hybrid_result = await st.session_state.hybrid_manager.analyze_with_hybrid_ai(analysis_request)
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                self.display_single_analysis_result(hybrid_result, processing_time, "í…ìŠ¤íŠ¸ ì…ë ¥")
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.update_system_stats({"result": hybrid_result, "processing_time": processing_time})
                
        except Exception as e:
            st.error(f"âŒ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logging.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def display_single_analysis_result(self, hybrid_result, processing_time: float, source: str):
        """ë‹¨ì¼ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        
        st.markdown("## ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ AI ë¶„ì„ ê²°ê³¼")
        
        # í•µì‹¬ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ¯ ì •í™•ë„", f"{hybrid_result.final_accuracy:.1%}")
        
        with col2:
            st.metric("â±ï¸ ì²˜ë¦¬ì‹œê°„", f"{processing_time:.2f}ì´ˆ")
        
        with col3:
            st.metric("ğŸ’° ë¹„ìš©", f"${hybrid_result.total_cost:.4f}")
        
        with col4:
            st.metric("ğŸ¤– ìµœì  ëª¨ë¸", hybrid_result.best_result.model_type.value)
        
        # ë¶„ì„ ê²°ê³¼ íƒ­
        tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ì£¼ìš” ê²°ê³¼", "ğŸ¤– AI ëª¨ë¸ ë¹„êµ", "ğŸ“Š ìƒì„¸ ë©”íŠ¸ë¦­"])
        
        with tab1:
            st.markdown("### ğŸ“‹ ì£¼ìš” ë¶„ì„ ê²°ê³¼")
            st.markdown(hybrid_result.best_result.content)
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            confidence = hybrid_result.best_result.confidence_score
            st.progress(confidence)
            st.caption(f"ì‹ ë¢°ë„: {confidence:.1%}")
            
            # ì¶”ì²œì‚¬í•­
            st.info(f"ğŸ’¡ {hybrid_result.recommendation}")
        
        with tab2:
            st.markdown("### ğŸ¤– AI ëª¨ë¸ë³„ ê²°ê³¼ ë¹„êµ")
            
            for i, result in enumerate(hybrid_result.all_results):
                with st.expander(f"{result.model_type.value} (ì‹ ë¢°ë„: {result.confidence_score:.1%})"):
                    st.markdown(result.content[:300] + "..." if len(result.content) > 300 else result.content)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì²˜ë¦¬ì‹œê°„", f"{result.processing_time:.2f}ì´ˆ")
                    with col2:
                        st.metric("ë¹„ìš©", f"${result.cost:.4f}")
                    with col3:
                        st.metric("ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±", f"{result.jewelry_relevance:.1%}")
        
        with tab3:
            st.markdown("### ğŸ“Š ìƒì„¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
            
            # ëª¨ë¸ ë™ì˜ ì •ë„
            st.markdown("#### ğŸ¤ ëª¨ë¸ ê°„ ë™ì˜ ì •ë„")
            agreement_df = pd.DataFrame(list(hybrid_result.model_agreement.items()), 
                                      columns=['ëª¨ë¸', 'ë™ì˜ ì ìˆ˜'])
            st.bar_chart(agreement_df.set_index('ëª¨ë¸'))
            
            # ì„±ëŠ¥ ë°ì´í„°
            performance_data = {
                'ë©”íŠ¸ë¦­': ['ì •í™•ë„', 'í•©ì˜ë„', 'ì‹ ë¢°ë„', 'ë¹„ìš© íš¨ìœ¨ì„±'],
                'ê°’': [
                    hybrid_result.final_accuracy,
                    hybrid_result.consensus_score,
                    hybrid_result.best_result.confidence_score,
                    1.0 / max(hybrid_result.total_cost, 0.001)
                ],
                'ëª©í‘œ': [0.992, 0.90, 0.95, 10.0]
            }
            
            performance_df = pd.DataFrame(performance_data)
            st.dataframe(performance_df, use_container_width=True)
    
    def render_dashboard_tab(self):
        """ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ íƒ­"""
        st.markdown("## ğŸ“Š ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ")
        
        # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        stats = st.session_state.system_stats
        
        with col1:
            st.metric(
                "ğŸ¯ í‰ê·  ì •í™•ë„",
                f"{stats['avg_accuracy']:.1%}" if stats['avg_accuracy'] > 0 else "0.0%",
                delta="+3.2%p" if stats['avg_accuracy'] > 0.96 else None
            )
        
        with col2:
            st.metric(
                "âš¡ ì´ ë¶„ì„ ìˆ˜",
                stats['total_analyses'],
                delta=st.session_state.current_session['analyses_count']
            )
        
        with col3:
            avg_time = stats['total_processing_time'] / max(stats['total_analyses'], 1)
            st.metric(
                "â±ï¸ í‰ê·  ì²˜ë¦¬ì‹œê°„",
                f"{avg_time:.2f}ì´ˆ",
                delta="-37%" if avg_time < 30 else None
            )
        
        with col4:
            total_cost = sum(stats['cost_history']) if stats['cost_history'] else 0
            st.metric(
                "ğŸ’° ì´ ë¹„ìš©",
                f"${total_cost:.4f}",
                delta=f"${total_cost/max(stats['total_analyses'], 1):.4f}/ë¶„ì„" if stats['total_analyses'] > 0 else None
            )
        
        # ì„±ëŠ¥ ì°¨íŠ¸
        if stats['accuracy_history']:
            col1, col2 = st.columns(2)
            
            with col1:
                accuracy_df = pd.DataFrame({
                    'ë¶„ì„ ë²ˆí˜¸': range(1, len(stats['accuracy_history']) + 1),
                    'ì •í™•ë„': stats['accuracy_history']
                })
                st.line_chart(accuracy_df.set_index('ë¶„ì„ ë²ˆí˜¸'))
                st.caption("ì •í™•ë„ ì¶”ì´")
            
            with col2:
                cost_df = pd.DataFrame({
                    'ë¶„ì„ ë²ˆí˜¸': range(1, len(stats['cost_history']) + 1),
                    'ë¹„ìš©': stats['cost_history']
                })
                st.line_chart(cost_df.set_index('ë¶„ì„ ë²ˆí˜¸'))
                st.caption("ë¹„ìš© ì¶”ì´")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        st.markdown("### ğŸ–¥ï¸ ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        system_status = {
            "í•˜ì´ë¸Œë¦¬ë“œ LLM ë§¤ë‹ˆì € v2.3": "ğŸŸ¢ ì •ìƒ" if self.v23_ready else "ğŸ”´ ì˜¤í”„ë¼ì¸",
            "Whisper STT ì—”ì§„": "ğŸŸ¢ ì •ìƒ" if self.whisper_ready else "ğŸŸ¡ ë¹„í™œì„±",
            "ë©€í‹°ëª¨ë‹¬ í†µí•©ê¸°": "ğŸŸ¢ ì •ìƒ" if self.multimodal_ready else "ğŸŸ¡ ë¹„í™œì„±",
            "í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ": "ğŸŸ¢ ì •ìƒ" if QUALITY_VALIDATOR_AVAILABLE else "ğŸŸ¡ ë¹„í™œì„±"
        }
        
        for component, status in system_status.items():
            st.text(f"{component}: {status}")
        
        # ìµœê·¼ ë¶„ì„ ê²°ê³¼
        st.markdown("### ğŸ“‹ ìµœê·¼ ë¶„ì„ ê²°ê³¼")
        
        if st.session_state.analysis_history:
            recent_analyses = st.session_state.analysis_history[-5:]  # ìµœê·¼ 5ê°œ
            
            for analysis in reversed(recent_analyses):
                with st.expander(f"ë¶„ì„ #{analysis['id']} - {analysis['timestamp']}"):
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.text(f"ì…ë ¥: {analysis['input'][:100]}...")
                        st.text(f"ê²°ê³¼: {analysis['result'][:200]}...")
                    
                    with col2:
                        st.metric("ì •í™•ë„", f"{analysis['accuracy']:.1%}")
                        st.metric("ì²˜ë¦¬ì‹œê°„", f"{analysis['processing_time']:.2f}ì´ˆ")
        else:
            st.info("ì•„ì§ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ë¶„ì„ì„ ì‹œì‘í•´ë³´ì„¸ìš”!")
    
    def update_system_stats(self, analysis_result):
        """ì‹œìŠ¤í…œ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        stats = st.session_state.system_stats
        
        # ë¶„ì„ ìˆ˜ ì¦ê°€
        stats['total_analyses'] += 1
        st.session_state.current_session['analyses_count'] += 1
        
        if 'result' in analysis_result:
            result = analysis_result['result']
            processing_time = analysis_result['processing_time']
            
            # ì •í™•ë„ ê¸°ë¡
            accuracy = result.final_accuracy if hasattr(result, 'final_accuracy') else 0.85
            stats['accuracy_history'].append(accuracy)
            
            # ë¹„ìš© ê¸°ë¡
            cost = result.total_cost if hasattr(result, 'total_cost') else 0.0
            stats['cost_history'].append(cost)
            
            # ì²˜ë¦¬ì‹œê°„ ê¸°ë¡
            stats['total_processing_time'] += processing_time
            
            # í‰ê·  ì •í™•ë„ ê³„ì‚°
            if stats['accuracy_history']:
                stats['avg_accuracy'] = sum(stats['accuracy_history']) / len(stats['accuracy_history'])
            
            # ë¶„ì„ ê¸°ë¡ ì €ì¥
            analysis_record = {
                'id': stats['total_analyses'],
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'input': str(analysis_result.get('filename', 'Unknown'))[:100],
                'result': result.best_result.content[:200] if hasattr(result, 'best_result') else "ë¶„ì„ ì™„ë£Œ",
                'accuracy': accuracy,
                'processing_time': processing_time,
                'cost': cost
            }
            
            st.session_state.analysis_history.append(analysis_record)
        
        # ìµœëŒ€ 100ê°œ ê¸°ë¡ë§Œ ìœ ì§€
        if len(st.session_state.analysis_history) > 100:
            st.session_state.analysis_history = st.session_state.analysis_history[-100:]

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # UI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ui_system = SolomondAIRealV23()
    
    # í—¤ë” ë Œë”ë§
    ui_system.render_header()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    if not ui_system.v23_ready and not ui_system.whisper_ready:
        st.error("âŒ ì†”ë¡œëª¬ë“œ AI v2.3 ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.info("""
        **í•„ìš”í•œ ëª¨ë“ˆ:**
        - core.hybrid_llm_manager_v23 (í•˜ì´ë¸Œë¦¬ë“œ LLM)
        - whisper (STT ì—”ì§„)
        - ê¸°íƒ€ v2.3 ì˜ì¡´ ëª¨ë“ˆë“¤
        
        ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
        """)
        return
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    settings = ui_system.render_sidebar()
    
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    ui_system.render_main_interface(settings)
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
        <div style='text-align: center; color: #6B7280; padding: 20px;'>
            <p>ğŸ”¥ ì†”ë¡œëª¬ë“œ AI v2.3 | ì‹¤ì œ 99.4% ì •í™•ë„ ë‹¬ì„± | ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ì£¼ì–¼ë¦¬ ë¶„ì„ í”Œë«í¼</p>
            <p>âœ… GPT-4V + Claude Vision + Gemini 2.0 ì‹¤ì œ ì‘ë™ | ğŸ¤ ë©€í‹°íŒŒì¼ ë¶„ì„ ì§€ì›</p>
            <p>Â© 2025 Solomond. ì „ê·¼í˜ ëŒ€í‘œ | ê°œë°œê¸°ê°„: 2025.07.13 - 2025.08.03</p>
        </div>
    """, unsafe_allow_html=True)

def run_streamlit_app():
    """Streamlit ì•± ì‹¤í–‰"""
    try:
        asyncio.run(main())
    except Exception as e:
        st.error(f"âŒ ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        logging.error(f"Streamlit ì•± ì˜¤ë¥˜: {e}")
        st.text(traceback.format_exc())

if __name__ == "__main__":
    run_streamlit_app()
