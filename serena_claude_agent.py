#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– Serena Claude Code Sub-Agent
SOLOMOND AI ì „ìš© Serena ì—ì´ì „íŠ¸ - Claude Code ë„¤ì´í‹°ë¸Œ í†µí•©

ì´ ëª¨ë“ˆì€ Claude Codeì˜ MCP ë„êµ¬ë“¤ì„ í™œìš©í•˜ì—¬ Serena ì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ì„
ë„¤ì´í‹°ë¸Œ Claude Code í™˜ê²½ì— í†µí•©í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
/agent serena [command] [options]

Commands:
- analyze: ì½”ë“œ ë¶„ì„ ìˆ˜í–‰
- fix: ìë™ ìˆ˜ì • ì ìš©  
- health: í”„ë¡œì íŠ¸ ê±´ê°•ë„ ì²´í¬
- optimize: ì„±ëŠ¥ ìµœì í™” ì œì•ˆ

Author: SOLOMOND AI Team
Version: 1.0.0
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime

class SerenaClaudeAgent:
    """Serena Claude Code ì„œë¸Œì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.agent_name = "serena"
        self.version = "1.0.0"
        self.project_root = Path.cwd()
        
        # Serena ì—ì´ì „íŠ¸ ì„¤ì •
        self.config = {
            "name": "Serena",
            "role": "SOLOMOND AI ì½”ë”© ì „ë¬¸ê°€",
            "expertise": [
                "Symbol-level ì½”ë“œ ë¶„ì„",
                "ThreadPool ìµœì í™”", 
                "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íƒì§€",
                "Streamlit ì„±ëŠ¥ í–¥ìƒ",
                "Ollama AI í†µí•© ìµœì í™”"
            ],
            "response_style": "ì •ë°€í•˜ê³  ì‹¤ìš©ì ì¸ ê¸°ìˆ  ì¡°ì–¸"
        }
        
        # SOLOMOND AI íŠ¹í™” íŒ¨í„´
        self.analysis_patterns = {
            "threadpool_critical": {
                "regex": r"ThreadPoolExecutor.*(?:submit|map).*(?!with\s)",
                "severity": "critical",
                "message": "ThreadPoolExecutorê°€ context manager ì—†ì´ ì‚¬ìš©ë¨",
                "solution": "with ThreadPoolExecutor() as executor: íŒ¨í„´ ì‚¬ìš©"
            },
            "memory_leak_gpu": {
                "regex": r"torch\.cuda.*(?!empty_cache)",
                "severity": "high", 
                "message": "GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì—†ì´ CUDA ì—°ì‚° ìˆ˜í–‰",
                "solution": "torch.cuda.empty_cache() í˜¸ì¶œ ì¶”ê°€"
            },
            "streamlit_no_cache": {
                "regex": r"st\.(?!cache_data|cache_resource).*(?:heavy|process|analyze)",
                "severity": "medium",
                "message": "ë¬´ê±°ìš´ ì—°ì‚°ì— Streamlit ìºì‹œ ë¯¸ì‚¬ìš©",
                "solution": "@st.cache_data ë˜ëŠ” @st.cache_resource ë°ì½”ë ˆì´í„° ì¶”ê°€"
            },
            "ollama_no_error_handling": {
                "regex": r"ollama.*(?:generate|chat).*(?!try|except)",
                "severity": "medium",
                "message": "Ollama API í˜¸ì¶œì— ì—ëŸ¬ ì²˜ë¦¬ ì—†ìŒ",
                "solution": "try-except ë¸”ë¡ìœ¼ë¡œ ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€"
            }
        }

    def analyze_project(self, target_files: List[str] = None) -> Dict[str, Any]:
        """
        í”„ë¡œì íŠ¸ ë¶„ì„ ìˆ˜í–‰
        Claude Codeì˜ Read, Glob ë„êµ¬ë¥¼ í™œìš©
        """
        analysis_result = {
            "agent": "Serena",
            "timestamp": datetime.now().isoformat(),
            "analysis_type": "SOLOMOND AI íŠ¹í™” ì½”ë“œ ë¶„ì„",
            "files_analyzed": 0,
            "issues_found": [],
            "health_score": 0,
            "recommendations": [],
            "critical_fixes": []
        }
        
        try:
            # ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ê²°ì •
            if not target_files:
                # SOLOMOND AI í•µì‹¬ íŒŒì¼ë“¤
                target_files = [
                    "conference_analysis_COMPLETE_WORKING.py",
                    "solomond_ai_main_dashboard.py", 
                    "dual_brain_integration.py",
                    "ai_insights_engine.py",
                    "google_calendar_connector.py"
                ]
            
            analyzed_files = 0
            total_issues = 0
            critical_issues = 0
            
            for file_path in target_files:
                full_path = self.project_root / file_path
                if full_path.exists():
                    analyzed_files += 1
                    file_issues = self._analyze_single_file(str(full_path))
                    
                    for issue in file_issues:
                        analysis_result["issues_found"].append(issue)
                        total_issues += 1
                        
                        if issue["severity"] == "critical":
                            critical_issues += 1
                            analysis_result["critical_fixes"].append({
                                "file": file_path,
                                "line": issue["line"],
                                "fix": issue["solution"]
                            })
            
            analysis_result["files_analyzed"] = analyzed_files
            
            # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°
            if analyzed_files > 0:
                penalty = (critical_issues * 20) + (total_issues * 5)
                analysis_result["health_score"] = max(100 - penalty, 0)
            
            # ì¶”ì²œì‚¬í•­ ìƒì„±
            analysis_result["recommendations"] = self._generate_recommendations(
                total_issues, critical_issues, analysis_result["issues_found"]
            )
            
        except Exception as e:
            analysis_result["error"] = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
        return analysis_result

    def _analyze_single_file(self, file_path: str) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # íŒ¨í„´ë³„ ë¶„ì„
            for pattern_name, pattern_info in self.analysis_patterns.items():
                matches = re.finditer(
                    pattern_info["regex"], 
                    content, 
                    re.MULTILINE | re.IGNORECASE
                )
                
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    code_line = lines[line_num - 1].strip() if line_num <= len(lines) else ""
                    
                    issue = {
                        "file": str(Path(file_path).name),
                        "line": line_num,
                        "pattern": pattern_name,
                        "severity": pattern_info["severity"],
                        "message": pattern_info["message"],
                        "code": code_line,
                        "solution": pattern_info["solution"],
                        "confidence": 0.85
                    }
                    issues.append(issue)
                    
        except Exception as e:
            issues.append({
                "file": str(Path(file_path).name),
                "line": 0,
                "pattern": "analysis_error",
                "severity": "error",
                "message": f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "code": "",
                "solution": "íŒŒì¼ ì ‘ê·¼ ê¶Œí•œ ë° ì¸ì½”ë”© í™•ì¸",
                "confidence": 1.0
            })
        
        return issues

    def _generate_recommendations(self, total_issues: int, critical_issues: int, issues: List[Dict]) -> List[str]:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ê¸°ë³¸ ì¶”ì²œì‚¬í•­
        if critical_issues > 0:
            recommendations.append(
                f"ğŸš¨ {critical_issues}ê°œì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆë¥¼ ì¦‰ì‹œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. "
                "íŠ¹íˆ ThreadPool ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ëŠ” ì‹œìŠ¤í…œ ì•ˆì •ì„±ì— ì§ì ‘ì  ì˜í–¥ì„ ì¤ë‹ˆë‹¤."
            )
        
        if total_issues > 5:
            recommendations.append(
                "ğŸ“Š ë°œê²¬ëœ ì´ìŠˆê°€ ë§ìŠµë‹ˆë‹¤. ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê°•í™”ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
        
        # íŒ¨í„´ë³„ ì¶”ì²œì‚¬í•­
        pattern_counts = {}
        for issue in issues:
            pattern = issue.get("pattern", "unknown")
            pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
        
        if pattern_counts.get("threadpool_critical", 0) > 0:
            recommendations.append(
                "ğŸ”§ ThreadPoolExecutor ì‚¬ìš© ì‹œ í•­ìƒ with ë¬¸ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
                "ì´ëŠ” SOLOMOND AI ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤."
            )
        
        if pattern_counts.get("memory_leak_gpu", 0) > 0:
            recommendations.append(
                "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ê°•í™”í•˜ì„¸ìš”. "
                "torch.cuda.empty_cache()ë¥¼ ì •ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ì„¸ìš”."
            )
        
        if pattern_counts.get("streamlit_no_cache", 0) > 0:
            recommendations.append(
                "âš¡ Streamlit ìºì‹±ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”. "
                "ë¬´ê±°ìš´ AI ëª¨ë¸ ë¡œë”©ê³¼ ë°ì´í„° ì²˜ë¦¬ì— ìºì‹œë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤."
            )
        
        if not recommendations:
            recommendations.append(
                "âœ… ì£¼ìš” íŒ¨í„´ì—ì„œ ì‹¬ê°í•œ ë¬¸ì œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "í˜„ì¬ ì½”ë“œ í’ˆì§ˆì´ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤."
            )
        
        return recommendations

    def generate_fix_script(self, analysis_result: Dict[str, Any]) -> str:
        """ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        if not analysis_result.get("critical_fixes"):
            return "# ìˆ˜ì •ì´ í•„ìš”í•œ í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.\nprint('ì½”ë“œê°€ ì•ˆì •ì ì…ë‹ˆë‹¤!')"
        
        script_lines = [
            "#!/usr/bin/env python3",
            "# Serena ìë™ ìƒì„± ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸",
            "# SOLOMOND AI ì‹œìŠ¤í…œ ìë™ ìµœì í™”",
            f"# ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "import re",
            "import shutil",
            "from pathlib import Path",
            "",
            "def backup_file(file_path):",
            "    \"\"\"íŒŒì¼ ë°±ì—…\"\"\"",
            "    backup_path = f'{file_path}.serena_backup'",
            "    shutil.copy2(file_path, backup_path)",
            "    print(f'ë°±ì—… ìƒì„±: {backup_path}')",
            "",
            "def fix_threadpool_issues():",
            "    \"\"\"ThreadPool ì´ìŠˆ ìë™ ìˆ˜ì •\"\"\"",
            "    fixes_applied = 0",
            ""
        ]
        
        # ThreadPool ìˆ˜ì • ë¡œì§ ì¶”ê°€
        threadpool_files = [
            fix["file"] for fix in analysis_result["critical_fixes"] 
            if "threadpool" in fix.get("fix", "").lower()
        ]
        
        if threadpool_files:
            script_lines.extend([
                "    files_to_fix = [",
                *[f"        '{file}'," for file in set(threadpool_files)],
                "    ]",
                "",
                "    for file_path in files_to_fix:",
                "        if Path(file_path).exists():",
                "            backup_file(file_path)",
                "            ",
                "            with open(file_path, 'r', encoding='utf-8') as f:",
                "                content = f.read()",
                "            ",
                "            # ThreadPoolExecutorë¥¼ with ë¬¸ìœ¼ë¡œ ê°ì‹¸ê¸°",
                "            original_content = content",
                "            ",
                "            # íŒ¨í„´ 1: ê¸°ë³¸ ThreadPoolExecutor í• ë‹¹",
                "            pattern1 = r'(\\s*)(executor\\s*=\\s*ThreadPoolExecutor\\([^)]*\\))\\s*\\n'",
                "            replacement1 = r'\\1with ThreadPoolExecutor() as executor:\\n\\1    # Serena ìˆ˜ì •: with ë¬¸ ì‚¬ìš©ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ì•ˆì „ ê´€ë¦¬\\n'",
                "            content = re.sub(pattern1, replacement1, content, flags=re.MULTILINE)",
                "            ",
                "            if content != original_content:",
                "                with open(file_path, 'w', encoding='utf-8') as f:",
                "                    f.write(content)",
                "                fixes_applied += 1",
                "                print(f'ThreadPool ìˆ˜ì • ì™„ë£Œ: {file_path}')",
                "    ",
                "    return fixes_applied",
                ""
            ])
        
        script_lines.extend([
            "def main():",
            "    \"\"\"ë©”ì¸ ì‹¤í–‰\"\"\"",
            "    print('ğŸ”§ Serena ìë™ ìˆ˜ì • ì‹œìŠ¤í…œ ì‹œì‘')",
            "    print('=' * 50)",
            "    ",
            "    total_fixes = 0",
            "    ",
            "    # ThreadPool ì´ìŠˆ ìˆ˜ì •",
            "    threadpool_fixes = fix_threadpool_issues()",
            "    total_fixes += threadpool_fixes",
            "    ",
            "    print(f'\\nâœ… ìˆ˜ì • ì™„ë£Œ: ì´ {total_fixes}ê°œ íŒŒì¼')",
            "    ",
            "    if total_fixes > 0:",
            "        print('ğŸ’¡ ìˆ˜ì • í›„ ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”.')",
            "        print('ğŸ“ ë°±ì—… íŒŒì¼ë“¤ì´ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ í•„ìš”ì‹œ ë³µì› ê°€ëŠ¥í•©ë‹ˆë‹¤.')",
            "    else:",
            "        print('â„¹ï¸  ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ])
        
        return "\n".join(script_lines)

    def get_agent_info(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì •ë³´ ë°˜í™˜"""
        return {
            "name": self.config["name"],
            "version": self.version,
            "role": self.config["role"],
            "expertise": self.config["expertise"],
            "response_style": self.config["response_style"],
            "capabilities": [
                "SOLOMOND AI íŠ¹í™” ì½”ë“œ ë¶„ì„",
                "ThreadPool ìµœì í™” ìë™ ìˆ˜ì •",
                "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒ¨í„´ íƒì§€",
                "Streamlit ì„±ëŠ¥ ìµœì í™” ì œì•ˆ",
                "í”„ë¡œì íŠ¸ ê±´ê°•ë„ í‰ê°€",
                "ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"
            ],
            "supported_commands": [
                "analyze - ì½”ë“œ ë¶„ì„ ìˆ˜í–‰",
                "fix - ìë™ ìˆ˜ì • ì ìš©",
                "health - í”„ë¡œì íŠ¸ ê±´ê°•ë„ ì²´í¬", 
                "optimize - ì„±ëŠ¥ ìµœì í™” ì œì•ˆ",
                "info - ì—ì´ì „íŠ¸ ì •ë³´ í‘œì‹œ"
            ]
        }

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ¤– Serena Claude Code Sub-Agent")
    print("=" * 50)
    
    serena = SerenaClaudeAgent()
    
    # ì—ì´ì „íŠ¸ ì •ë³´ í‘œì‹œ
    info = serena.get_agent_info()
    print(f"ğŸ§  {info['name']} v{info['version']}")
    print(f"ğŸ“‹ ì—­í• : {info['role']}")
    print(f"âš¡ ì „ë¬¸ ë¶„ì•¼: {', '.join(info['expertise'][:3])}...")
    
    # í”„ë¡œì íŠ¸ ë¶„ì„ ì‹¤í–‰
    print(f"\nğŸ“Š SOLOMOND AI í”„ë¡œì íŠ¸ ë¶„ì„ ì¤‘...")
    result = serena.analyze_project()
    
    print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“ ë¶„ì„ëœ íŒŒì¼: {result['files_analyzed']}ê°œ")
    print(f"ğŸ“ˆ ê±´ê°•ë„ ì ìˆ˜: {result['health_score']}/100")
    print(f"ğŸ” ë°œê²¬ëœ ì´ìŠˆ: {len(result['issues_found'])}ê°œ")
    
    if result['critical_fixes']:
        print(f"ğŸš¨ í¬ë¦¬í‹°ì»¬ ìˆ˜ì •ì‚¬í•­: {len(result['critical_fixes'])}ê°œ")
    
    # ì¶”ì²œì‚¬í•­ í‘œì‹œ
    if result['recommendations']:
        print(f"\nğŸ’¡ Serenaì˜ ì¶”ì²œì‚¬í•­:")
        for i, rec in enumerate(result['recommendations'][:3], 1):
            print(f"  {i}. {rec}")
    
    # ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ìˆëŠ” ê²½ìš°)
    if result['critical_fixes']:
        print(f"\nğŸ”§ ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        fix_script = serena.generate_fix_script(result)
        
        script_path = Path("serena_auto_fix.py")
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(fix_script)
        
        print(f"âœ… ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸: {script_path}")
        print(f"ğŸ’¡ ì‹¤í–‰: python {script_path}")

if __name__ == "__main__":
    main()