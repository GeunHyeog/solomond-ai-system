#!/usr/bin/env python3
"""
Supabase ì—°ê²° ì„¤ì • ë° ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ êµ¬ì¶•
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œì„ ìœ„í•œ ì™„ì „í•œ DB êµ¬ì¡° ì„¤ê³„
"""

import os
import json
from datetime import datetime
from pathlib import Path

class SupabaseSetup:
    """Supabase ì„¤ì • ë° ìŠ¤í‚¤ë§ˆ ê´€ë¦¬"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.config_file = self.project_root / "supabase_config.json"
        
    def create_config_template(self):
        """Supabase ì„¤ì • í…œí”Œë¦¿ ìƒì„±"""
        config_template = {
            "supabase": {
                "url": "YOUR_SUPABASE_URL_HERE",
                "anon_key": "YOUR_SUPABASE_ANON_KEY_HERE", 
                "service_role_key": "YOUR_SUPABASE_SERVICE_ROLE_KEY_HERE",
                "db_password": "YOUR_DATABASE_PASSWORD_HERE"
            },
            "database": {
                "host": "db.YOUR_PROJECT_REF.supabase.co",
                "port": 5432,
                "database": "postgres",
                "user": "postgres"
            },
            "created_at": datetime.now().isoformat(),
            "status": "template"
        }
        
        with open(self.config_file, "w", encoding="utf-8") as f:
            json.dump(config_template, f, indent=2, ensure_ascii=False)
        
        print(f"SUCCESS: Supabase ì„¤ì • í…œí”Œë¦¿ ìƒì„±ë¨: {self.config_file}")
        return config_template
    
    def generate_database_schema(self):
        """ì†”ë¡œëª¬ë“œ AIë¥¼ ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±"""
        schema_sql = """
-- ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
-- ìƒì„±ì¼: {timestamp}

-- 1. ì‚¬ìš©ì ë° ì„¸ì…˜ ê´€ë¦¬
CREATE TABLE IF NOT EXISTS users (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    email VARCHAR(255) UNIQUE,
    name VARCHAR(100),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true,
    user_type VARCHAR(20) DEFAULT 'standard',
    metadata JSONB DEFAULT '{{}}'::jsonb
);

CREATE TABLE IF NOT EXISTS user_sessions (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    session_token VARCHAR(255) UNIQUE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    expires_at TIMESTAMP WITH TIME ZONE,
    is_active BOOLEAN DEFAULT true,
    metadata JSONB DEFAULT '{{}}'::jsonb
);

-- 2. ë¶„ì„ ì‘ì—… ê´€ë¦¬
CREATE TABLE IF NOT EXISTS analysis_jobs (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    job_type VARCHAR(50) NOT NULL, -- 'conference', 'gemstone', 'crawler', '3d_cad'
    status VARCHAR(20) DEFAULT 'pending', -- 'pending', 'processing', 'completed', 'failed'
    input_data JSONB NOT NULL,
    output_data JSONB DEFAULT '{{}}'::jsonb,
    file_paths JSONB DEFAULT '[]'::jsonb,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    error_message TEXT,
    processing_time_seconds INTEGER,
    metadata JSONB DEFAULT '{{}}'::jsonb
);

-- 3. íŒŒì¼ ê´€ë¦¬
CREATE TABLE IF NOT EXISTS uploaded_files (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    analysis_job_id UUID REFERENCES analysis_jobs(id) ON DELETE CASCADE,
    original_filename VARCHAR(255) NOT NULL,
    stored_filename VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_size_bytes BIGINT,
    file_type VARCHAR(100),
    mime_type VARCHAR(100),
    upload_status VARCHAR(20) DEFAULT 'uploaded',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB DEFAULT '{{}}'::jsonb
);

-- 4. ë¶„ì„ ê²°ê³¼ ì €ì¥
CREATE TABLE IF NOT EXISTS analysis_results (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    analysis_job_id UUID REFERENCES analysis_jobs(id) ON DELETE CASCADE,
    result_type VARCHAR(50) NOT NULL, -- 'stt', 'ocr', 'summary', 'translation', etc.
    result_data JSONB NOT NULL,
    confidence_score DECIMAL(5,4),
    processing_engine VARCHAR(50), -- 'whisper', 'easyocr', 'ollama', etc.
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB DEFAULT '{{}}'::jsonb
);

-- 5. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
CREATE TABLE IF NOT EXISTS system_health (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    health_score INTEGER NOT NULL,
    cpu_percent DECIMAL(5,2),
    memory_percent DECIMAL(5,2),
    process_memory_mb DECIMAL(10,2),
    active_modules INTEGER,
    total_analyses_count INTEGER,
    recommendations JSONB DEFAULT '[]'::jsonb,
    metadata JSONB DEFAULT '{{}}'::jsonb
);

-- 6. ëª¨ë“ˆë³„ í†µê³„
CREATE TABLE IF NOT EXISTS module_statistics (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    module_name VARCHAR(50) NOT NULL,
    date DATE DEFAULT CURRENT_DATE,
    usage_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,
    failure_count INTEGER DEFAULT 0,
    avg_processing_time_seconds DECIMAL(10,2),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(module_name, date)
);

-- 7. Notion ì—°ë™ ë¡œê·¸
CREATE TABLE IF NOT EXISTS notion_sync_log (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    analysis_job_id UUID REFERENCES analysis_jobs(id),
    notion_page_id VARCHAR(100),
    sync_type VARCHAR(30), -- 'create', 'update', 'delete'
    sync_status VARCHAR(20) DEFAULT 'pending',
    sync_data JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    synced_at TIMESTAMP WITH TIME ZONE,
    error_message TEXT,
    metadata JSONB DEFAULT '{{}}'::jsonb
);

-- 8. ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX IF NOT EXISTS idx_analysis_jobs_user_id ON analysis_jobs(user_id);
CREATE INDEX IF NOT EXISTS idx_analysis_jobs_status ON analysis_jobs(status);
CREATE INDEX IF NOT EXISTS idx_analysis_jobs_created_at ON analysis_jobs(created_at);
CREATE INDEX IF NOT EXISTS idx_uploaded_files_analysis_job_id ON uploaded_files(analysis_job_id);
CREATE INDEX IF NOT EXISTS idx_analysis_results_job_id ON analysis_results(analysis_job_id);
CREATE INDEX IF NOT EXISTS idx_system_health_timestamp ON system_health(timestamp);
CREATE INDEX IF NOT EXISTS idx_module_statistics_date ON module_statistics(date);

-- 9. í•¨ìˆ˜ ìƒì„±
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 10. íŠ¸ë¦¬ê±° ìƒì„±
CREATE TRIGGER update_users_updated_at 
    BEFORE UPDATE ON users 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_module_statistics_updated_at 
    BEFORE UPDATE ON module_statistics 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- 11. RLS (Row Level Security) ì„¤ì •
ALTER TABLE users ENABLE ROW LEVEL SECURITY;
ALTER TABLE analysis_jobs ENABLE ROW LEVEL SECURITY;
ALTER TABLE uploaded_files ENABLE ROW LEVEL SECURITY;
ALTER TABLE analysis_results ENABLE ROW LEVEL SECURITY;

-- 12. ê¸°ë³¸ ì •ì±… ìƒì„± (ì‚¬ìš©ìëŠ” ìì‹ ì˜ ë°ì´í„°ë§Œ ì ‘ê·¼)
CREATE POLICY IF NOT EXISTS "Users can view own data" ON users
    FOR SELECT USING (auth.uid() = id);

CREATE POLICY IF NOT EXISTS "Users can view own analysis_jobs" ON analysis_jobs
    FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY IF NOT EXISTS "Users can insert own analysis_jobs" ON analysis_jobs
    FOR INSERT WITH CHECK (auth.uid() = user_id);

-- 13. ì´ˆê¸° ë°ì´í„° ì‚½ì…
INSERT INTO users (id, email, name, user_type) VALUES 
    ('00000000-0000-0000-0000-000000000001', 'admin@solomond.ai', 'System Admin', 'admin')
ON CONFLICT (id) DO NOTHING;

-- 14. ë·° ìƒì„±
CREATE OR REPLACE VIEW analysis_summary AS
SELECT 
    DATE(created_at) as analysis_date,
    job_type,
    COUNT(*) as total_jobs,
    COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_jobs,
    COUNT(CASE WHEN status = 'failed' THEN 1 END) as failed_jobs,
    AVG(processing_time_seconds) as avg_processing_time
FROM analysis_jobs 
WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY DATE(created_at), job_type
ORDER BY analysis_date DESC, job_type;

COMMENT ON TABLE users IS 'ì†”ë¡œëª¬ë“œ AI ì‚¬ìš©ì ê´€ë¦¬';
COMMENT ON TABLE analysis_jobs IS 'ë¶„ì„ ì‘ì—… ê´€ë¦¬ ë° ì¶”ì ';
COMMENT ON TABLE uploaded_files IS 'ì—…ë¡œë“œëœ íŒŒì¼ ë©”íƒ€ë°ì´í„°';
COMMENT ON TABLE analysis_results IS 'ë¶„ì„ ê²°ê³¼ ì €ì¥';
COMMENT ON TABLE system_health IS 'ì‹œìŠ¤í…œ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§';
COMMENT ON TABLE module_statistics IS 'ëª¨ë“ˆë³„ ì‚¬ìš© í†µê³„';
COMMENT ON TABLE notion_sync_log IS 'Notion ì—°ë™ ë¡œê·¸';
""".format(timestamp=datetime.now().isoformat())
        
        schema_file = self.project_root / "supabase_schema.sql"
        with open(schema_file, "w", encoding="utf-8") as f:
            f.write(schema_sql)
        
        print(f"SUCCESS: ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±ë¨: {schema_file}")
        return schema_file
    
    def generate_python_client(self):
        """Supabase Python í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        client_code = '''#!/usr/bin/env python3
"""
Supabase í´ë¼ì´ì–¸íŠ¸ - ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œìš©
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from supabase import create_client, Client

class SolomondSupabaseClient:
    """ì†”ë¡œëª¬ë“œ AI Supabase í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config_path: Optional[str] = None):
        if config_path is None:
            config_path = Path(__file__).parent / "supabase_config.json"
        
        self.config = self._load_config(config_path)
        self.client: Client = self._create_client()
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            raise Exception(f"Supabase ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    def _create_client(self) -> Client:
        """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        url = self.config['supabase']['url']
        key = self.config['supabase']['anon_key']
        return create_client(url, key)
    
    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            result = self.client.table('users').select('*').limit(1).execute()
            return True
        except Exception as e:
            print(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def create_analysis_job(self, user_id: str, job_type: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ì‘ì—… ìƒì„±"""
        job_data = {
            'user_id': user_id,
            'job_type': job_type,
            'input_data': input_data,
            'status': 'pending'
        }
        
        result = self.client.table('analysis_jobs').insert(job_data).execute()
        return result.data[0] if result.data else None
    
    def update_analysis_job(self, job_id: str, updates: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ì‘ì—… ì—…ë°ì´íŠ¸"""
        result = self.client.table('analysis_jobs').update(updates).eq('id', job_id).execute()
        return result.data[0] if result.data else None
    
    def save_analysis_result(self, job_id: str, result_type: str, result_data: Dict[str, Any], 
                           confidence_score: Optional[float] = None, 
                           processing_engine: Optional[str] = None) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        result_record = {
            'analysis_job_id': job_id,
            'result_type': result_type,
            'result_data': result_data,
            'confidence_score': confidence_score,
            'processing_engine': processing_engine
        }
        
        result = self.client.table('analysis_results').insert(result_record).execute()
        return result.data[0] if result.data else None
    
    def save_system_health(self, health_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ì €ì¥"""
        result = self.client.table('system_health').insert(health_data).execute()
        return result.data[0] if result.data else None
    
    def get_analysis_jobs(self, user_id: Optional[str] = None, status: Optional[str] = None, 
                         limit: int = 50) -> List[Dict[str, Any]]:
        """ë¶„ì„ ì‘ì—… ì¡°íšŒ"""
        query = self.client.table('analysis_jobs').select('*')
        
        if user_id:
            query = query.eq('user_id', user_id)
        if status:
            query = query.eq('status', status)
        
        result = query.order('created_at', desc=True).limit(limit).execute()
        return result.data or []
    
    def get_system_health_latest(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ìµœê·¼ ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¡°íšŒ"""
        result = self.client.table('system_health').select('*').order('timestamp', desc=True).limit(limit).execute()
        return result.data or []

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_supabase_client = None

def get_supabase_client() -> SolomondSupabaseClient:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _supabase_client
    if _supabase_client is None:
        _supabase_client = SolomondSupabaseClient()
    return _supabase_client

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    try:
        client = SolomondSupabaseClient()
        if client.test_connection():
            print("SUCCESS: Supabase ì—°ê²° ì„±ê³µ!")
        else:
            print("ERROR: Supabase ì—°ê²° ì‹¤íŒ¨!")
    except Exception as e:
        print(f"ERROR: ì˜¤ë¥˜: {e}")
'''
        
        client_file = self.project_root / "supabase_client.py"
        with open(client_file, "w", encoding="utf-8") as f:
            f.write(client_code)
        
        print(f"SUCCESS: Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±ë¨: {client_file}")
        return client_file
    
    def setup_complete_system(self):
        """ì™„ì „í•œ Supabase ì‹œìŠ¤í…œ ì„¤ì •"""
        print("=== ì†”ë¡œëª¬ë“œ AI Supabase ì‹œìŠ¤í…œ ì„¤ì • ===")
        
        # 1. ì„¤ì • í…œí”Œë¦¿ ìƒì„±
        config = self.create_config_template()
        
        # 2. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±
        schema_file = self.generate_database_schema()
        
        # 3. Python í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client_file = self.generate_python_client()
        
        # 4. ìš”êµ¬ì‚¬í•­ íŒŒì¼ ì—…ë°ì´íŠ¸
        requirements = [
            "supabase>=2.0.0",
            "psycopg2-binary>=2.9.0",
            "python-dotenv>=1.0.0"
        ]
        
        req_file = self.project_root / "requirements_supabase.txt"
        with open(req_file, "w") as f:
            f.write("\\n".join(requirements))
        
        print(f"SUCCESS: Supabase ìš”êµ¬ì‚¬í•­ íŒŒì¼: {req_file}")
        
        # 5. ì„¤ì • ê°€ì´ë“œ ìƒì„±
        guide = self.generate_setup_guide()
        
        print("\\n=== ì„¤ì • ì™„ë£Œ ===")
        print("ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"  1. ì„¤ì • í…œí”Œë¦¿: {self.config_file}")
        print(f"  2. DB ìŠ¤í‚¤ë§ˆ: {schema_file}")
        print(f"  3. Python í´ë¼ì´ì–¸íŠ¸: {client_file}")
        print(f"  4. ìš”êµ¬ì‚¬í•­: {req_file}")
        print(f"  5. ì„¤ì • ê°€ì´ë“œ: supabase_setup_guide.md")
        
        return {
            "config_file": self.config_file,
            "schema_file": schema_file,
            "client_file": client_file,
            "requirements_file": req_file
        }
    
    def generate_setup_guide(self):
        """ì„¤ì • ê°€ì´ë“œ ìƒì„±"""
        guide_content = """# ğŸ—„ï¸ Supabase ì„¤ì • ê°€ì´ë“œ

## 1. Supabase í”„ë¡œì íŠ¸ ìƒì„±
1. https://supabase.com ë°©ë¬¸
2. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
3. ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸ ì„¤ì •

## 2. API í‚¤ í™•ì¸
í”„ë¡œì íŠ¸ ëŒ€ì‹œë³´ë“œì—ì„œ ë‹¤ìŒ ì •ë³´ ìˆ˜ì§‘:
- Project URL
- Anon/Public Key  
- Service Role Key

## 3. ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
`supabase_config.json` íŒŒì¼ì„ ì‹¤ì œ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸:

```json
{
  "supabase": {
    "url": "https://YOUR_PROJECT_REF.supabase.co",
    "anon_key": "YOUR_ACTUAL_ANON_KEY",
    "service_role_key": "YOUR_ACTUAL_SERVICE_ROLE_KEY",
    "db_password": "YOUR_DATABASE_PASSWORD"
  }
}
```

## 4. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì‹¤í–‰
Supabase SQL Editorì—ì„œ `supabase_schema.sql` ì‹¤í–‰

## 5. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements_supabase.txt
```

## 6. ì—°ê²° í…ŒìŠ¤íŠ¸
```bash
python supabase_client.py
```

## 7. ì†”ë¡œëª¬ë“œ AI í†µí•©
ë©”ì¸ ëŒ€ì‹œë³´ë“œì™€ ëª¨ë“ˆë“¤ì´ ìë™ìœ¼ë¡œ Supabaseë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.

## ë³´ì•ˆ ì£¼ì˜ì‚¬í•­
- API í‚¤ë¥¼ Gitì— ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”
- Service Role KeyëŠ” ì„œë²„ì‚¬ì´ë“œì—ì„œë§Œ ì‚¬ìš©
- RLS(Row Level Security) ì •ì±… í™•ì¸
"""
        
        guide_file = self.project_root / "supabase_setup_guide.md"
        with open(guide_file, "w", encoding="utf-8") as f:
            f.write(guide_content)
        
        print(f"SUCCESS: ì„¤ì • ê°€ì´ë“œ ìƒì„±ë¨: {guide_file}")
        return guide_file

if __name__ == "__main__":
    setup = SupabaseSetup()
    setup.setup_complete_system()