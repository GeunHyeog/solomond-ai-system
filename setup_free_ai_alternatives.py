#!/usr/bin/env python3
"""
ë¬´ë£Œ AI ëŒ€ì•ˆ ì„¤ì • ê°€ì´ë“œ
ë¹„ìš© ì—†ì´ ê³ ê¸‰ AI ê¸°ëŠ¥ í™œìš©í•˜ê¸°
"""

import os
import sys
import json
from pathlib import Path

def setup_ollama_integration():
    """Ollama ë¡œì»¬ LLM ì„¤ì •"""
    print("Ollama ë¡œì»¬ LLM ì„¤ì •")
    print("="*50)
    
    print("ì„¤ì¹˜ ë°©ë²•:")
    print("1. https://ollama.ai ì—ì„œ Ollama ë‹¤ìš´ë¡œë“œ")
    print("2. ì„¤ì¹˜ í›„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰:")
    print("   ollama pull llama3.2:3b        # 3B ëª¨ë¸ (ë¹ ë¦„)")
    print("   ollama pull llama3.2:8b        # 8B ëª¨ë¸ (ê³ í’ˆì§ˆ)")
    print("   ollama pull qwen2.5:7b         # ë‹¤êµ­ì–´ ì§€ì›")
    print("   ollama pull mistral:7b         # ì½”ë”© íŠ¹í™”")
    
    print("\nì¥ì :")
    print("- ì™„ì „ ë¬´ë£Œ")
    print("- ê°œì¸ì •ë³´ ë³´í˜¸ (ë¡œì»¬ ì‹¤í–‰)")
    print("- ì¸í„°ë„· ì—°ê²° ë¶ˆí•„ìš”")
    print("- ë¬´ì œí•œ ì‚¬ìš©")
    
    print("\nìš”êµ¬ì‚¬í•­:")
    print("- RAM: ìµœì†Œ 8GB (3B ëª¨ë¸), ê¶Œì¥ 16GB (8B ëª¨ë¸)")
    print("- ì €ì¥ê³µê°„: ëª¨ë¸ë‹¹ 2-5GB")

def setup_huggingface_free():
    """Hugging Face ë¬´ë£Œ API ì„¤ì •"""
    print("\nHugging Face ë¬´ë£Œ API ì„¤ì •")
    print("="*50)
    
    print("ğŸ“‹ ì„¤ì • ë°©ë²•:")
    print("1. https://huggingface.co ê°€ì…")
    print("2. Settings â†’ Access Tokensì—ì„œ í† í° ìƒì„±")
    print("3. ì†”ë¡œëª¬ë“œ AI ì„¤ì •ì—ì„œ í† í° ì…ë ¥")
    
    print("\nğŸ†“ ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸:")
    print("- microsoft/DialoGPT-large (ëŒ€í™”)")
    print("- facebook/bart-large-cnn (ìš”ì•½)")
    print("- google/flan-t5-large (ë²”ìš©)")
    print("- microsoft/Phi-3-mini (ê²½ëŸ‰)")
    
    print("\nğŸ’¡ ë¬´ë£Œ ì œí•œ:")
    print("- ì›” 30,000 ìš”ì²­")
    print("- ì‘ë‹µ ì†ë„ ì œí•œ")
    print("- ìƒìš© ì‚¬ìš© ì œí•œ")

def setup_google_colab():
    """Google Colab ë¬´ë£Œ GPU í™œìš©"""
    print("\nâ˜ï¸ Google Colab ë¬´ë£Œ GPU ì„¤ì •")
    print("="*50)
    
    print("ğŸ“‹ í™œìš© ë°©ë²•:")
    print("1. Google Colabì—ì„œ ì†”ë¡œëª¬ë“œ AI ì‹¤í–‰")
    print("2. ë¬´ë£Œ T4 GPU ì‚¬ìš© (15GB VRAM)")
    print("3. ëŒ€í˜• ëª¨ë¸ ì‹¤í–‰ ê°€ëŠ¥")
    
    print("\nğŸ’¡ ì¥ì :")
    print("- ì™„ì „ ë¬´ë£Œ GPU ì‚¬ìš©")
    print("- ê°•ë ¥í•œ í•˜ë“œì›¨ì–´")
    print("- í´ë¼ìš°ë“œ ì €ì¥")
    
    print("\nâš ï¸ ì œí•œì‚¬í•­:")
    print("- ì„¸ì…˜ë‹¹ ìµœëŒ€ 12ì‹œê°„")
    print("- ì¼ì¼ ì‚¬ìš© ì œí•œ")
    print("- ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±")

def setup_local_models_config():
    """ë¡œì»¬ ëª¨ë¸ ìµœì í™” ì„¤ì •"""
    print("\nğŸ”§ í˜„ì¬ ë¡œì»¬ ëª¨ë¸ ìµœì í™”")
    print("="*50)
    
    config = {
        "ai_models": {
            "whisper": {
                "enabled": True,
                "model_size": "base",  # tiny, base, small, medium, large
                "language": "ko",
                "cost": 0.0
            },
            "easyocr": {
                "enabled": True,
                "languages": ["ko", "en"],
                "gpu": False,
                "cost": 0.0
            },
            "transformers": {
                "enabled": True,
                "model": "facebook/bart-large-cnn",
                "task": "summarization",
                "cost": 0.0
            }
        },
        "free_alternatives": {
            "ollama": {
                "enabled": False,
                "models": ["llama3.2:3b", "qwen2.5:7b"],
                "api_url": "http://localhost:11434"
            },
            "huggingface": {
                "enabled": False,
                "token": "",
                "models": [
                    "microsoft/DialoGPT-large",
                    "facebook/bart-large-cnn",
                    "google/flan-t5-large"
                ]
            }
        }
    }
    
    config_path = Path("free_ai_config.json")
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    print("ğŸ“‹ í˜„ì¬ í™œì„±í™”ëœ ë¬´ë£Œ AI ê¸°ëŠ¥:")
    print("- âœ… Whisper STT (ìŒì„±â†’í…ìŠ¤íŠ¸)")
    print("- âœ… EasyOCR (ì´ë¯¸ì§€â†’í…ìŠ¤íŠ¸)")
    print("- âœ… Transformers (í…ìŠ¤íŠ¸ ìš”ì•½)")
    print("- â¸ï¸ Ollama LLM (ì„¤ì¹˜ í›„ í™œì„±í™” ê°€ëŠ¥)")
    print("- â¸ï¸ Hugging Face API (í† í° ì„¤ì • í›„ í™œì„±í™”)")

def show_cost_comparison():
    """ë¹„ìš© ë¹„êµí‘œ"""
    print("\nğŸ’° AI ì„œë¹„ìŠ¤ ë¹„ìš© ë¹„êµ")
    print("="*60)
    
    print("ğŸ“Š ìœ ë£Œ ì„œë¹„ìŠ¤ (1M í† í°ë‹¹):")
    print("- OpenAI GPT-4o:        $5.00")
    print("- OpenAI GPT-3.5:       $0.50")
    print("- Anthropic Claude:     $3.00")
    print("- Google Gemini:        $3.50")
    
    print("\nğŸ†“ ë¬´ë£Œ ëŒ€ì•ˆ:")
    print("- ì†”ë¡œëª¬ë“œ ë¡œì»¬ ëª¨ë¸:    $0.00 (ë¬´ì œí•œ)")
    print("- Ollama LLM:          $0.00 (ë¬´ì œí•œ)")
    print("- Hugging Face:        $0.00 (ì›” 30K ìš”ì²­)")
    print("- Google Colab:        $0.00 (ì¼ì¼ ì œí•œ)")
    
    print("\nğŸ“ˆ ì˜ˆìƒ ì›” ì‚¬ìš© ë¹„ìš© (100íšŒ ë¶„ì„ ê¸°ì¤€):")
    print("- OpenAI GPT-4o:        ~$15-30")
    print("- ì†”ë¡œëª¬ë“œ ë¡œì»¬:         $0")
    print("- Ollama:              $0")

def recommend_free_setup():
    """ë¬´ë£Œ ì„¤ì • ì¶”ì²œ"""
    print("\nğŸ¯ ì¶”ì²œ ë¬´ë£Œ AI ì„¤ì •")
    print("="*50)
    
    print("ğŸ¥‡ ìµœê³  ì¶”ì²œ (í˜„ì¬ ìƒíƒœ ìœ ì§€):")
    print("- âœ… ì†”ë¡œëª¬ë“œ ë¡œì»¬ ëª¨ë¸ (Whisper + EasyOCR + Transformers)")
    print("- ì¥ì : ì™„ì „ ë¬´ë£Œ, ë¹ ë¥¸ ì†ë„, ê°œì¸ì •ë³´ ë³´í˜¸")
    print("- í˜„ì¬ ìƒíƒœ: ì´ë¯¸ ì™„ë²½ êµ¬í˜„ë¨")
    
    print("\nğŸ¥ˆ ê³ ê¸‰ ê¸°ëŠ¥ ì›í•  ì‹œ:")
    print("- ğŸ“¥ Ollama ì„¤ì¹˜ â†’ ë¡œì»¬ LLM ì¶”ê°€")
    print("- ì¥ì : GPTê¸‰ ì„±ëŠ¥, ì™„ì „ ë¬´ë£Œ")
    print("- ìš”êµ¬ì‚¬í•­: RAM 8GB+")
    
    print("\nğŸ¥‰ í´ë¼ìš°ë“œ í™œìš©:")
    print("- â˜ï¸ Google Colab + ì†”ë¡œëª¬ë“œ AI")
    print("- ì¥ì : ë¬´ë£Œ GPU, ê°•ë ¥í•œ ì„±ëŠ¥")
    print("- ë‹¨ì : ì„¸ì…˜ ì œí•œ")
    
    print("\nğŸ’¡ ê¶Œì¥ ìˆœì„œ:")
    print("1. í˜„ì¬ ë¡œì»¬ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸ (ë¬´ë£Œ)")
    print("2. í•„ìš”ì‹œ Ollama ì„¤ì¹˜ (ë¬´ë£Œ)")
    print("3. ê³ ê¸‰ ê¸°ëŠ¥ í•„ìš”ì‹œë§Œ ìœ ë£Œ API ê³ ë ¤")

def create_free_integration_guide():
    """ë¬´ë£Œ í†µí•© ê°€ì´ë“œ ìƒì„±"""
    guide_content = """
# ğŸ†“ ì†”ë¡œëª¬ë“œ AI ë¬´ë£Œ í™œìš© ê°€ì´ë“œ

## í˜„ì¬ ë¬´ë£Œ ê¸°ëŠ¥ (ì´ë¯¸ êµ¬í˜„ë¨)
- **Whisper STT**: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë¬´ë£Œ, ì˜¤í”„ë¼ì¸)
- **EasyOCR**: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¬´ë£Œ, ë‹¤êµ­ì–´)
- **Transformers**: í…ìŠ¤íŠ¸ ìš”ì•½ ë° ë¶„ì„ (ë¬´ë£Œ)

## ì¶”ê°€ ë¬´ë£Œ ì˜µì…˜

### 1. Ollama ë¡œì»¬ LLM (ê°•ë ¥ ì¶”ì²œ)
```bash
# ì„¤ì¹˜
curl -fsSL https://ollama.ai/install.sh | sh

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.2:3b    # ë¹ ë¥¸ ëª¨ë¸
ollama pull qwen2.5:7b     # í•œêµ­ì–´ íŠ¹í™”
```

### 2. Hugging Face ë¬´ë£Œ API
```python
# í† í° ì„¤ì • í›„ ì‚¬ìš©
from transformers import pipeline
summarizer = pipeline("summarization", 
                     model="facebook/bart-large-cnn")
```

### 3. Google Colab ë¬´ë£Œ GPU
- ì†”ë¡œëª¬ë“œ AIë¥¼ Colabì—ì„œ ì‹¤í–‰
- ë¬´ë£Œ T4 GPU ì‚¬ìš© ê°€ëŠ¥
- ëŒ€í˜• ëª¨ë¸ ì‹¤í–‰ ê°€ëŠ¥

## ë¹„ìš© ì—†ëŠ” ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©ë²•
1. **ë²ˆì—­**: Google Translate API ë¬´ë£Œ í• ë‹¹ëŸ‰
2. **ìŒì„± í•©ì„±**: gTTS (Google Text-to-Speech) ë¬´ë£Œ
3. **ì´ë¯¸ì§€ ìƒì„±**: Stable Diffusion ë¡œì»¬ ì‹¤í–‰
4. **ì½”ë“œ ë¶„ì„**: ë¡œì»¬ CodeT5 ëª¨ë¸

## ì„±ëŠ¥ ìµœì í™” íŒ
- CPU ëª¨ë“œì—ì„œë„ ì¶©ë¶„í•œ ì„±ëŠ¥
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± ì¦ëŒ€
- ëª¨ë¸ ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ
- ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
"""
    
    guide_path = Path("FREE_AI_GUIDE.md")
    with open(guide_path, 'w', encoding='utf-8') as f:
        f.write(guide_content)
    
    print(f"\nğŸ“– ë¬´ë£Œ í™œìš© ê°€ì´ë“œ ìƒì„±: {guide_path}")

def main():
    print("ë¬´ë£Œ ì†”ë¡œëª¬ë“œ AI - ë¬´ë£Œ AI ì„œë¹„ìŠ¤ ì„¤ì • ê°€ì´ë“œ")
    print("="*60)
    
    show_cost_comparison()
    recommend_free_setup()
    setup_local_models_config()
    setup_ollama_integration()
    setup_huggingface_free()
    setup_google_colab()
    create_free_integration_guide()
    
    print("\nğŸ‰ ê²°ë¡ :")
    print("í˜„ì¬ ì†”ë¡œëª¬ë“œ AIëŠ” ì´ë¯¸ ì™„ì „ ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    print("ì¶”ê°€ ê¸°ëŠ¥ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ìœ„ ì˜µì…˜ë“¤ì„ ê³ ë ¤í•˜ì„¸ìš”.")
    
    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"- free_ai_config.json (ì„¤ì •)")
    print(f"- FREE_AI_GUIDE.md (ê°€ì´ë“œ)")

if __name__ == "__main__":
    main()