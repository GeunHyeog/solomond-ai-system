#!/usr/bin/env python3
"""
ğŸš€ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ v3.0 (í•œêµ­ì–´ ìš”ì•½ ë²„ì „)
- ë¬¸ì„œ+ì˜ìƒ+ìŒì„±+ì´ë¯¸ì§€+ìœ íŠœë¸Œ ì™„ì „ ì§€ì› (ë‹¤êµ­ì–´ ì…ë ¥)
- ìœ íŠœë¸Œ URL ìë™ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
- ì—¬ëŸ¬ AIì—”ì§„ ì¡°í•© ë¶„ì„ â†’ í•œêµ­ì–´ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸
- ì£¼ì–¼ë¦¬ ê°•ì˜/íšŒì˜ ë‚´ìš© ì¢…í•© ìš”ì•½ (í•œêµ­ì–´ ì¶œë ¥)

ì‚¬ìš©ë²•:
1. ë¶„ì„í•  íŒŒì¼ë“¤ì„ input_files/ í´ë”ì— ë„£ê¸°
2. ìœ íŠœë¸Œ URLë“¤ì„ youtube_urls.txtì— ì…ë ¥
3. python youtube_integrated_engine_korean.py ì‹¤í–‰
4. í•œêµ­ì–´ í†µí•© ë¶„ì„ ê²°ê³¼ í™•ì¸
"""

import os
import sys
import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass, asdict
from enum import Enum
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AnalysisType(Enum):
    AUDIO = "audio"
    VIDEO = "video"
    IMAGE = "image"
    DOCUMENT = "document"
    YOUTUBE = "youtube"
    WEB = "web"

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    file_name: str
    file_size_mb: float
    analysis_type: AnalysisType
    processing_time: float
    content: str
    jewelry_keywords: List[str]
    confidence: float
    jewelry_relevance: float
    metadata: Dict[str, Any]
    success: bool
    error_message: Optional[str] = None
    youtube_url: Optional[str] = None

    def to_dict(self):
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = asdict(self)
        result['analysis_type'] = self.analysis_type.value  # Enumì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        return result

class YouTubeProcessor:
    """ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.download_dir = Path("temp_youtube")
        self.download_dir.mkdir(exist_ok=True)
        
    async def process_youtube_url(self, url: str) -> Dict[str, Any]:
        """ìœ íŠœë¸Œ URL ì²˜ë¦¬"""
        try:
            # yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ íŠœë¸Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
            logger.info(f"ğŸ“º ìœ íŠœë¸Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
            
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            safe_filename = self.get_safe_filename(url)
            output_path = self.download_dir / f"{safe_filename}.%(ext)s"
            
            # yt-dlp ëª…ë ¹ì–´ êµ¬ì„± (audio only for faster processing)
            import subprocess
            
            # ì˜¤ë””ì˜¤ë§Œ ì¶”ì¶œ (ë” ë¹ ë¥¸ ì²˜ë¦¬)
            cmd = [
                "yt-dlp",
                "--extract-audio",
                "--audio-format", "wav",
                "--audio-quality", "0",
                "--output", str(output_path),
                "--no-playlist",
                url
            ]
            
            # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            
            if result.returncode != 0:
                raise Exception(f"yt-dlp ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
            
            # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì°¾ê¸°
            downloaded_files = list(self.download_dir.glob(f"{safe_filename}.*"))
            if not downloaded_files:
                raise Exception("ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            audio_file = downloaded_files[0]
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ì„ STTë¡œ ì²˜ë¦¬
            stt_processor = AudioSTTProcessor()
            stt_result = await stt_processor.process_audio(str(audio_file))
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            video_info = await self.get_video_info(url)
            
            result_data = {
                "text": stt_result["text"],
                "jewelry_keywords": stt_result["jewelry_keywords"],
                "confidence": stt_result["confidence"],
                "type": "youtube_video_stt",
                "video_info": video_info,
                "downloaded_file": str(audio_file)
            }
            
            logger.info(f"âœ… ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ: {video_info.get('title', 'Unknown')}")
            
            return result_data
            
        except Exception as e:
            logger.error(f"âŒ ìœ íŠœë¸Œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ìœ íŠœë¸Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0,
                "type": "youtube_error"
            }
    
    def get_safe_filename(self, url: str) -> str:
        """URLì—ì„œ ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±"""
        # ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ
        video_id_match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*', url)
        if video_id_match:
            return f"youtube_{video_id_match.group(1)}"
        else:
            return f"youtube_{int(time.time())}"
    
    async def get_video_info(self, url: str) -> Dict[str, Any]:
        """ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import subprocess
            
            cmd = [
                "yt-dlp",
                "--dump-json",
                "--no-playlist",
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                video_data = json.loads(result.stdout)
                return {
                    "title": video_data.get("title", "Unknown"),
                    "duration": video_data.get("duration", 0),
                    "uploader": video_data.get("uploader", "Unknown"),
                    "view_count": video_data.get("view_count", 0),
                    "upload_date": video_data.get("upload_date", "Unknown")
                }
            else:
                return {"title": "Unknown", "error": result.stderr}
                
        except Exception as e:
            return {"title": "Unknown", "error": str(e)}
    
    def cleanup_temp_files(self):
        """ì„ì‹œ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ì •ë¦¬"""
        try:
            import shutil
            if self.download_dir.exists():
                shutil.rmtree(self.download_dir)
                logger.info("ğŸ§¹ ì„ì‹œ ìœ íŠœë¸Œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

class AudioSTTProcessor:
    """ìŒì„± STT ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.model_name = "whisper-base"
        
    async def process_audio(self, file_path: str) -> Dict[str, Any]:
        """ìŒì„± íŒŒì¼ STT ì²˜ë¦¬"""
        try:
            import whisper
            
            logger.info(f"ğŸµ ìŒì„± íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
            model = whisper.load_model("base")
            
            result = model.transcribe(file_path, language="ko")
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            jewelry_keywords = self.extract_jewelry_keywords(result["text"])
            
            return {
                "text": result["text"],
                "segments": result.get("segments", []),
                "language": result.get("language", "ko"),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.85
            }
            
        except Exception as e:
            logger.error(f"âŒ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    def extract_jewelry_keywords(self, text: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œ/ì˜/ì¤‘ í˜¼í•©)"""
        jewelry_terms = [
            # í•œêµ­ì–´ ìš©ì–´
            "ë‹¤ì´ì•„ëª¬ë“œ", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", "ì—ë©”ë„ë“œ", "ë°˜ì§€", "ëª©ê±¸ì´", "ê·€ê±¸ì´", "íŒ”ì°Œ",
            "ê¸ˆ", "ì€", "ë°±ê¸ˆ", "ìºëŸ¿", "ì»·", "íˆ¬ëª…ë„", "ìƒ‰ìƒ", "ë¬´ê²Œ", "ê°ì •ì„œ", "ì¸ì¦ì„œ", 
            "ë³´ì„", "ì£¼ì–¼ë¦¬", "ì„¸íŒ…", "í”„ë¡±", "íŒŒë² ", "ì†”ë¦¬í…Œì–´", "í™ì½©", "í™ì½©ë°•ëŒíšŒ", 
            "ë°”ì ¤ì›”ë“œ", "ì£¼ì–¼ë¦¬í˜ì–´", "ê°ì •", "ë“±ê¸‰", "ì²˜ë¦¬", "ê°€ì—´", "ì˜¤ì¼ë§",
            
            # ì˜ì–´ ìš©ì–´
            "diamond", "ruby", "sapphire", "emerald", "ring", "necklace", "earring", "bracelet",
            "gold", "silver", "platinum", "carat", "cut", "clarity", "color", "weight",
            "GIA", "certificate", "gem", "jewelry", "setting", "prong", "pave", "solitaire",
            "baselworld", "jewelry fair", "treatment", "heated", "pigeon blood", "royal blue",
            "F1", "F2", "F3", "type A", "type B", "enhancement", "diffusion", "flux", "residue",
            
            # ì¤‘êµ­ì–´ ìš©ì–´ (ê°„ì²´)
            "é’»çŸ³", "çº¢å®çŸ³", "è“å®çŸ³", "ç¥–æ¯ç»¿", "æˆ’æŒ‡", "é¡¹é“¾", "è€³ç¯", "æ‰‹é•¯",
            "é»„é‡‘", "ç™½é“¶", "é“‚é‡‘", "å…‹æ‹‰", "åˆ‡å·¥", "å‡€åº¦", "é¢œè‰²", "é‡é‡", "è¯ä¹¦", "å®çŸ³"
        ]
        
        found_keywords = []
        text_lower = text.lower()
        
        for term in jewelry_terms:
            if term.lower() in text_lower:
                found_keywords.append(term)
        
        return list(set(found_keywords))

# ê¸°ì¡´ í”„ë¡œì„¸ì„œë“¤ (ë³€ê²½ ì—†ìŒ)
class VideoProcessor:
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ê¸°"""
    
    async def process_video(self, file_path: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ + STT)"""
        try:
            import ffmpeg
            
            logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}")
            
            temp_audio = f"temp_audio_{int(time.time())}.wav"
            
            (
                ffmpeg
                .input(file_path)
                .output(temp_audio, acodec='pcm_s16le', ac=1, ar='16000')
                .overwrite_output()
                .run(quiet=True)
            )
            
            stt_processor = AudioSTTProcessor()
            audio_result = await stt_processor.process_audio(temp_audio)
            
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
            
            return {
                "text": audio_result["text"],
                "jewelry_keywords": audio_result["jewelry_keywords"],
                "confidence": audio_result["confidence"],
                "type": "video_to_audio_stt"
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class ImageProcessor:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ê¸°"""
    
    async def process_image(self, file_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ OCR ì²˜ë¦¬"""
        try:
            import pytesseract
            from PIL import Image
            
            logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ì¤‘: {file_path}")
            
            image = Image.open(file_path)
            text = pytesseract.image_to_string(image, lang='kor+eng')
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.75,
                "type": "image_ocr"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ê¸°"""
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬"""
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.pdf':
                return await self.process_pdf(file_path)
            elif file_ext == '.docx':
                return await self.process_docx(file_path)
            elif file_ext == '.txt':
                return await self.process_txt(file_path)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œ í˜•ì‹: {file_ext}")
                
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "text": f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_pdf(self, file_path: str) -> Dict[str, Any]:
        """PDF ì²˜ë¦¬"""
        try:
            import PyPDF2
            
            logger.info(f"ğŸ“„ PDF ì²˜ë¦¬ ì¤‘: {file_path}")
            
            text = ""
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.90,
                "type": "pdf_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_docx(self, file_path: str) -> Dict[str, Any]:
        """DOCX ì²˜ë¦¬"""
        try:
            from docx import Document
            
            logger.info(f"ğŸ“ DOCX ì²˜ë¦¬ ì¤‘: {file_path}")
            
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 0.95,
                "type": "docx_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"DOCX ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }
    
    async def process_txt(self, file_path: str) -> Dict[str, Any]:
        """TXT ì²˜ë¦¬"""
        try:
            logger.info(f"ğŸ“‹ TXT ì²˜ë¦¬ ì¤‘: {file_path}")
            
            with open(file_path, 'r', encoding='utf-8') as file:
                text = file.read()
            
            stt_processor = AudioSTTProcessor()
            jewelry_keywords = stt_processor.extract_jewelry_keywords(text)
            
            return {
                "text": text.strip(),
                "jewelry_keywords": jewelry_keywords,
                "confidence": 1.0,
                "type": "txt_extraction"
            }
            
        except Exception as e:
            return {
                "text": f"TXT ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "jewelry_keywords": [],
                "confidence": 0.0
            }

class CompleteMultimodalEngine:
    """ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ (ìœ íŠœë¸Œ í¬í•¨ + í•œêµ­ì–´ ìš”ì•½)"""
    
    def __init__(self):
        self.audio_processor = AudioSTTProcessor()
        self.video_processor = VideoProcessor()
        self.image_processor = ImageProcessor()
        self.document_processor = DocumentProcessor()
        self.youtube_processor = YouTubeProcessor()
        
    async def analyze_single_file(self, file_path: str) -> AnalysisResult:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        start_time = time.time()
        file_name = Path(file_path).name
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        
        logger.info(f"ğŸ” íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name} ({file_size_mb:.2f}MB)")
        
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext in ['.mp3', '.wav', '.m4a', '.aac']:
                analysis_type = AnalysisType.AUDIO
                result = await self.audio_processor.process_audio(file_path)
                
            elif file_ext in ['.mp4', '.mov', '.avi', '.mkv']:
                analysis_type = AnalysisType.VIDEO
                result = await self.video_processor.process_video(file_path)
                
            elif file_ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                analysis_type = AnalysisType.IMAGE
                result = await self.image_processor.process_image(file_path)
                
            elif file_ext in ['.pdf', '.docx', '.txt']:
                analysis_type = AnalysisType.DOCUMENT
                result = await self.document_processor.process_document(file_path)
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            
            processing_time = time.time() - start_time
            
            jewelry_relevance = self.calculate_jewelry_relevance(
                result.get("jewelry_keywords", []), 
                result.get("text", "")
            )
            
            return AnalysisResult(
                file_path=file_path,
                file_name=file_name,
                file_size_mb=file_size_mb,
                analysis_type=analysis_type,
                processing_time=processing_time,
                content=result.get("text", ""),
                jewelry_keywords=result.get("jewelry_keywords", []),
                confidence=result.get("confidence", 0.0),
                jewelry_relevance=jewelry_relevance,
                metadata=result,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_name} - {str(e)}")
            
            return AnalysisResult(
                file_path=file_path,
                file_name=file_name,
                file_size_mb=file_size_mb,
                analysis_type=AnalysisType.DOCUMENT,
                processing_time=processing_time,
                content="",
                jewelry_keywords=[],
                confidence=0.0,
                jewelry_relevance=0.0,
                metadata={},
                success=False,
                error_message=str(e)
            )
    
    async def analyze_youtube_url(self, url: str) -> AnalysisResult:
        """ìœ íŠœë¸Œ URL ë¶„ì„"""
        start_time = time.time()
        
        logger.info(f"ğŸ“º ìœ íŠœë¸Œ URL ë¶„ì„ ì‹œì‘: {url}")
        
        try:
            result = await self.youtube_processor.process_youtube_url(url)
            
            processing_time = time.time() - start_time
            
            # ì¶”ì • íŒŒì¼ í¬ê¸° (ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê¸°ì¤€)
            file_size_mb = 0.0
            if "downloaded_file" in result and os.path.exists(result["downloaded_file"]):
                file_size_mb = os.path.getsize(result["downloaded_file"]) / (1024 * 1024)
            
            jewelry_relevance = self.calculate_jewelry_relevance(
                result.get("jewelry_keywords", []), 
                result.get("text", "")
            )
            
            # ë¹„ë””ì˜¤ ì œëª©ì„ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©
            video_title = result.get("video_info", {}).get("title", "Unknown YouTube Video")
            
            return AnalysisResult(
                file_path=url,
                file_name=f"[YouTube] {video_title}",
                file_size_mb=file_size_mb,
                analysis_type=AnalysisType.YOUTUBE,
                processing_time=processing_time,
                content=result.get("text", ""),
                jewelry_keywords=result.get("jewelry_keywords", []),
                confidence=result.get("confidence", 0.0),
                jewelry_relevance=jewelry_relevance,
                metadata=result,
                success=True,
                youtube_url=url
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ ìœ íŠœë¸Œ ë¶„ì„ ì‹¤íŒ¨: {url} - {str(e)}")
            
            return AnalysisResult(
                file_path=url,
                file_name=f"[YouTube] {url}",
                file_size_mb=0.0,
                analysis_type=AnalysisType.YOUTUBE,
                processing_time=processing_time,
                content="",
                jewelry_keywords=[],
                confidence=0.0,
                jewelry_relevance=0.0,
                metadata={},
                success=False,
                error_message=str(e),
                youtube_url=url
            )
    
    def calculate_jewelry_relevance(self, keywords: List[str], text: str) -> float:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚°"""
        if not keywords:
            return 0.0
        
        keyword_score = min(len(keywords) / 10, 1.0)
        
        text_length = len(text.split())
        if text_length > 0:
            density_score = len(keywords) / text_length * 100
            density_score = min(density_score, 1.0)
        else:
            density_score = 0.0
        
        relevance = (keyword_score * 0.7) + (density_score * 0.3)
        return round(relevance, 2)
    
    async def integrate_complete_analysis(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•© (í•œêµ­ì–´ ìš”ì•½)"""
        logger.info("ğŸ”— ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ í†µí•© ì¤‘...")
        
        successful_results = [r for r in results if r.success]
        
        if not successful_results:
            return {
                "summary": "ë¶„ì„ ê°€ëŠ¥í•œ ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "total_sources": len(results),
                "successful_sources": 0,
                "total_processing_time": sum(r.processing_time for r in results),
                "jewelry_relevance": 0.0
            }
        
        # ì†ŒìŠ¤ë³„ í…ìŠ¤íŠ¸ í†µí•©
        all_text = []
        all_keywords = []
        source_breakdown = {
            "audio": 0, "video": 0, "image": 0, 
            "document": 0, "youtube": 0
        }
        
        for result in successful_results:
            if result.content.strip():
                source_label = f"[{self._get_korean_source_name(result.analysis_type.value)}] {result.file_name}"
                all_text.append(f"{source_label}\n{result.content}")
            
            all_keywords.extend(result.jewelry_keywords)
            source_breakdown[result.analysis_type.value] += 1
        
        combined_text = "\n\n" + "="*50 + "\n\n".join(all_text)
        unique_keywords = list(set(all_keywords))
        
        # í•œêµ­ì–´ í†µí•© ë¶„ì„ ìƒì„±
        korean_summary = self.generate_korean_summary(combined_text, unique_keywords, source_breakdown)
        
        # í†µê³„ ê³„ì‚°
        avg_confidence = sum(r.confidence for r in successful_results) / len(successful_results)
        avg_jewelry_relevance = sum(r.jewelry_relevance for r in successful_results) / len(successful_results)
        total_processing_time = sum(r.processing_time for r in results)
        
        return {
            "summary": korean_summary,
            "combined_text": combined_text,
            "unique_keywords": unique_keywords,
            "total_sources": len(results),
            "successful_sources": len(successful_results),
            "failed_sources": len(results) - len(successful_results),
            "average_confidence": round(avg_confidence, 2),
            "average_jewelry_relevance": round(avg_jewelry_relevance, 2),
            "total_processing_time": round(total_processing_time, 2),
            "source_breakdown": source_breakdown,
            "youtube_count": source_breakdown["youtube"]
        }
    
    def _get_korean_source_name(self, source_type: str) -> str:
        """ì†ŒìŠ¤ íƒ€ì…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
        type_mapping = {
            "audio": "ìŒì„±",
            "video": "ì˜ìƒ", 
            "image": "ì´ë¯¸ì§€",
            "document": "ë¬¸ì„œ",
            "youtube": "ìœ íŠœë¸Œ",
            "web": "ì›¹"
        }
        return type_mapping.get(source_type, source_type)
    
    def generate_korean_summary(self, text: str, keywords: List[str], breakdown: Dict[str, int]) -> str:
        """í•œêµ­ì–´ í†µí•© ìš”ì•½ ìƒì„±"""
        if not text.strip():
            return "ë¶„ì„í•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        summary_parts = []
        
        # ğŸ¯ ì†ŒìŠ¤ ë‹¤ì–‘ì„± ë¶„ì„ (í•œêµ­ì–´)
        source_types = [self._get_korean_source_name(k) for k, v in breakdown.items() if v > 0]
        if len(source_types) > 1:
            summary_parts.append(f"ë‹¤ì–‘í•œ ë©€í‹°ë¯¸ë””ì–´ ì†ŒìŠ¤({', '.join(source_types)})ë¥¼ í†µí•œ ì¢…í•©ì ì¸ ì£¼ì–¼ë¦¬ ë¶„ì„ì…ë‹ˆë‹¤.")
        
        # ğŸ“º ìœ íŠœë¸Œ íŠ¹ë³„ ì–¸ê¸‰
        if breakdown.get("youtube", 0) > 0:
            summary_parts.append(f"ìœ íŠœë¸Œ ì˜ìƒ {breakdown['youtube']}ê°œë¥¼ í¬í•¨í•œ ì˜¨ë¼ì¸ ì½˜í…ì¸  ë¶„ì„ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„
        if keywords:
            korean_keywords = [k for k in keywords if any('\uac00' <= c <= '\ud7af' for c in k)]
            english_keywords = [k for k in keywords if k.isascii()]
            
            if korean_keywords and english_keywords:
                top_keywords = (korean_keywords + english_keywords)[:8]
            elif korean_keywords:
                top_keywords = korean_keywords[:8]
            else:
                top_keywords = english_keywords[:8]
                
            summary_parts.append(f"í•µì‹¬ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ: {', '.join(top_keywords)}")
        
        # ğŸ“š ì½˜í…ì¸  ìœ í˜• ë¶„ì„ (í•œêµ­ì–´)
        text_lower = text.lower()
        korean_text = text
        
        content_types = []
        
        # êµìœ¡/ì„¸ë¯¸ë‚˜ ê°ì§€
        if any(word in korean_text for word in ["êµìœ¡", "ê°•ì˜", "ì„¸ë¯¸ë‚˜", "ì›Œí¬ìƒµ", "í•™ìŠµ", "training"]):
            content_types.append("êµìœ¡ ë° í•™ìŠµ ì½˜í…ì¸ ")
        
        # ì‹œì¥/íŠ¸ë Œë“œ ê°ì§€  
        if any(word in korean_text for word in ["ì‹œì¥", "íŠ¸ë Œë“œ", "ë™í–¥", "ì „ë§", "ë¶„ì„", "market", "trend"]):
            content_types.append("ì‹œì¥ ë™í–¥ ë° ì—…ê³„ íŠ¸ë Œë“œ ë¶„ì„")
        
        # ê¸°ìˆ /ì œì¡° ê°ì§€
        if any(word in korean_text for word in ["ê¸°ìˆ ", "ì œì¡°", "ê³µì •", "ê°€ê³µ", "ì²˜ë¦¬", "treatment", "process"]):
            content_types.append("ê¸°ìˆ ì  ì œì¡° ê³¼ì • ë° ê³µì • ì •ë³´")
        
        # ê°ì •/ì¸ì¦ ê°ì§€
        if any(word in text_lower for word in ["gia", "ê°ì •", "ì¸ì¦", "certificate", "grading", "appraisal"]):
            content_types.append("ë³´ì„ ê°ì • ë° ì¸ì¦ ê´€ë ¨ ì „ë¬¸ ì •ë³´")
        
        # íˆ¬ì/ê°€ì¹˜ ê°ì§€
        if any(word in korean_text for word in ["íˆ¬ì", "ê°€ì¹˜", "ê°€ê²©", "price", "value", "investment"]):
            content_types.append("íˆ¬ì ê°€ì¹˜ ë° ê°€ê²© ì •ë³´")
        
        if content_types:
            summary_parts.append(f"ì£¼ìš” ë¶„ì„ ì˜ì—­: {', '.join(content_types)}")
        
        # ğŸ“ ì½˜í…ì¸  ê·œëª¨ í‰ê°€
        content_length = len(text)
        if content_length > 10000:
            summary_parts.append("ëŒ€ìš©ëŸ‰ì˜ ìƒì„¸í•œ ì „ë¬¸ ìë£Œë¡œ ì‹¬ì¸µì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        elif content_length > 3000:
            summary_parts.append("ì¶©ë¶„í•œ ë¶„ëŸ‰ì˜ ì‹¤ë¬´ ì¤‘ì‹¬ ì •ë³´ê°€ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.")
        elif content_length > 500:
            summary_parts.append("í•µì‹¬ì ì¸ ì£¼ì–¼ë¦¬ ì—…ê³„ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ğŸ¯ ì „ë¬¸ì„± í‰ê°€
        professional_terms = ["GIA", "ì‚¬íŒŒì´ì–´", "ë‹¤ì´ì•„ëª¬ë“œ", "ì—ë©”ë„ë“œ", "ë£¨ë¹„", "ìºëŸ¿", "ê°ì •ì„œ"]
        found_pro_terms = [term for term in professional_terms if term in text]
        
        if len(found_pro_terms) >= 3:
            summary_parts.append("ë†’ì€ ìˆ˜ì¤€ì˜ ì „ë¬¸ ì§€ì‹ê³¼ ì—…ê³„ í‘œì¤€ ìš©ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ìµœì¢… ìš”ì•½ ìƒì„±
        if summary_parts:
            return " ".join(summary_parts)
        else:
            return "ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ë ¨ ê¸°ë³¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ì„¤ì •"""
    dirs = ["input_files", "output_results"]
    for dir_name in dirs:
        Path(dir_name).mkdir(exist_ok=True)
    return dirs

def find_input_files() -> List[str]:
    """ì…ë ¥ íŒŒì¼ ì°¾ê¸°"""
    input_dir = Path("input_files")
    
    supported_extensions = [
        "*.mp3", "*.wav", "*.m4a", "*.aac",
        "*.mp4", "*.mov", "*.avi", "*.mkv",
        "*.jpg", "*.jpeg", "*.png", "*.gif", "*.bmp",
        "*.pdf", "*.docx", "*.txt"
    ]
    
    all_files = []
    for ext in supported_extensions:
        files = list(input_dir.glob(ext))
        all_files.extend([str(f) for f in files])
    
    return all_files

def find_youtube_urls() -> List[str]:
    """ìœ íŠœë¸Œ URL ì°¾ê¸°"""
    url_file = Path("youtube_urls.txt")
    
    if not url_file.exists():
        # ë¹ˆ íŒŒì¼ ìƒì„±
        with open(url_file, 'w', encoding='utf-8') as f:
            f.write("# ë¶„ì„í•  ìœ íŠœë¸Œ URLë“¤ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” (í•œ ì¤„ì— í•˜ë‚˜ì”©)\n")
            f.write("# ì˜ˆì‹œ:\n")
            f.write("# https://www.youtube.com/watch?v=example1\n")
            f.write("# https://youtu.be/example2\n")
        return []
    
    urls = []
    with open(url_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):
                if 'youtube.com' in line or 'youtu.be' in line:
                    urls.append(line)
    
    return urls

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì†”ë¡œëª¬ë“œ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì—”ì§„ v3.0 (í•œêµ­ì–´ ìš”ì•½ ë²„ì „)")
    print("ğŸ“º ìœ íŠœë¸Œ ì§€ì› í¬í•¨ - ë‹¤êµ­ì–´ ì…ë ¥ â†’ í•œêµ­ì–´ ìš”ì•½ ì¶œë ¥")
    print("=" * 80)
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    setup_directories()
    
    # ì…ë ¥ ì†ŒìŠ¤ í™•ì¸
    input_files = find_input_files()
    youtube_urls = find_youtube_urls()
    
    total_sources = len(input_files) + len(youtube_urls)
    
    if total_sources == 0:
        print("ğŸ“ ë¶„ì„í•  ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   1. input_files/ í´ë”ì— íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”")
        print("   2. youtube_urls.txtì— ìœ íŠœë¸Œ URLë“¤ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
        print("ğŸ”§ ì§€ì› í˜•ì‹: MP3, WAV, M4A, MP4, MOV, JPG, PNG, PDF, DOCX, TXT, YouTube")
        print("ğŸ‡°ğŸ‡· ìµœì¢… ìš”ì•½: í•œêµ­ì–´ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤")
        return
    
    print(f"ğŸ“‹ ë¶„ì„í•  ì†ŒìŠ¤ ì´ {total_sources}ê°œ ë°œê²¬:")
    
    # íŒŒì¼ ëª©ë¡ ì¶œë ¥
    if input_files:
        print(f"\nğŸ“ ë¡œì»¬ íŒŒì¼ {len(input_files)}ê°œ:")
        for i, file_path in enumerate(input_files, 1):
            file_size = os.path.getsize(file_path) / (1024*1024)
            print(f"   {i}. {Path(file_path).name} ({file_size:.2f}MB)")
    
    # ìœ íŠœë¸Œ URL ëª©ë¡ ì¶œë ¥
    if youtube_urls:
        print(f"\nğŸ“º ìœ íŠœë¸Œ ì˜ìƒ {len(youtube_urls)}ê°œ:")
        for i, url in enumerate(youtube_urls, 1):
            print(f"   {i}. {url}")
    
    # yt-dlp ì„¤ì¹˜ í™•ì¸
    print(f"\nğŸ”§ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...")
    try:
        import subprocess
        result = subprocess.run(["yt-dlp", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… yt-dlp ì„¤ì¹˜ í™•ì¸: {result.stdout.strip()}")
        else:
            print("âŒ yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ë°©ë²•: pip install yt-dlp")
            if youtube_urls:
                print("âš ï¸ ìœ íŠœë¸Œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” yt-dlpê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return
    except FileNotFoundError:
        print("âŒ yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ì„¤ì¹˜ ë°©ë²•: pip install yt-dlp")
        if youtube_urls:
            print("âš ï¸ ìœ íŠœë¸Œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” yt-dlpê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
    
    # ë¶„ì„ ì‹œì‘ í™•ì¸
    response = input(f"\nğŸ”„ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ìµœì¢… ìš”ì•½: í•œêµ­ì–´) (y/n): ")
    if response.lower() not in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
        print("â¸ï¸ ë¶„ì„ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™”
    engine = CompleteMultimodalEngine()
    
    print(f"\nğŸ” {total_sources}ê°œ ì†ŒìŠ¤ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹œì‘...")
    start_time = time.time()
    
    # ëª¨ë“  ì†ŒìŠ¤ ë¶„ì„
    analysis_results = []
    
    # ë¡œì»¬ íŒŒì¼ ë¶„ì„
    if input_files:
        print(f"\nğŸ“ ë¡œì»¬ íŒŒì¼ {len(input_files)}ê°œ ë¶„ì„ ì¤‘...")
        for i, file_path in enumerate(input_files, 1):
            print(f"\nğŸ“Š íŒŒì¼ ì§„í–‰ë¥ : {i}/{len(input_files)}")
            result = await engine.analyze_single_file(file_path)
            analysis_results.append(result)
            
            if result.success:
                print(f"âœ… ì„±ê³µ: {result.file_name}")
                print(f"   ğŸ¯ ê´€ë ¨ì„±: {result.jewelry_relevance:.2f}")
                print(f"   ğŸ”‘ í‚¤ì›Œë“œ: {', '.join(result.jewelry_keywords[:5])}")
            else:
                print(f"âŒ ì‹¤íŒ¨: {result.file_name} - {result.error_message}")
    
    # ìœ íŠœë¸Œ URL ë¶„ì„
    if youtube_urls:
        print(f"\nğŸ“º ìœ íŠœë¸Œ ì˜ìƒ {len(youtube_urls)}ê°œ ë¶„ì„ ì¤‘...")
        for i, url in enumerate(youtube_urls, 1):
            print(f"\nğŸ“Š ìœ íŠœë¸Œ ì§„í–‰ë¥ : {i}/{len(youtube_urls)}")
            result = await engine.analyze_youtube_url(url)
            analysis_results.append(result)
            
            if result.success:
                print(f"âœ… ì„±ê³µ: {result.file_name}")
                print(f"   ğŸ¯ ê´€ë ¨ì„±: {result.jewelry_relevance:.2f}")
                print(f"   ğŸ”‘ í‚¤ì›Œë“œ: {', '.join(result.jewelry_keywords[:5])}")
                print(f"   â±ï¸ ì²˜ë¦¬ì‹œê°„: {result.processing_time:.1f}ì´ˆ")
            else:
                print(f"âŒ ì‹¤íŒ¨: {result.file_name} - {result.error_message}")
    
    # ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ (í•œêµ­ì–´ ìš”ì•½)
    print(f"\nğŸ”— ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì¤‘... (í•œêµ­ì–´ ìš”ì•½ ìƒì„±)")
    integrated_result = await engine.integrate_complete_analysis(analysis_results)
    
    total_time = time.time() - start_time
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    engine.youtube_processor.cleanup_temp_files()
    
    # ê²°ê³¼ ì €ì¥
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_dir = Path("output_results")
    
    # ìƒì„¸ ê²°ê³¼ JSON ì €ì¥
    detailed_results = {
        "timestamp": timestamp,
        "analysis_info": {
            "engine_version": "v3.0_complete_multimodal_korean",
            "youtube_support": True,
            "korean_summary": True,
            "total_sources": total_sources,
            "local_files": len(input_files),
            "youtube_videos": len(youtube_urls)
        },
        "individual_analysis": [r.to_dict() for r in analysis_results],
        "integrated_analysis": integrated_result,
        "performance": {
            "total_processing_time": total_time,
            "average_time_per_source": total_time / total_sources if total_sources > 0 else 0,
            "sources_per_minute": (total_sources / total_time) * 60 if total_time > 0 else 0
        }
    }
    
    json_file = output_dir / f"complete_multimodal_analysis_korean_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    
    # í•œêµ­ì–´ ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥
    report_file = output_dir / f"complete_analysis_report_korean_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ’ ì†”ë¡œëª¬ë“œ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸ v3.0 (í•œêµ­ì–´ ìš”ì•½ ë²„ì „)\n")
        f.write("ğŸ“º ìœ íŠœë¸Œ ì§€ì› í¬í•¨ - ë‹¤êµ­ì–´ ì…ë ¥ â†’ í•œêµ­ì–´ ìš”ì•½ ì¶œë ¥\n")
        f.write("=" * 80 + "\n\n")
        
        f.write(f"ğŸ“Š ì „ì²´ í†µê³„:\n")
        f.write(f"   ì´ ì†ŒìŠ¤ ìˆ˜: {integrated_result['total_sources']}\n")
        f.write(f"   - ë¡œì»¬ íŒŒì¼: {len(input_files)}ê°œ\n")
        f.write(f"   - ìœ íŠœë¸Œ ì˜ìƒ: {integrated_result['youtube_count']}ê°œ\n")
        f.write(f"   ì„±ê³µ ì†ŒìŠ¤: {integrated_result['successful_sources']}\n")
        f.write(f"   ì‹¤íŒ¨ ì†ŒìŠ¤: {integrated_result['failed_sources']}\n")
        f.write(f"   ì „ì²´ ì²˜ë¦¬ì‹œê°„: {integrated_result['total_processing_time']:.2f}ì´ˆ\n")
        f.write(f"   í‰ê·  ì‹ ë¢°ë„: {integrated_result['average_confidence']:.2f}\n")
        f.write(f"   í‰ê·  ì£¼ì–¼ë¦¬ ê´€ë ¨ì„±: {integrated_result['average_jewelry_relevance']:.2f}\n\n")
        
        f.write(f"ğŸ”‘ ë°œê²¬ëœ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ({len(integrated_result['unique_keywords'])}ê°œ):\n")
        f.write(f"   {', '.join(integrated_result['unique_keywords'])}\n\n")
        
        f.write(f"ğŸ“‹ ì†ŒìŠ¤ë³„ ë¶„ì„:\n")
        breakdown = integrated_result['source_breakdown']
        f.write(f"   ìŒì„±: {breakdown['audio']}ê°œ\n")
        f.write(f"   ì˜ìƒ: {breakdown['video']}ê°œ\n")
        f.write(f"   ì´ë¯¸ì§€: {breakdown['image']}ê°œ\n")
        f.write(f"   ë¬¸ì„œ: {breakdown['document']}ê°œ\n")
        f.write(f"   ìœ íŠœë¸Œ: {breakdown['youtube']}ê°œ\n\n")
        
        f.write(f"ğŸ¯ í•œêµ­ì–´ í†µí•© ë¶„ì„ ìš”ì•½:\n")
        f.write(f"   {integrated_result['summary']}\n\n")
        
        if integrated_result['combined_text']:
            f.write(f"ğŸ“ ì „ì²´ ë‚´ìš© (ì²˜ìŒ 1000ì):\n")
            f.write(f"   {integrated_result['combined_text'][:1000]}...\n")
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n" + "=" * 80)
    print(f"ğŸ‰ ì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ì™„ë£Œ! (í•œêµ­ì–´ ìš”ì•½)")
    print(f"   ğŸ“Š ì´ {integrated_result['total_sources']}ê°œ ì†ŒìŠ¤ ì²˜ë¦¬")
    print(f"      - ë¡œì»¬ íŒŒì¼: {len(input_files)}ê°œ")
    print(f"      - ìœ íŠœë¸Œ ì˜ìƒ: {integrated_result['youtube_count']}ê°œ")
    print(f"   âœ… ì„±ê³µ: {integrated_result['successful_sources']}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {integrated_result['failed_sources']}ê°œ")
    print(f"   â±ï¸ ì „ì²´ ì‹œê°„: {integrated_result['total_processing_time']:.2f}ì´ˆ")
    print(f"   ğŸ“ˆ í‰ê·  ê´€ë ¨ì„±: {integrated_result['average_jewelry_relevance']:.2f}")
    print(f"   ğŸ”‘ í‚¤ì›Œë“œ ìˆ˜: {len(integrated_result['unique_keywords'])}ê°œ")
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥:")
    print(f"   ğŸ“„ ìƒì„¸ ë°ì´í„°: {json_file}")
    print(f"   ğŸ“‹ í•œêµ­ì–´ ë¦¬í¬íŠ¸: {report_file}")
    print(f"\nğŸ‡°ğŸ‡· í•œêµ­ì–´ í†µí•© ìš”ì•½:")
    print(f"   {integrated_result['summary']}")
    
    print(f"\nğŸš€ ì´ì œ ë‹¤êµ­ì–´ ì…ë ¥ì„ ì§€ì›í•˜ë©´ì„œë„")
    print(f"   ìµœì¢… ìš”ì•½ì€ í•œêµ­ì–´ë¡œ ì¶œë ¥í•˜ëŠ” ì™„ë²½í•œ ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    asyncio.run(main())
