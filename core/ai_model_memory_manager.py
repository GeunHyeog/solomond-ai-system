#!/usr/bin/env python3
"""
AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ v2.6
Whisper, EasyOCR, Transformers ë“± AI ëª¨ë¸ì˜ ì§€ëŠ¥ì  ë©”ëª¨ë¦¬ ê´€ë¦¬
"""

import gc
import time
import threading
import psutil
import torch
from typing import Dict, List, Any, Optional, Union, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
import logging
import weakref
from enum import Enum
import json

class ModelType(Enum):
    """AI ëª¨ë¸ íƒ€ì…"""
    WHISPER = "whisper"
    EASYOCR = "easyocr"
    TRANSFORMERS = "transformers"
    PYTORCH = "pytorch"
    TENSORFLOW = "tensorflow"
    CUSTOM = "custom"

class ModelPriority(Enum):
    """ëª¨ë¸ ìš°ì„ ìˆœìœ„"""
    CRITICAL = 1  # í•­ìƒ ë©”ëª¨ë¦¬ì— ìœ ì§€
    HIGH = 2      # ê°€ëŠ¥í•œ í•œ ìœ ì§€
    MEDIUM = 3    # í•„ìš”ì‹œ ì–¸ë¡œë“œ
    LOW = 4       # ì ê·¹ì ìœ¼ë¡œ ì–¸ë¡œë“œ

@dataclass
class ModelInfo:
    """AI ëª¨ë¸ ì •ë³´"""
    model_id: str
    model_type: ModelType
    priority: ModelPriority
    memory_usage_mb: float = 0.0
    last_accessed: datetime = field(default_factory=datetime.now)
    load_count: int = 0
    reference: Optional[Any] = None
    device: str = "cpu"
    model_size_mb: float = 0.0
    initialization_time_seconds: float = 0.0
    is_loaded: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MemoryProfile:
    """ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼"""
    total_memory_mb: float
    available_memory_mb: float
    ai_models_memory_mb: float
    system_memory_mb: float
    gpu_memory_mb: float = 0.0
    gpu_available_mb: float = 0.0
    memory_pressure_level: str = "low"  # low, medium, high, critical

class AIModelMemoryManager:
    """AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_memory_mb: float = 2048.0, enable_gpu_management: bool = True):
        self.max_memory_mb = max_memory_mb
        self.enable_gpu_management = enable_gpu_management
        self.lock = threading.RLock()
        self.logger = self._setup_logging()
        
        # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
        self.models: Dict[str, ModelInfo] = {}
        self.weak_references: Dict[str, weakref.ref] = {}
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        self.memory_monitor_thread = None
        self.monitoring_enabled = True
        self.monitoring_interval = 5.0  # 5ì´ˆ ê°„ê²©
        
        # í†µê³„
        self.stats = {
            'models_loaded': 0,
            'models_unloaded': 0,
            'memory_optimizations': 0,
            'total_memory_saved_mb': 0.0,
            'last_optimization': None
        }
        
        # ì„¤ì •
        self.auto_unload_timeout = 300.0  # 5ë¶„ í›„ ìë™ ì–¸ë¡œë“œ
        self.memory_warning_threshold = 0.8  # 80% ì‚¬ìš© ì‹œ ê²½ê³ 
        self.memory_critical_threshold = 0.9  # 90% ì‚¬ìš© ì‹œ ìœ„í—˜
        
        # GPU ê´€ë¦¬
        self.gpu_available = False
        if enable_gpu_management:
            self._initialize_gpu_management()
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self._start_memory_monitoring()
        
        self.logger.info("ğŸ§  AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(f'{__name__}.{self.__class__.__name__}')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | %(name)s | %(levelname)s | %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _initialize_gpu_management(self) -> None:
        """GPU ê´€ë¦¬ ì´ˆê¸°í™”"""
        try:
            if torch.cuda.is_available():
                self.gpu_available = True
                gpu_count = torch.cuda.device_count()
                self.logger.info(f"ğŸ® GPU ê´€ë¦¬ í™œì„±í™”: {gpu_count}ê°œ GPU ê°ì§€")
                
                # GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥
                for i in range(gpu_count):
                    props = torch.cuda.get_device_properties(i)
                    total_memory = props.total_memory / (1024**3)  # GB
                    self.logger.info(f"  GPU {i}: {props.name} ({total_memory:.1f}GB)")
            else:
                self.logger.info("ğŸ’» CPU ì „ìš© ëª¨ë“œë¡œ ì‹¤í–‰")
        except Exception as e:
            self.logger.warning(f"âš ï¸ GPU ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def register_model(self, 
                      model_id: str,
                      model_type: ModelType,
                      model_obj: Any,
                      priority: ModelPriority = ModelPriority.MEDIUM,
                      device: str = "cpu",
                      metadata: Optional[Dict] = None) -> bool:
        """AI ëª¨ë¸ ë“±ë¡"""
        with self.lock:
            try:
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
                memory_usage = self._calculate_model_memory(model_obj)
                model_size = self._estimate_model_size(model_obj, model_type)
                
                # ëª¨ë¸ ì •ë³´ ìƒì„±
                model_info = ModelInfo(
                    model_id=model_id,
                    model_type=model_type,
                    priority=priority,
                    memory_usage_mb=memory_usage,
                    reference=model_obj,
                    device=device,
                    model_size_mb=model_size,
                    is_loaded=True,
                    metadata=metadata or {}
                )
                
                # ì•½í•œ ì°¸ì¡° ìƒì„±
                def cleanup_callback(ref):
                    self._handle_model_cleanup(model_id)
                
                weak_ref = weakref.ref(model_obj, cleanup_callback)
                
                # ë“±ë¡
                self.models[model_id] = model_info
                self.weak_references[model_id] = weak_ref
                
                self.stats['models_loaded'] += 1
                
                self.logger.info(f"âœ… ëª¨ë¸ ë“±ë¡: {model_id} ({memory_usage:.1f}MB, {priority.name})")
                
                # ë©”ëª¨ë¦¬ ì••ë°• ì²´í¬
                self._check_memory_pressure()
                
                return True
                
            except Exception as e:
                self.logger.error(f"âŒ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨ {model_id}: {e}")
                return False
    
    def unregister_model(self, model_id: str) -> bool:
        """AI ëª¨ë¸ ë“±ë¡ í•´ì œ"""
        with self.lock:
            if model_id in self.models:
                model_info = self.models[model_id]
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if model_info.reference:
                    del model_info.reference
                
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                if model_info.device.startswith('cuda'):
                    self._cleanup_gpu_memory()
                
                # ë“±ë¡ í•´ì œ
                del self.models[model_id]
                if model_id in self.weak_references:
                    del self.weak_references[model_id]
                
                self.stats['models_unloaded'] += 1
                self.stats['total_memory_saved_mb'] += model_info.memory_usage_mb
                
                self.logger.info(f"ğŸ—‘ï¸ ëª¨ë¸ ë“±ë¡ í•´ì œ: {model_id} ({model_info.memory_usage_mb:.1f}MB í•´ì œ)")
                
                return True
            return False
    
    def access_model(self, model_id: str) -> Optional[Any]:
        """ëª¨ë¸ ì ‘ê·¼ (ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸)"""
        with self.lock:
            if model_id in self.models:
                model_info = self.models[model_id]
                model_info.last_accessed = datetime.now()
                model_info.load_count += 1
                
                # ì•½í•œ ì°¸ì¡°ì—ì„œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
                if model_id in self.weak_references:
                    weak_ref = self.weak_references[model_id]
                    model_obj = weak_ref()
                    
                    if model_obj is not None:
                        self.logger.debug(f"ğŸ¯ ëª¨ë¸ ì ‘ê·¼: {model_id}")
                        return model_obj
                    else:
                        # ëª¨ë¸ì´ GCë˜ì—ˆìŒ
                        self._handle_model_cleanup(model_id)
                
            return None
    
    def optimize_memory(self, target_memory_mb: Optional[float] = None) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰"""
        with self.lock:
            optimization_start = time.time()
            initial_memory = self.get_memory_profile()
            
            if target_memory_mb is None:
                target_memory_mb = self.max_memory_mb * 0.8  # 80% ëª©í‘œ
            
            # ìµœì í™” ì „ëµ ê²°ì •
            current_ai_memory = initial_memory.ai_models_memory_mb
            memory_to_free = max(0, current_ai_memory - target_memory_mb)
            
            if memory_to_free <= 0:
                return {
                    'status': 'no_action_needed',
                    'initial_memory_mb': current_ai_memory,
                    'target_memory_mb': target_memory_mb,
                    'optimization_time_ms': 0
                }
            
            # ì–¸ë¡œë“œ í›„ë³´ ëª¨ë¸ ì„ ì •
            candidates = self._select_unload_candidates(memory_to_free)
            
            freed_memory = 0.0
            unloaded_models = []
            
            # ëª¨ë¸ ìˆœì°¨ì  ì–¸ë¡œë“œ
            for model_id, model_info in candidates:
                if freed_memory >= memory_to_free:
                    break
                
                success = self._unload_model(model_id)
                if success:
                    freed_memory += model_info.memory_usage_mb
                    unloaded_models.append(model_id)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.gpu_available:
                self._cleanup_gpu_memory()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
            final_memory = self.get_memory_profile()
            optimization_time = (time.time() - optimization_start) * 1000
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['memory_optimizations'] += 1
            self.stats['last_optimization'] = datetime.now().isoformat()
            
            result = {
                'status': 'success',
                'initial_memory_mb': current_ai_memory,
                'final_memory_mb': final_memory.ai_models_memory_mb,
                'target_memory_mb': target_memory_mb,
                'freed_memory_mb': freed_memory,
                'unloaded_models': unloaded_models,
                'optimization_time_ms': optimization_time
            }
            
            self.logger.info(f"ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {freed_memory:.1f}MB í•´ì œ, {len(unloaded_models)}ê°œ ëª¨ë¸ ì–¸ë¡œë“œ")
            
            return result
    
    def _select_unload_candidates(self, target_memory_mb: float) -> List[tuple]:
        """ì–¸ë¡œë“œ í›„ë³´ ëª¨ë¸ ì„ ì •"""
        candidates = []
        
        for model_id, model_info in self.models.items():
            # ì¤‘ìš”ë„ê°€ CRITICALì¸ ëª¨ë¸ì€ ì œì™¸
            if model_info.priority == ModelPriority.CRITICAL:
                continue
            
            # ì–¸ë¡œë“œ ì ìˆ˜ ê³„ì‚°
            time_since_access = (datetime.now() - model_info.last_accessed).total_seconds()
            
            # ì ìˆ˜ = ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ + ì‹œê°„ ê°€ì¤‘ì¹˜ - ì‚¬ìš© ë¹ˆë„ ê°€ì¤‘ì¹˜
            priority_weight = model_info.priority.value * 100
            time_weight = min(time_since_access / 60, 300)  # ìµœëŒ€ 5ë¶„
            usage_weight = -model_info.load_count * 10
            
            score = priority_weight + time_weight + usage_weight
            
            candidates.append((model_id, model_info, score))
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ = ì–¸ë¡œë“œ ìš°ì„ )
        candidates.sort(key=lambda x: x[2], reverse=True)
        
        # ëª©í‘œ ë©”ëª¨ë¦¬ê¹Œì§€ ì„ íƒ
        selected = []
        cumulative_memory = 0.0
        
        for model_id, model_info, score in candidates:
            if cumulative_memory >= target_memory_mb:
                break
            
            selected.append((model_id, model_info))
            cumulative_memory += model_info.memory_usage_mb
        
        return selected
    
    def _unload_model(self, model_id: str) -> bool:
        """íŠ¹ì • ëª¨ë¸ ì–¸ë¡œë“œ"""
        try:
            if model_id in self.models:
                model_info = self.models[model_id]
                
                # ì°¸ì¡° ì œê±°
                if model_info.reference:
                    del model_info.reference
                    model_info.reference = None
                
                model_info.is_loaded = False
                
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                if model_info.device.startswith('cuda'):
                    torch.cuda.empty_cache()
                
                self.logger.debug(f"ğŸ“¤ ëª¨ë¸ ì–¸ë¡œë“œ: {model_id}")
                return True
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì–¸ë¡œë“œ ì‹¤íŒ¨ {model_id}: {e}")
        
        return False
    
    def _calculate_model_memory(self, model_obj: Any) -> float:
        """ëª¨ë¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°"""
        try:
            import sys
            
            # PyTorch ëª¨ë¸
            if hasattr(model_obj, 'parameters'):
                total_params = sum(p.numel() for p in model_obj.parameters())
                # ëŒ€ëµì ì¸ ë©”ëª¨ë¦¬ ê³„ì‚° (íŒŒë¼ë¯¸í„° ìˆ˜ Ã— 4ë°”ì´íŠ¸)
                memory_bytes = total_params * 4
                return memory_bytes / (1024 * 1024)  # MB
            
            # ê¸°ë³¸ ê°ì²´ í¬ê¸°
            return sys.getsizeof(model_obj) / (1024 * 1024)
            
        except Exception:
            return 0.0
    
    def _estimate_model_size(self, model_obj: Any, model_type: ModelType) -> float:
        """ëª¨ë¸ í¬ê¸° ì¶”ì •"""
        try:
            # ëª¨ë¸ íƒ€ì…ë³„ ì¶”ì •
            if model_type == ModelType.WHISPER:
                # Whisper ëª¨ë¸ í¬ê¸° ì¶”ì •
                if hasattr(model_obj, 'dims'):
                    if model_obj.dims.n_audio_state >= 1280:  # large
                        return 1550.0  # MB
                    elif model_obj.dims.n_audio_state >= 1024:  # medium
                        return 769.0
                    elif model_obj.dims.n_audio_state >= 768:  # small
                        return 244.0
                    else:  # base/tiny
                        return 142.0
                return 500.0  # ê¸°ë³¸ê°’
            
            elif model_type == ModelType.EASYOCR:
                return 100.0  # EasyOCR ê¸°ë³¸ í¬ê¸°
            
            elif model_type == ModelType.TRANSFORMERS:
                # Transformers ëª¨ë¸ í¬ê¸° ì¶”ì •
                if hasattr(model_obj, 'config'):
                    config = model_obj.config
                    if hasattr(config, 'hidden_size'):
                        # ëŒ€ëµì ì¸ ì¶”ì • ê³µì‹
                        hidden_size = config.hidden_size
                        num_layers = getattr(config, 'num_hidden_layers', 12)
                        vocab_size = getattr(config, 'vocab_size', 50000)
                        
                        # íŒŒë¼ë¯¸í„° ìˆ˜ ì¶”ì •
                        params = hidden_size * hidden_size * num_layers * 8 + vocab_size * hidden_size
                        return (params * 4) / (1024 * 1024)  # MB
                
                return 400.0  # ê¸°ë³¸ê°’
            
            else:
                return self._calculate_model_memory(model_obj)
                
        except Exception:
            return 100.0  # ê¸°ë³¸ê°’
    
    def _cleanup_gpu_memory(self) -> None:
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if self.gpu_available:
            try:
                torch.cuda.empty_cache()
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                self.logger.debug("ğŸ® GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _handle_model_cleanup(self, model_id: str) -> None:
        """ëª¨ë¸ ì •ë¦¬ ì½œë°±"""
        with self.lock:
            if model_id in self.models:
                self.logger.debug(f"ğŸ§¹ ìë™ ëª¨ë¸ ì •ë¦¬: {model_id}")
                self.models[model_id].is_loaded = False
                self.models[model_id].reference = None
    
    def _start_memory_monitoring(self) -> None:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.memory_monitor_thread is None or not self.memory_monitor_thread.is_alive():
            self.memory_monitor_thread = threading.Thread(
                target=self._memory_monitoring_loop,
                daemon=True
            )
            self.memory_monitor_thread.start()
            self.logger.debug("ğŸ“Š ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def _memory_monitoring_loop(self) -> None:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_enabled:
            try:
                profile = self.get_memory_profile()
                
                # ë©”ëª¨ë¦¬ ì••ë°• ì²´í¬
                if profile.memory_pressure_level in ['high', 'critical']:
                    self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì••ë°• ê°ì§€: {profile.memory_pressure_level}")
                    
                    if profile.memory_pressure_level == 'critical':
                        # ê¸´ê¸‰ ìµœì í™” ì‹¤í–‰
                        self.optimize_memory(self.max_memory_mb * 0.6)
                
                # ìë™ ì–¸ë¡œë“œ ì²´í¬
                self._check_auto_unload()
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(10)  # ì˜¤ë¥˜ ì‹œ ë” ê¸´ ëŒ€ê¸°
    
    def _check_memory_pressure(self) -> None:
        """ë©”ëª¨ë¦¬ ì••ë°• ìƒíƒœ ì²´í¬"""
        profile = self.get_memory_profile()
        
        if profile.memory_pressure_level == 'critical':
            self.logger.warning("ğŸš¨ ì‹¬ê°í•œ ë©”ëª¨ë¦¬ ì••ë°•! ê¸´ê¸‰ ìµœì í™” ì‹¤í–‰")
            self.optimize_memory(self.max_memory_mb * 0.5)
        elif profile.memory_pressure_level == 'high':
            self.logger.warning("âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì••ë°• ê°ì§€")
    
    def _check_auto_unload(self) -> None:
        """ìë™ ì–¸ë¡œë“œ ì²´í¬"""
        current_time = datetime.now()
        candidates = []
        
        with self.lock:
            for model_id, model_info in self.models.items():
                if model_info.priority == ModelPriority.CRITICAL:
                    continue
                
                time_since_access = (current_time - model_info.last_accessed).total_seconds()
                
                if time_since_access > self.auto_unload_timeout:
                    candidates.append(model_id)
            
            # ìë™ ì–¸ë¡œë“œ ì‹¤í–‰
            for model_id in candidates:
                self._unload_model(model_id)
                self.logger.debug(f"â° ìë™ ì–¸ë¡œë“œ: {model_id} (ë¹„í™œì„± ì‹œê°„: {time_since_access/60:.1f}ë¶„)")
    
    def get_memory_profile(self) -> MemoryProfile:
        """í˜„ì¬ ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ ë°˜í™˜"""
        try:
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
            memory = psutil.virtual_memory()
            total_mb = memory.total / (1024**2)
            available_mb = memory.available / (1024**2)
            used_mb = memory.used / (1024**2)
            
            # AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê³„ì‚°
            ai_memory_mb = sum(
                model_info.memory_usage_mb 
                for model_info in self.models.values() 
                if model_info.is_loaded
            )
            
            # GPU ë©”ëª¨ë¦¬
            gpu_memory_mb = 0.0
            gpu_available_mb = 0.0
            
            if self.gpu_available:
                try:
                    gpu_memory_mb = torch.cuda.memory_allocated() / (1024**2)
                    gpu_available_mb = torch.cuda.memory_reserved() / (1024**2) - gpu_memory_mb
                except:
                    pass
            
            # ë©”ëª¨ë¦¬ ì••ë°• ìˆ˜ì¤€ ê³„ì‚°
            usage_ratio = used_mb / total_mb
            if usage_ratio > self.memory_critical_threshold:
                pressure_level = "critical"
            elif usage_ratio > self.memory_warning_threshold:
                pressure_level = "high"
            elif usage_ratio > 0.6:
                pressure_level = "medium"
            else:
                pressure_level = "low"
            
            return MemoryProfile(
                total_memory_mb=total_mb,
                available_memory_mb=available_mb,
                ai_models_memory_mb=ai_memory_mb,
                system_memory_mb=used_mb - ai_memory_mb,
                gpu_memory_mb=gpu_memory_mb,
                gpu_available_mb=gpu_available_mb,
                memory_pressure_level=pressure_level
            )
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return MemoryProfile(0, 0, 0, 0)
    
    def get_model_stats(self) -> Dict[str, Any]:
        """ëª¨ë¸ í†µê³„ ë°˜í™˜"""
        with self.lock:
            loaded_models = sum(1 for m in self.models.values() if m.is_loaded)
            total_memory = sum(m.memory_usage_mb for m in self.models.values() if m.is_loaded)
            
            model_types = {}
            for model_info in self.models.values():
                model_type = model_info.model_type.value
                if model_type not in model_types:
                    model_types[model_type] = 0
                model_types[model_type] += 1
            
            return {
                'total_models': len(self.models),
                'loaded_models': loaded_models,
                'total_memory_mb': total_memory,
                'model_types': model_types,
                'stats': self.stats.copy(),
                'gpu_available': self.gpu_available
            }
    
    def get_model_details(self) -> List[Dict[str, Any]]:
        """ëª¨ë¸ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        with self.lock:
            details = []
            
            for model_id, model_info in self.models.items():
                detail = {
                    'model_id': model_id,
                    'model_type': model_info.model_type.value,
                    'priority': model_info.priority.name,
                    'memory_usage_mb': model_info.memory_usage_mb,
                    'model_size_mb': model_info.model_size_mb,
                    'is_loaded': model_info.is_loaded,
                    'device': model_info.device,
                    'load_count': model_info.load_count,
                    'last_accessed': model_info.last_accessed.isoformat(),
                    'metadata': model_info.metadata
                }
                details.append(detail)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
            details.sort(key=lambda x: x['memory_usage_mb'], reverse=True)
            
            return details
    
    def set_auto_unload_timeout(self, timeout_seconds: float) -> None:
        """ìë™ ì–¸ë¡œë“œ íƒ€ì„ì•„ì›ƒ ì„¤ì •"""
        self.auto_unload_timeout = timeout_seconds
        self.logger.info(f"â° ìë™ ì–¸ë¡œë“œ íƒ€ì„ì•„ì›ƒ: {timeout_seconds/60:.1f}ë¶„")
    
    def set_memory_thresholds(self, warning: float, critical: float) -> None:
        """ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì„¤ì •"""
        self.memory_warning_threshold = warning
        self.memory_critical_threshold = critical
        self.logger.info(f"ğŸ¯ ë©”ëª¨ë¦¬ ì„ê³„ê°’: ê²½ê³  {warning*100:.0f}%, ìœ„í—˜ {critical*100:.0f}%")
    
    def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.monitoring_enabled = False
        
        if self.memory_monitor_thread and self.memory_monitor_thread.is_alive():
            self.memory_monitor_thread.join(timeout=2.0)
        
        with self.lock:
            # ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ
            model_ids = list(self.models.keys())
            for model_id in model_ids:
                self.unregister_model(model_id)
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if self.gpu_available:
            self._cleanup_gpu_memory()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        
        self.logger.info("ğŸ§¹ AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì
_global_ai_memory_manager = None
_global_manager_lock = threading.Lock()

def get_global_ai_memory_manager(max_memory_mb: float = 2048.0, enable_gpu: bool = True) -> AIModelMemoryManager:
    """ì „ì—­ AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ê°€ì ¸ì˜¤ê¸°"""
    global _global_ai_memory_manager
    
    with _global_manager_lock:
        if _global_ai_memory_manager is None:
            _global_ai_memory_manager = AIModelMemoryManager(max_memory_mb, enable_gpu)
        return _global_ai_memory_manager

# í¸ì˜ í•¨ìˆ˜ë“¤
def register_ai_model(model_id: str, model_type: str, model_obj: Any, 
                     priority: str = "medium", device: str = "cpu") -> bool:
    """AI ëª¨ë¸ ë“±ë¡ (í¸ì˜ í•¨ìˆ˜)"""
    manager = get_global_ai_memory_manager()
    
    model_type_enum = ModelType(model_type.lower())
    priority_enum = ModelPriority[priority.upper()]
    
    return manager.register_model(model_id, model_type_enum, model_obj, priority_enum, device)

def access_ai_model(model_id: str) -> Optional[Any]:
    """AI ëª¨ë¸ ì ‘ê·¼ (í¸ì˜ í•¨ìˆ˜)"""
    manager = get_global_ai_memory_manager()
    return manager.access_model(model_id)

def optimize_ai_memory(target_mb: Optional[float] = None) -> Dict[str, Any]:
    """AI ëª¨ë¸ ë©”ëª¨ë¦¬ ìµœì í™” (í¸ì˜ í•¨ìˆ˜)"""
    manager = get_global_ai_memory_manager()
    return manager.optimize_memory(target_mb)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸
    manager = AIModelMemoryManager(max_memory_mb=1024.0)
    
    # ê°€ìƒì˜ ëª¨ë¸ ë“±ë¡
    class DummyModel:
        def __init__(self, size_mb: float):
            self.data = bytearray(int(size_mb * 1024 * 1024))
    
    # ëª¨ë¸ë“¤ ë“±ë¡
    models = [
        ("whisper_large", ModelType.WHISPER, DummyModel(500), ModelPriority.HIGH),
        ("easyocr_en", ModelType.EASYOCR, DummyModel(100), ModelPriority.MEDIUM),
        ("bert_base", ModelType.TRANSFORMERS, DummyModel(300), ModelPriority.LOW),
    ]
    
    for model_id, model_type, model_obj, priority in models:
        success = manager.register_model(model_id, model_type, model_obj, priority)
        print(f"ëª¨ë¸ ë“±ë¡ {model_id}: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
    
    # ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ í™•ì¸
    profile = manager.get_memory_profile()
    print(f"\në©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼:")
    print(f"  AI ëª¨ë¸ ë©”ëª¨ë¦¬: {profile.ai_models_memory_mb:.1f}MB")
    print(f"  ë©”ëª¨ë¦¬ ì••ë°• ìˆ˜ì¤€: {profile.memory_pressure_level}")
    
    # ëª¨ë¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    model = manager.access_model("whisper_large")
    if model:
        print(f"ëª¨ë¸ ì ‘ê·¼ ì„±ê³µ: whisper_large")
    
    # ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸
    result = manager.optimize_memory(600.0)
    print(f"\në©”ëª¨ë¦¬ ìµœì í™” ê²°ê³¼:")
    print(f"  í•´ì œëœ ë©”ëª¨ë¦¬: {result.get('freed_memory_mb', 0):.1f}MB")
    print(f"  ì–¸ë¡œë“œëœ ëª¨ë¸: {result.get('unloaded_models', [])}")
    
    # í†µê³„ í™•ì¸
    stats = manager.get_model_stats()
    print(f"\nëª¨ë¸ í†µê³„:")
    print(f"  ì´ ëª¨ë¸: {stats['total_models']}ê°œ")
    print(f"  ë¡œë“œëœ ëª¨ë¸: {stats['loaded_models']}ê°œ")
    print(f"  ì´ ë©”ëª¨ë¦¬: {stats['total_memory_mb']:.1f}MB")
    
    # ì •ë¦¬
    manager.cleanup()
    print("\nâœ… AI ëª¨ë¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")