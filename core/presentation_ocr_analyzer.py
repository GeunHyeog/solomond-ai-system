"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - PPT í™”ë©´ íŠ¹í™” OCR ë¶„ì„ ì—”ì§„
í˜„ì¥ì—ì„œ ì´¬ì˜í•œ PPT í™”ë©´ì˜ OCR ì •í™•ë„ ë¶„ì„ ë° ìµœì í™” ëª¨ë“ˆ
"""

import cv2
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
import tempfile
import os
from pathlib import Path
import json
from datetime import datetime
import re

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageDraw
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False

try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False

# ì»´í“¨í„° ë¹„ì „
try:
    import skimage
    from skimage import feature, filters, morphology, measure
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

class PresentationOCRAnalyzer:
    """PPT í™”ë©´ íŠ¹í™” OCR ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # PPT íŠ¹ì„± ê°ì§€ ê¸°ì¤€ê°’ë“¤
        self.ppt_detection_thresholds = {
            "aspect_ratio_min": 1.2,  # ì¼ë°˜ì ì¸ PPT ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨
            "aspect_ratio_max": 2.0,
            "min_text_area_ratio": 0.05,  # í…ìŠ¤íŠ¸ê°€ ì°¨ì§€í•˜ëŠ” ìµœì†Œ ë©´ì  ë¹„ìœ¨
            "slide_border_threshold": 0.8,  # ìŠ¬ë¼ì´ë“œ ê²½ê³„ ê°ì§€ ì„ê³„ê°’
        }
        
        # OCR í’ˆì§ˆ í‰ê°€ ê¸°ì¤€
        self.quality_metrics = {
            "excellent": {"confidence": 0.9, "word_accuracy": 0.95, "layout_score": 0.9},
            "good": {"confidence": 0.8, "word_accuracy": 0.85, "layout_score": 0.8},
            "fair": {"confidence": 0.7, "word_accuracy": 0.75, "layout_score": 0.7},
            "poor": {"confidence": 0.6, "word_accuracy": 0.65, "layout_score": 0.6}
        }
        
        # PPT ë ˆì´ì•„ì›ƒ íŒ¨í„´
        self.layout_patterns = {
            "title_slide": {"title_area": (0.1, 0.2, 0.9, 0.4), "content_area": (0.1, 0.5, 0.9, 0.8)},
            "bullet_slide": {"title_area": (0.1, 0.1, 0.9, 0.25), "content_area": (0.1, 0.3, 0.9, 0.9)},
            "two_column": {"left_area": (0.05, 0.25, 0.48, 0.9), "right_area": (0.52, 0.25, 0.95, 0.9)},
            "image_text": {"text_area": (0.05, 0.1, 0.6, 0.9), "image_area": (0.65, 0.2, 0.95, 0.8)}
        }
        
        # EasyOCR ì´ˆê¸°í™”
        self.easyocr_reader = None
        if EASYOCR_AVAILABLE:
            try:
                self.easyocr_reader = easyocr.Reader(['en', 'ko'], gpu=False)
            except Exception as e:
                logging.warning(f"EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ìŠ¤ë ˆë“œ í’€ executor
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        logging.info("PPT í™”ë©´ íŠ¹í™” OCR ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def analyze_presentation_image(self, 
                                       image_data: bytes, 
                                       filename: str,
                                       enhance_quality: bool = True) -> Dict:
        """
        PPT í™”ë©´ ì´ë¯¸ì§€ ì¢…í•© ë¶„ì„
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            filename: íŒŒì¼ëª…
            enhance_quality: ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì—¬ë¶€
            
        Returns:
            PPT OCR ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            print(f"ğŸ“Š PPT í™”ë©´ OCR ë¶„ì„ ì‹œì‘: {filename}")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = await self._load_image_data(image_data)
            if image is None:
                return {
                    "success": False,
                    "error": "ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨",
                    "filename": filename
                }
            
            # PPT ìŠ¬ë¼ì´ë“œ ê°ì§€
            slide_detection = await self._detect_ppt_slide(image)
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ìµœì í™”
            if enhance_quality:
                optimized_image = await self._optimize_ppt_image(image, slide_detection)
            else:
                optimized_image = image
            
            # ë³‘ë ¬ë¡œ OCR ë¶„ì„ ìˆ˜í–‰
            ocr_tasks = [
                self._perform_ocr_analysis(optimized_image, "tesseract"),
                self._perform_ocr_analysis(optimized_image, "easyocr"),
                self._analyze_layout_structure(optimized_image),
                self._detect_tables_and_charts(optimized_image),
                self._analyze_text_regions(optimized_image)
            ]
            
            results = await asyncio.gather(*ocr_tasks, return_exceptions=True)
            
            # ê²°ê³¼ í†µí•©
            tesseract_result = results[0] if not isinstance(results[0], Exception) else {}
            easyocr_result = results[1] if not isinstance(results[1], Exception) else {}
            layout_result = results[2] if not isinstance(results[2], Exception) else {}
            tables_charts = results[3] if not isinstance(results[3], Exception) else {}
            text_regions = results[4] if not isinstance(results[4], Exception) else {}
            
            # ìµœì  OCR ê²°ê³¼ ì„ íƒ
            best_ocr_result = self._select_best_ocr_result(tesseract_result, easyocr_result)
            
            # OCR ì •í™•ë„ í‰ê°€
            accuracy_assessment = await self._assess_ocr_accuracy(
                best_ocr_result, layout_result, text_regions
            )
            
            # ê°œì„  ì œì•ˆ ìƒì„±
            recommendations = self._generate_ppt_recommendations(
                slide_detection, accuracy_assessment, layout_result, image
            )
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            result = {
                "success": True,
                "filename": filename,
                "image_info": {
                    "width": image.width,
                    "height": image.height,
                    "mode": image.mode,
                    "file_size_mb": round(len(image_data) / (1024 * 1024), 2)
                },
                "slide_detection": slide_detection,
                "ocr_analysis": {
                    "best_method": best_ocr_result.get("method", "unknown"),
                    "extracted_text": best_ocr_result.get("text", ""),
                    "confidence": best_ocr_result.get("confidence", 0.0),
                    "word_count": len(best_ocr_result.get("text", "").split()),
                    "tesseract_result": tesseract_result,
                    "easyocr_result": easyocr_result
                },
                "layout_analysis": layout_result,
                "tables_and_charts": tables_charts,
                "text_regions": text_regions,
                "accuracy_assessment": accuracy_assessment,
                "recommendations": recommendations,
                "analyzed_at": datetime.now().isoformat()
            }
            
            print(f"âœ… PPT OCR ë¶„ì„ ì™„ë£Œ: ì •í™•ë„ {accuracy_assessment.get('overall_score', 0)}/100")
            return result
            
        except Exception as e:
            logging.error(f"PPT í™”ë©´ OCR ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "filename": filename
            }
    
    async def _load_image_data(self, image_data: bytes) -> Optional[Image.Image]:
        """ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ"""
        try:
            if not PIL_AVAILABLE:
                raise Exception("PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            image = Image.open(io.BytesIO(image_data))
            
            # RGBë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            return image
            
        except Exception as e:
            logging.error(f"ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    async def _detect_ppt_slide(self, image: Image.Image) -> Dict:
        """PPT ìŠ¬ë¼ì´ë“œ ìë™ ê°ì§€"""
        try:
            width, height = image.size
            aspect_ratio = width / height
            
            # ê¸°ë³¸ PPT íŠ¹ì„± í™•ì¸
            is_ppt_ratio = (self.ppt_detection_thresholds["aspect_ratio_min"] <= 
                           aspect_ratio <= self.ppt_detection_thresholds["aspect_ratio_max"])
            
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(image)
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            
            # ìŠ¬ë¼ì´ë“œ ê²½ê³„ ê°ì§€
            edges = cv2.Canny(gray, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ê°€ì¥ í° ì‚¬ê°í˜• ì°¾ê¸° (ìŠ¬ë¼ì´ë“œ ê²½ê³„)
            slide_boundary = None
            max_area = 0
            
            for contour in contours:
                # ì»¨íˆ¬ì–´ë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ ê·¼ì‚¬
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # 4ê°œ ê¼­ì§“ì ì„ ê°€ì§„ ì‚¬ê°í˜•ì¸ì§€ í™•ì¸
                if len(approx) == 4:
                    area = cv2.contourArea(contour)
                    if area > max_area and area > (width * height * 0.3):  # ì „ì²´ ë©´ì ì˜ 30% ì´ìƒ
                        max_area = area
                        slide_boundary = approx
            
            # ìŠ¬ë¼ì´ë“œ ê²½ê³„ ì •í™•ë„
            boundary_score = min(1.0, max_area / (width * height)) if slide_boundary is not None else 0.0
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ë¹„ìœ¨ ì¶”ì •
            text_area_ratio = await self._estimate_text_area_ratio(gray)
            
            # PPT ê°ì§€ ì‹ ë¢°ë„ ê³„ì‚°
            ppt_confidence = 0.0
            if is_ppt_ratio:
                ppt_confidence += 0.3
            if boundary_score > 0.5:
                ppt_confidence += 0.4
            if text_area_ratio > self.ppt_detection_thresholds["min_text_area_ratio"]:
                ppt_confidence += 0.3
            
            return {
                "is_presentation": ppt_confidence > 0.6,
                "confidence": round(ppt_confidence, 3),
                "aspect_ratio": round(aspect_ratio, 2),
                "slide_boundary": slide_boundary.tolist() if slide_boundary is not None else None,
                "boundary_score": round(boundary_score, 3),
                "text_area_ratio": round(text_area_ratio, 3),
                "image_characteristics": {
                    "width": width,
                    "height": height,
                    "is_landscape": width > height,
                    "resolution_category": self._categorize_resolution(width, height)
                }
            }
            
        except Exception as e:
            logging.error(f"PPT ìŠ¬ë¼ì´ë“œ ê°ì§€ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    async def _estimate_text_area_ratio(self, gray_image: np.ndarray) -> float:
        """í…ìŠ¤íŠ¸ ì˜ì—­ ë¹„ìœ¨ ì¶”ì •"""
        try:
            # ì ì‘ì  ì„ê³„í™”ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ
            adaptive_thresh = cv2.adaptiveThreshold(
                gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
            )
            
            # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ì •ë¦¬
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            cleaned = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ë¹„ìœ¨ ê³„ì‚°
            text_pixels = np.sum(cleaned > 0)
            total_pixels = cleaned.shape[0] * cleaned.shape[1]
            
            return text_pixels / total_pixels
            
        except Exception as e:
            logging.error(f"í…ìŠ¤íŠ¸ ì˜ì—­ ë¹„ìœ¨ ì¶”ì • ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _categorize_resolution(self, width: int, height: int) -> str:
        """í•´ìƒë„ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        total_pixels = width * height
        
        if total_pixels >= 2073600:  # 1920x1080 ì´ìƒ
            return "high"
        elif total_pixels >= 921600:  # 1280x720 ì´ìƒ
            return "medium"
        else:
            return "low"
    
    async def _optimize_ppt_image(self, image: Image.Image, slide_detection: Dict) -> Image.Image:
        """PPT ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ìµœì í™”"""
        try:
            optimized = image.copy()
            
            # í•´ìƒë„ ìµœì í™” (ë„ˆë¬´ ì‘ìœ¼ë©´ ì—…ìŠ¤ì¼€ì¼ë§)
            width, height = optimized.size
            if width < 1200 or height < 800:
                scale_factor = max(1200/width, 800/height)
                new_size = (int(width * scale_factor), int(height * scale_factor))
                optimized = optimized.resize(new_size, Image.Resampling.LANCZOS)
            
            # ëŒ€ë¹„ í–¥ìƒ
            enhancer = ImageEnhance.Contrast(optimized)
            optimized = enhancer.enhance(1.3)
            
            # ì„ ëª…ë„ í–¥ìƒ
            enhancer = ImageEnhance.Sharpness(optimized)
            optimized = enhancer.enhance(1.2)
            
            # ë°ê¸° ì¡°ì • (ë„ˆë¬´ ì–´ë‘ìš°ë©´ ë°ê²Œ)
            img_array = np.array(optimized)
            mean_brightness = np.mean(img_array)
            if mean_brightness < 100:  # 0-255 ë²”ìœ„ì—ì„œ 100 ë¯¸ë§Œì´ë©´ ì–´ë‘ì›€
                enhancer = ImageEnhance.Brightness(optimized)
                optimized = enhancer.enhance(1.2)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            optimized = optimized.filter(ImageFilter.MedianFilter(size=3))
            
            # ìŠ¬ë¼ì´ë“œ ê²½ê³„ê°€ ê°ì§€ë˜ì—ˆìœ¼ë©´ í¬ë¡­
            if slide_detection.get("slide_boundary") and slide_detection.get("boundary_score", 0) > 0.7:
                try:
                    boundary = np.array(slide_detection["slide_boundary"])
                    x, y, w, h = cv2.boundingRect(boundary)
                    # ì•½ê°„ì˜ ì—¬ë°±ì„ ë‘ê³  í¬ë¡­
                    margin = 10
                    left = max(0, x - margin)
                    top = max(0, y - margin)
                    right = min(optimized.width, x + w + margin)
                    bottom = min(optimized.height, y + h + margin)
                    optimized = optimized.crop((left, top, right, bottom))
                except Exception as crop_error:
                    logging.warning(f"ìŠ¬ë¼ì´ë“œ í¬ë¡­ ì‹¤íŒ¨: {crop_error}")
            
            return optimized
            
        except Exception as e:
            logging.error(f"PPT ì´ë¯¸ì§€ ìµœì í™” ì˜¤ë¥˜: {e}")
            return image
    
    async def _perform_ocr_analysis(self, image: Image.Image, method: str) -> Dict:
        """OCR ë¶„ì„ ìˆ˜í–‰"""
        try:
            if method == "tesseract" and TESSERACT_AVAILABLE:
                return await self._ocr_with_tesseract(image)
            elif method == "easyocr" and EASYOCR_AVAILABLE and self.easyocr_reader:
                return await self._ocr_with_easyocr(image)
            else:
                return {"error": f"OCR ë°©ë²• {method}ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
                
        except Exception as e:
            logging.error(f"OCR ë¶„ì„ ì˜¤ë¥˜ ({method}): {e}")
            return {"error": str(e)}
    
    async def _ocr_with_tesseract(self, image: Image.Image) -> Dict:
        """Tesseract OCR ë¶„ì„"""
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                image.save(temp_file.name, 'PNG')
                temp_path = temp_file.name
            
            try:
                # ë¹„ë™ê¸°ë¡œ Tesseract ì‹¤í–‰
                loop = asyncio.get_event_loop()
                
                # PPTì— ìµœì í™”ëœ ì„¤ì •
                config = '--oem 3 --psm 6 -c preserve_interword_spaces=1'
                
                text = await loop.run_in_executor(
                    self.executor,
                    lambda: pytesseract.image_to_string(temp_path, config=config, lang='kor+eng')
                )
                
                # ìƒì„¸ ë°ì´í„° ì¶”ì¶œ
                data = await loop.run_in_executor(
                    self.executor,
                    lambda: pytesseract.image_to_data(
                        temp_path, 
                        config=config,
                        lang='kor+eng',
                        output_type=pytesseract.Output.DICT
                    )
                )
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
                avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                
                # ë‹¨ì–´ë³„ ê²°ê³¼ ì •ë¦¬
                words = []
                for i in range(len(data['text'])):
                    if int(data['conf'][i]) > 0 and data['text'][i].strip():
                        words.append({
                            "text": data['text'][i],
                            "confidence": int(data['conf'][i]),
                            "bbox": {
                                "left": data['left'][i],
                                "top": data['top'][i],
                                "width": data['width'][i],
                                "height": data['height'][i]
                            }
                        })
                
                return {
                    "method": "tesseract",
                    "text": text.strip(),
                    "confidence": round(avg_confidence / 100, 3),
                    "word_count": len(text.split()),
                    "words": words,
                    "raw_data": data
                }
                
            finally:
                try:
                    os.unlink(temp_path)
                except:
                    pass
                    
        except Exception as e:
            logging.error(f"Tesseract OCR ì˜¤ë¥˜: {e}")
            return {"method": "tesseract", "error": str(e)}
    
    async def _ocr_with_easyocr(self, image: Image.Image) -> Dict:
        """EasyOCR ë¶„ì„"""
        try:
            # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
            image_array = np.array(image)
            
            # ë¹„ë™ê¸°ë¡œ EasyOCR ì‹¤í–‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self.executor,
                self.easyocr_reader.readtext,
                image_array
            )
            
            # ê²°ê³¼ íŒŒì‹±
            texts = []
            confidences = []
            words = []
            
            for detection in result:
                if len(detection) >= 2:
                    bbox, text, confidence = detection[0], detection[1], detection[2] if len(detection) > 2 else 0.5
                    
                    texts.append(text)
                    confidences.append(confidence)
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë¦¬
                    x_coords = [point[0] for point in bbox]
                    y_coords = [point[1] for point in bbox]
                    left, top = min(x_coords), min(y_coords)
                    width, height = max(x_coords) - left, max(y_coords) - top
                    
                    words.append({
                        "text": text,
                        "confidence": round(confidence * 100, 1),
                        "bbox": {
                            "left": int(left),
                            "top": int(top),
                            "width": int(width),
                            "height": int(height)
                        }
                    })
            
            full_text = " ".join(texts)
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            return {
                "method": "easyocr",
                "text": full_text,
                "confidence": round(avg_confidence, 3),
                "word_count": len(full_text.split()),
                "words": words,
                "raw_result": result
            }
            
        except Exception as e:
            logging.error(f"EasyOCR ì˜¤ë¥˜: {e}")
            return {"method": "easyocr", "error": str(e)}
    
    def _select_best_ocr_result(self, tesseract_result: Dict, easyocr_result: Dict) -> Dict:
        """ìµœì  OCR ê²°ê³¼ ì„ íƒ"""
        try:
            # ì—ëŸ¬ê°€ ìˆëŠ” ê²°ê³¼ ì œì™¸
            valid_results = []
            if "error" not in tesseract_result and tesseract_result.get("text"):
                valid_results.append(tesseract_result)
            if "error" not in easyocr_result and easyocr_result.get("text"):
                valid_results.append(easyocr_result)
            
            if not valid_results:
                return {"method": "none", "text": "", "confidence": 0.0}
            
            # ì‹ ë¢°ë„ê°€ ë†’ì€ ê²°ê³¼ ì„ íƒ
            best_result = max(valid_results, key=lambda x: x.get("confidence", 0))
            
            # ë‘ ê²°ê³¼ê°€ ë¹„ìŠ·í•˜ë©´ ë” ë§ì€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ ê²ƒ ì„ íƒ
            if len(valid_results) == 2:
                conf_diff = abs(valid_results[0].get("confidence", 0) - valid_results[1].get("confidence", 0))
                if conf_diff < 0.1:  # ì‹ ë¢°ë„ ì°¨ì´ê°€ 0.1 ë¯¸ë§Œì´ë©´
                    best_result = max(valid_results, key=lambda x: x.get("word_count", 0))
            
            return best_result
            
        except Exception as e:
            logging.error(f"ìµœì  OCR ê²°ê³¼ ì„ íƒ ì˜¤ë¥˜: {e}")
            return {"method": "error", "text": "", "confidence": 0.0}
    
    async def _analyze_layout_structure(self, image: Image.Image) -> Dict:
        """ë ˆì´ì•„ì›ƒ êµ¬ì¡° ë¶„ì„"""
        try:
            width, height = image.size
            
            # ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ ë¶„í• í•˜ì—¬ í…ìŠ¤íŠ¸ ë°€ë„ ë¶„ì„
            grid_size = 8
            cell_width = width // grid_size
            cell_height = height // grid_size
            
            text_density_map = []
            
            for row in range(grid_size):
                row_densities = []
                for col in range(grid_size):
                    left = col * cell_width
                    top = row * cell_height
                    right = min(left + cell_width, width)
                    bottom = min(top + cell_height, height)
                    
                    # ì…€ ì˜ì—­ í¬ë¡­
                    cell = image.crop((left, top, right, bottom))
                    
                    # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë°€ë„ ê³„ì‚° (ì—£ì§€ ê¸°ë°˜)
                    cell_array = np.array(cell.convert('L'))
                    edges = cv2.Canny(cell_array, 50, 150)
                    density = np.sum(edges > 0) / (cell_array.shape[0] * cell_array.shape[1])
                    
                    row_densities.append(round(density, 4))
                
                text_density_map.append(row_densities)
            
            # ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê°ì§€
            detected_pattern = self._detect_layout_pattern(text_density_map)
            
            # ì œëª© ì˜ì—­ ê°ì§€
            title_region = self._detect_title_region(text_density_map, width, height)
            
            # ì»¬ëŸ¼ êµ¬ì¡° ê°ì§€
            column_structure = self._detect_column_structure(text_density_map)
            
            return {
                "text_density_map": text_density_map,
                "detected_pattern": detected_pattern,
                "title_region": title_region,
                "column_structure": column_structure,
                "layout_score": self._calculate_layout_score(text_density_map, detected_pattern)
            }
            
        except Exception as e:
            logging.error(f"ë ˆì´ì•„ì›ƒ êµ¬ì¡° ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _detect_layout_pattern(self, density_map: List[List[float]]) -> Dict:
        """ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê°ì§€"""
        try:
            grid_size = len(density_map)
            
            # ìƒë‹¨ ì˜ì—­ (ì œëª©) í…ìŠ¤íŠ¸ ë°€ë„
            top_density = np.mean([density_map[i] for i in range(min(2, grid_size))])
            
            # ì¤‘ê°„ ì˜ì—­ í…ìŠ¤íŠ¸ ë°€ë„
            mid_start = grid_size // 4
            mid_end = 3 * grid_size // 4
            mid_density = np.mean([density_map[i] for i in range(mid_start, mid_end)])
            
            # ì¢Œìš° ê· í˜•ë„ ê³„ì‚°
            left_density = np.mean([[row[j] for j in range(grid_size//2)] for row in density_map])
            right_density = np.mean([[row[j] for j in range(grid_size//2, grid_size)] for row in density_map])
            balance_ratio = min(left_density, right_density) / max(left_density, right_density) if max(left_density, right_density) > 0 else 0
            
            # íŒ¨í„´ ë¶„ë¥˜
            if top_density > mid_density * 1.5:
                pattern_type = "title_slide"
            elif balance_ratio < 0.6:  # ì¢Œìš° ë¶ˆê· í˜•
                pattern_type = "image_text"
            elif balance_ratio > 0.8 and left_density > 0.01 and right_density > 0.01:
                pattern_type = "two_column"
            else:
                pattern_type = "bullet_slide"
            
            return {
                "pattern_type": pattern_type,
                "confidence": min(1.0, max(top_density, mid_density) * 10),
                "balance_ratio": round(balance_ratio, 3),
                "top_density": round(top_density, 4),
                "mid_density": round(mid_density, 4)
            }
            
        except Exception as e:
            logging.error(f"ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê°ì§€ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _detect_title_region(self, density_map: List[List[float]], width: int, height: int) -> Dict:
        """ì œëª© ì˜ì—­ ê°ì§€"""
        try:
            grid_size = len(density_map)
            
            # ìƒë‹¨ 2-3í–‰ì—ì„œ ì œëª© ì˜ì—­ ì°¾ê¸°
            title_candidates = []
            for row in range(min(3, grid_size)):
                row_density = density_map[row]
                if max(row_density) > 0.02:  # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨
                    title_candidates.append((row, max(row_density), np.mean(row_density)))
            
            if title_candidates:
                # ê°€ì¥ ë°€ë„ê°€ ë†’ì€ í–‰ì„ ì œëª©ìœ¼ë¡œ ì„ íƒ
                best_row = max(title_candidates, key=lambda x: x[1])
                row_idx = best_row[0]
                
                # ì œëª© ì˜ì—­ ì¢Œí‘œ ê³„ì‚°
                cell_height = height // grid_size
                title_region = {
                    "top": row_idx * cell_height,
                    "bottom": (row_idx + 1) * cell_height,
                    "left": 0,
                    "right": width,
                    "confidence": min(1.0, best_row[1] * 20)
                }
            else:
                title_region = None
            
            return {
                "region": title_region,
                "candidates": title_candidates
            }
            
        except Exception as e:
            logging.error(f"ì œëª© ì˜ì—­ ê°ì§€ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _detect_column_structure(self, density_map: List[List[float]]) -> Dict:
        """ì»¬ëŸ¼ êµ¬ì¡° ê°ì§€"""
        try:
            grid_size = len(density_map)
            
            # ì„¸ë¡œ ë°©í–¥ í…ìŠ¤íŠ¸ ë°€ë„ í•©ê³„
            col_densities = []
            for col in range(grid_size):
                col_density = sum(density_map[row][col] for row in range(grid_size))
                col_densities.append(col_density)
            
            # ì»¬ëŸ¼ ê²½ê³„ ê°ì§€ (ë°€ë„ê°€ ë‚®ì€ ì§€ì )
            boundaries = []
            threshold = np.mean(col_densities) * 0.3
            
            for i in range(1, grid_size - 1):
                if col_densities[i] < threshold and col_densities[i-1] > threshold and col_densities[i+1] > threshold:
                    boundaries.append(i)
            
            # ì»¬ëŸ¼ ìˆ˜ ì¶”ì •
            if len(boundaries) == 0:
                column_count = 1
            elif len(boundaries) == 1:
                column_count = 2
            else:
                column_count = len(boundaries) + 1
            
            return {
                "column_count": column_count,
                "boundaries": boundaries,
                "column_densities": col_densities,
                "structure_confidence": min(1.0, max(col_densities) * 5)
            }
            
        except Exception as e:
            logging.error(f"ì»¬ëŸ¼ êµ¬ì¡° ê°ì§€ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _calculate_layout_score(self, density_map: List[List[float]], pattern_info: Dict) -> float:
        """ë ˆì´ì•„ì›ƒ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ì „ì²´ í…ìŠ¤íŠ¸ ë°€ë„
            total_density = np.mean([np.mean(row) for row in density_map])
            
            # íŒ¨í„´ ì¼ì¹˜ë„
            pattern_confidence = pattern_info.get("confidence", 0)
            
            # ê· í˜•ë„
            balance_ratio = pattern_info.get("balance_ratio", 0.5)
            
            # ì¢…í•© ì ìˆ˜ (0-1)
            layout_score = (total_density * 20 + pattern_confidence + balance_ratio) / 3
            
            return round(min(1.0, layout_score), 3)
            
        except Exception as e:
            logging.error(f"ë ˆì´ì•„ì›ƒ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5
    
    async def _detect_tables_and_charts(self, image: Image.Image) -> Dict:
        """í‘œì™€ ì°¨íŠ¸ ê°ì§€"""
        try:
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(image.convert('L'))
            
            # ê°€ë¡œì„  ê°ì§€ (í‘œì˜ í–‰ êµ¬ë¶„ì„ )
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
            horizontal_lines = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, horizontal_kernel)
            
            # ì„¸ë¡œì„  ê°ì§€ (í‘œì˜ ì—´ êµ¬ë¶„ì„ )
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
            vertical_lines = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, vertical_kernel)
            
            # í‘œ êµ¬ì¡° ê°ì§€
            table_mask = cv2.add(horizontal_lines, vertical_lines)
            table_score = np.sum(table_mask > 0) / (img_array.shape[0] * img_array.shape[1])
            
            # ì›í˜• êµ¬ì¡° ê°ì§€ (íŒŒì´ ì°¨íŠ¸)
            circles = cv2.HoughCircles(
                img_array, cv2.HOUGH_GRADIENT, 1, img_array.shape[0]//8,
                param1=50, param2=30, minRadius=30, maxRadius=min(img_array.shape)//4
            )
            
            pie_chart_detected = circles is not None and len(circles[0]) > 0
            
            # ì§ì‚¬ê°í˜• êµ¬ì¡° ê°ì§€ (ë§‰ëŒ€ ì°¨íŠ¸)
            contours, _ = cv2.findContours(
                cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY)[1],
                cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            )
            
            rectangles = []
            for contour in contours:
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                if len(approx) == 4:
                    area = cv2.contourArea(contour)
                    if area > 1000:  # ì¶©ë¶„íˆ í° ì‚¬ê°í˜•ë§Œ
                        rectangles.append(contour)
            
            bar_chart_detected = len(rectangles) >= 3  # 3ê°œ ì´ìƒì˜ ë§‰ëŒ€
            
            return {
                "table_detected": table_score > 0.01,
                "table_score": round(table_score, 4),
                "pie_chart_detected": pie_chart_detected,
                "bar_chart_detected": bar_chart_detected,
                "chart_elements": {
                    "horizontal_lines": int(np.sum(horizontal_lines > 0)),
                    "vertical_lines": int(np.sum(vertical_lines > 0)),
                    "circles": len(circles[0]) if circles is not None else 0,
                    "rectangles": len(rectangles)
                }
            }
            
        except Exception as e:
            logging.error(f"í‘œ/ì°¨íŠ¸ ê°ì§€ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    async def _analyze_text_regions(self, image: Image.Image) -> Dict:
        """í…ìŠ¤íŠ¸ ì˜ì—­ ë¶„ì„"""
        try:
            # ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            gray = np.array(image.convert('L'))
            
            # ì ì‘ì  ì„ê³„í™”
            binary = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
            )
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ì°¾ê¸°
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # í…ìŠ¤íŠ¸ ë¸”ë¡ ë¶„ì„
            text_blocks = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # ìµœì†Œ í¬ê¸° í•„í„°
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # í…ìŠ¤íŠ¸ ë¸”ë¡ íŠ¹ì„± ë¶„ì„
                    aspect_ratio = w / h
                    if 0.1 <= aspect_ratio <= 10:  # í•©ë¦¬ì ì¸ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨
                        text_blocks.append({
                            "bbox": {"x": int(x), "y": int(y), "width": int(w), "height": int(h)},
                            "area": int(area),
                            "aspect_ratio": round(aspect_ratio, 2)
                        })
            
            # ì½ê¸° ìˆœì„œ ì¶”ì • (ìœ„ì—ì„œ ì•„ë˜, ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½)
            text_blocks.sort(key=lambda block: (block["bbox"]["y"], block["bbox"]["x"]))
            
            # í…ìŠ¤íŠ¸ ë°€ë„ ê³„ì‚°
            total_text_area = sum(block["area"] for block in text_blocks)
            image_area = image.width * image.height
            text_density = total_text_area / image_area
            
            return {
                "text_blocks": text_blocks,
                "block_count": len(text_blocks),
                "text_density": round(text_density, 4),
                "reading_order_confidence": 0.8 if len(text_blocks) > 0 else 0.0
            }
            
        except Exception as e:
            logging.error(f"í…ìŠ¤íŠ¸ ì˜ì—­ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    async def _assess_ocr_accuracy(self, 
                                 ocr_result: Dict, 
                                 layout_result: Dict, 
                                 text_regions: Dict) -> Dict:
        """OCR ì •í™•ë„ í‰ê°€"""
        try:
            # ê¸°ë³¸ ì‹ ë¢°ë„
            base_confidence = ocr_result.get("confidence", 0.0)
            
            # í…ìŠ¤íŠ¸ ì–‘ í‰ê°€
            word_count = ocr_result.get("word_count", 0)
            text_quantity_score = min(1.0, word_count / 50)  # 50ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
            
            # ë ˆì´ì•„ì›ƒ ì¼ì¹˜ë„
            layout_score = layout_result.get("layout_score", 0.5)
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ì»¤ë²„ë¦¬ì§€
            detected_blocks = text_regions.get("block_count", 0)
            coverage_score = min(1.0, detected_blocks / 10)  # 10ê°œ ë¸”ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
            
            # ì¢…í•© ì •í™•ë„ ì ìˆ˜
            overall_score = (
                base_confidence * 0.4 +
                text_quantity_score * 0.2 +
                layout_score * 0.2 +
                coverage_score * 0.2
            ) * 100
            
            # í’ˆì§ˆ ë ˆë²¨ í‰ê°€
            if overall_score >= 85:
                quality_level = "excellent"
            elif overall_score >= 70:
                quality_level = "good"
            elif overall_score >= 55:
                quality_level = "fair"
            else:
                quality_level = "poor"
            
            return {
                "overall_score": round(overall_score, 1),
                "quality_level": quality_level,
                "component_scores": {
                    "base_confidence": round(base_confidence, 3),
                    "text_quantity": round(text_quantity_score, 3),
                    "layout_quality": round(layout_score, 3),
                    "coverage": round(coverage_score, 3)
                },
                "detailed_metrics": {
                    "word_count": word_count,
                    "detected_blocks": detected_blocks,
                    "ocr_method": ocr_result.get("method", "unknown")
                }
            }
            
        except Exception as e:
            logging.error(f"OCR ì •í™•ë„ í‰ê°€ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _generate_ppt_recommendations(self, 
                                    slide_detection: Dict,
                                    accuracy_assessment: Dict, 
                                    layout_result: Dict,
                                    original_image: Image.Image) -> List[Dict]:
        """PPT OCR ê°œì„  ì œì•ˆ ìƒì„±"""
        recommendations = []
        
        try:
            # ìŠ¬ë¼ì´ë“œ ê°ì§€ ê¸°ë°˜ ì œì•ˆ
            if not slide_detection.get("is_presentation", False):
                recommendations.append({
                    "type": "slide_detection",
                    "priority": "medium",
                    "issue": "PPT ìŠ¬ë¼ì´ë“œë¡œ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                    "solution": "í™”ë©´ ì „ì²´ê°€ í¬í•¨ë˜ë„ë¡ ì •ë©´ì—ì„œ ì´¬ì˜í•˜ì„¸ìš”",
                    "icon": "ğŸ“Š"
                })
            
            # í•´ìƒë„ ê´€ë ¨ ì œì•ˆ
            width, height = original_image.size
            resolution_category = slide_detection.get("image_characteristics", {}).get("resolution_category", "low")
            
            if resolution_category == "low":
                recommendations.append({
                    "type": "resolution",
                    "priority": "high",
                    "issue": f"í•´ìƒë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({width}x{height})",
                    "solution": "ë” ê°€ê¹Œì´ì—ì„œ ì´¬ì˜í•˜ê±°ë‚˜ ë” ë†’ì€ í•´ìƒë„ë¡œ ì„¤ì •í•˜ì„¸ìš”",
                    "icon": "ğŸ“·"
                })
            
            # OCR ì •í™•ë„ ê¸°ë°˜ ì œì•ˆ
            overall_score = accuracy_assessment.get("overall_score", 0)
            
            if overall_score < 70:
                base_confidence = accuracy_assessment.get("component_scores", {}).get("base_confidence", 0)
                
                if base_confidence < 0.7:
                    recommendations.append({
                        "type": "ocr_accuracy",
                        "priority": "high",
                        "issue": f"í…ìŠ¤íŠ¸ ì¸ì‹ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ ({base_confidence:.2f})",
                        "solution": "ì¡°ëª…ì„ ì¶©ë¶„íˆ í™•ë³´í•˜ê³  í™”ë©´ì— ê·¸ë¦¼ìê°€ ìƒê¸°ì§€ ì•Šë„ë¡ ì´¬ì˜í•˜ì„¸ìš”",
                        "icon": "ğŸ’¡"
                    })
            
            # ë ˆì´ì•„ì›ƒ ê´€ë ¨ ì œì•ˆ
            layout_score = layout_result.get("layout_score", 0)
            
            if layout_score < 0.6:
                recommendations.append({
                    "type": "layout",
                    "priority": "medium",
                    "issue": "ìŠ¬ë¼ì´ë“œ ë ˆì´ì•„ì›ƒ êµ¬ì¡° ì¸ì‹ì´ ì–´ë µìŠµë‹ˆë‹¤",
                    "solution": "í™”ë©´ì„ ì •ë©´ì—ì„œ ìˆ˜ì§ìœ¼ë¡œ ì´¬ì˜í•˜ì—¬ ì™œê³¡ì„ ìµœì†Œí™”í•˜ì„¸ìš”",
                    "icon": "ğŸ“"
                })
            
            # í‘œ/ì°¨íŠ¸ ê´€ë ¨ ì œì•ˆ
            tables_charts = layout_result.get("tables_and_charts", {})
            if tables_charts.get("table_detected") or tables_charts.get("pie_chart_detected"):
                recommendations.append({
                    "type": "tables_charts",
                    "priority": "medium",
                    "issue": "í‘œë‚˜ ì°¨íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                    "solution": "í‘œì™€ ì°¨íŠ¸ì˜ í…ìŠ¤íŠ¸ê°€ ì„ ëª…í•˜ê²Œ ë³´ì´ë„ë¡ ë” ê°€ê¹Œì´ì—ì„œ ì´¬ì˜í•˜ì„¸ìš”",
                    "icon": "ğŸ“ˆ"
                })
            
            # ì¼ë°˜ì ì¸ ì´¬ì˜ íŒ
            if len(recommendations) >= 2:
                recommendations.append({
                    "type": "general",
                    "priority": "low",
                    "issue": "ì „ë°˜ì ì¸ ì´¬ì˜ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
                    "solution": "ì‚¼ê°ëŒ€ ì‚¬ìš©, ì¶©ë¶„í•œ ì¡°ëª…, í™”ë©´ ì •ë©´ ì´¬ì˜ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                    "icon": "ğŸ¯"
                })
            
            # ì„±ê³µì ì¸ ê²½ìš°ì˜ ê²©ë ¤
            if overall_score >= 85:
                recommendations.append({
                    "type": "success",
                    "priority": "info",
                    "issue": "ìš°ìˆ˜í•œ PPT í™”ë©´ ì¸ì‹ ê²°ê³¼ì…ë‹ˆë‹¤",
                    "solution": "í˜„ì¬ì™€ ê°™ì€ ì´¬ì˜ ë°©ì‹ì„ ìœ ì§€í•˜ì„¸ìš”",
                    "icon": "âœ…"
                })
            
            return recommendations[:5]  # ìµœëŒ€ 5ê°œ ì œì•ˆ
            
        except Exception as e:
            logging.error(f"PPT ê°œì„  ì œì•ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            return [{
                "type": "error",
                "priority": "low",
                "issue": "ê°œì„  ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                "solution": "ìˆ˜ë™ìœ¼ë¡œ PPT í™”ë©´ í’ˆì§ˆì„ í™•ì¸í•´ ì£¼ì„¸ìš”",
                "icon": "âš ï¸"
            }]

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_presentation_ocr_analyzer_instance = None

def get_presentation_ocr_analyzer() -> PresentationOCRAnalyzer:
    """ì „ì—­ PPT OCR ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _presentation_ocr_analyzer_instance
    if _presentation_ocr_analyzer_instance is None:
        _presentation_ocr_analyzer_instance = PresentationOCRAnalyzer()
    return _presentation_ocr_analyzer_instance

# í¸ì˜ í•¨ìˆ˜ë“¤
async def analyze_presentation_ocr(image_data: bytes, filename: str, **kwargs) -> Dict:
    """PPT í™”ë©´ OCR ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    analyzer = get_presentation_ocr_analyzer()
    return await analyzer.analyze_presentation_image(image_data, filename, **kwargs)

def check_ppt_ocr_support() -> Dict:
    """PPT OCR ë¶„ì„ê¸° ì§€ì› ìƒíƒœ í™•ì¸"""
    return {
        "libraries": {
            "PIL": PIL_AVAILABLE,
            "tesseract": TESSERACT_AVAILABLE,
            "easyocr": EASYOCR_AVAILABLE,
            "opencv": True,  # cv2ëŠ” ê¸°ë³¸ ì„¤ì¹˜
            "skimage": SKIMAGE_AVAILABLE
        },
        "features": {
            "slide_detection": True,
            "layout_analysis": True,
            "table_chart_detection": True,
            "text_region_analysis": True,
            "quality_assessment": True
        },
        "layout_patterns": list(PresentationOCRAnalyzer().layout_patterns.keys()),
        "quality_levels": ["excellent", "good", "fair", "poor"]
    }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    async def test_ppt_analyzer():
        print("PPT í™”ë©´ íŠ¹í™” OCR ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸")
        support_info = check_ppt_ocr_support()
        print(f"ì§€ì› ìƒíƒœ: {support_info}")
    
    import asyncio
    import io
    asyncio.run(test_ppt_analyzer())
