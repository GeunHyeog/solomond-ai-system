# ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„ v1.0
# Phase 2: ì£¼ì–¼ë¦¬ AI í”Œë«í¼ - ì‹¤ì œ í˜„ì¥ ìš”êµ¬ì‚¬í•­ ë°˜ì˜

import asyncio
import uuid
import time
import hashlib
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
import json
from pathlib import Path

class FileType(Enum):
    AUDIO = "audio"
    VIDEO = "video" 
    DOCUMENT = "document"
    IMAGE = "image"

class ProcessingStatus(Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    VERIFIED = "verified"

@dataclass
class FileItem:
    """ê°œë³„ íŒŒì¼ ì •ë³´"""
    file_id: str
    filename: str
    file_type: FileType
    file_path: str
    size_mb: float
    quality_score: float = 0.0
    processing_status: ProcessingStatus = ProcessingStatus.PENDING
    content: str = ""
    extracted_keywords: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    processing_time: float = 0.0
    error_message: str = ""

@dataclass
class SessionConfig:
    """ì„¸ì…˜ ì„¤ì •"""
    session_id: str
    session_name: str
    event_type: str  # "ì£¼ì–¼ë¦¬ ì „ì‹œíšŒ", "ì—…ê³„ ì„¸ë¯¸ë‚˜", "ê³ ê° ìƒë‹´", "ì œí’ˆ êµìœ¡"
    topic: str
    participants: List[str] = field(default_factory=list)
    expected_duration: int = 0  # ë¶„ ë‹¨ìœ„
    priority_file_types: List[FileType] = field(default_factory=list)

@dataclass
class CrossValidation:
    """í¬ë¡œìŠ¤ ê²€ì¦ ê²°ê³¼"""
    common_keywords: List[str] = field(default_factory=list)
    content_overlap_percentage: float = 0.0
    confidence_score: float = 0.0
    contradictions: List[str] = field(default_factory=list)
    missing_content: List[str] = field(default_factory=list)
    verified_content: str = ""

class BatchProcessingEngine:
    """ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self):
        self.sessions: Dict[str, Dict] = {}
        self.processing_queue = asyncio.Queue()
        self.is_processing = False
        
    async def create_session(self, config: SessionConfig) -> str:
        """ìƒˆ ì„¸ì…˜ ìƒì„±"""
        session_data = {
            "config": config,
            "files": [],
            "status": "created",
            "created_at": time.time(),
            "progress": 0.0,
            "cross_validation": None,
            "final_result": None
        }
        
        self.sessions[config.session_id] = session_data
        return config.session_id
    
    async def add_files_to_session(self, session_id: str, files: List[FileItem]):
        """ì„¸ì…˜ì— íŒŒì¼ ì¶”ê°€"""
        if session_id not in self.sessions:
            raise ValueError(f"ì„¸ì…˜ {session_id}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        session = self.sessions[session_id]
        
        for file_item in files:
            # íŒŒì¼ í•´ì‹œ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
            file_hash = self._generate_file_hash(file_item.file_path)
            file_item.file_id = file_hash
            
            # í’ˆì§ˆ ì ìˆ˜ ì´ˆê¸° ê³„ì‚°
            file_item.quality_score = self._calculate_initial_quality(file_item)
            
            session["files"].append(file_item)
        
        session["status"] = "files_added"
        return len(files)
    
    async def start_batch_processing(self, session_id: str) -> Dict[str, Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘"""
        if session_id not in self.sessions:
            raise ValueError(f"ì„¸ì…˜ {session_id}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        session = self.sessions[session_id]
        session["status"] = "processing"
        session["started_at"] = time.time()
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘
        files = session["files"]
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ íŒŒì¼ ì •ë ¬
        sorted_files = self._sort_files_by_priority(files, session["config"])
        
        # ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
        tasks = []
        for file_item in sorted_files:
            task = asyncio.create_task(self._process_single_file(file_item))
            tasks.append(task)
        
        # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
        processing_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        for i, result in enumerate(processing_results):
            if isinstance(result, Exception):
                sorted_files[i].processing_status = ProcessingStatus.FAILED
                sorted_files[i].error_message = str(result)
            else:
                sorted_files[i] = result
        
        # í¬ë¡œìŠ¤ ê²€ì¦ ìˆ˜í–‰
        cross_validation = await self._perform_cross_validation(sorted_files)
        session["cross_validation"] = cross_validation
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        final_result = await self._generate_final_result(sorted_files, cross_validation)
        session["final_result"] = final_result
        
        session["status"] = "completed"
        session["completed_at"] = time.time()
        session["progress"] = 100.0
        
        return {
            "session_id": session_id,
            "status": "completed",
            "files_processed": len([f for f in sorted_files if f.processing_status == ProcessingStatus.COMPLETED]),
            "cross_validation": cross_validation,
            "final_result": final_result
        }
    
    async def _process_single_file(self, file_item: FileItem) -> FileItem:
        """ê°œë³„ íŒŒì¼ ì²˜ë¦¬"""
        start_time = time.time()
        file_item.processing_status = ProcessingStatus.PROCESSING
        
        try:
            # íŒŒì¼ íƒ€ì…ë³„ ì²˜ë¦¬
            if file_item.file_type == FileType.AUDIO:
                content = await self._process_audio_file(file_item)
            elif file_item.file_type == FileType.VIDEO:
                content = await self._process_video_file(file_item)
            elif file_item.file_type == FileType.DOCUMENT:
                content = await self._process_document_file(file_item)
            elif file_item.file_type == FileType.IMAGE:
                content = await self._process_image_file(file_item)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_item.file_type}")
            
            # ì£¼ì–¼ë¦¬ íŠ¹í™” í›„ì²˜ë¦¬
            enhanced_content = await self._enhance_jewelry_content(content)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = await self._extract_jewelry_keywords(enhanced_content)
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            file_item.content = enhanced_content
            file_item.extracted_keywords = keywords
            file_item.confidence_score = self._calculate_confidence(enhanced_content, keywords)
            file_item.processing_status = ProcessingStatus.COMPLETED
            file_item.processing_time = time.time() - start_time
            
        except Exception as e:
            file_item.processing_status = ProcessingStatus.FAILED
            file_item.error_message = str(e)
            file_item.processing_time = time.time() - start_time
        
        return file_item
    
    async def _process_audio_file(self, file_item: FileItem) -> str:
        """ìŒì„± íŒŒì¼ ì²˜ë¦¬ (ê¸°ì¡´ Whisper STT í™œìš©)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê¸°ì¡´ Whisper STT ì‹œìŠ¤í…œ í˜¸ì¶œ
        await asyncio.sleep(0.5)  # ì‹œë®¬ë ˆì´ì…˜
        
        # ëª¨ì˜ STT ê²°ê³¼ (ì‹¤ì œë¡œëŠ” Whisper ì—”ì§„ í˜¸ì¶œ)
        mock_content = f"""
        2025ë…„ ë‹¤ì´ì•„ëª¬ë“œ ì‹œì¥ ì „ë§ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. 
        4C ë“±ê¸‰ ì¤‘ì—ì„œ íŠ¹íˆ ì»¬ëŸ¬ì™€ í´ë˜ë¦¬í‹° ë“±ê¸‰ì´ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í´ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.
        GIA ì¸ì¦ì„œì˜ ì¤‘ìš”ì„±ì´ ë”ìš± ê°•ì¡°ë˜ê³  ìˆìœ¼ë©°, í”„ë¦°ì„¸ìŠ¤ ì»·ê³¼ ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸ ì»·ì˜ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        1ìºëŸ¿ ë‹¤ì´ì•„ëª¬ë“œì˜ ë„ë§¤ê°€ê²©ì´ ì „ë…„ ëŒ€ë¹„ 15% ìƒìŠ¹í•  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.
        """
        
        return mock_content.strip()
    
    async def _process_video_file(self, file_item: FileItem) -> str:
        """ì˜ìƒ íŒŒì¼ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ í›„ STT)"""
        await asyncio.sleep(1.0)  # ì˜ìƒ ì²˜ë¦¬ëŠ” ë” ì˜¤ë˜ ê±¸ë¦¼
        
        # ëª¨ì˜ ì˜ìƒ ìŒì„± ì¶”ì¶œ ê²°ê³¼
        mock_content = f"""
        í™”ë©´ì— ë³´ì‹œëŠ” ê²ƒì²˜ëŸ¼ ì‚¬íŒŒì´ì–´ì˜ ìƒ‰ìƒ ë“±ê¸‰ì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
        ë¡œì–„ ë¸”ë£¨ ì‚¬íŒŒì´ì–´ì˜ ê²½ìš° ìºëŸ¿ë‹¹ ê°€ê²©ì´ $3,000ì—ì„œ $5,000 ì‚¬ì´ì…ë‹ˆë‹¤.
        ìŠ¤ë¦¬ë‘ì¹´ì‚°ê³¼ ë²„ë§ˆì‚°ì˜ í’ˆì§ˆ ì°¨ì´ë¥¼ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.
        íˆíŠ¸ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ ì—¬ë¶€ê°€ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        
        return mock_content.strip()
    
    async def _process_document_file(self, file_item: FileItem) -> str:
        """ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬"""
        await asyncio.sleep(0.3)
        
        # ëª¨ì˜ ë¬¸ì„œ ë‚´ìš©
        mock_content = f"""
        ì£¼ì–¼ë¦¬ ì‹œì¥ ë™í–¥ ë³´ê³ ì„œ
        
        1. ë‹¤ì´ì•„ëª¬ë“œ ì‹œì¥
        - 1ìºëŸ¿ D-IF ë“±ê¸‰: $8,500 (ì „ì›” ëŒ€ë¹„ 3% ìƒìŠ¹)
        - 2ìºëŸ¿ E-VS1 ë“±ê¸‰: $25,000 (ì•ˆì •ì„¸)
        
        2. ì»¬ëŸ¬ë“œ ìŠ¤í†¤ ì‹œì¥  
        - ë£¨ë¹„: ë²„ë§ˆì‚° 1ìºëŸ¿ $4,500 (5% ìƒìŠ¹)
        - ì—ë©”ë„ë“œ: ì½œë¡¬ë¹„ì•„ì‚° 1ìºëŸ¿ $3,200 (2% í•˜ë½)
        
        3. íŠ¸ë Œë“œ ë¶„ì„
        - ë©ê·¸ë¡œìš´ ë‹¤ì´ì•„ëª¬ë“œ ìˆ˜ìš” ì¦ê°€
        - ì„œìŠ¤í…Œì´ë„ˆë¸” ì£¼ì–¼ë¦¬ ê´€ì‹¬ í™•ëŒ€
        """
        
        return mock_content.strip()
    
    async def _process_image_file(self, file_item: FileItem) -> str:
        """ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ (OCR)"""
        await asyncio.sleep(0.4)
        
        # ëª¨ì˜ OCR ê²°ê³¼
        mock_content = f"""
        GIA Report Number: 2141234567
        Shape: Round Brilliant
        Carat Weight: 1.52
        Color Grade: F
        Clarity Grade: VS1
        Cut Grade: Excellent
        Polish: Excellent
        Symmetry: Excellent
        Fluorescence: None
        """
        
        return mock_content.strip()
    
    async def _enhance_jewelry_content(self, content: str) -> str:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” ë‚´ìš© í–¥ìƒ"""
        # ì‹¤ì œë¡œëŠ” ì£¼ì–¼ë¦¬ ìš©ì–´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ ë³´ì •
        enhanced = content
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ì •ê·œí™” (ì˜ˆì‹œ)
        jewelry_terms = {
            "ë‹¤ì´ì•„ëª¬ë“œ": "Diamond",
            "ì‚¬íŒŒì´ì–´": "Sapphire", 
            "ë£¨ë¹„": "Ruby",
            "ì—ë©”ë„ë“œ": "Emerald",
            "4ì”¨": "4C",
            "ì§€ì•„": "GIA"
        }
        
        for korean, english in jewelry_terms.items():
            if korean in enhanced:
                enhanced = enhanced.replace(korean, f"{korean}({english})")
        
        return enhanced
    
    async def _extract_jewelry_keywords(self, content: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        jewelry_keywords = [
            "ë‹¤ì´ì•„ëª¬ë“œ", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", "ì—ë©”ë„ë“œ", "4C", "GIA", 
            "ìºëŸ¿", "ì»¬ëŸ¬", "í´ë˜ë¦¬í‹°", "ì»·", "ë„ë§¤ê°€", "ì†Œë§¤ê°€",
            "í”„ë¦°ì„¸ìŠ¤ ì»·", "ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸", "ì¸ì¦ì„œ", "ê°ì •ì„œ"
        ]
        
        found_keywords = []
        content_lower = content.lower()
        
        for keyword in jewelry_keywords:
            if keyword.lower() in content_lower:
                found_keywords.append(keyword)
        
        return found_keywords
    
    async def _perform_cross_validation(self, files: List[FileItem]) -> CrossValidation:
        """íŒŒì¼ ê°„ í¬ë¡œìŠ¤ ê²€ì¦"""
        completed_files = [f for f in files if f.processing_status == ProcessingStatus.COMPLETED]
        
        if len(completed_files) < 2:
            return CrossValidation(
                confidence_score=1.0 if len(completed_files) == 1 else 0.0,
                verified_content=completed_files[0].content if completed_files else ""
            )
        
        # ê³µí†µ í‚¤ì›Œë“œ ì°¾ê¸°
        all_keywords = []
        for file_item in completed_files:
            all_keywords.extend(file_item.extracted_keywords)
        
        keyword_counts = {}
        for keyword in all_keywords:
            keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
        
        # 2ê°œ ì´ìƒ íŒŒì¼ì—ì„œ ë°œê²¬ëœ í‚¤ì›Œë“œë¥¼ ê³µí†µ í‚¤ì›Œë“œë¡œ ì¸ì •
        common_keywords = [k for k, v in keyword_counts.items() if v >= 2]
        
        # ë‚´ìš© ì¤‘ë³µë„ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ì‹)
        all_contents = [f.content for f in completed_files]
        content_overlap = self._calculate_content_overlap(all_contents)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = min(0.95, 0.5 + (len(common_keywords) * 0.05) + (content_overlap * 0.4))
        
        # ê²€ì¦ëœ ë‚´ìš© ìƒì„± (ê°€ì¥ ê¸´ ë‚´ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ)
        verified_content = max(all_contents, key=len)
        
        return CrossValidation(
            common_keywords=common_keywords,
            content_overlap_percentage=content_overlap * 100,
            confidence_score=confidence_score,
            verified_content=verified_content
        )
    
    async def _generate_final_result(self, files: List[FileItem], cross_validation: CrossValidation) -> Dict[str, Any]:
        """ìµœì¢… í†µí•© ê²°ê³¼ ìƒì„±"""
        completed_files = [f for f in files if f.processing_status == ProcessingStatus.COMPLETED]
        
        # í†µê³„ ê³„ì‚°
        total_processing_time = sum(f.processing_time for f in files)
        avg_confidence = sum(f.confidence_score for f in completed_files) / max(len(completed_files), 1)
        
        # ì£¼ì–¼ë¦¬ íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        jewelry_insights = self._extract_jewelry_insights(cross_validation.verified_content, cross_validation.common_keywords)
        
        return {
            "summary": {
                "total_files": len(files),
                "successfully_processed": len(completed_files),
                "failed_files": len([f for f in files if f.processing_status == ProcessingStatus.FAILED]),
                "total_processing_time": round(total_processing_time, 2),
                "average_confidence": round(avg_confidence, 3),
                "cross_validation_score": round(cross_validation.confidence_score, 3)
            },
            "content": {
                "verified_content": cross_validation.verified_content,
                "common_keywords": cross_validation.common_keywords,
                "content_overlap_percentage": round(cross_validation.content_overlap_percentage, 1)
            },
            "jewelry_insights": jewelry_insights,
            "files_detail": [
                {
                    "filename": f.filename,
                    "type": f.file_type.value,
                    "status": f.processing_status.value,
                    "confidence": round(f.confidence_score, 3),
                    "processing_time": round(f.processing_time, 2),
                    "keywords_found": len(f.extracted_keywords)
                } for f in files
            ]
        }
    
    def _extract_jewelry_insights(self, content: str, keywords: List[str]) -> Dict[str, Any]:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = {
            "price_mentions": [],
            "quality_grades": [],
            "market_trends": [],
            "technical_terms": []
        }
        
        # ê°€ê²© ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
        import re
        price_patterns = [
            r'\$[\d,]+',
            r'[\d,]+ë‹¬ëŸ¬',
            r'[\d,]+ì›',
            r'ìºëŸ¿ë‹¹ [\d,]+'
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, content)
            insights["price_mentions"].extend(matches)
        
        # í’ˆì§ˆ ë“±ê¸‰ ì¶”ì¶œ
        grade_keywords = ["4C", "GIA", "ì»·", "ì»¬ëŸ¬", "í´ë˜ë¦¬í‹°", "ìºëŸ¿"]
        insights["quality_grades"] = [k for k in keywords if k in grade_keywords]
        
        # ì‹œì¥ íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        trend_keywords = ["ìƒìŠ¹", "í•˜ë½", "íŠ¸ë Œë“œ", "ì „ë§", "ìˆ˜ìš”", "ê³µê¸‰"]
        insights["market_trends"] = [k for k in keywords if k in trend_keywords]
        
        # ê¸°ìˆ  ìš©ì–´
        tech_keywords = ["íˆíŠ¸ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸", "í”„ë¦°ì„¸ìŠ¤ ì»·", "ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸", "ì¸ì¦ì„œ"]
        insights["technical_terms"] = [k for k in keywords if k in tech_keywords]
        
        return insights
    
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    def _generate_file_hash(self, file_path: str) -> str:
        """íŒŒì¼ í•´ì‹œ ìƒì„±"""
        return hashlib.md5(f"{file_path}_{time.time()}".encode()).hexdigest()[:8]
    
    def _calculate_initial_quality(self, file_item: FileItem) -> float:
        """ì´ˆê¸° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        # íŒŒì¼ í¬ê¸° ê¸°ë°˜ ì ìˆ˜ (í° íŒŒì¼ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ì¢‹ì€ í’ˆì§ˆ)
        size_score = min(1.0, file_item.size_mb / 100.0)  # 100MBë¥¼ ìµœëŒ€ë¡œ
        
        # íŒŒì¼ íƒ€ì…ë³„ ê¸°ë³¸ ì ìˆ˜
        type_scores = {
            FileType.AUDIO: 0.8,
            FileType.VIDEO: 0.9,  # ì˜ìƒì´ ë³´í†µ ë” ì™„ì „í•œ ì •ë³´
            FileType.DOCUMENT: 0.95,  # ë¬¸ì„œê°€ ê°€ì¥ ì •í™•
            FileType.IMAGE: 0.7
        }
        
        type_score = type_scores.get(file_item.file_type, 0.5)
        
        return (size_score * 0.3 + type_score * 0.7)
    
    def _sort_files_by_priority(self, files: List[FileItem], config: SessionConfig) -> List[FileItem]:
        """ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ íŒŒì¼ ì •ë ¬"""
        def priority_score(file_item):
            score = file_item.quality_score
            
            # ì„¤ì •ëœ ìš°ì„ ìˆœìœ„ íŒŒì¼ íƒ€ì… ê°€ì‚°ì 
            if file_item.file_type in config.priority_file_types:
                score += 0.2
            
            return score
        
        return sorted(files, key=priority_score, reverse=True)
    
    def _calculate_confidence(self, content: str, keywords: List[str]) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        if not content:
            return 0.0
        
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.6
        
        # ë‚´ìš© ê¸¸ì´ ê¸°ë°˜ ê°€ì‚°ì 
        length_score = min(0.2, len(content) / 1000)
        
        # í‚¤ì›Œë“œ ê°œìˆ˜ ê¸°ë°˜ ê°€ì‚°ì   
        keyword_score = min(0.2, len(keywords) * 0.02)
        
        return base_score + length_score + keyword_score
    
    def _calculate_content_overlap(self, contents: List[str]) -> float:
        """ë‚´ìš© ì¤‘ë³µë„ ê³„ì‚°"""
        if len(contents) < 2:
            return 1.0
        
        # ê°„ë‹¨í•œ ë‹¨ì–´ ê¸°ë°˜ ì¤‘ë³µë„ ê³„ì‚°
        all_words = set()
        common_words = set()
        
        word_sets = []
        for content in contents:
            words = set(content.lower().split())
            word_sets.append(words)
            all_words.update(words)
        
        # ëª¨ë“  íŒŒì¼ì— ê³µí†µìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ ì°¾ê¸°
        if word_sets:
            common_words = word_sets[0]
            for word_set in word_sets[1:]:
                common_words = common_words.intersection(word_set)
        
        if not all_words:
            return 0.0
        
        return len(common_words) / len(all_words)
    
    def get_session_status(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ"""
        if session_id not in self.sessions:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        session = self.sessions[session_id]
        
        return {
            "session_id": session_id,
            "status": session["status"],
            "progress": session.get("progress", 0),
            "files_count": len(session["files"]),
            "created_at": session["created_at"],
            "config": {
                "session_name": session["config"].session_name,
                "event_type": session["config"].event_type,
                "topic": session["config"].topic
            }
        }

# ì‚¬ìš© ì˜ˆì‹œ
async def demo_batch_processing():
    """ë°°ì¹˜ ì²˜ë¦¬ ë°ëª¨"""
    engine = BatchProcessingEngine()
    
    # ì„¸ì…˜ ì„¤ì •
    config = SessionConfig(
        session_id=str(uuid.uuid4()),
        session_name="2025 í™ì½©ì£¼ì–¼ë¦¬ì‡¼ ë‹¤ì´ì•„ëª¬ë“œ ì„¸ë¯¸ë‚˜",
        event_type="ì£¼ì–¼ë¦¬ ì „ì‹œíšŒ",
        topic="2025ë…„ ë‹¤ì´ì•„ëª¬ë“œ ì‹œì¥ ì „ë§",
        participants=["ì „ê·¼í˜ ëŒ€í‘œ", "ì—…ê³„ ì „ë¬¸ê°€ë“¤"],
        priority_file_types=[FileType.AUDIO, FileType.DOCUMENT]
    )
    
    # ì„¸ì…˜ ìƒì„±
    session_id = await engine.create_session(config)
    print(f"âœ… ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {session_id}")
    
    # íŒŒì¼ ì¶”ê°€
    files = [
        FileItem(
            file_id="",
            filename="main_recording.mp3",
            file_type=FileType.AUDIO,
            file_path="/path/to/main_recording.mp3",
            size_mb=25.3
        ),
        FileItem(
            file_id="",
            filename="backup_recording.wav", 
            file_type=FileType.AUDIO,
            file_path="/path/to/backup_recording.wav",
            size_mb=18.7
        ),
        FileItem(
            file_id="",
            filename="presentation.mp4",
            file_type=FileType.VIDEO,
            file_path="/path/to/presentation.mp4", 
            size_mb=156.8
        ),
        FileItem(
            file_id="",
            filename="market_report.pdf",
            file_type=FileType.DOCUMENT,
            file_path="/path/to/market_report.pdf",
            size_mb=2.1
        ),
        FileItem(
            file_id="",
            filename="gia_certificate.jpg",
            file_type=FileType.IMAGE,
            file_path="/path/to/gia_certificate.jpg",
            size_mb=0.8
        )
    ]
    
    files_added = await engine.add_files_to_session(session_id, files)
    print(f"âœ… íŒŒì¼ ì¶”ê°€ ì™„ë£Œ: {files_added}ê°œ")
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
    print("ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘...")
    result = await engine.start_batch_processing(session_id)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*60)
    print(f"ì„¸ì…˜ ID: {result['session_id']}")
    print(f"ì²˜ë¦¬ ìƒíƒœ: {result['status']}")
    print(f"ì²˜ë¦¬ëœ íŒŒì¼: {result['files_processed']}ê°œ")
    print(f"ì‹ ë¢°ë„: {result['cross_validation'].confidence_score:.1%}")
    print(f"ê³µí†µ í‚¤ì›Œë“œ: {', '.join(result['cross_validation'].common_keywords)}")
    
    print("\nğŸ“Š ìµœì¢… ê²°ê³¼:")
    final_result = result['final_result']
    print(f"- ì „ì²´ íŒŒì¼: {final_result['summary']['total_files']}ê°œ")
    print(f"- ì„±ê³µ ì²˜ë¦¬: {final_result['summary']['successfully_processed']}ê°œ") 
    print(f"- í‰ê·  ì‹ ë¢°ë„: {final_result['summary']['average_confidence']:.1%}")
    print(f"- ì²˜ë¦¬ ì‹œê°„: {final_result['summary']['total_processing_time']:.1f}ì´ˆ")
    
    print("\nğŸ’ ì£¼ì–¼ë¦¬ ì¸ì‚¬ì´íŠ¸:")
    insights = final_result['jewelry_insights']
    if insights['price_mentions']:
        print(f"- ê°€ê²© ì •ë³´: {', '.join(insights['price_mentions'])}")
    if insights['quality_grades']:
        print(f"- í’ˆì§ˆ ë“±ê¸‰: {', '.join(insights['quality_grades'])}")
    
    return result

if __name__ == "__main__":
    # ë°ëª¨ ì‹¤í–‰
    import asyncio
    asyncio.run(demo_batch_processing())