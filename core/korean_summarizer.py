"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - í•œêµ­ì–´ ìµœì¢… ìš”ì•½ ë¶„ì„ê¸°
ë‹¤êµ­ì–´ ì…ë ¥ì„ í•œêµ­ì–´ë¡œ í†µí•© ìš”ì•½í•˜ê³  ì£¼ì–¼ë¦¬ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë¶„ì„
"""

import asyncio
from typing import Dict, List, Optional, Union, Tuple, Any
from datetime import datetime
import json
import logging
import re
from pathlib import Path

# ë²ˆì—­ ëª¨ë“ˆ
from .multilingual_translator import get_translator, detect_language, translate_to_korean

# AI ë¶„ì„ ëª¨ë“ˆ
from .jewelry_ai_engine import JewelryAIEngine

# í’ˆì§ˆ ë¶„ì„ ëª¨ë“ˆ
from .quality_analyzer import get_quality_analyzer

class KoreanSummarizer:
    """í•œêµ­ì–´ ìµœì¢… ìš”ì•½ ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.translator = get_translator()
        self.ai_engine = JewelryAIEngine()
        self.quality_analyzer = get_quality_analyzer()
        
        # ìƒí™©ë³„ ë¶„ì„ í…œí”Œë¦¿
        self.situation_templates = {
            "seminar": {
                "name": "ì„¸ë¯¸ë‚˜",
                "key_points": ["ì£¼ì œ", "ë°œí‘œì", "í•µì‹¬ ë‚´ìš©", "ì§ˆì˜ì‘ë‹µ", "ì°¸ê³ ìë£Œ"],
                "business_focus": ["ì‹œì¥ ë™í–¥", "ê¸°ìˆ  í˜ì‹ ", "ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ", "ë„¤íŠ¸ì›Œí‚¹"]
            },
            "meeting": {
                "name": "íšŒì˜",
                "key_points": ["ì•ˆê±´", "ê²°ì •ì‚¬í•­", "ì•¡ì…˜ ì•„ì´í…œ", "ë‹´ë‹¹ì", "ì¼ì •"],
                "business_focus": ["ì˜ì‚¬ê²°ì •", "ì—…ë¬´ ë¶„ë‹´", "ì„±ê³¼ ì§€í‘œ", "ë¦¬ìŠ¤í¬ ê´€ë¦¬"]
            },
            "lecture": {
                "name": "ê°•ì˜",
                "key_points": ["í•™ìŠµ ëª©í‘œ", "í•µì‹¬ ê°œë…", "ì‹¤ìŠµ ë‚´ìš©", "í‰ê°€ ë°©ë²•", "ê³¼ì œ"],
                "business_focus": ["êµìœ¡ íš¨ê³¼", "ì—­ëŸ‰ ê°•í™”", "ì§€ì‹ ì „ìˆ˜", "ì‹¤ë¬´ ì ìš©"]
            },
            "conference": {
                "name": "ì»¨í¼ëŸ°ìŠ¤",
                "key_points": ["ì£¼ìš” ë°œí‘œ", "íŒ¨ë„ í† ë¡ ", "ë„¤íŠ¸ì›Œí‚¹", "ì „ì‹œ ë¶€ìŠ¤", "í›„ì† ì¼ì •"],
                "business_focus": ["ì—…ê³„ íŠ¸ë Œë“œ", "ê²½ìŸì‚¬ ë™í–¥", "íŒŒíŠ¸ë„ˆì‹­", "ì‹œì¥ ê¸°íšŒ"]
            }
        }
        
        # ì£¼ì–¼ë¦¬ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í‚¤ì›Œë“œ
        self.business_keywords = {
            "market": ["ì‹œì¥", "íŠ¸ë Œë“œ", "ìˆ˜ìš”", "ê³µê¸‰", "ê°€ê²©", "ê²½ìŸ", "ì ìœ ìœ¨"],
            "product": ["ì œí’ˆ", "ë””ìì¸", "í’ˆì§ˆ", "ì¸ì¦", "ë¸Œëœë“œ", "ì°¨ë³„í™”"],
            "technology": ["ê¸°ìˆ ", "ê³µì •", "í˜ì‹ ", "ìë™í™”", "ë””ì§€í„¸", "AI"],
            "trade": ["ë¬´ì—­", "ìˆ˜ì¶œ", "ìˆ˜ì…", "ê´€ì„¸", "ì¸ì¦", "ë¬¼ë¥˜"],
            "customer": ["ê³ ê°", "ì†Œë¹„ì", "ì„ í˜¸ë„", "ë§Œì¡±ë„", "ì¶©ì„±ë„", "ì„¸ê·¸ë¨¼íŠ¸"],
            "finance": ["ë§¤ì¶œ", "ìˆ˜ìµ", "ë¹„ìš©", "íˆ¬ì", "ìê¸ˆ", "ìˆ˜ìµì„±"]
        }
        
        logging.info("í•œêµ­ì–´ ìµœì¢… ìš”ì•½ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def analyze_situation_comprehensively(self, 
                                              multimodal_results: Dict,
                                              situation_type: str = "auto",
                                              focus_areas: List[str] = None) -> Dict:
        """
        ìƒí™© ì¢…í•© ë¶„ì„ (ì„¸ë¯¸ë‚˜/íšŒì˜/ê°•ì˜ ë“±)
        
        Args:
            multimodal_results: ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼
            situation_type: ìƒí™© íƒ€ì… ("auto", "seminar", "meeting", "lecture", "conference")
            focus_areas: ì§‘ì¤‘ ë¶„ì„ ì˜ì—­
            
        Returns:
            í•œêµ­ì–´ ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        try:
            print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì¢…í•© ë¶„ì„ ì‹œì‘")
            
            # 1. ìƒí™© íƒ€ì… ìë™ ê°ì§€
            if situation_type == "auto":
                situation_type = self._detect_situation_type(multimodal_results)
            
            # 2. ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ë° ë²ˆì—­
            korean_content = await self._collect_and_translate_content(multimodal_results)
            
            # 3. í’ˆì§ˆ í‰ê°€ ì¢…í•©
            quality_assessment = await self._comprehensive_quality_assessment(multimodal_results)
            
            # 4. ìƒí™©ë³„ êµ¬ì¡°í™” ë¶„ì„
            structured_analysis = await self._perform_structured_analysis(
                korean_content, situation_type, focus_areas
            )
            
            # 5. ì£¼ì–¼ë¦¬ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  ë¶„ì„
            business_analysis = await self._analyze_business_perspective(korean_content)
            
            # 6. ìµœì¢… í•œêµ­ì–´ ìš”ì•½ ìƒì„±
            final_summary = await self._generate_final_korean_summary(
                korean_content, structured_analysis, business_analysis, situation_type
            )
            
            # 7. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
            actionable_insights = self._generate_actionable_insights(
                structured_analysis, business_analysis, quality_assessment
            )
            
            # 8. ì¢…í•© ë¦¬í¬íŠ¸ êµ¬ì„±
            comprehensive_report = {
                "success": True,
                "analysis_info": {
                    "situation_type": situation_type,
                    "situation_name": self.situation_templates.get(situation_type, {}).get("name", "ì¼ë°˜ ìƒí™©"),
                    "analysis_time": datetime.now().isoformat(),
                    "content_sources": list(multimodal_results.get("source_results", {}).keys()),
                    "total_content_length": len(korean_content)
                },
                "quality_assessment": quality_assessment,
                "korean_content": korean_content[:1000] + "..." if len(korean_content) > 1000 else korean_content,
                "structured_analysis": structured_analysis,
                "business_analysis": business_analysis,
                "final_summary": final_summary,
                "actionable_insights": actionable_insights
            }
            
            print(f"âœ… í•œêµ­ì–´ ì¢…í•© ë¶„ì„ ì™„ë£Œ: {situation_type} ({len(korean_content)}ì ë¶„ì„)")
            return comprehensive_report
            
        except Exception as e:
            logging.error(f"í•œêµ­ì–´ ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_time": datetime.now().isoformat()
            }
    
    def _detect_situation_type(self, multimodal_results: Dict) -> str:
        """ìƒí™© íƒ€ì… ìë™ ê°ì§€"""
        try:
            # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            all_text = ""
            source_results = multimodal_results.get("source_results", {})
            
            for source_data in source_results.values():
                if source_data and "combined_text" in source_data:
                    all_text += " " + source_data["combined_text"]
            
            text_lower = all_text.lower()
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
            seminar_keywords = ["ì„¸ë¯¸ë‚˜", "seminar", "ë°œí‘œ", "presentation", "ê°•ì—°", "lecture"]
            meeting_keywords = ["íšŒì˜", "meeting", "ë¯¸íŒ…", "ë…¼ì˜", "ê²°ì •", "ì•ˆê±´"]
            lecture_keywords = ["ê°•ì˜", "ìˆ˜ì—…", "êµìœ¡", "í•™ìŠµ", "ê³¼ì •", "curriculum"]
            conference_keywords = ["ì»¨í¼ëŸ°ìŠ¤", "conference", "ë°•ëŒíšŒ", "ì „ì‹œíšŒ", "í¬ëŸ¼", "forum"]
            
            scores = {
                "seminar": sum(1 for kw in seminar_keywords if kw in text_lower),
                "meeting": sum(1 for kw in meeting_keywords if kw in text_lower),
                "lecture": sum(1 for kw in lecture_keywords if kw in text_lower),
                "conference": sum(1 for kw in conference_keywords if kw in text_lower)
            }
            
            detected_type = max(scores.items(), key=lambda x: x[1])[0]
            
            # ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì¼ë°˜ íšŒì˜ë¡œ ë¶„ë¥˜
            if scores[detected_type] == 0:
                return "meeting"
            
            return detected_type
            
        except Exception as e:
            logging.warning(f"ìƒí™© íƒ€ì… ê°ì§€ ì‹¤íŒ¨: {e}")
            return "meeting"
    
    async def _collect_and_translate_content(self, multimodal_results: Dict) -> str:
        """ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ë° í•œêµ­ì–´ ë²ˆì—­"""
        try:
            korean_texts = []
            source_results = multimodal_results.get("source_results", {})
            
            for source_type, source_data in source_results.items():
                if not source_data or "combined_text" not in source_data:
                    continue
                
                text = source_data["combined_text"]
                if not text.strip():
                    continue
                
                print(f"ğŸ“ {source_type} í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘...")
                
                # ì–¸ì–´ ê°ì§€
                detected_lang = detect_language(text)
                
                if detected_lang == "ko":
                    # ì´ë¯¸ í•œêµ­ì–´
                    korean_texts.append(f"[{source_type}] {text}")
                else:
                    # í•œêµ­ì–´ë¡œ ë²ˆì—­
                    try:
                        translated = await translate_to_korean(text, source_lang=detected_lang)
                        korean_texts.append(f"[{source_type}] {translated}")
                    except Exception as e:
                        logging.warning(f"{source_type} ë²ˆì—­ ì‹¤íŒ¨: {e}")
                        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ì‚¬ìš©
                        korean_texts.append(f"[{source_type}] {text}")
            
            combined_korean = "\n\n".join(korean_texts)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° í›„ì²˜ë¦¬
            cleaned_korean = self._clean_korean_text(combined_korean)
            
            return cleaned_korean
            
        except Exception as e:
            logging.error(f"í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ë° ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return "í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨"
    
    def _clean_korean_text(self, text: str) -> str:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        try:
            # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
            text = re.sub(r'\s+', ' ', text)
            
            # ì¤‘ë³µëœ ë¬¸ì¥ ì œê±° (ê°„ë‹¨í•œ ë²„ì „)
            sentences = text.split('.')
            unique_sentences = []
            seen = set()
            
            for sentence in sentences:
                sentence = sentence.strip()
                if sentence and sentence not in seen and len(sentence) > 10:
                    unique_sentences.append(sentence)
                    seen.add(sentence)
            
            cleaned = '. '.join(unique_sentences)
            
            # ë§ˆì§€ë§‰ ì •ë¦¬
            cleaned = cleaned.replace('..', '.').replace('  ', ' ').strip()
            
            return cleaned
            
        except Exception:
            return text
    
    async def _comprehensive_quality_assessment(self, multimodal_results: Dict) -> Dict:
        """ì¢…í•© í’ˆì§ˆ í‰ê°€"""
        try:
            quality_summary = {
                "overall_score": 0.0,
                "source_qualities": {},
                "issues_found": [],
                "recommendations": []
            }
            
            source_results = multimodal_results.get("source_results", {})
            total_score = 0
            source_count = 0
            
            for source_type, source_data in source_results.items():
                if not source_data:
                    continue
                
                source_quality = {
                    "score": 0.0,
                    "details": {},
                    "issues": []
                }
                
                # ì†ŒìŠ¤ë³„ í’ˆì§ˆ í‰ê°€
                if source_type == "audio":
                    # ìŒì„± í’ˆì§ˆ (ì´ë¯¸ ë¶„ì„ëœ ê²½ìš°)
                    if "summary" in source_data and "average_confidence" in source_data["summary"]:
                        source_quality["score"] = source_data["summary"]["average_confidence"]
                        source_quality["details"]["confidence"] = source_data["summary"]["average_confidence"]
                    else:
                        source_quality["score"] = 0.7  # ê¸°ë³¸ê°’
                
                elif source_type in ["video", "documents"]:
                    # ë¹„ë””ì˜¤/ë¬¸ì„œ í’ˆì§ˆ
                    if "individual_results" in source_data:
                        scores = []
                        for result in source_data["individual_results"]:
                            if "quality_score" in result:
                                scores.append(result["quality_score"])
                            elif "confidence" in result:
                                scores.append(result["confidence"])
                        
                        if scores:
                            source_quality["score"] = sum(scores) / len(scores)
                    else:
                        source_quality["score"] = 0.6  # ê¸°ë³¸ê°’
                
                elif source_type == "web":
                    # ì›¹ ì†ŒìŠ¤ í’ˆì§ˆ (ì‹ ë¢°ë„ ê¸°ë°˜)
                    source_quality["score"] = 0.5  # ì›¹ì€ ë‚®ì€ ì‹ ë¢°ë„
                
                # í’ˆì§ˆ ì´ìŠˆ ì‹ë³„
                if source_quality["score"] < 0.6:
                    source_quality["issues"].append("ë‚®ì€ í’ˆì§ˆë¡œ ì¸í•œ ì‹ ë¢°ë„ ê°ì†Œ")
                    quality_summary["issues_found"].append(f"{source_type}: í’ˆì§ˆ ê°œì„  í•„ìš”")
                
                quality_summary["source_qualities"][source_type] = source_quality
                total_score += source_quality["score"]
                source_count += 1
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            if source_count > 0:
                quality_summary["overall_score"] = total_score / source_count
            
            # ì¢…í•© ê¶Œì¥ì‚¬í•­
            if quality_summary["overall_score"] >= 0.8:
                quality_summary["recommendations"].append("ìš°ìˆ˜í•œ í’ˆì§ˆì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.")
            elif quality_summary["overall_score"] >= 0.6:
                quality_summary["recommendations"].append("ì–‘í˜¸í•œ í’ˆì§ˆì´ì§€ë§Œ ì¼ë¶€ ê°œì„  ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            else:
                quality_summary["recommendations"].append("í’ˆì§ˆ ê°œì„ ì„ í†µí•´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                quality_summary["recommendations"].append("í˜„ì¥ ì´¬ì˜/ë…¹ìŒ í™˜ê²½ ê°œì„ ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            return quality_summary
            
        except Exception as e:
            logging.error(f"í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
            return {
                "overall_score": 0.5,
                "error": str(e)
            }
    
    async def _perform_structured_analysis(self, 
                                         korean_content: str,
                                         situation_type: str,
                                         focus_areas: List[str] = None) -> Dict:
        """ìƒí™©ë³„ êµ¬ì¡°í™” ë¶„ì„"""
        try:
            template = self.situation_templates.get(situation_type, self.situation_templates["meeting"])
            
            # AI ì—”ì§„ì„ ì‚¬ìš©í•œ êµ¬ì¡°í™” ë¶„ì„
            ai_analysis = await self.ai_engine.analyze_jewelry_content(
                korean_content,
                analysis_type="comprehensive"
            )
            
            # ìƒí™©ë³„ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
            key_points = {}
            for point in template["key_points"]:
                extracted = self._extract_content_by_keyword(korean_content, point)
                if extracted:
                    key_points[point] = extracted
            
            # ì‹œê°„ìˆœ êµ¬ì¡° ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
            timeline = self._extract_timeline(korean_content)
            
            # ì°¸ì„ì/ë°œí‘œì ì •ë³´
            participants = self._extract_participants(korean_content)
            
            # ì£¼ìš” ê²°ì •ì‚¬í•­/ê²°ë¡ 
            decisions = self._extract_decisions(korean_content)
            
            structured = {
                "situation_type": template["name"],
                "key_points": key_points,
                "timeline": timeline,
                "participants": participants,
                "decisions": decisions,
                "ai_insights": ai_analysis.get("insights", []),
                "main_topics": ai_analysis.get("main_topics", []),
                "technical_terms": ai_analysis.get("technical_analysis", {}).get("terms_found", [])
            }
            
            return structured
            
        except Exception as e:
            logging.error(f"êµ¬ì¡°í™” ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "situation_type": situation_type,
                "error": str(e)
            }
    
    def _extract_content_by_keyword(self, text: str, keyword: str) -> List[str]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë‚´ìš© ì¶”ì¶œ"""
        try:
            # í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ì¥ ì¶”ì¶œ
            sentences = re.split(r'[.!?]', text)
            related_content = []
            
            keyword_variants = {
                "ì£¼ì œ": ["ì£¼ì œ", "topic", "ì œëª©", "íƒ€ì´í‹€"],
                "ë°œí‘œì": ["ë°œí‘œì", "speaker", "presenter", "ê°•ì—°ì"],
                "í•µì‹¬ ë‚´ìš©": ["í•µì‹¬", "ì£¼ìš”", "ì¤‘ìš”", "í¬ì¸íŠ¸", "ìš”ì "],
                "ì•ˆê±´": ["ì•ˆê±´", "agenda", "ë…¼ì˜ì‚¬í•­", "í•­ëª©"],
                "ê²°ì •ì‚¬í•­": ["ê²°ì •", "ê²°ë¡ ", "í•©ì˜", "decision"],
                "ì•¡ì…˜ ì•„ì´í…œ": ["ì•¡ì…˜", "í–‰ë™", "ì‹¤í–‰", "ê³¼ì œ", "ì—…ë¬´"]
            }
            
            search_terms = keyword_variants.get(keyword, [keyword])
            
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 10:
                    continue
                
                for term in search_terms:
                    if term in sentence:
                        related_content.append(sentence)
                        break
            
            return related_content[:3]  # ìµœëŒ€ 3ê°œ
            
        except Exception:
            return []
    
    def _extract_timeline(self, text: str) -> List[Dict]:
        """ì‹œê°„ìˆœ êµ¬ì¡° ì¶”ì¶œ"""
        try:
            timeline = []
            
            # ì‹œê°„ í‘œí˜„ íŒ¨í„´
            time_patterns = [
                r'(\d{1,2}:\d{2})',  # ì‹œ:ë¶„
                r'(\d{1,2}ì‹œ\s*\d{0,2}ë¶„?)',  # Xì‹œ Yë¶„
                r'(ì˜¤ì „|ì˜¤í›„)\s*(\d{1,2}ì‹œ)',  # ì˜¤ì „/ì˜¤í›„ Xì‹œ
                r'(\d{1,2}ì›”\s*\d{1,2}ì¼)',  # Xì›” Yì¼
                r'(ì²«ì§¸|ë‘˜ì§¸|ì…‹ì§¸|ì²« ë²ˆì§¸|ë‘ ë²ˆì§¸|ì„¸ ë²ˆì§¸|ë§ˆì§€ë§‰)',  # ìˆœì„œ
                r'(ì‹œì‘|ì¤‘ê°„|ë§ˆì§€ë§‰|ê²°ë¡ |ë)'  # êµ¬ê°„
            ]
            
            sentences = re.split(r'[.!?]', text)
            
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 10:
                    continue
                
                for pattern in time_patterns:
                    match = re.search(pattern, sentence)
                    if match:
                        timeline.append({
                            "time_indicator": match.group(1),
                            "content": sentence,
                            "type": "time_based" if ":" in match.group(1) else "sequence_based"
                        })
                        break
            
            return timeline[:5]  # ìµœëŒ€ 5ê°œ
            
        except Exception:
            return []
    
    def _extract_participants(self, text: str) -> List[str]:
        """ì°¸ì„ì/ë°œí‘œì ì •ë³´ ì¶”ì¶œ"""
        try:
            participants = []
            
            # ì¸ëª… íŒ¨í„´ (í•œêµ­ì–´)
            name_patterns = [
                r'([ê°€-í£]{2,4})\s*(ëŒ€í‘œ|ì‚¬ì¥|ì´ì‚¬|ë¶€ì¥|ê³¼ì¥|íŒ€ì¥|êµìˆ˜|ë°•ì‚¬|ì—°êµ¬ì›|ì „ë¬¸ê°€)',
                r'(Mr\.|Ms\.|Dr\.)\s*([A-Z][a-z]+\s*[A-Z][a-z]+)',
                r'([ê°€-í£]{2,4})\s*(ì”¨|ë‹˜|ì„ ìƒë‹˜)',
                r'ë°œí‘œì[:\s]*([ê°€-í£]{2,4})',
                r'ê°•ì—°ì[:\s]*([ê°€-í£]{2,4})'
            ]
            
            for pattern in name_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    if isinstance(match, tuple):
                        name = ' '.join(match).strip()
                    else:
                        name = match.strip()
                    
                    if name and name not in participants:
                        participants.append(name)
            
            return participants[:10]  # ìµœëŒ€ 10ëª…
            
        except Exception:
            return []
    
    def _extract_decisions(self, text: str) -> List[str]:
        """ì£¼ìš” ê²°ì •ì‚¬í•­/ê²°ë¡  ì¶”ì¶œ"""
        try:
            decisions = []
            
            # ê²°ì •ì‚¬í•­ íŒ¨í„´
            decision_patterns = [
                r'(ê²°ì •[í–ˆí•œ][ë‹¤ë‹ˆ]|í•©ì˜[í–ˆí•œ][ë‹¤ë‹ˆ]|í™•ì •[í–ˆí•œ][ë‹¤ë‹ˆ])[^.!?]*[.!?]',
                r'(ë”°ë¼ì„œ|ê·¸ëŸ¬ë¯€ë¡œ|ê²°ë¡ ì ìœ¼ë¡œ)[^.!?]*[.!?]',
                r'(~í•˜ê¸°ë¡œ\s*í–ˆë‹¤|~í•˜ê¸°ë¡œ\s*ê²°ì •|~í•˜ê¸°ë¡œ\s*í•©ì˜)[^.!?]*[.!?]',
                r'(ì•¡ì…˜\s*ì•„ì´í…œ|ì‹¤í–‰\s*ê³„íš|í–¥í›„\s*ê³„íš)[^.!?]*[.!?]'
            ]
            
            for pattern in decision_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        decision = match[0]
                    else:
                        decision = match
                    
                    if len(decision) > 10 and decision not in decisions:
                        decisions.append(decision.strip())
            
            return decisions[:5]  # ìµœëŒ€ 5ê°œ
            
        except Exception:
            return []
    
    async def _analyze_business_perspective(self, korean_content: str) -> Dict:
        """ì£¼ì–¼ë¦¬ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  ë¶„ì„"""
        try:
            business_analysis = {
                "market_insights": [],
                "product_insights": [],
                "technology_insights": [],
                "customer_insights": [],
                "financial_insights": [],
                "strategic_recommendations": [],
                "risk_factors": [],
                "opportunities": []
            }
            
            # ê° ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì—­ë³„ í‚¤ì›Œë“œ ë¶„ì„
            for category, keywords in self.business_keywords.items():
                insights = []
                
                for keyword in keywords:
                    if keyword in korean_content:
                        # í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
                        context = self._extract_context_around_keyword(korean_content, keyword)
                        if context:
                            insights.extend(context)
                
                if insights:
                    if category == "market":
                        business_analysis["market_insights"] = insights[:3]
                    elif category == "product":
                        business_analysis["product_insights"] = insights[:3]
                    elif category == "technology":
                        business_analysis["technology_insights"] = insights[:3]
                    elif category == "customer":
                        business_analysis["customer_insights"] = insights[:3]
                    elif category == "finance":
                        business_analysis["financial_insights"] = insights[:3]
            
            # AI ì—”ì§„ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ í™œìš©
            ai_business = await self.ai_engine.analyze_jewelry_content(
                korean_content,
                analysis_type="business_focused"
            )
            
            if ai_business.get("success"):
                business_analysis["strategic_recommendations"] = ai_business.get("strategic_insights", [])[:5]
                business_analysis["opportunities"] = ai_business.get("business_opportunities", [])[:3]
                business_analysis["risk_factors"] = ai_business.get("risk_analysis", [])[:3]
            
            return business_analysis
            
        except Exception as e:
            logging.error(f"ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "error": str(e),
                "market_insights": [],
                "strategic_recommendations": []
            }
    
    def _extract_context_around_keyword(self, text: str, keyword: str, window: int = 100) -> List[str]:
        """í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ"""
        try:
            contexts = []
            start = 0
            
            while True:
                index = text.find(keyword, start)
                if index == -1:
                    break
                
                # ì•ë’¤ ë¬¸ë§¥ ì¶”ì¶œ
                context_start = max(0, index - window)
                context_end = min(len(text), index + len(keyword) + window)
                context = text[context_start:context_end].strip()
                
                if len(context) > 20 and context not in contexts:
                    contexts.append(context)
                
                start = index + 1
                
                if len(contexts) >= 3:  # ìµœëŒ€ 3ê°œ
                    break
            
            return contexts
            
        except Exception:
            return []
    
    async def _generate_final_korean_summary(self, 
                                           korean_content: str,
                                           structured_analysis: Dict,
                                           business_analysis: Dict,
                                           situation_type: str) -> Dict:
        """ìµœì¢… í•œêµ­ì–´ ìš”ì•½ ìƒì„±"""
        try:
            # AI ì—”ì§„ìœ¼ë¡œ ê³ í’ˆì§ˆ ìš”ì•½ ìƒì„±
            ai_summary = await self.ai_engine.generate_comprehensive_summary(
                korean_content,
                summary_type="korean_executive",
                max_length=1000
            )
            
            # ìƒí™©ë³„ ë§ì¶¤ ìš”ì•½
            situation_name = self.situation_templates.get(situation_type, {}).get("name", situation_type)
            
            # êµ¬ì¡°í™”ëœ ìš”ì•½ êµ¬ì„±
            structured_summary = {
                "executive_summary": self._create_executive_summary(
                    structured_analysis, business_analysis, situation_name
                ),
                "key_findings": self._extract_key_findings(structured_analysis, business_analysis),
                "main_discussions": structured_analysis.get("key_points", {}),
                "business_implications": self._create_business_implications(business_analysis),
                "next_steps": self._generate_next_steps(structured_analysis, business_analysis),
                "ai_generated_summary": ai_summary.get("summary", "") if ai_summary.get("success") else ""
            }
            
            return structured_summary
            
        except Exception as e:
            logging.error(f"ìµœì¢… ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "executive_summary": "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(e)
            }
    
    def _create_executive_summary(self, 
                                structured_analysis: Dict, 
                                business_analysis: Dict,
                                situation_name: str) -> str:
        """ê²½ì˜ì§„ìš© ìš”ì•½ ìƒì„±"""
        try:
            summary_parts = []
            
            # ìƒí™© ê°œìš”
            summary_parts.append(f"ë³¸ {situation_name}ì—ì„œëŠ”")
            
            # ì£¼ìš” ì£¼ì œ
            main_topics = structured_analysis.get("main_topics", [])
            if main_topics:
                topics_str = ", ".join(main_topics[:3])
                summary_parts.append(f"{topics_str} ë“±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë…¼ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # í•µì‹¬ ê²°ì •ì‚¬í•­
            decisions = structured_analysis.get("decisions", [])
            if decisions:
                summary_parts.append(f"ì£¼ìš” ê²°ì •ì‚¬í•­ìœ¼ë¡œëŠ” {decisions[0][:50]}... ë“±ì´ ìˆìŠµë‹ˆë‹¤.")
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ í•¨ì˜
            market_insights = business_analysis.get("market_insights", [])
            if market_insights:
                summary_parts.append(f"ì‹œì¥ ê´€ì ì—ì„œëŠ” {market_insights[0][:50]}... ë“±ì˜ ì¸ì‚¬ì´íŠ¸ê°€ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # í–¥í›„ ê³„íš
            opportunities = business_analysis.get("opportunities", [])
            if opportunities:
                summary_parts.append(f"í–¥í›„ {opportunities[0][:50]}... ë“±ì˜ ê¸°íšŒë¥¼ ê³ ë ¤í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.")
            
            return " ".join(summary_parts)
            
        except Exception:
            return f"ë³¸ {situation_name}ì˜ ì£¼ìš” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤."
    
    def _extract_key_findings(self, 
                            structured_analysis: Dict, 
                            business_analysis: Dict) -> List[str]:
        """í•µì‹¬ ë°œê²¬ì‚¬í•­ ì¶”ì¶œ"""
        findings = []
        
        # êµ¬ì¡°í™”ëœ ë¶„ì„ì—ì„œ ì¶”ì¶œ
        ai_insights = structured_analysis.get("ai_insights", [])
        findings.extend(ai_insights[:2])
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ì—ì„œ ì¶”ì¶œ
        strategic_recommendations = business_analysis.get("strategic_recommendations", [])
        findings.extend(strategic_recommendations[:2])
        
        # ê¸°ìˆ ì  ë°œê²¬ì‚¬í•­
        technical_terms = structured_analysis.get("technical_terms", [])
        if technical_terms:
            findings.append(f"ì£¼ìš” ê¸°ìˆ  ìš©ì–´: {', '.join(technical_terms[:5])}")
        
        return findings[:5]  # ìµœëŒ€ 5ê°œ
    
    def _create_business_implications(self, business_analysis: Dict) -> Dict:
        """ë¹„ì¦ˆë‹ˆìŠ¤ í•¨ì˜ ì •ë¦¬"""
        implications = {
            "market_impact": business_analysis.get("market_insights", [])[:2],
            "product_impact": business_analysis.get("product_insights", [])[:2],
            "financial_impact": business_analysis.get("financial_insights", [])[:2],
            "strategic_impact": business_analysis.get("strategic_recommendations", [])[:2]
        }
        
        return {k: v for k, v in implications.items() if v}
    
    def _generate_next_steps(self, 
                           structured_analysis: Dict, 
                           business_analysis: Dict) -> List[str]:
        """í–¥í›„ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
        next_steps = []
        
        # ê²°ì •ì‚¬í•­ì—ì„œ ì¶”ì¶œ
        decisions = structured_analysis.get("decisions", [])
        for decision in decisions[:2]:
            next_steps.append(f"ê²°ì •ì‚¬í•­ ì‹¤í–‰: {decision[:50]}...")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒì—ì„œ ì¶”ì¶œ
        opportunities = business_analysis.get("opportunities", [])
        for opportunity in opportunities[:2]:
            next_steps.append(f"ê¸°íšŒ í™œìš©: {opportunity[:50]}...")
        
        # ë¦¬ìŠ¤í¬ ëŒ€ì‘
        risks = business_analysis.get("risk_factors", [])
        for risk in risks[:1]:
            next_steps.append(f"ë¦¬ìŠ¤í¬ ê´€ë¦¬: {risk[:50]}...")
        
        # ê¸°ë³¸ ì•¡ì…˜ ì•„ì´í…œ
        if not next_steps:
            next_steps = [
                "íšŒì˜ ë‚´ìš©ì„ ì´í•´ê´€ê³„ìë“¤ê³¼ ê³µìœ ",
                "í•µì‹¬ ê²°ì •ì‚¬í•­ì— ëŒ€í•œ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½",
                "í›„ì† íšŒì˜ ì¼ì • ì¡°ì •"
            ]
        
        return next_steps[:5]
    
    def _generate_actionable_insights(self, 
                                    structured_analysis: Dict,
                                    business_analysis: Dict,
                                    quality_assessment: Dict) -> Dict:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
        try:
            insights = {
                "immediate_actions": [],
                "short_term_goals": [],
                "long_term_strategy": [],
                "quality_improvements": [],
                "success_metrics": []
            }
            
            # ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜
            decisions = structured_analysis.get("decisions", [])
            insights["immediate_actions"] = [f"ì‹¤í–‰: {d[:40]}..." for d in decisions[:3]]
            
            # ë‹¨ê¸° ëª©í‘œ
            opportunities = business_analysis.get("opportunities", [])
            insights["short_term_goals"] = [f"ëª©í‘œ: {o[:40]}..." for o in opportunities[:3]]
            
            # ì¥ê¸° ì „ëµ
            strategic_recommendations = business_analysis.get("strategic_recommendations", [])
            insights["long_term_strategy"] = [f"ì „ëµ: {s[:40]}..." for s in strategic_recommendations[:3]]
            
            # í’ˆì§ˆ ê°œì„ ì‚¬í•­
            quality_recommendations = quality_assessment.get("recommendations", [])
            insights["quality_improvements"] = quality_recommendations[:3]
            
            # ì„±ê³µ ì§€í‘œ
            insights["success_metrics"] = [
                "ì°¸ì„ì ë§Œì¡±ë„ ì¡°ì‚¬",
                "ê²°ì •ì‚¬í•­ ì‹¤í–‰ë¥  ì¶”ì ",
                "ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ì¸¡ì •"
            ]
            
            return insights
            
        except Exception as e:
            logging.error(f"ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "immediate_actions": ["ë¶„ì„ ê²°ê³¼ ê²€í† "],
                "error": str(e)
            }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_korean_summarizer_instance = None

def get_korean_summarizer() -> KoreanSummarizer:
    """ì „ì—­ í•œêµ­ì–´ ìš”ì•½ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _korean_summarizer_instance
    if _korean_summarizer_instance is None:
        _korean_summarizer_instance = KoreanSummarizer()
    return _korean_summarizer_instance

# í¸ì˜ í•¨ìˆ˜ë“¤
async def analyze_situation_in_korean(multimodal_results: Dict, **kwargs) -> Dict:
    """ìƒí™© ì¢…í•© ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    summarizer = get_korean_summarizer()
    return await summarizer.analyze_situation_comprehensively(multimodal_results, **kwargs)

async def generate_korean_executive_summary(content: str, situation_type: str = "meeting") -> Dict:
    """í•œêµ­ì–´ ê²½ì˜ì§„ìš© ìš”ì•½ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    # ê°„ë‹¨í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„
    mock_results = {
        "source_results": {
            "primary": {
                "combined_text": content
            }
        }
    }
    
    return await analyze_situation_in_korean(mock_results, situation_type=situation_type)

if __name__ == "__main__":
    print("í•œêµ­ì–´ ìµœì¢… ìš”ì•½ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸")
    print("ì§€ì› ìƒí™© íƒ€ì…:", list(KoreanSummarizer().situation_templates.keys()))
