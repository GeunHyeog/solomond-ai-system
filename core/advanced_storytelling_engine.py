#!/usr/bin/env python3
"""
ê³ ê¸‰ ìŠ¤í† ë¦¬í…”ë§ ì—”ì§„ - GPT-4 API í†µí•©
ë‹¤ì¤‘ ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ í•œêµ­ì–´ ì´ì•¼ê¸°ë¡œ ì¡°í•©
"""

import os
import json
import time
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

try:
    from openai import OpenAI
    openai_available = True
except ImportError:
    openai_available = False

try:
    import anthropic
    claude_available = True
except ImportError:
    claude_available = False

# í•œêµ­ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from kss import split_sentences
    kss_available = True
except ImportError:
    kss_available = False

try:
    from konlpy.tag import Okt
    konlpy_available = True
except ImportError:
    konlpy_available = False

class AdvancedStorytellingEngine:
    """
    ë‹¤ì¤‘ ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ í•œêµ­ì–´ ìŠ¤í† ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ê³ ê¸‰ ì—”ì§„
    """
    
    def __init__(self):
        self.logger = self._setup_logger()
        
        # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.gpt4_client = None
        self.claude_client = None
        self.korean_analyzer = None
        
        self._initialize_ai_clients()
        self._initialize_korean_nlp()
        
        # ìŠ¤í† ë¦¬ í…œí”Œë¦¿
        self.story_templates = self._load_story_templates()
        
        self.logger.info("ğŸ­ ê³ ê¸‰ ìŠ¤í† ë¦¬í…”ë§ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger(f"{__name__}.AdvancedStorytellingEngine")
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _initialize_ai_clients(self):
        """AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        
        # OpenAI GPT-4 í´ë¼ì´ì–¸íŠ¸
        if openai_available:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                try:
                    self.gpt4_client = OpenAI(api_key=api_key)
                    self.logger.info("âœ… GPT-4 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ GPT-4 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            else:
                self.logger.info("â„¹ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        # Anthropic Claude í´ë¼ì´ì–¸íŠ¸
        if claude_available:
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if api_key:
                try:
                    self.claude_client = anthropic.Anthropic(api_key=api_key)
                    self.logger.info("âœ… Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Claude ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            else:
                self.logger.info("â„¹ï¸ ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    
    def _initialize_korean_nlp(self):
        """í•œêµ­ì–´ NLP ë„êµ¬ ì´ˆê¸°í™”"""
        if konlpy_available:
            try:
                self.korean_analyzer = Okt()
                self.logger.info("âœ… í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ í•œêµ­ì–´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _load_story_templates(self):
        """ìŠ¤í† ë¦¬ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            "general": {
                "intro": "ë‹¤ìŒì€ ë¶„ì„ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì„±í•œ ì¢…í•©ì ì¸ ì´ì•¼ê¸°ì…ë‹ˆë‹¤.",
                "sections": ["ìƒí™© ê°œìš”", "ì£¼ìš” ëŒ€í™” ë‚´ìš©", "í•µì‹¬ ë©”ì‹œì§€", "ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸"],
                "style": "ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±"
            },
            "consultation": {
                "intro": "ê³ ê° ìƒë‹´ ë‚´ìš©ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
                "sections": ["ê³ ê° ìš”ì²­ì‚¬í•­", "ìƒë‹´ ì§„í–‰ê³¼ì •", "ì œê³µëœ ì •ë³´", "ê³ ê° ë°˜ì‘", "í›„ì† ì¡°ì¹˜"],
                "style": "ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì— ì í•©í•œ ì •ì¤‘í•˜ê³  ëª…í™•í•œ í•œêµ­ì–´"
            },
            "meeting": {
                "intro": "íšŒì˜ ë‚´ìš©ì„ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
                "sections": ["íšŒì˜ ëª©ì ", "ì£¼ìš” ì•ˆê±´", "ë…¼ì˜ ì‚¬í•­", "ê²°ì • ì‚¬í•­", "ì•¡ì…˜ ì•„ì´í…œ"],
                "style": "ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì •í™•í•˜ê³  ê°„ê²°í•œ í•œêµ­ì–´"
            },
            "multimedia": {
                "intro": "ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ í•˜ë‚˜ì˜ ìŠ¤í† ë¦¬ë¡œ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.",
                "sections": ["ì‹œê°„ìˆœ ì „ê°œ", "í•µì‹¬ ë‚´ìš©", "ë“±ì¥ì¸ë¬¼/í™”ì", "ì£¼ìš” ë©”ì‹œì§€", "ì¢…í•© í‰ê°€"],
                "style": "ì„œì‚¬ì ì´ê³  í¥ë¯¸ë¡œìš´ í•œêµ­ì–´ ìŠ¤í† ë¦¬í…”ë§"
            }
        }
    
    def create_comprehensive_story(self, analysis_results: Dict[str, Any], 
                                   story_type: str = "general") -> Dict[str, Any]:
        """
        ë‹¤ì¤‘ ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ í•œêµ­ì–´ ìŠ¤í† ë¦¬ë¡œ ë³€í™˜
        
        Args:
            analysis_results: ë‹¤ì¤‘ ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼
            story_type: ìŠ¤í† ë¦¬ ìœ í˜• (general, consultation, meeting, multimedia)
            
        Returns:
            Dict containing the generated Korean story
        """
        
        try:
            self.logger.info(f"ğŸ­ ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„± ì‹œì‘ - ìœ í˜•: {story_type}")
            
            # 1. ë°ì´í„° ì „ì²˜ë¦¬ ë° êµ¬ì¡°í™”
            structured_data = self._structure_analysis_data(analysis_results)
            
            # 2. ì‹œê°„ìˆœ ì •ë ¬ ë° ë§¥ë½ ë¶„ì„
            temporal_context = self._analyze_temporal_context(structured_data)
            
            # 3. í•µì‹¬ ë©”ì‹œì§€ ì¶”ì¶œ
            key_messages = self._extract_key_messages(structured_data)
            
            # 4. AI ê¸°ë°˜ ìŠ¤í† ë¦¬ ìƒì„±
            generated_story = self._generate_ai_story(
                structured_data, temporal_context, key_messages, story_type
            )
            
            # 5. í•œêµ­ì–´ ë¬¸ì¥ ë‹¤ë“¬ê¸°
            polished_story = self._polish_korean_text(generated_story)
            
            # 6. ê²°ê³¼ êµ¬ì„±
            story_result = {
                "status": "success",
                "story_type": story_type,
                "generated_at": datetime.now().isoformat(),
                "story": polished_story,
                "metadata": {
                    "source_count": len(analysis_results.get("sources", [])),
                    "total_content_length": len(str(structured_data)),
                    "key_messages_count": len(key_messages),
                    "ai_engine_used": self._get_available_ai_engine()
                }
            }
            
            self.logger.info("âœ… ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„± ì™„ë£Œ")
            return story_result
            
        except Exception as e:
            self.logger.error(f"âŒ ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "story_type": story_type,
                "fallback_story": self._create_fallback_story(analysis_results)
            }
    
    def _structure_analysis_data(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        
        structured = {
            "audio_content": [],
            "visual_content": [], 
            "document_content": [],
            "metadata": {
                "sources": [],
                "timestamps": [],
                "confidence_scores": []
            }
        }
        
        sources = analysis_results.get("sources", [])
        
        for source in sources:
            source_type = source.get("type", "unknown")
            content = source.get("analysis_result", {})
            
            if source_type == "audio":
                if content.get("transcription"):
                    structured["audio_content"].append({
                        "text": content["transcription"],
                        "confidence": content.get("confidence", 0.0),
                        "timestamp": source.get("timestamp"),
                        "source_name": source.get("name", "Unknown")
                    })
            
            elif source_type == "image":
                if content.get("text"):
                    structured["visual_content"].append({
                        "text": content["text"],
                        "confidence": content.get("confidence", 0.0),
                        "source_name": source.get("name", "Unknown")
                    })
            
            elif source_type == "document":
                if content.get("text"):
                    structured["document_content"].append({
                        "text": content["text"],
                        "source_name": source.get("name", "Unknown")
                    })
            
            # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            structured["metadata"]["sources"].append(source.get("name", "Unknown"))
            if source.get("timestamp"):
                structured["metadata"]["timestamps"].append(source["timestamp"])
        
        return structured
    
    def _analyze_temporal_context(self, structured_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œê°„ì  ë§¥ë½ ë¶„ì„"""
        
        timestamps = structured_data["metadata"]["timestamps"]
        
        if not timestamps:
            return {"has_temporal_data": False}
        
        # ì‹œê°„ìˆœ ì •ë ¬
        sorted_timestamps = sorted(timestamps)
        
        return {
            "has_temporal_data": True,
            "start_time": sorted_timestamps[0] if sorted_timestamps else None,
            "end_time": sorted_timestamps[-1] if sorted_timestamps else None,
            "duration": len(sorted_timestamps),
            "temporal_flow": "sequential" if len(set(sorted_timestamps)) > 1 else "single_moment"
        }
    
    def _extract_key_messages(self, structured_data: Dict[str, Any]) -> List[str]:
        """í•µì‹¬ ë©”ì‹œì§€ ì¶”ì¶œ"""
        
        key_messages = []
        
        # ì˜¤ë””ì˜¤ ë‚´ìš©ì—ì„œ í•µì‹¬ ë©”ì‹œì§€
        for audio in structured_data["audio_content"]:
            text = audio["text"]
            if len(text) > 50:  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ë§Œ
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì¶”í›„ ê³ ë„í™” í•„ìš”)
                if any(keyword in text for keyword in ["ê°€ê²©", "êµ¬ë§¤", "ë¬¸ì˜", "ì£¼ë¬¸"]):
                    key_messages.append(f"êµ¬ë§¤ ê´€ë ¨: {text[:100]}...")
                elif any(keyword in text for keyword in ["ë¬¸ì œ", "ì˜¤ë¥˜", "ìˆ˜ë¦¬"]):
                    key_messages.append(f"ë¬¸ì œ í•´ê²°: {text[:100]}...")
                else:
                    key_messages.append(f"ì¼ë°˜ ëŒ€í™”: {text[:100]}...")
        
        # ì‹œê°ì  ë‚´ìš©ì—ì„œ í•µì‹¬ ì •ë³´
        for visual in structured_data["visual_content"]:
            text = visual["text"]
            if len(text) > 20:
                key_messages.append(f"í™”ë©´ ì •ë³´: {text[:80]}...")
        
        return key_messages[:10]  # ìµœëŒ€ 10ê°œ í•µì‹¬ ë©”ì‹œì§€
    
    def _generate_ai_story(self, structured_data: Dict[str, Any], 
                          temporal_context: Dict[str, Any],
                          key_messages: List[str], 
                          story_type: str) -> str:
        """AIë¥¼ í™œìš©í•œ ìŠ¤í† ë¦¬ ìƒì„±"""
        
        template = self.story_templates.get(story_type, self.story_templates["general"])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._create_story_prompt(structured_data, temporal_context, key_messages, template)
        
        # AI ì—”ì§„ ì„ íƒ ë° ìŠ¤í† ë¦¬ ìƒì„±
        if self.gpt4_client:
            return self._generate_with_gpt4(prompt)
        elif self.claude_client:
            return self._generate_with_claude(prompt)
        else:
            return self._generate_with_local_model(structured_data, key_messages)
    
    def _create_story_prompt(self, structured_data: Dict[str, Any],
                           temporal_context: Dict[str, Any], 
                           key_messages: List[str],
                           template: Dict[str, Any]) -> str:
        """ìŠ¤í† ë¦¬ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ì‘ì„±"""
        
        audio_texts = [item["text"] for item in structured_data["audio_content"]]
        visual_texts = [item["text"] for item in structured_data["visual_content"]]
        document_texts = [item["text"] for item in structured_data["document_content"]]
        
        prompt = f"""
ë‹¤ìŒì˜ ë‹¤ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ê´€ëœ í•œêµ­ì–´ ì´ì•¼ê¸°ë¥¼ êµ¬ì„±í•´ì£¼ì„¸ìš”.

{template["intro"]}

=== ë¶„ì„ ë°ì´í„° ===

**ìŒì„±/ëŒ€í™” ë‚´ìš©:**
{chr(10).join(audio_texts[:5]) if audio_texts else "ìŒì„± ë°ì´í„° ì—†ìŒ"}

**í™”ë©´/ì´ë¯¸ì§€ í…ìŠ¤íŠ¸:**
{chr(10).join(visual_texts[:3]) if visual_texts else "ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ"}

**ë¬¸ì„œ ë‚´ìš©:**
{chr(10).join(document_texts[:3]) if document_texts else "ë¬¸ì„œ ë°ì´í„° ì—†ìŒ"}

**í•µì‹¬ ë©”ì‹œì§€:**
{chr(10).join(key_messages[:5])}

**ì‹œê°„ì  ë§¥ë½:**
{json.dumps(temporal_context, ensure_ascii=False, indent=2)}

=== ìš”ì²­ì‚¬í•­ ===

ë‹¤ìŒ êµ¬ì¡°ë¡œ {template["style"]}ì„ ì‚¬ìš©í•´ì„œ ì¢…í•©ì ì¸ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{chr(10).join([f"{i+1}. {section}" for i, section in enumerate(template["sections"])])}

**ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­:**
1. ëª¨ë“  ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”
2. ì‹œê°„ìˆœì´ë‚˜ ë…¼ë¦¬ì  ìˆœì„œë¡œ ë‚´ìš©ì„ êµ¬ì„±í•˜ì„¸ìš”  
3. "ëˆ„ê°€ ë¬´ì—‡ì„ ë§í–ˆëŠ”ì§€" ëª…í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•˜ì„¸ìš”
4. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë‚˜ ê²°ë¡ ì„ í¬í•¨í•˜ì„¸ìš”
5. ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”

ìµœì¢… ê²°ê³¼ëŠ” ì™„ì „í•œ í•˜ë‚˜ì˜ ì´ì•¼ê¸° í˜•íƒœë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    def _generate_with_gpt4(self, prompt: str) -> str:
        """GPT-4ë¥¼ ì‚¬ìš©í•œ ìŠ¤í† ë¦¬ ìƒì„±"""
        
        try:
            response = self.gpt4_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë‹¤ì¤‘ ì†ŒìŠ¤ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ í•œêµ­ì–´ ìŠ¤í† ë¦¬ë¡œ êµ¬ì„±í•˜ëŠ” ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•´ì„œ ì½ê¸° ì‰¬ìš´ ì´ì•¼ê¸°ë¥¼ ë§Œë“œì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"GPT-4 ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_with_claude(self, prompt: str) -> str:
        """Claudeë¥¼ ì‚¬ìš©í•œ ìŠ¤í† ë¦¬ ìƒì„±"""
        
        try:
            response = self.claude_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=2000,
                messages=[{
                    "role": "user", 
                    "content": prompt
                }]
            )
            
            return response.content[0].text.strip()
            
        except Exception as e:
            self.logger.error(f"Claude ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_with_local_model(self, structured_data: Dict[str, Any], 
                                  key_messages: List[str]) -> str:
        """ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê¸°ë³¸ ìŠ¤í† ë¦¬ ìƒì„±"""
        
        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìŠ¤í† ë¦¬ ìƒì„± (AI APIê°€ ì—†ì„ ë•Œ í´ë°±)
        story_parts = []
        
        story_parts.append("## ì¢…í•© ë¶„ì„ ê²°ê³¼")
        story_parts.append("")
        
        if structured_data["audio_content"]:
            story_parts.append("### ëŒ€í™” ë‚´ìš©")
            for i, audio in enumerate(structured_data["audio_content"][:3], 1):
                story_parts.append(f"{i}. {audio['text'][:200]}...")
            story_parts.append("")
        
        if structured_data["visual_content"]:
            story_parts.append("### í™”ë©´/ë¬¸ì„œ ì •ë³´")  
            for i, visual in enumerate(structured_data["visual_content"][:3], 1):
                story_parts.append(f"{i}. {visual['text'][:150]}...")
            story_parts.append("")
        
        if key_messages:
            story_parts.append("### í•µì‹¬ ë©”ì‹œì§€")
            for i, message in enumerate(key_messages[:5], 1):
                story_parts.append(f"{i}. {message}")
            story_parts.append("")
        
        story_parts.append("### ì¢…í•© ì˜ê²¬")
        story_parts.append("ìœ„ì˜ ë‚´ìš©ì„ ì¢…í•©í•´ë³´ë©´, ì£¼ìš” ëŒ€í™”ë‚˜ ìƒí˜¸ì‘ìš©ì´ ì´ë£¨ì–´ì¡Œìœ¼ë©°, êµ¬ì²´ì ì¸ ë‚´ìš©ê³¼ ë§¥ë½ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return "\n".join(story_parts)
    
    def _polish_korean_text(self, text: str) -> str:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë‹¤ë“¬ê¸°"""
        
        if not text:
            return text
            
        # ê¸°ë³¸ì ì¸ ì •ì œ ì‘ì—…
        polished = text.strip()
        
        # í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¦¬ (kss ì‚¬ìš© ê°€ëŠ¥í•  ë•Œ)
        if kss_available:
            try:
                sentences = split_sentences(polished)
                polished = "\n\n".join(sentences) if len(sentences) > 1 else polished
            except:
                pass
        
        # ê¸°ë³¸ì ì¸ ë¬¸ì¥ ì •ì œ
        polished = polished.replace("  ", " ")  # ì´ì¤‘ ê³µë°± ì œê±°
        polished = polished.replace("\n\n\n", "\n\n")  # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
        
        return polished
    
    def _get_available_ai_engine(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ AI ì—”ì§„ ë°˜í™˜"""
        if self.gpt4_client:
            return "GPT-4"
        elif self.claude_client:
            return "Claude"
        else:
            return "Local Template"
    
    def _create_fallback_story(self, analysis_results: Dict[str, Any]) -> str:
        """í´ë°± ìŠ¤í† ë¦¬ ìƒì„±"""
        return f"""
## ë¶„ì„ ê²°ê³¼ ìš”ì•½

ì´ {len(analysis_results.get('sources', []))}ê°œì˜ ì†ŒìŠ¤ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.

ë¶„ì„ëœ ë‚´ìš©ì„ í†µí•´ ë‹¤ì–‘í•œ ì •ë³´ì™€ ëŒ€í™”ê°€ í¬í•¨ë˜ì–´ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.
ë” ìƒì„¸í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” AI ì—”ì§„ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì°¸ê³ **: OpenAI API Key ë˜ëŠ” Anthropic API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•˜ë©´ 
ë”ìš± ìƒì„¸í•˜ê³  ì¼ê´€ëœ ìŠ¤í† ë¦¬ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""

# ì „ì—­ ìŠ¤í† ë¦¬í…”ë§ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
global_storytelling_engine = AdvancedStorytellingEngine()

def create_comprehensive_korean_story(analysis_results: Dict[str, Any], 
                                     story_type: str = "general") -> Dict[str, Any]:
    """
    ë‹¤ì¤‘ ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ í•œêµ­ì–´ ìŠ¤í† ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        analysis_results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        story_type: ìŠ¤í† ë¦¬ ìœ í˜• (general, consultation, meeting, multimedia)
    
    Returns:
        ìƒì„±ëœ í•œêµ­ì–´ ìŠ¤í† ë¦¬ ë”•ì…”ë„ˆë¦¬
    """
    return global_storytelling_engine.create_comprehensive_story(analysis_results, story_type)