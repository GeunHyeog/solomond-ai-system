"""
ğŸ”¬ Solomond AI v2.1 - í’ˆì§ˆ ê²€ì¦ ì—”ì§„
ìŒì„± ë…¸ì´ì¦ˆ, OCR í’ˆì§ˆ, ì´ë¯¸ì§€ í’ˆì§ˆì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ê³  ê²€ì¦í•˜ëŠ” ì‹œìŠ¤í…œ

Author: ì „ê·¼í˜ (Solomond)
Created: 2025.07.11
Version: 2.1.0
"""

import numpy as np
import cv2
import librosa
import pytesseract
from PIL import Image
import easyocr
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import json
import time

@dataclass
class QualityScore:
    """í’ˆì§ˆ ì ìˆ˜ ë°ì´í„° í´ë˜ìŠ¤"""
    overall_score: float  # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (0-100)
    audio_score: float    # ìŒì„± í’ˆì§ˆ ì ìˆ˜
    ocr_score: float      # OCR í’ˆì§ˆ ì ìˆ˜
    image_score: float    # ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜
    details: Dict[str, Any]  # ì„¸ë¶€ ë¶„ì„ ê²°ê³¼
    recommendations: List[str]  # ê°œì„  ê¶Œì¥ì‚¬í•­
    timestamp: float

class AudioQualityChecker:
    """ìŒì„± í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def analyze_audio_quality(self, audio_path: str) -> Dict[str, Any]:
        """ìŒì„± íŒŒì¼ì˜ í’ˆì§ˆì„ ì¢…í•© ë¶„ì„"""
        try:
            # ìŒì„± ë¡œë“œ
            y, sr = librosa.load(audio_path, sr=None)
            
            # 1. SNR (Signal-to-Noise Ratio) ê³„ì‚°
            snr_db = self.calculate_snr(y, sr)
            
            # 2. ìŒì„± ëª…ë£Œë„ ë¶„ì„
            clarity_score = self.analyze_speech_clarity(y, sr)
            
            # 3. ë°°ê²½ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¸¡ì •
            noise_level = self.measure_background_noise(y, sr)
            
            # 4. ìŒì„± ì—°ì†ì„± ë¶„ì„
            continuity_score = self.analyze_speech_continuity(y, sr)
            
            # 5. ì£¼íŒŒìˆ˜ ë¶„í¬ ë¶„ì„
            freq_quality = self.analyze_frequency_distribution(y, sr)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            overall_score = self.calculate_audio_overall_score({
                'snr': snr_db,
                'clarity': clarity_score,
                'noise_level': noise_level,
                'continuity': continuity_score,
                'frequency': freq_quality
            })
            
            return {
                'snr_db': snr_db,
                'clarity_score': clarity_score,
                'noise_level': noise_level,
                'continuity_score': continuity_score,
                'frequency_quality': freq_quality,
                'overall_score': overall_score,
                'duration': len(y) / sr,
                'sample_rate': sr,
                'recommendations': self.generate_audio_recommendations(overall_score, snr_db, noise_level)
            }
            
        except Exception as e:
            self.logger.error(f"ìŒì„± í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'overall_score': 0,
                'recommendations': ['ìŒì„± íŒŒì¼ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.']
            }
    
    def calculate_snr(self, y: np.ndarray, sr: int) -> float:
        """SNR (Signal-to-Noise Ratio) ê³„ì‚°"""
        try:
            # RMS ì—ë„ˆì§€ ê³„ì‚°
            rms_energy = librosa.feature.rms(y=y)[0]
            
            # ìŒì„± êµ¬ê°„ê³¼ ë¬´ìŒ êµ¬ê°„ ë¶„ë¦¬
            intervals = librosa.effects.split(y, top_db=20)
            
            if len(intervals) == 0:
                return 0.0
            
            # ìŒì„± êµ¬ê°„ì˜ í‰ê·  ì—ë„ˆì§€
            signal_energy = []
            for start, end in intervals:
                signal_energy.extend(rms_energy[start//512:end//512])
            
            # ì „ì²´ êµ¬ê°„ì—ì„œ ìŒì„± êµ¬ê°„ ì œì™¸í•œ ë…¸ì´ì¦ˆ êµ¬ê°„
            noise_energy = []
            last_end = 0
            for start, end in intervals:
                if start > last_end:
                    noise_energy.extend(rms_energy[last_end//512:start//512])
                last_end = end
            
            if len(noise_energy) == 0:
                return 30.0  # ë…¸ì´ì¦ˆê°€ ì—†ë‹¤ë©´ ë†’ì€ SNR
            
            signal_power = np.mean(signal_energy) ** 2
            noise_power = np.mean(noise_energy) ** 2
            
            if noise_power == 0:
                return 30.0
            
            snr = 10 * np.log10(signal_power / noise_power)
            return max(0, min(40, snr))  # 0-40dB ë²”ìœ„ë¡œ ì œí•œ
            
        except Exception as e:
            self.logger.error(f"SNR ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def analyze_speech_clarity(self, y: np.ndarray, sr: int) -> float:
        """ìŒì„± ëª…ë£Œë„ ë¶„ì„ (0-100ì )"""
        try:
            # 1. ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ (ìŒì„±ì˜ ë°ê¸°)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            centroid_score = min(100, np.mean(spectral_centroids) / 30)
            
            # 2. ì˜êµì°¨ìœ¨ (ìŒì„±ì˜ ì•ˆì •ì„±)
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            zcr_score = min(100, (1 - np.std(zcr)) * 100)
            
            # 3. ìŠ¤í™íŠ¸ëŸ´ ëŒ€ì—­í­ (ìŒì„±ì˜ ì„ ëª…ë„)
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            bandwidth_score = min(100, np.mean(spectral_bandwidth) / 50)
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ëª…ë£Œë„ ì ìˆ˜ ê³„ì‚°
            clarity_score = (centroid_score * 0.4 + zcr_score * 0.3 + bandwidth_score * 0.3)
            return max(0, min(100, clarity_score))
            
        except Exception as e:
            self.logger.error(f"ìŒì„± ëª…ë£Œë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def measure_background_noise(self, y: np.ndarray, sr: int) -> float:
        """ë°°ê²½ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¸¡ì • (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, 0-100)"""
        try:
            # ë¬´ìŒ êµ¬ê°„ ê°ì§€
            intervals = librosa.effects.split(y, top_db=20)
            
            # ë¬´ìŒ êµ¬ê°„ì˜ RMS ì—ë„ˆì§€ ê³„ì‚°
            noise_segments = []
            last_end = 0
            
            for start, end in intervals:
                if start > last_end + sr * 0.5:  # 0.5ì´ˆ ì´ìƒì˜ ë¬´ìŒ êµ¬ê°„
                    noise_segment = y[last_end:start]
                    if len(noise_segment) > sr * 0.1:  # 0.1ì´ˆ ì´ìƒ
                        noise_segments.append(noise_segment)
                last_end = end
            
            if not noise_segments:
                return 10.0  # ë¬´ìŒ êµ¬ê°„ì´ ì—†ìœ¼ë©´ ë‚®ì€ ë…¸ì´ì¦ˆë¡œ ê°€ì •
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚°
            all_noise = np.concatenate(noise_segments)
            noise_rms = np.sqrt(np.mean(all_noise ** 2))
            
            # 0-100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            noise_level = min(100, noise_rms * 1000)
            return noise_level
            
        except Exception as e:
            self.logger.error(f"ë°°ê²½ ë…¸ì´ì¦ˆ ì¸¡ì • ì‹¤íŒ¨: {e}")
            return 50.0
    
    def analyze_speech_continuity(self, y: np.ndarray, sr: int) -> float:
        """ìŒì„± ì—°ì†ì„± ë¶„ì„ (0-100ì )"""
        try:
            # ìŒì„± êµ¬ê°„ ê°ì§€
            intervals = librosa.effects.split(y, top_db=20)
            
            if len(intervals) == 0:
                return 0.0
            
            # ìŒì„± êµ¬ê°„ ê¸¸ì´ì™€ ê°„ê²© ë¶„ì„
            speech_lengths = []
            silence_lengths = []
            
            for i, (start, end) in enumerate(intervals):
                speech_lengths.append((end - start) / sr)
                
                if i > 0:
                    prev_end = intervals[i-1][1]
                    silence_lengths.append((start - prev_end) / sr)
            
            # ì—°ì†ì„± ì ìˆ˜ ê³„ì‚°
            avg_speech_length = np.mean(speech_lengths)
            avg_silence_length = np.mean(silence_lengths) if silence_lengths else 0
            
            # ì ì ˆí•œ ë°œí™” ê¸¸ì´ì™€ ì¹¨ë¬µ ê¸¸ì´ ê¸°ì¤€
            speech_score = min(100, avg_speech_length * 20)  # 5ì´ˆê°€ ë§Œì 
            silence_score = max(0, 100 - avg_silence_length * 50)  # 2ì´ˆ ì´ìƒ ì¹¨ë¬µ ì‹œ ê°ì 
            
            continuity_score = (speech_score * 0.7 + silence_score * 0.3)
            return max(0, min(100, continuity_score))
            
        except Exception as e:
            self.logger.error(f"ìŒì„± ì—°ì†ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def analyze_frequency_distribution(self, y: np.ndarray, sr: int) -> float:
        """ì£¼íŒŒìˆ˜ ë¶„í¬ í’ˆì§ˆ ë¶„ì„ (0-100ì )"""
        try:
            # STFT ê³„ì‚°
            stft = librosa.stft(y)
            magnitude = np.abs(stft)
            
            # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ë¶„ì„
            freq_bins = librosa.fft_frequencies(sr=sr)
            
            # ìŒì„± ì£¼ìš” ì£¼íŒŒìˆ˜ ëŒ€ì—­ (80Hz-8000Hz)
            speech_mask = (freq_bins >= 80) & (freq_bins <= 8000)
            speech_energy = np.mean(magnitude[speech_mask])
            
            # ì „ì²´ ì—ë„ˆì§€ ëŒ€ë¹„ ìŒì„± ëŒ€ì—­ ì—ë„ˆì§€ ë¹„ìœ¨
            total_energy = np.mean(magnitude)
            
            if total_energy == 0:
                return 0.0
            
            freq_quality = (speech_energy / total_energy) * 100
            return max(0, min(100, freq_quality))
            
        except Exception as e:
            self.logger.error(f"ì£¼íŒŒìˆ˜ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def calculate_audio_overall_score(self, metrics: Dict[str, float]) -> float:
        """ìŒì„± í’ˆì§ˆ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        try:
            # SNR ì ìˆ˜ (20dB ì´ìƒì´ ìš°ìˆ˜)
            snr_score = min(100, max(0, metrics['snr'] * 5))
            
            # ê° ì§€í‘œë³„ ê°€ì¤‘ì¹˜ ì ìš©
            weights = {
                'snr': 0.3,
                'clarity': 0.25,
                'noise_level': 0.2,  # ì—­ì‚° ì ìš© (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
                'continuity': 0.15,
                'frequency': 0.1
            }
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨ì€ ì—­ì‚° ì ìš©
            noise_score = 100 - metrics['noise_level']
            
            overall_score = (
                snr_score * weights['snr'] +
                metrics['clarity'] * weights['clarity'] +
                noise_score * weights['noise_level'] +
                metrics['continuity'] * weights['continuity'] +
                metrics['frequency'] * weights['frequency']
            )
            
            return max(0, min(100, overall_score))
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 50.0
    
    def generate_audio_recommendations(self, overall_score: float, snr_db: float, noise_level: float) -> List[str]:
        """ìŒì„± í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if overall_score < 60:
            recommendations.append("âš ï¸ ìŒì„± í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì¬ë…¹ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        if snr_db < 15:
            recommendations.append("ğŸ”Š ë°°ê²½ ì†ŒìŒì´ ë§ìŠµë‹ˆë‹¤. ì¡°ìš©í•œ ì¥ì†Œì—ì„œ ë…¹ìŒí•´ì£¼ì„¸ìš”.")
        
        if noise_level > 70:
            recommendations.append("ğŸ™ï¸ ë§ˆì´í¬ë¥¼ ì…ì— ë” ê°€ê¹Œì´ ê°€ì ¸ê°€ì„¸ìš”.")
        
        if overall_score >= 85:
            recommendations.append("âœ… ìŒì„± í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        elif overall_score >= 70:
            recommendations.append("ğŸ‘ ìŒì„± í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        
        return recommendations

class OCRQualityValidator:
    """OCR í’ˆì§ˆ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.easy_reader = easyocr.Reader(['ko', 'en', 'ch_sim'])
        
    def analyze_ocr_quality(self, image_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ì˜ OCR í’ˆì§ˆì„ ì¢…í•© ë¶„ì„"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError("ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í’ˆì§ˆ ë¶„ì„
            preprocessing_score = self.analyze_preprocessing_quality(image)
            
            # 2. í…ìŠ¤íŠ¸ ê°ì§€ í’ˆì§ˆ
            detection_score = self.analyze_text_detection_quality(image)
            
            # 3. ë¬¸ì ì¸ì‹ ì •í™•ë„
            recognition_score = self.analyze_character_recognition(image)
            
            # 4. ë ˆì´ì•„ì›ƒ ë¶„ì„ í’ˆì§ˆ
            layout_score = self.analyze_layout_quality(image)
            
            # 5. ë‹¤ì¤‘ OCR ì—”ì§„ ë¹„êµ
            comparison_score = self.compare_ocr_engines(image)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            overall_score = self.calculate_ocr_overall_score({
                'preprocessing': preprocessing_score,
                'detection': detection_score,
                'recognition': recognition_score,
                'layout': layout_score,
                'comparison': comparison_score
            })
            
            return {
                'preprocessing_score': preprocessing_score,
                'detection_score': detection_score,
                'recognition_score': recognition_score,
                'layout_score': layout_score,
                'comparison_score': comparison_score,
                'overall_score': overall_score,
                'image_dimensions': image.shape[:2],
                'recommendations': self.generate_ocr_recommendations(overall_score, preprocessing_score, detection_score)
            }
            
        except Exception as e:
            self.logger.error(f"OCR í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'overall_score': 0,
                'recommendations': ['ì´ë¯¸ì§€ íŒŒì¼ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.']
            }
    
    def analyze_preprocessing_quality(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í’ˆì§ˆ ë¶„ì„"""
        try:
            # 1. í•´ìƒë„ í’ˆì§ˆ
            height, width = image.shape[:2]
            resolution_score = min(100, (width * height) / 10000)  # 100x100 = 1ì 
            
            # 2. ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_score = min(100, sharpness / 500)
            
            # 3. ëŒ€ë¹„ (íˆìŠ¤í† ê·¸ë¨ ë¶„ì‚°)
            contrast = np.std(gray)
            contrast_score = min(100, contrast / 60)
            
            # 4. ê¸°ìš¸ê¸° ê°ì§€
            edges = cv2.Canny(gray, 50, 150)
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            tilt_score = 100
            if lines is not None:
                angles = []
                for line in lines[:10]:  # ìƒìœ„ 10ê°œ ì„ ë§Œ í™•ì¸
                    rho, theta = line[0]
                    angle = theta * 180 / np.pi
                    angles.append(angle)
                
                if angles:
                    angle_variance = np.var(angles)
                    tilt_score = max(0, 100 - angle_variance)
            
            # ê°€ì¤‘ í‰ê· 
            preprocessing_score = (
                resolution_score * 0.3 +
                sharpness_score * 0.3 +
                contrast_score * 0.2 +
                tilt_score * 0.2
            )
            
            return max(0, min(100, preprocessing_score))
            
        except Exception as e:
            self.logger.error(f"ì „ì²˜ë¦¬ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def analyze_text_detection_quality(self, image: np.ndarray) -> float:
        """í…ìŠ¤íŠ¸ ê°ì§€ í’ˆì§ˆ ë¶„ì„"""
        try:
            # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
            results = self.easy_reader.readtext(image)
            
            if not results:
                return 0.0
            
            # 1. ê°ì§€ëœ í…ìŠ¤íŠ¸ ì˜ì—­ ìˆ˜
            detection_count_score = min(100, len(results) * 10)
            
            # 2. ì‹ ë¢°ë„ í‰ê· 
            confidences = [result[2] for result in results]
            avg_confidence = np.mean(confidences) if confidences else 0
            confidence_score = avg_confidence * 100
            
            # 3. í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ì¼ê´€ì„±
            areas = []
            for result in results:
                bbox = result[0]
                width = max(point[0] for point in bbox) - min(point[0] for point in bbox)
                height = max(point[1] for point in bbox) - min(point[1] for point in bbox)
                areas.append(width * height)
            
            area_consistency = 100 - (np.std(areas) / np.mean(areas) * 100) if areas else 0
            area_consistency = max(0, min(100, area_consistency))
            
            # ì¢…í•© ì ìˆ˜
            detection_score = (
                detection_count_score * 0.3 +
                confidence_score * 0.5 +
                area_consistency * 0.2
            )
            
            return max(0, min(100, detection_score))
            
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ê°ì§€ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def analyze_character_recognition(self, image: np.ndarray) -> float:
        """ë¬¸ì ì¸ì‹ ì •í™•ë„ ë¶„ì„"""
        try:
            # 1. EasyOCR ê²°ê³¼
            easy_results = self.easy_reader.readtext(image)
            
            # 2. Tesseract ê²°ê³¼
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            tess_text = pytesseract.image_to_string(gray, lang='kor+eng')
            
            # 3. ì¸ì‹ ì¼ê´€ì„± ê²€ì‚¬
            easy_text = ' '.join([result[1] for result in easy_results])
            
            # ë¬¸ì ìˆ˜ ë¹„êµ
            easy_char_count = len(easy_text.strip())
            tess_char_count = len(tess_text.strip())
            
            if easy_char_count == 0 and tess_char_count == 0:
                return 0.0
            
            # ê³µí†µ ë¬¸ì ë¹„ìœ¨
            common_chars = set(easy_text.lower()) & set(tess_text.lower())
            total_chars = set(easy_text.lower()) | set(tess_text.lower())
            
            similarity_score = len(common_chars) / len(total_chars) * 100 if total_chars else 0
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜
            confidence_score = np.mean([result[2] for result in easy_results]) * 100 if easy_results else 0
            
            # ì¢…í•© ì ìˆ˜
            recognition_score = (similarity_score * 0.6 + confidence_score * 0.4)
            
            return max(0, min(100, recognition_score))
            
        except Exception as e:
            self.logger.error(f"ë¬¸ì ì¸ì‹ ì •í™•ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def analyze_layout_quality(self, image: np.ndarray) -> float:
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ í’ˆì§ˆ"""
        try:
            # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ì •ë³´ íšë“
            results = self.easy_reader.readtext(image)
            
            if len(results) < 2:
                return 50.0  # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
            
            # 1. í…ìŠ¤íŠ¸ ì •ë ¬ ë¶„ì„
            y_positions = []
            for result in results:
                bbox = result[0]
                y_center = sum(point[1] for point in bbox) / len(bbox)
                y_positions.append(y_center)
            
            # Y ì¢Œí‘œ ê¸°ì¤€ ì •ë ¬ í’ˆì§ˆ
            y_variance = np.var(y_positions)
            alignment_score = max(0, 100 - y_variance / 100)
            
            # 2. í…ìŠ¤íŠ¸ ê°„ê²© ì¼ê´€ì„±
            y_sorted = sorted(y_positions)
            gaps = [y_sorted[i+1] - y_sorted[i] for i in range(len(y_sorted)-1)]
            
            if gaps:
                gap_consistency = 100 - (np.std(gaps) / np.mean(gaps) * 100)
                gap_consistency = max(0, min(100, gap_consistency))
            else:
                gap_consistency = 50.0
            
            # 3. í…ìŠ¤íŠ¸ ë°€ë„
            image_area = image.shape[0] * image.shape[1]
            text_area = 0
            
            for result in results:
                bbox = result[0]
                width = max(point[0] for point in bbox) - min(point[0] for point in bbox)
                height = max(point[1] for point in bbox) - min(point[1] for point in bbox)
                text_area += width * height
            
            density_score = min(100, (text_area / image_area) * 500)
            
            # ì¢…í•© ë ˆì´ì•„ì›ƒ ì ìˆ˜
            layout_score = (
                alignment_score * 0.4 +
                gap_consistency * 0.3 +
                density_score * 0.3
            )
            
            return max(0, min(100, layout_score))
            
        except Exception as e:
            self.logger.error(f"ë ˆì´ì•„ì›ƒ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def compare_ocr_engines(self, image: np.ndarray) -> float:
        """ë‹¤ì¤‘ OCR ì—”ì§„ ë¹„êµ ë¶„ì„"""
        try:
            # 1. EasyOCR ê²°ê³¼
            easy_results = self.easy_reader.readtext(image)
            easy_text = ' '.join([result[1] for result in easy_results])
            easy_confidence = np.mean([result[2] for result in easy_results]) if easy_results else 0
            
            # 2. Tesseract ê²°ê³¼
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Tesseract ì‹ ë¢°ë„ í¬í•¨ ê²°ê³¼
            tess_data = pytesseract.image_to_data(gray, lang='kor+eng', output_type=pytesseract.Output.DICT)
            tess_confidences = [int(conf) for conf in tess_data['conf'] if int(conf) > 0]
            tess_confidence = np.mean(tess_confidences) / 100 if tess_confidences else 0
            
            # 3. ì—”ì§„ ê°„ ì¼ì¹˜ë„
            tess_text = pytesseract.image_to_string(gray, lang='kor+eng')
            
            # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë¬¸ì ê¸°ë°˜)
            easy_chars = set(easy_text.lower().replace(' ', ''))
            tess_chars = set(tess_text.lower().replace(' ', ''))
            
            if not easy_chars and not tess_chars:
                return 0.0
            
            intersection = easy_chars & tess_chars
            union = easy_chars | tess_chars
            
            similarity = len(intersection) / len(union) if union else 0
            
            # ì¢…í•© ë¹„êµ ì ìˆ˜
            comparison_score = (
                easy_confidence * 100 * 0.3 +
                tess_confidence * 100 * 0.3 +
                similarity * 100 * 0.4
            )
            
            return max(0, min(100, comparison_score))
            
        except Exception as e:
            self.logger.error(f"OCR ì—”ì§„ ë¹„êµ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def calculate_ocr_overall_score(self, metrics: Dict[str, float]) -> float:
        """OCR í’ˆì§ˆ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        try:
            weights = {
                'preprocessing': 0.2,
                'detection': 0.25,
                'recognition': 0.3,
                'layout': 0.15,
                'comparison': 0.1
            }
            
            overall_score = sum(metrics[key] * weights[key] for key in weights.keys())
            return max(0, min(100, overall_score))
            
        except Exception as e:
            self.logger.error(f"OCR ì¢…í•© ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 50.0
    
    def generate_ocr_recommendations(self, overall_score: float, preprocessing_score: float, detection_score: float) -> List[str]:
        """OCR í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if overall_score < 60:
            recommendations.append("âš ï¸ OCR í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if preprocessing_score < 50:
            recommendations.append("ğŸ“¸ ì´ë¯¸ì§€ê°€ íë¦¿í•©ë‹ˆë‹¤. ì´ˆì ì„ ë§ì¶°ì„œ ë‹¤ì‹œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if detection_score < 50:
            recommendations.append("ğŸ” í…ìŠ¤íŠ¸ ê°ì§€ê°€ ì–´ë µìŠµë‹ˆë‹¤. ì¡°ëª…ì„ ë°ê²Œ í•˜ê³  ì •ë©´ì—ì„œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if preprocessing_score < 60:
            recommendations.append("ğŸ“ ì´ë¯¸ì§€ê°€ ê¸°ìš¸ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ìˆ˜í‰ìœ¼ë¡œ ë§ì¶°ì„œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if overall_score >= 85:
            recommendations.append("âœ… OCR í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        elif overall_score >= 70:
            recommendations.append("ğŸ‘ OCR í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        
        return recommendations

class ImageQualityAssessor:
    """ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def analyze_image_quality(self, image_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì¢…í•© ë¶„ì„"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError("ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # 1. í•´ìƒë„ í’ˆì§ˆ
            resolution_score = self.analyze_resolution(image)
            
            # 2. ì„ ëª…ë„ ë¶„ì„
            sharpness_score = self.analyze_sharpness(image)
            
            # 3. ë°ê¸° ë° ëŒ€ë¹„
            brightness_score = self.analyze_brightness_contrast(image)
            
            # 4. ì»¬ëŸ¬ í’ˆì§ˆ
            color_score = self.analyze_color_quality(image)
            
            # 5. ë…¸ì´ì¦ˆ ë ˆë²¨
            noise_score = self.analyze_noise_level(image)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            overall_score = self.calculate_image_overall_score({
                'resolution': resolution_score,
                'sharpness': sharpness_score,
                'brightness': brightness_score,
                'color': color_score,
                'noise': noise_score
            })
            
            return {
                'resolution_score': resolution_score,
                'sharpness_score': sharpness_score,
                'brightness_score': brightness_score,
                'color_score': color_score,
                'noise_score': noise_score,
                'overall_score': overall_score,
                'image_dimensions': image.shape,
                'file_size': Path(image_path).stat().st_size,
                'recommendations': self.generate_image_recommendations(overall_score, sharpness_score, brightness_score)
            }
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'overall_score': 0,
                'recommendations': ['ì´ë¯¸ì§€ íŒŒì¼ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.']
            }
    
    def analyze_resolution(self, image: np.ndarray) -> float:
        """í•´ìƒë„ í’ˆì§ˆ ë¶„ì„"""
        height, width = image.shape[:2]
        total_pixels = height * width
        
        # ê¶Œì¥ í•´ìƒë„ ê¸°ì¤€ (1920x1080 = 100ì )
        target_pixels = 1920 * 1080
        resolution_score = min(100, (total_pixels / target_pixels) * 100)
        
        return resolution_score
    
    def analyze_sharpness(self, image: np.ndarray) -> float:
        """ì„ ëª…ë„ ë¶„ì„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° ê¸°ë°˜)"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # ê²½í—˜ì  ì„ê³„ê°’ (500ì´ ì¢‹ì€ ì„ ëª…ë„)
        sharpness_score = min(100, laplacian_var / 500 * 100)
        
        return max(0, sharpness_score)
    
    def analyze_brightness_contrast(self, image: np.ndarray) -> float:
        """ë°ê¸° ë° ëŒ€ë¹„ ë¶„ì„"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ë°ê¸° (í‰ê· ê°’, 128ì´ ì´ìƒì )
        mean_brightness = np.mean(gray)
        brightness_score = 100 - abs(mean_brightness - 128) / 128 * 100
        
        # ëŒ€ë¹„ (í‘œì¤€í¸ì°¨, 60 ì´ìƒì´ ì¢‹ìŒ)
        contrast = np.std(gray)
        contrast_score = min(100, contrast / 60 * 100)
        
        # íˆìŠ¤í† ê·¸ë¨ ë¶„í¬ ë¶„ì„
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist_normalized = hist / np.sum(hist)
        
        # ë™ì  ë²”ìœ„ (0-255 ì „ì²´ ì‚¬ìš© ì‹œ 100ì )
        non_zero_bins = np.count_nonzero(hist_normalized)
        dynamic_range_score = non_zero_bins / 256 * 100
        
        # ì¢…í•© ì ìˆ˜
        overall_brightness_score = (
            brightness_score * 0.4 +
            contrast_score * 0.4 +
            dynamic_range_score * 0.2
        )
        
        return max(0, min(100, overall_brightness_score))
    
    def analyze_color_quality(self, image: np.ndarray) -> float:
        """ì»¬ëŸ¬ í’ˆì§ˆ ë¶„ì„"""
        # HSV ìƒ‰ê³µê°„ ë³€í™˜
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # ì±„ë„ ë¶„ì„
        saturation = hsv[:, :, 1]
        avg_saturation = np.mean(saturation)
        saturation_score = min(100, avg_saturation / 255 * 150)  # ì±„ë„ëŠ” ì•½ê°„ ë†’ì€ ê²Œ ì¢‹ìŒ
        
        # ìƒ‰ìƒ ë¶„í¬ ê· ë“±ì„±
        hue = hsv[:, :, 0]
        hue_hist = cv2.calcHist([hue], [0], None, [180], [0, 180])
        hue_normalized = hue_hist / np.sum(hue_hist)
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ìƒ‰ìƒ ë‹¤ì–‘ì„±)
        entropy = -np.sum(hue_normalized * np.log2(hue_normalized + 1e-10))
        entropy_score = min(100, entropy / 7 * 100)  # ìµœëŒ€ ì—”íŠ¸ë¡œí”¼ëŠ” ì•½ 7
        
        # ì»¬ëŸ¬ ìºìŠ¤íŠ¸ ê²€ì‚¬ (RGB ì±„ë„ ê· í˜•)
        b, g, r = cv2.split(image)
        r_mean, g_mean, b_mean = np.mean(r), np.mean(g), np.mean(b)
        
        # RGB ê· í˜•ë„ (í¸ì°¨ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
        rgb_std = np.std([r_mean, g_mean, b_mean])
        balance_score = max(0, 100 - rgb_std / 50 * 100)
        
        # ì¢…í•© ì»¬ëŸ¬ ì ìˆ˜
        color_score = (
            saturation_score * 0.4 +
            entropy_score * 0.3 +
            balance_score * 0.3
        )
        
        return max(0, min(100, color_score))
    
    def analyze_noise_level(self, image: np.ndarray) -> float:
        """ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš© í›„ ì°¨ì´ ê³„ì‚°
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        noise_map = cv2.absdiff(gray, blurred)
        
        # ë…¸ì´ì¦ˆ ê°•ë„ ê³„ì‚°
        noise_level = np.mean(noise_map)
        
        # ì ìˆ˜í™” (ë‚®ì€ ë…¸ì´ì¦ˆê°€ ë†’ì€ ì ìˆ˜)
        noise_score = max(0, 100 - noise_level / 10 * 100)
        
        return noise_score
    
    def calculate_image_overall_score(self, metrics: Dict[str, float]) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        weights = {
            'resolution': 0.2,
            'sharpness': 0.3,
            'brightness': 0.25,
            'color': 0.15,
            'noise': 0.1
        }
        
        overall_score = sum(metrics[key] * weights[key] for key in weights.keys())
        return max(0, min(100, overall_score))
    
    def generate_image_recommendations(self, overall_score: float, sharpness_score: float, brightness_score: float) -> List[str]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if overall_score < 60:
            recommendations.append("âš ï¸ ì´ë¯¸ì§€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if sharpness_score < 50:
            recommendations.append("ğŸ“· ì´ë¯¸ì§€ê°€ íë¦¿í•©ë‹ˆë‹¤. ì´ˆì ì„ ë§ì¶°ì„œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if brightness_score < 50:
            recommendations.append("ğŸ’¡ ì¡°ëª…ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°ì€ ê³³ì—ì„œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if overall_score >= 85:
            recommendations.append("âœ… ì´ë¯¸ì§€ í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        elif overall_score >= 70:
            recommendations.append("ğŸ‘ ì´ë¯¸ì§€ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        
        return recommendations

class QualityAnalyzerV21:
    """v2.1 í†µí•© í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.audio_checker = AudioQualityChecker()
        self.ocr_validator = OCRQualityValidator()
        self.image_assessor = ImageQualityAssessor()
    
    def analyze_file_quality(self, file_path: str, file_type: str) -> QualityScore:
        """íŒŒì¼ í’ˆì§ˆ ì¢…í•© ë¶„ì„"""
        try:
            start_time = time.time()
            
            # íŒŒì¼ íƒ€ì…ë³„ ë¶„ì„
            if file_type.startswith('audio'):
                audio_result = self.audio_checker.analyze_audio_quality(file_path)
                result = QualityScore(
                    overall_score=audio_result.get('overall_score', 0),
                    audio_score=audio_result.get('overall_score', 0),
                    ocr_score=0,
                    image_score=0,
                    details=audio_result,
                    recommendations=audio_result.get('recommendations', []),
                    timestamp=start_time
                )
            
            elif file_type.startswith('image'):
                image_result = self.image_assessor.analyze_image_quality(file_path)
                ocr_result = self.ocr_validator.analyze_ocr_quality(file_path)
                
                # ì´ë¯¸ì§€ + OCR ì¢…í•© ì ìˆ˜
                combined_score = (image_result.get('overall_score', 0) * 0.6 + 
                                ocr_result.get('overall_score', 0) * 0.4)
                
                result = QualityScore(
                    overall_score=combined_score,
                    audio_score=0,
                    ocr_score=ocr_result.get('overall_score', 0),
                    image_score=image_result.get('overall_score', 0),
                    details={
                        'image_analysis': image_result,
                        'ocr_analysis': ocr_result
                    },
                    recommendations=(image_result.get('recommendations', []) + 
                                   ocr_result.get('recommendations', [])),
                    timestamp=start_time
                )
            
            else:
                # ê¸°íƒ€ íŒŒì¼ íƒ€ì… (ë¬¸ì„œ ë“±)
                result = QualityScore(
                    overall_score=75,  # ê¸°ë³¸ ì ìˆ˜
                    audio_score=0,
                    ocr_score=0,
                    image_score=0,
                    details={'message': 'ì§€ì›ë˜ëŠ” í’ˆì§ˆ ë¶„ì„ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤.'},
                    recommendations=['íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ì²˜ë¦¬ë  ì˜ˆì •ì…ë‹ˆë‹¤.'],
                    timestamp=start_time
                )
            
            return result
            
        except Exception as e:
            self.logger.error(f"íŒŒì¼ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return QualityScore(
                overall_score=0,
                audio_score=0,
                ocr_score=0,
                image_score=0,
                details={'error': str(e)},
                recommendations=['íŒŒì¼ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.'],
                timestamp=time.time()
            )
    
    def analyze_batch_quality(self, file_paths: List[str]) -> Dict[str, Any]:
        """ë°°ì¹˜ íŒŒì¼ í’ˆì§ˆ ë¶„ì„"""
        try:
            results = {}
            overall_scores = []
            all_recommendations = []
            
            for file_path in file_paths:
                # íŒŒì¼ íƒ€ì… ì¶”ì •
                file_ext = Path(file_path).suffix.lower()
                if file_ext in ['.mp3', '.wav', '.m4a', '.aac']:
                    file_type = 'audio'
                elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:
                    file_type = 'image'
                else:
                    file_type = 'document'
                
                quality_score = self.analyze_file_quality(file_path, file_type)
                results[file_path] = quality_score
                
                overall_scores.append(quality_score.overall_score)
                all_recommendations.extend(quality_score.recommendations)
            
            # ë°°ì¹˜ í†µê³„
            batch_stats = {
                'total_files': len(file_paths),
                'average_quality': np.mean(overall_scores) if overall_scores else 0,
                'min_quality': min(overall_scores) if overall_scores else 0,
                'max_quality': max(overall_scores) if overall_scores else 0,
                'quality_std': np.std(overall_scores) if overall_scores else 0,
                'high_quality_count': sum(1 for score in overall_scores if score >= 80),
                'low_quality_count': sum(1 for score in overall_scores if score < 60),
                'recommendations': list(set(all_recommendations))  # ì¤‘ë³µ ì œê±°
            }
            
            return {
                'individual_results': results,
                'batch_statistics': batch_stats,
                'processing_complete': True
            }
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'processing_complete': False
            }
    
    def get_quality_report(self, analysis_results: Dict[str, Any]) -> str:
        """í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            if 'error' in analysis_results:
                return f"âŒ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {analysis_results['error']}"
            
            stats = analysis_results['batch_statistics']
            
            # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
            avg_quality = stats['average_quality']
            if avg_quality >= 90:
                grade = "ğŸ† ìµœìš°ìˆ˜"
                grade_color = "ğŸŸ¢"
            elif avg_quality >= 80:
                grade = "âœ… ìš°ìˆ˜"
                grade_color = "ğŸŸ¢"
            elif avg_quality >= 70:
                grade = "ğŸ‘ ì–‘í˜¸"
                grade_color = "ğŸŸ¡"
            elif avg_quality >= 60:
                grade = "âš ï¸ ë³´í†µ"
                grade_color = "ğŸŸ¡"
            else:
                grade = "âŒ ê°œì„ í•„ìš”"
                grade_color = "ğŸ”´"
            
            report = f"""
ğŸ“Š **í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸**

{grade_color} **ì¢…í•© í’ˆì§ˆ**: {grade} ({avg_quality:.1f}/100ì )

ğŸ“ˆ **í†µê³„ ì •ë³´**
â€¢ ì „ì²´ íŒŒì¼: {stats['total_files']}ê°œ
â€¢ í‰ê·  í’ˆì§ˆ: {avg_quality:.1f}ì 
â€¢ ìµœê³  í’ˆì§ˆ: {stats['max_quality']:.1f}ì 
â€¢ ìµœì € í’ˆì§ˆ: {stats['min_quality']:.1f}ì 
â€¢ ê³ í’ˆì§ˆ íŒŒì¼: {stats['high_quality_count']}ê°œ (80ì  ì´ìƒ)
â€¢ ê°œì„ í•„ìš” íŒŒì¼: {stats['low_quality_count']}ê°œ (60ì  ë¯¸ë§Œ)

ğŸ’¡ **ê°œì„  ê¶Œì¥ì‚¬í•­**
{chr(10).join('â€¢ ' + rec for rec in stats['recommendations'][:5])}
            """
            
            return report.strip()
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return "í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # í’ˆì§ˆ ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = QualityAnalyzerV21()
    
    # ìƒ˜í”Œ íŒŒì¼ ë¶„ì„
    # quality_score = analyzer.analyze_file_quality("sample_audio.mp3", "audio")
    # print(f"í’ˆì§ˆ ì ìˆ˜: {quality_score.overall_score}")
    # print(f"ê¶Œì¥ì‚¬í•­: {quality_score.recommendations}")
    
    print("âœ… í’ˆì§ˆ ê²€ì¦ ì—”ì§„ v2.1 ë¡œë“œ ì™„ë£Œ!")
