#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì†”ë¡œëª¬ë“œ AI v2.1 - í’ˆì§ˆ ê²€ì¦ ì—”ì§„
ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ë° ìë™ ê°œì„  ì œì•ˆ ì‹œìŠ¤í…œ

ì‘ì„±ì: ì „ê·¼í˜ (ì†”ë¡œëª¬ë“œ ëŒ€í‘œ)
ìƒì„±ì¼: 2025.07.11
ëª©ì : í˜„ì¥ì—ì„œ ì¦‰ì‹œ í’ˆì§ˆ í™•ì¸ ë° ê°œì„  ê¶Œì¥
"""

import numpy as np
import cv2
import librosa
import json
from datetime import datetime
from pathlib import Path
import logging
from typing import Dict, Tuple, List, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AudioQualityAnalyzer:
    """ìŒì„± í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.min_snr = 20.0  # dB
        self.min_clarity = 0.8
        self.sample_rate = 22050
    
    def analyze_audio_quality(self, audio_file: str) -> Dict:
        """ìŒì„± íŒŒì¼ í’ˆì§ˆ ë¶„ì„"""
        try:
            # ìŒì„± íŒŒì¼ ë¡œë“œ
            y, sr = librosa.load(audio_file, sr=self.sample_rate)
            
            # SNR ê³„ì‚°
            snr = self._calculate_snr(y)
            
            # ëª…ë£Œë„ ê³„ì‚°
            clarity = self._calculate_clarity(y, sr)
            
            # ë°°ê²½ìŒ ë ˆë²¨
            noise_level = self._estimate_noise_level(y)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
            quality_score = self._calculate_overall_score(snr, clarity, noise_level)
            
            analysis = {
                "snr_db": round(snr, 2),
                "clarity_score": round(clarity, 3),
                "noise_level": round(noise_level, 3),
                "overall_quality": round(quality_score, 3),
                "duration_seconds": len(y) / sr,
                "sample_rate": sr,
                "recommendations": self._generate_recommendations(snr, clarity, noise_level),
                "quality_status": self._get_quality_status(quality_score),
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"ğŸ¤ ìŒì„± í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: {quality_score:.1%}")
            return analysis
            
        except Exception as e:
            logger.error(f"ìŒì„± í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e), "quality_status": "ë¶„ì„ ì‹¤íŒ¨"}
    
    def _calculate_snr(self, y: np.ndarray) -> float:
        """Signal-to-Noise Ratio ê³„ì‚°"""
        # ìŒì„± êµ¬ê°„ê³¼ ë¬´ìŒ êµ¬ê°„ ë¶„ë¦¬
        intervals = librosa.effects.split(y, top_db=20)
        
        if len(intervals) == 0:
            return 0.0
        
        # ì‹ í˜¸ êµ¬ê°„ì˜ í‰ê·  ì—ë„ˆì§€
        signal_energy = 0
        signal_samples = 0
        
        for start, end in intervals:
            signal_energy += np.sum(y[start:end] ** 2)
            signal_samples += (end - start)
        
        if signal_samples == 0:
            return 0.0
        
        signal_power = signal_energy / signal_samples
        
        # ì „ì²´ ì—ë„ˆì§€ì—ì„œ ì‹ í˜¸ ì—ë„ˆì§€ë¥¼ ëº€ ê²ƒì´ ë…¸ì´ì¦ˆ
        total_energy = np.sum(y ** 2)
        noise_energy = total_energy - signal_energy
        noise_samples = len(y) - signal_samples
        
        if noise_samples <= 0:
            return 40.0  # ë…¸ì´ì¦ˆê°€ ì—†ìœ¼ë©´ ë†’ì€ SNR
        
        noise_power = noise_energy / noise_samples
        
        if noise_power <= 0:
            return 40.0
        
        snr = 10 * np.log10(signal_power / noise_power)
        return max(0, snr)
    
    def _calculate_clarity(self, y: np.ndarray, sr: int) -> float:
        """ìŒì„± ëª…ë£Œë„ ê³„ì‚°"""
        # ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬ì£¼íŒŒìˆ˜ ê³„ì‚°
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        
        # MFCC ê³„ìˆ˜ ê³„ì‚° (ìŒì„± íŠ¹ì§•)
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        
        # ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨ (ë°œìŒ ëª…í™•ì„± ì§€í‘œ)
        zcr = librosa.feature.zero_crossing_rate(y)[0]
        
        # ì •ê·œí™”ëœ ëª…ë£Œë„ ì ìˆ˜ ê³„ì‚°
        clarity = (
            np.mean(spectral_centroids) / 4000 * 0.3 +  # ì£¼íŒŒìˆ˜ íŠ¹ì„±
            np.std(mfccs) / 50 * 0.4 +                  # ìŒì„± íŠ¹ì§• ë‹¤ì–‘ì„±
            np.mean(zcr) * 100 * 0.3                    # ë°œìŒ ëª…í™•ì„±
        )
        
        return min(1.0, max(0.0, clarity))
    
    def _estimate_noise_level(self, y: np.ndarray) -> float:
        """ë°°ê²½ìŒ ë ˆë²¨ ì¶”ì •"""
        # ë¬´ìŒ êµ¬ê°„ ê²€ì¶œ
        intervals = librosa.effects.split(y, top_db=20)
        
        if len(intervals) == 0:
            return np.std(y)  # ì „ì²´ê°€ ë…¸ì´ì¦ˆ
        
        # ìŒì„± êµ¬ê°„ì´ ì•„ë‹Œ ë¶€ë¶„ì˜ í‘œì¤€í¸ì°¨ (ë…¸ì´ì¦ˆ ë ˆë²¨)
        noise_segments = []
        prev_end = 0
        
        for start, end in intervals:
            if start > prev_end:
                noise_segments.extend(y[prev_end:start])
            prev_end = end
        
        if noise_segments:
            return np.std(noise_segments)
        else:
            return 0.0
    
    def _calculate_overall_score(self, snr: float, clarity: float, noise_level: float) -> float:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        snr_score = min(1.0, snr / 30.0)  # 30dBë¥¼ ìµœëŒ€ë¡œ ì •ê·œí™”
        clarity_score = clarity
        noise_score = max(0.0, 1.0 - noise_level * 10)  # ë…¸ì´ì¦ˆê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        
        return (snr_score * 0.4 + clarity_score * 0.4 + noise_score * 0.2)
    
    def _generate_recommendations(self, snr: float, clarity: float, noise_level: float) -> List[str]:
        """í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if snr < 15:
            recommendations.append("ğŸ”´ ë…¸ì´ì¦ˆê°€ ì‹¬í•©ë‹ˆë‹¤. ì¡°ìš©í•œ ê³³ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
        elif snr < 20:
            recommendations.append("ğŸŸ¡ ë°°ê²½ìŒì´ ìˆìŠµë‹ˆë‹¤. ê°€ëŠ¥í•˜ë©´ ë” ì¡°ìš©í•œ í™˜ê²½ì—ì„œ ë…¹ìŒí•˜ì„¸ìš”.")
        
        if clarity < 0.6:
            recommendations.append("ğŸ”´ ë°œìŒì´ ë¶ˆëª…í™•í•©ë‹ˆë‹¤. ë§ˆì´í¬ì— ë” ê°€ê¹Œì´ ë§ì”€í•˜ì„¸ìš”.")
        elif clarity < 0.8:
            recommendations.append("ğŸŸ¡ ë°œìŒì„ ë” ëª…í™•íˆ í•´ì£¼ì„¸ìš”.")
        
        if noise_level > 0.1:
            recommendations.append("ğŸ”´ ë°°ê²½ìŒì´ í½ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ìº”ìŠ¬ë§ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ğŸŸ¢ ìŒì„± í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations
    
    def _get_quality_status(self, score: float) -> str:
        """í’ˆì§ˆ ìƒíƒœ ë°˜í™˜"""
        if score >= 0.8:
            return "ìš°ìˆ˜"
        elif score >= 0.6:
            return "ì–‘í˜¸"
        elif score >= 0.4:
            return "ë³´í†µ"
        else:
            return "ê°œì„ í•„ìš”"


class OCRQualityAnalyzer:
    """OCR í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.min_resolution = 1920
        self.min_confidence = 0.8
    
    def analyze_image_quality(self, image_path: str) -> Dict:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(image_path)
            if image is None:
                return {"error": "ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨", "quality_status": "ë¶„ì„ ì‹¤íŒ¨"}
            
            # í•´ìƒë„ í™•ì¸
            height, width = image.shape[:2]
            resolution_score = min(1.0, width / self.min_resolution)
            
            # ì„ ëª…ë„ ê³„ì‚°
            sharpness = self._calculate_sharpness(image)
            
            # ëŒ€ë¹„ ê³„ì‚°
            contrast = self._calculate_contrast(image)
            
            # ì¡°ëª… ê· ì¼ì„±
            lighting = self._calculate_lighting_uniformity(image)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
            quality_score = self._calculate_image_quality_score(
                resolution_score, sharpness, contrast, lighting
            )
            
            analysis = {
                "resolution": {"width": width, "height": height, "score": round(resolution_score, 3)},
                "sharpness_score": round(sharpness, 3),
                "contrast_score": round(contrast, 3),
                "lighting_score": round(lighting, 3),
                "overall_quality": round(quality_score, 3),
                "ocr_readiness": quality_score > 0.7,
                "recommendations": self._generate_image_recommendations(
                    resolution_score, sharpness, contrast, lighting
                ),
                "quality_status": self._get_quality_status(quality_score),
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"ğŸ“¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: {quality_score:.1%}")
            return analysis
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e), "quality_status": "ë¶„ì„ ì‹¤íŒ¨"}
    
    def _calculate_sharpness(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ì„ ëª…ë„ ê³„ì‚° (Laplacian variance)"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sharpness = laplacian.var()
        return min(1.0, sharpness / 1000.0)  # ì •ê·œí™”
    
    def _calculate_contrast(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ëŒ€ë¹„ ê³„ì‚°"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        contrast = gray.std()
        return min(1.0, contrast / 128.0)  # ì •ê·œí™”
    
    def _calculate_lighting_uniformity(self, image: np.ndarray) -> float:
        """ì¡°ëª… ê· ì¼ì„± ê³„ì‚°"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ì´ë¯¸ì§€ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê° ë¸”ë¡ì˜ í‰ê·  ë°ê¸° ê³„ì‚°
        h, w = gray.shape
        block_size = min(h, w) // 8
        
        if block_size < 10:
            return 0.5  # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ìŒ
        
        block_means = []
        for i in range(0, h - block_size, block_size):
            for j in range(0, w - block_size, block_size):
                block = gray[i:i + block_size, j:j + block_size]
                block_means.append(np.mean(block))
        
        if not block_means:
            return 0.5
        
        # ë¸”ë¡ ê°„ ë°ê¸° ì°¨ì´ê°€ ì ì„ìˆ˜ë¡ ì¡°ëª…ì´ ê· ì¼
        uniformity = 1.0 - (np.std(block_means) / 128.0)
        return max(0.0, min(1.0, uniformity))
    
    def _calculate_image_quality_score(self, resolution: float, sharpness: float, 
                                     contrast: float, lighting: float) -> float:
        """ì „ì²´ ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        return (resolution * 0.2 + sharpness * 0.3 + contrast * 0.3 + lighting * 0.2)
    
    def _generate_image_recommendations(self, resolution: float, sharpness: float,
                                      contrast: float, lighting: float) -> List[str]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        if resolution < 0.5:
            recommendations.append("ğŸ”´ í•´ìƒë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ê³ í•´ìƒë„ë¡œ ì´¬ì˜í•˜ì„¸ìš”.")
        elif resolution < 0.8:
            recommendations.append("ğŸŸ¡ í•´ìƒë„ë¥¼ ë†’ì´ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        if sharpness < 0.3:
            recommendations.append("ğŸ”´ ì´ë¯¸ì§€ê°€ íë¦¿í•©ë‹ˆë‹¤. ì´ˆì ì„ ë‹¤ì‹œ ë§ì¶°ì£¼ì„¸ìš”.")
        elif sharpness < 0.6:
            recommendations.append("ğŸŸ¡ ì¡°ê¸ˆ ë” ì„ ëª…í•˜ê²Œ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        
        if contrast < 0.3:
            recommendations.append("ğŸ”´ ëŒ€ë¹„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¡°ëª…ì„ ê°œì„ í•˜ì„¸ìš”.")
        elif contrast < 0.6:
            recommendations.append("ğŸŸ¡ ì¡°ëª…ì„ ì¡°ì •í•˜ì—¬ ëŒ€ë¹„ë¥¼ ë†’ì—¬ë³´ì„¸ìš”.")
        
        if lighting < 0.4:
            recommendations.append("ğŸ”´ ì¡°ëª…ì´ ë¶ˆê· ì¼í•©ë‹ˆë‹¤. ê· ì¼í•œ ì¡°ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        elif lighting < 0.7:
            recommendations.append("ğŸŸ¡ ì¡°ëª…ì„ ë” ê· ì¼í•˜ê²Œ ì¡°ì •í•´ë³´ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ğŸŸ¢ ì´ë¯¸ì§€ í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. OCR ì²˜ë¦¬ì— ì í•©í•©ë‹ˆë‹¤.")
        
        return recommendations
    
    def _get_quality_status(self, score: float) -> str:
        """í’ˆì§ˆ ìƒíƒœ ë°˜í™˜"""
        if score >= 0.8:
            return "ìš°ìˆ˜"
        elif score >= 0.6:
            return "ì–‘í˜¸" 
        elif score >= 0.4:
            return "ë³´í†µ"
        else:
            return "ê°œì„ í•„ìš”"


class QualityManager:
    """í†µí•© í’ˆì§ˆ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.audio_analyzer = AudioQualityAnalyzer()
        self.ocr_analyzer = OCRQualityAnalyzer()
        
    def comprehensive_quality_check(self, files: Dict[str, str]) -> Dict:
        """í¬ê´„ì  í’ˆì§ˆ ê²€ì‚¬"""
        results = {
            "timestamp": datetime.now().isoformat(),
            "files_analyzed": len(files),
            "audio_results": {},
            "image_results": {},
            "overall_summary": {},
            "recommendations": []
        }
        
        # ìŒì„± íŒŒì¼ ë¶„ì„
        for file_type, file_path in files.items():
            if file_type.startswith('audio'):
                results["audio_results"][file_type] = self.audio_analyzer.analyze_audio_quality(file_path)
            elif file_type.startswith('image'):
                results["image_results"][file_type] = self.ocr_analyzer.analyze_image_quality(file_path)
        
        # ì „ì²´ ìš”ì•½ ìƒì„±
        results["overall_summary"] = self._generate_overall_summary(results)
        
        return results
    
    def _generate_overall_summary(self, results: Dict) -> Dict:
        """ì „ì²´ í’ˆì§ˆ ìš”ì•½ ìƒì„±"""
        audio_scores = [r.get("overall_quality", 0) for r in results["audio_results"].values() if "overall_quality" in r]
        image_scores = [r.get("overall_quality", 0) for r in results["image_results"].values() if "overall_quality" in r]
        
        summary = {
            "audio_avg_quality": np.mean(audio_scores) if audio_scores else 0,
            "image_avg_quality": np.mean(image_scores) if image_scores else 0,
            "total_files": len(audio_scores) + len(image_scores),
            "ready_for_processing": True
        }
        
        # ì²˜ë¦¬ ì¤€ë¹„ë„ íŒë‹¨
        if summary["audio_avg_quality"] < 0.6 or summary["image_avg_quality"] < 0.6:
            summary["ready_for_processing"] = False
            summary["reason"] = "í’ˆì§ˆì´ ê¸°ì¤€ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤. ê°œì„  í›„ ì¬ì‹œë„í•˜ì„¸ìš”."
        
        return summary


class QualityAnalyzerV21:
    """ì£¼ì–¼ë¦¬ AI í”Œë«í¼ v2.1 í†µí•© í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.audio_analyzer = AudioQualityAnalyzer()
        self.ocr_analyzer = OCRQualityAnalyzer()
        self.quality_manager = QualityManager()
        self.version = "2.1.0"
        
        logger.info(f"ğŸ”¬ QualityAnalyzerV21 v{self.version} ì´ˆê¸°í™” ì™„ë£Œ")
    
    def analyze_quality(self, file_path: str, file_type: str = "auto") -> Dict:
        """ë‹¨ì¼ íŒŒì¼ í’ˆì§ˆ ë¶„ì„"""
        try:
            if file_type == "auto":
                file_type = self._detect_file_type(file_path)
            
            if file_type in ["audio", "wav", "mp3", "mp4"]:
                return self.audio_analyzer.analyze_audio_quality(file_path)
            elif file_type in ["image", "jpg", "png", "jpeg"]:
                return self.ocr_analyzer.analyze_image_quality(file_path)
            else:
                return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}", "quality_status": "ë¶„ì„ ì‹¤íŒ¨"}
                
        except Exception as e:
            logger.error(f"í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e), "quality_status": "ë¶„ì„ ì‹¤íŒ¨"}
    
    def batch_analyze(self, files: Dict[str, str]) -> Dict:
        """ë‹¤ì¤‘ íŒŒì¼ ì¼ê´„ í’ˆì§ˆ ë¶„ì„"""
        return self.quality_manager.comprehensive_quality_check(files)
    
    def get_real_time_quality_metrics(self) -> Dict:
        """ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ ë°˜í™˜ (ë°ëª¨ìš©)"""
        return {
            "audio_quality": {
                "snr_db": 24.5,
                "clarity": 92,
                "background_noise": "ë‚®ìŒ",
                "status": "âœ…"
            },
            "ocr_quality": {
                "accuracy": 97,
                "ppt_recognition": 98,
                "table_chart": 94,
                "status": "âœ…"
            },
            "integration_analysis": {
                "language_consistency": 95,
                "content_connectivity": 89,
                "translation_accuracy": 93,
                "status": "âœ…"
            },
            "overall_status": "ìš°ìˆ˜",
            "timestamp": datetime.now().isoformat()
        }
    
    def get_quality_recommendations(self, quality_scores: Dict) -> List[str]:
        """í’ˆì§ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì˜¤ë””ì˜¤ í’ˆì§ˆ ê¶Œì¥ì‚¬í•­
        audio_score = quality_scores.get("audio_quality", {}).get("snr_db", 0)
        if audio_score < 20:
            recommendations.append("ğŸ”´ ë…¸ì´ì¦ˆ ë†’ìŒ: ì¡°ìš©í•œ ê³³ìœ¼ë¡œ ì´ë™ ê¶Œì¥")
        elif audio_score < 25:
            recommendations.append("ğŸŸ¡ OCR ë‚®ìŒ: ì¹´ë©”ë¼ ê°ë„ ì¡°ì • í•„ìš”")
        else:
            recommendations.append("ğŸŸ¢ í’ˆì§ˆ ìš°ìˆ˜: í˜„ì¬ ì„¤ì • ìœ ì§€")
        
        return recommendations
    
    def _detect_file_type(self, file_path: str) -> str:
        """íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… ê°ì§€"""
        extension = Path(file_path).suffix.lower()
        
        if extension in ['.wav', '.mp3', '.mp4', '.m4a']:
            return "audio"
        elif extension in ['.jpg', '.jpeg', '.png', '.bmp']:
            return "image"
        else:
            return "unknown"
    
    def get_version_info(self) -> Dict:
        """ë²„ì „ ì •ë³´ ë°˜í™˜"""
        return {
            "version": self.version,
            "components": {
                "audio_analyzer": "AudioQualityAnalyzer",
                "ocr_analyzer": "OCRQualityAnalyzer", 
                "quality_manager": "QualityManager"
            },
            "features": [
                "ì‹¤ì‹œê°„ ìŒì„± í’ˆì§ˆ ë¶„ì„",
                "OCR ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì¦",
                "í†µí•© í’ˆì§ˆ ê´€ë¦¬",
                "ìë™ ê°œì„  ê¶Œì¥ì‚¬í•­"
            ]
        }


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    quality_analyzer = QualityAnalyzerV21()
    
    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
    test_files = {
        "audio_meeting": "sample_meeting.wav",
        "image_document": "sample_document.jpg"
    }
    
    print("ğŸ” í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ í™•ì¸
    metrics = quality_analyzer.get_real_time_quality_metrics()
    print("ğŸ“Š ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ:")
    print(json.dumps(metrics, indent=2, ensure_ascii=False))
    
    # ë²„ì „ ì •ë³´ í™•ì¸
    version_info = quality_analyzer.get_version_info()
    print(f"\nâœ… QualityAnalyzerV21 v{version_info['version']} ë¡œë“œ ì™„ë£Œ")
    print("ğŸ“Š ì‹¤ì œ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ íŒŒì¼ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”")
