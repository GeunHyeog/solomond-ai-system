#!/usr/bin/env python3
"""
MCP í†µí•© ëª¨ë“ˆ - Perplexity, Memory, GitHub ì—°ë™
"""

import json
from typing import Dict, Any, List, Optional
from datetime import datetime
import logging

class MCPIntegration:
    """MCP ì„œë¹„ìŠ¤ë“¤ì„ í†µí•©í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def search_jewelry_info(self, query: str, language: str = "ko") -> Dict[str, Any]:
        """
        ì£¼ì–¼ë¦¬ ê´€ë ¨ ì‹¤ì‹œê°„ ì •ë³´ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            language: ì–¸ì–´ ì„¤ì • (ko/en)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            self.logger.info(f"[INFO] ì£¼ì–¼ë¦¬ ì •ë³´ ê²€ìƒ‰ ì‹œì‘: {query}")
            
            # Perplexity APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ê²€ìƒ‰
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” mcp__perplexity__chat_completion í˜¸ì¶œ
            
            # ëª¨ì˜ ê²€ìƒ‰ ê²°ê³¼ (ì‹¤ì œë¡œëŠ” Perplexity MCP í˜¸ì¶œ)
            search_result = {
                "query": query,
                "language": language,
                "timestamp": datetime.now().isoformat(),
                "results": {
                    "summary": f"{query}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.",
                    "market_data": {
                        "price_trend": "ìƒìŠ¹ì„¸",
                        "market_size": "ì„±ì¥ ì¤‘",
                        "key_factors": ["ìˆ˜ìš” ì¦ê°€", "ê³µê¸‰ ì œí•œ", "í’ˆì§ˆ ê°œì„ "]
                    },
                    "expert_insights": [
                        "ì „ë¬¸ê°€ë“¤ì€ ì§€ì†ì ì¸ ì„±ì¥ì„ ì˜ˆìƒí•œë‹¤ê³  ë¶„ì„í•©ë‹ˆë‹¤.",
                        "í’ˆì§ˆ ì¸ì¦ì˜ ì¤‘ìš”ì„±ì´ ë”ìš± ê°•ì¡°ë˜ê³  ìˆìŠµë‹ˆë‹¤."
                    ]
                },
                "confidence": 0.85,
                "sources": [
                    "ì—…ê³„ ì „ë¬¸ ë§¤ì²´",
                    "ì‹œì¥ ì¡°ì‚¬ ê¸°ê´€",
                    "ì „ë¬¸ê°€ ë¦¬í¬íŠ¸"
                ]
            }
            
            self.logger.info(f"[SUCCESS] ì£¼ì–¼ë¦¬ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ")
            return search_result
            
        except Exception as e:
            error_msg = f"ì£¼ì–¼ë¦¬ ì •ë³´ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
            self.logger.error(f"[ERROR] {error_msg}")
            return {
                "query": query,
                "error": error_msg,
                "timestamp": datetime.now().isoformat(),
                "success": False
            }
    
    def save_analysis_to_memory(self, analysis_data: Dict[str, Any], 
                               project_name: str = "jewelry_analysis") -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ Memory MCPì— ì €ì¥
        
        Args:
            analysis_data: ë¶„ì„ ë°ì´í„°
            project_name: í”„ë¡œì íŠ¸ ëª…
            
        Returns:
            ì €ì¥ ê²°ê³¼
        """
        try:
            self.logger.info(f"[INFO] ë¶„ì„ ê²°ê³¼ ë©”ëª¨ë¦¬ ì €ì¥ ì‹œì‘: {project_name}")
            
            # ì—”í‹°í‹° ìƒì„±
            entities = []
            
            # í”„ë¡œì íŠ¸ ì—”í‹°í‹°
            project_entity = {
                "name": f"{project_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "entityType": "jewelry_analysis_project",
                "observations": [
                    f"ë¶„ì„ ì¼ì‹œ: {analysis_data.get('timestamp', datetime.now().isoformat())}",
                    f"ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {analysis_data.get('total_files', 0)}",
                    f"ì„±ê³µë¥ : {analysis_data.get('success_rate', 0)}%",
                    f"ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(analysis_data.get('keywords', [])[:5])}"
                ]
            }
            entities.append(project_entity)
            
            # íŒŒì¼ë³„ ì—”í‹°í‹° ìƒì„±
            for file_result in analysis_data.get('file_results', []):
                file_entity = {
                    "name": f"file_{file_result.get('filename', 'unknown')}",
                    "entityType": "analyzed_file",
                    "observations": [
                        f"íŒŒì¼ í˜•ì‹: {file_result.get('file_type', 'unknown')}",
                        f"ì²˜ë¦¬ ìƒíƒœ: {file_result.get('status', 'unknown')}",
                        f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(file_result.get('extracted_text', ''))}ì",
                        f"ì£¼ìš” ë‚´ìš©: {file_result.get('summary', 'N/A')[:100]}..."
                    ]
                }
                entities.append(file_entity)
            
            # ì‹¤ì œë¡œëŠ” mcp__memory__create_entities í˜¸ì¶œ
            memory_result = {
                "success": True,
                "entities_created": len(entities),
                "project_name": project_name,
                "timestamp": datetime.now().isoformat()
            }
            
            self.logger.info(f"[SUCCESS] ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ: {len(entities)}ê°œ ì—”í‹°í‹°")
            return memory_result
            
        except Exception as e:
            error_msg = f"ë©”ëª¨ë¦¬ ì €ì¥ ì˜¤ë¥˜: {str(e)}"
            self.logger.error(f"[ERROR] {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "timestamp": datetime.now().isoformat()
            }
    
    def create_github_summary(self, analysis_results: Dict[str, Any]) -> str:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ GitHub ì»¤ë°‹ìš© ìš”ì•½ìœ¼ë¡œ ë³€í™˜
        
        Args:
            analysis_results: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            
        Returns:
            GitHub ì»¤ë°‹ ë©”ì‹œì§€ í˜•ì‹ì˜ ìš”ì•½
        """
        try:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
            
            summary = f"""ğŸ” ì†”ë¡œëª¬ë“œ AI ë¶„ì„ ê²°ê³¼ - {timestamp}

ğŸ“Š ë¶„ì„ ê°œìš”:
- ì²˜ë¦¬ëœ íŒŒì¼: {analysis_results.get('total_files', 0)}ê°œ
- ì„±ê³µë¥ : {analysis_results.get('success_rate', 0):.1f}%
- ì²˜ë¦¬ ì‹œê°„: {analysis_results.get('processing_time', 0):.1f}ì´ˆ

ğŸ’ ì£¼ìš” ë°œê²¬ì‚¬í•­:
- ê°ì§€ëœ í‚¤ì›Œë“œ: {len(analysis_results.get('keywords', []))}ê°œ
- ì£¼ì–¼ë¦¬ ê´€ë ¨ ì½˜í…ì¸  ë¹„ìœ¨: {analysis_results.get('jewelry_relevance', 0):.1f}%

ğŸ¯ ë¶„ì„ í’ˆì§ˆ: {analysis_results.get('quality_score', 'N/A')}

ğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸:
{chr(10).join([f'- {insight}' for insight in analysis_results.get('insights', ['ë¶„ì„ ì™„ë£Œ'])])}
"""
            
            return summary
            
        except Exception as e:
            self.logger.error(f"[ERROR] GitHub ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ë¶„ì„ ì™„ë£Œ - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    def enhance_analysis_with_realtime_data(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ ë°ì´í„°ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê°•
        
        Args:
            analysis_data: ê¸°ë³¸ ë¶„ì„ ë°ì´í„°
            
        Returns:
            ë³´ê°•ëœ ë¶„ì„ ë°ì´í„°
        """
        try:
            self.logger.info("[INFO] ì‹¤ì‹œê°„ ë°ì´í„°ë¡œ ë¶„ì„ ê²°ê³¼ ë³´ê°• ì‹œì‘")
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì‹¤ì‹œê°„ ê²€ìƒ‰
            keywords = analysis_data.get('keywords', [])
            enhanced_data = analysis_data.copy()
            enhanced_data['realtime_insights'] = []
            
            # ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‹œì¥ ì •ë³´ ê²€ìƒ‰
            jewelry_keywords = ['ë‹¤ì´ì•„ëª¬ë“œ', 'ë³´ì„', 'ë°˜ì§€', 'ëª©ê±¸ì´', 'ê·€ê±¸ì´', 'diamond', 'jewelry', 'ring']
            has_jewelry_content = any(keyword in str(keywords) for keyword in jewelry_keywords)
            
            if has_jewelry_content:
                # ì‹œì¥ ë™í–¥ ì •ë³´ ì¶”ê°€
                market_info = self.search_jewelry_info("2025ë…„ ì£¼ì–¼ë¦¬ ì‹œì¥ ë™í–¥")
                enhanced_data['realtime_insights'].append({
                    "type": "market_trend",
                    "data": market_info,
                    "relevance": "high"
                })
                
                # GIA ì¸ì¦ ì •ë³´ ì¶”ê°€
                gia_info = self.search_jewelry_info("GIA ì¸ì¦ì„œ ìµœì‹  ê¸°ì¤€")
                enhanced_data['realtime_insights'].append({
                    "type": "certification_standards",
                    "data": gia_info,
                    "relevance": "medium"
                })
            
            enhanced_data['enhancement_timestamp'] = datetime.now().isoformat()
            enhanced_data['realtime_data_sources'] = len(enhanced_data['realtime_insights'])
            
            self.logger.info(f"[SUCCESS] ì‹¤ì‹œê°„ ë°ì´í„° ë³´ê°• ì™„ë£Œ: {len(enhanced_data['realtime_insights'])}ê°œ ì¸ì‚¬ì´íŠ¸")
            return enhanced_data
            
        except Exception as e:
            error_msg = f"ì‹¤ì‹œê°„ ë°ì´í„° ë³´ê°• ì˜¤ë¥˜: {str(e)}"
            self.logger.error(f"[ERROR] {error_msg}")
            
            # ì˜¤ë¥˜ ë°œìƒì‹œ ì›ë³¸ ë°ì´í„° ë°˜í™˜
            analysis_data['enhancement_error'] = error_msg
            return analysis_data

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
mcp_integration = MCPIntegration()

def get_mcp_integration() -> MCPIntegration:
    """MCP í†µí•© ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return mcp_integration