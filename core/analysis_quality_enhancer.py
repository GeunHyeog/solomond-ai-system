#!/usr/bin/env python3
"""
ë¶„ì„ ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ ì—”ì§„
ì‚¬ìš©ìê°€ "ì´ ì‚¬ëŒë“¤ì´ ë¬´ì—‡ì„ ë§í•˜ëŠ” ê²ƒì¸ì§€ ì•Œê³  ì‹¶ë‹¤"ê³  í•  ë•Œ ì‹¤ì œë¡œ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µ
"""

import os
import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import difflib

# ê³ ê¸‰ NLP ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from transformers import pipeline, AutoTokenizer, AutoModel
    transformers_available = True
except ImportError:
    transformers_available = False

try:
    import spacy
    spacy_available = True
except ImportError:
    spacy_available = False

try:
    from sentence_transformers import SentenceTransformer
    sentence_transformers_available = True
except ImportError:
    sentence_transformers_available = False

try:
    import google.generativeai as genai
    gemini_available = True
except ImportError:
    gemini_available = False

class AnalysisQualityEnhancer:
    """ë¶„ì„ ê²°ê³¼ í’ˆì§ˆì„ ëŒ€í­ ê°œì„ í•˜ëŠ” ì—”ì§„"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
        # ê³ ê¸‰ ëª¨ë¸ë“¤ ì§€ì—° ë¡œë”©
        self.sentiment_analyzer = None
        self.ner_model = None
        self.semantic_model = None
        self.advanced_summarizer = None
        self.conversation_classifier = None
        
        # ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ë² ì´ìŠ¤
        self.jewelry_knowledge_base = self._build_jewelry_knowledge_base()
        
        # ëŒ€í™” íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œ
        self.conversation_patterns = self._build_conversation_patterns()
        
        self.logger.info("ğŸš€ ë¶„ì„ í’ˆì§ˆ í–¥ìƒ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _build_jewelry_knowledge_base(self) -> Dict[str, Any]:
        """ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ë² ì´ìŠ¤ êµ¬ì¶•"""
        return {
            "materials": {
                "precious_metals": ["ê¸ˆ", "ê¸ˆë„ê¸ˆ", "ê³¨ë“œ", "gold", "ì€", "ì‹¤ë²„", "silver", "ë°±ê¸ˆ", "í”Œë˜í‹°ë„˜", "platinum"],
                "gemstones": ["ë‹¤ì´ì•„ëª¬ë“œ", "diamond", "ë£¨ë¹„", "ruby", "ì‚¬íŒŒì´ì–´", "sapphire", "ì—ë©”ë„ë“œ", "emerald", 
                             "ì§„ì£¼", "pearl", "ì˜¤íŒ”", "opal", "í† íŒŒì¦ˆ", "topaz", "ê°€ë„·", "garnet"],
                "other_materials": ["í¬ë¦¬ìŠ¤íƒˆ", "crystal", "ìŠ¤ì™€ë¡œë¸ŒìŠ¤í‚¤", "swarovski", "íë¹…", "cubic", "ì§€ë¥´ì½”ë‹ˆì•„", "zirconia"]
            },
            "products": {
                "jewelry_types": ["ë°˜ì§€", "ring", "ëª©ê±¸ì´", "necklace", "ê·€ê±¸ì´", "earring", "íŒ”ì°Œ", "bracelet", 
                                "íœë˜íŠ¸", "pendant", "ë¸Œë¡œì¹˜", "brooch", "ì‹œê³„", "watch", "ì²´ì¸", "chain"],
                "categories": ["ì›¨ë”©", "wedding", "ì•½í˜¼", "engagement", "ì¼ìƒ", "daily", "íŒŒí‹°", "party", 
                              "ì •ì¥", "formal", "ìºì£¼ì–¼", "casual"]
            },
            "quality_terms": {
                "characteristics": ["íˆ¬ëª…ë„", "clarity", "ì»¬ëŸ¬", "color", "ìºëŸ¿", "carat", "ì»¤íŒ…", "cut", 
                                  "ê´‘íƒ", "luster", "ë¸Œë¦´ë¦¬ì–¸ìŠ¤", "brilliance"],
                "certifications": ["GIA", "ì§€ì•„", "ì¸ì¦ì„œ", "certificate", "ê°ì •ì„œ", "appraisal", "ë³´ì¦ì„œ", "warranty"]
            },
            "business_terms": {
                "price_related": ["ê°€ê²©", "price", "í• ì¸", "discount", "ì„¸ì¼", "sale", "í”„ë¡œëª¨ì…˜", "promotion", 
                                "ë¹„ìš©", "cost", "ì˜ˆì‚°", "budget"],
                "service_related": ["ìˆ˜ë¦¬", "repair", "ë¦¬í¼", "reform", "ë§ì¶¤", "custom", "ì£¼ë¬¸ì œì‘", "order", 
                                  "ë°°ì†¡", "delivery", "A/S", "ì„œë¹„ìŠ¤", "service"]
            }
        }
    
    def _build_conversation_patterns(self) -> Dict[str, List[str]]:
        """ëŒ€í™” íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œ"""
        return {
            "inquiry": ["ë¬¸ì˜", "ì§ˆë¬¸", "ê¶ê¸ˆ", "ì•Œê³  ì‹¶", "ì–´ë–»ê²Œ", "ë¬´ì—‡", "ì–¸ì œ", "ì–´ë””ì„œ", "ì–¼ë§ˆ"],
            "purchase_intent": ["êµ¬ë§¤", "ì‚¬ê³  ì‹¶", "ì£¼ë¬¸", "ì˜ˆì•½", "ê²°ì œ", "ê³„ì‚°", "ì¹´ë“œ", "í˜„ê¸ˆ"],
            "comparison": ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸", "ë” ì¢‹ì€", "ì¶”ì²œ", "ì„ íƒ", "ê³ ë¯¼"],
            "complaint": ["ë¶ˆë§Œ", "ë¬¸ì œ", "ì´ìƒ", "ì•ˆ ì¢‹", "ì‹¤ë§", "í™˜ë¶ˆ", "êµí™˜", "AS"],
            "satisfaction": ["ë§Œì¡±", "ì¢‹ë‹¤", "ì˜ˆì˜ë‹¤", "ë§ˆìŒì— ë“¤", "ê°ì‚¬", "ì¶”ì²œí•˜ê³  ì‹¶"],
            "technical": ["ì‚¬ì–‘", "ê·œê²©", "í¬ê¸°", "ë¬´ê²Œ", "ì¬ì§ˆ", "ì„±ë¶„", "ì œì¡°", "ì›ì‚°ì§€"],
            "negotiation": ["í• ì¸", "ê¹ì•„", "ê°€ê²© ì¡°ì •", "í¥ì •", "ë” ì‹¸ê²Œ", "íŠ¹ê°€", "ì´ë²¤íŠ¸"],
            "relationship": ["ì„ ë¬¼", "ê¸°ë…ì¼", "ìƒì¼", "ê²°í˜¼", "ì•½í˜¼", "ë¶€ëª¨ë‹˜", "ì—°ì¸", "ì¹œêµ¬"]
        }
    
    def enhance_stt_result(self, original_text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """STT ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ"""
        self.logger.info("ğŸ¤ STT ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ ì‹œì‘")
        
        if not original_text or len(original_text.strip()) < 10:
            return {
                "enhanced_text": original_text,
                "improvements": ["í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ê°œì„ í•  ìˆ˜ ì—†ìŒ"],
                "confidence_score": 0.1
            }
        
        enhanced_text = original_text
        improvements = []
        
        # 1. í•œêµ­ì–´ ë§ì¶¤ë²• ë° ë¬¸ë²• ë³´ì •
        enhanced_text, grammar_improvements = self._improve_korean_grammar(enhanced_text)
        improvements.extend(grammar_improvements)
        
        # 2. ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ë³´ì •
        enhanced_text, term_improvements = self._correct_jewelry_terms(enhanced_text)
        improvements.extend(term_improvements)
        
        # 3. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ëª…/ì¥ì†Œëª… ë³´ì •
        if context:
            enhanced_text, context_improvements = self._apply_context_corrections(enhanced_text, context)
            improvements.extend(context_improvements)
        
        # 4. ë¬¸ì¥ êµ¬ì¡° ê°œì„ 
        enhanced_text, structure_improvements = self._improve_sentence_structure(enhanced_text)
        improvements.extend(structure_improvements)
        
        # 5. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = self._calculate_text_confidence(original_text, enhanced_text)
        
        return {
            "enhanced_text": enhanced_text,
            "original_text": original_text,
            "improvements": improvements,
            "confidence_score": confidence_score,
            "enhancement_type": "stt_quality_boost"
        }
    
    def enhance_ocr_result(self, detected_blocks: List[Dict], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """OCR ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ"""
        self.logger.info("ğŸ–¼ï¸ OCR ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ ì‹œì‘")
        
        if not detected_blocks:
            return {
                "enhanced_text": "",
                "improvements": ["OCR ë¸”ë¡ì´ ì—†ìŒ"],
                "confidence_score": 0.0
            }
        
        improvements = []
        enhanced_blocks = []
        
        # 1. ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§
        filtered_blocks = [block for block in detected_blocks if block.get('confidence', 0) > 0.3]
        if len(filtered_blocks) < len(detected_blocks):
            improvements.append(f"ë‚®ì€ ì‹ ë¢°ë„ ë¸”ë¡ {len(detected_blocks) - len(filtered_blocks)}ê°œ ì œê±°")
        
        # 2. ê³µê°„ì  ì •ë ¬ (ìƒí•˜ì¢Œìš° ìˆœì„œë¡œ ì •ë ¬)
        sorted_blocks = self._sort_ocr_blocks_spatially(filtered_blocks)
        if sorted_blocks != filtered_blocks:
            improvements.append("í…ìŠ¤íŠ¸ ë¸”ë¡ ê³µê°„ì  ìˆœì„œ ì •ë ¬")
        
        # 3. í…ìŠ¤íŠ¸ ë³‘í•© ë° ì •ì œ
        for block in sorted_blocks:
            enhanced_text = block.get('text', '')
            
            # ì£¼ì–¼ë¦¬ ìš©ì–´ ë³´ì •
            enhanced_text, term_improvements = self._correct_jewelry_terms(enhanced_text)
            
            # ìˆ«ì/ê°€ê²© ì •ë³´ ë³´ì •
            enhanced_text, number_improvements = self._correct_numbers_and_prices(enhanced_text)
            
            enhanced_blocks.append({
                **block,
                'enhanced_text': enhanced_text,
                'improvements': term_improvements + number_improvements
            })
            
            improvements.extend(term_improvements + number_improvements)
        
        # 4. ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
        full_enhanced_text = ' '.join([block['enhanced_text'] for block in enhanced_blocks if block.get('enhanced_text')])
        
        # 5. ì»¨í…ìŠ¤íŠ¸ ì ìš©
        if context:
            full_enhanced_text, context_improvements = self._apply_context_corrections(full_enhanced_text, context)
            improvements.extend(context_improvements)
        
        # 6. ì‹ ë¢°ë„ ê³„ì‚°
        original_text = ' '.join([block.get('text', '') for block in detected_blocks])
        confidence_score = self._calculate_text_confidence(original_text, full_enhanced_text)
        
        return {
            "enhanced_text": full_enhanced_text,
            "enhanced_blocks": enhanced_blocks,
            "improvements": improvements,
            "confidence_score": confidence_score,
            "enhancement_type": "ocr_quality_boost"
        }
    
    def generate_meaningful_summary(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì˜ë¯¸ìˆëŠ” ìš”ì•½ ìƒì„± - "ì´ ì‚¬ëŒë“¤ì´ ë¬´ì—‡ì„ ë§í•˜ëŠ”ì§€" ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€"""
        self.logger.info("ğŸ§  ì˜ë¯¸ìˆëŠ” ìš”ì•½ ìƒì„± ì‹œì‘")
        
        if not text or len(text.strip()) < 50:
            return {
                "executive_summary": "ë¶„ì„í•  ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.",
                "key_points": [],
                "main_topics": [],
                "insights": [],
                "confidence": 0.1
            }
        
        # 1. ëŒ€í™” íŒ¨í„´ ë¶„ì„
        conversation_analysis = self._analyze_conversation_patterns(text)
        
        # 2. í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
        main_topics = self._extract_main_topics(text, context)
        
        # 3. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
        key_insights = self._derive_key_insights(text, conversation_analysis, main_topics, context)
        
        # 4. ì‹¤ìš©ì  ìš”ì•½ ìƒì„±
        executive_summary = self._generate_executive_summary(text, main_topics, key_insights, context)
        
        # 5. ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
        action_items = self._extract_action_items(text, conversation_analysis)
        
        return {
            "executive_summary": executive_summary,
            "main_topics": main_topics,
            "key_insights": key_insights,
            "conversation_patterns": conversation_analysis,
            "action_items": action_items,
            "confidence": self._calculate_summary_confidence(text, main_topics, key_insights),
            "enhancement_type": "meaningful_summary"
        }
    
    def _improve_korean_grammar(self, text: str) -> Tuple[str, List[str]]:
        """í•œêµ­ì–´ ë§ì¶¤ë²• ë° ë¬¸ë²• ë³´ì •"""
        improvements = []
        enhanced_text = text
        
        # ìì£¼ í‹€ë¦¬ëŠ” í•œêµ­ì–´ í‘œí˜„ ë³´ì •
        corrections = {
            # ë§ì¶¤ë²• ì˜¤ë¥˜
            "ë¬ë‹¤": "ëë‹¤", "ë¬ìŠµë‹ˆë‹¤": "ëìŠµë‹ˆë‹¤", "ë¬ì–´ìš”": "ëì–´ìš”",
            "ë§ì¶”ë‹¤": "ë§ì¶”ë‹¤", "ë§ì¶˜ë‹¤": "ë§ì¶˜ë‹¤",
            "ì–´ë–»í•´": "ì–´ë–»ê²Œ", "ì–´ë–»ì¼€": "ì–´ë–»ê²Œ",
            "ì–¼ë§ˆì—ìš”": "ì–¼ë§ˆì˜ˆìš”", "ë­ì—ìš”": "ë­ì˜ˆìš”",
            
            # ì£¼ì–¼ë¦¬ ê´€ë ¨ ìì£¼ í‹€ë¦¬ëŠ” í‘œí˜„
            "ë‹¤ì´ì•„": "ë‹¤ì´ì•„ëª¬ë“œ", "ë‹¤ì´ì•¼": "ë‹¤ì´ì•„ëª¬ë“œ",
            "ê³¨ë“œ": "ê¸ˆ", "ì‹¤ë²„": "ì€",
            "ìºë¡¯": "ìºëŸ¿", "ì¼€ëŸ¿": "ìºëŸ¿",
            "íœë´íŠ¸": "íœë˜íŠ¸", "íœë˜ë“œ": "íœë˜íŠ¸"
        }
        
        for wrong, correct in corrections.items():
            if wrong in enhanced_text:
                enhanced_text = enhanced_text.replace(wrong, correct)
                improvements.append(f"ë§ì¶¤ë²• ë³´ì •: '{wrong}' â†’ '{correct}'")
        
        return enhanced_text, improvements
    
    def _correct_jewelry_terms(self, text: str) -> Tuple[str, List[str]]:
        """ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ë³´ì •"""
        improvements = []
        enhanced_text = text
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ì •ê·œí™”
        jewelry_corrections = {
            # ì¬ì§ˆ ê´€ë ¨
            "14k": "14K", "18k": "18K", "24k": "24K",
            "ê³¨ë“œí•„ë“œ": "ê³¨ë“œ í•„ë“œ", "ë¡œì¦ˆê³¨ë“œ": "ë¡œì¦ˆ ê³¨ë“œ",
            "í™”ì´íŠ¸ê³¨ë“œ": "í™”ì´íŠ¸ ê³¨ë“œ", "ì˜ë¡œìš°ê³¨ë“œ": "ì˜ë¡œìš° ê³¨ë“œ",
            
            # ë³´ì„ ê´€ë ¨
            "cz": "CZ", "íë¹…ì§€ë¥´ì½”ë‹ˆì•„": "íë¹… ì§€ë¥´ì½”ë‹ˆì•„",
            "ìŠ¤ì™€ë¡œë¸ŒìŠ¤í‚¤": "ìŠ¤ì™€ë¡œë¸ŒìŠ¤í‚¤", "í¬ë¦¬ìŠ¤í„¸": "í¬ë¦¬ìŠ¤íƒˆ",
            
            # ì œí’ˆ ê´€ë ¨
            "ì´ì–´ë§": "ê·€ê±¸ì´", "ë„¤í´ë¦¬ìŠ¤": "ëª©ê±¸ì´",
            "ë¸Œë ˆì´ìŠ¬ë¦¿": "íŒ”ì°Œ", "ë§": "ë°˜ì§€",
            
            # í’ˆì§ˆ ê´€ë ¨
            "vvs": "VVS", "vs": "VS", "si": "SI",
            "gia": "GIA", "ì§€ì•„ì¸ì¦": "GIA ì¸ì¦"
        }
        
        for wrong, correct in jewelry_corrections.items():
            if wrong.lower() in enhanced_text.lower():
                enhanced_text = re.sub(rf"\b{re.escape(wrong)}\b", correct, enhanced_text, flags=re.IGNORECASE)
                improvements.append(f"ì „ë¬¸ìš©ì–´ ë³´ì •: '{wrong}' â†’ '{correct}'")
        
        return enhanced_text, improvements
    
    def _apply_context_corrections(self, text: str, context: Dict[str, Any]) -> Tuple[str, List[str]]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ì •"""
        improvements = []
        enhanced_text = text
        
        # ì°¸ì„ì/ë°œí‘œì ì´ë¦„ ë³´ì •
        if context.get('participants') or context.get('speakers'):
            names = []
            if context.get('speakers'):
                names.extend([n.strip() for n in context['speakers'].split(',')])
            if context.get('participants'):
                participant_names = re.findall(r'([ê°€-í£a-zA-Z\s]+?)(?:\s*\([^)]*\))?(?:,|$)', context['participants'])
                names.extend([n.strip() for n in participant_names if n.strip()])
            
            # ì´ë¦„ ìœ ì‚¬ë„ ê¸°ë°˜ ë³´ì •
            for name in names:
                if name and len(name) > 1:
                    words = enhanced_text.split()
                    for i, word in enumerate(words):
                        if difflib.SequenceMatcher(None, word, name).ratio() > 0.7:
                            words[i] = name
                            improvements.append(f"ì¸ëª… ë³´ì •: '{word}' â†’ '{name}'")
                    enhanced_text = ' '.join(words)
        
        # ì£¼ì œ í‚¤ì›Œë“œ ê°•í™”
        if context.get('topic_keywords'):
            keywords = [k.strip() for k in context['topic_keywords'].split(',')]
            for keyword in keywords:
                if keyword and len(keyword) > 2:
                    words = enhanced_text.split()
                    for i, word in enumerate(words):
                        if difflib.SequenceMatcher(None, word.lower(), keyword.lower()).ratio() > 0.8:
                            words[i] = keyword
                            improvements.append(f"í‚¤ì›Œë“œ ë³´ì •: '{word}' â†’ '{keyword}'")
                    enhanced_text = ' '.join(words)
        
        return enhanced_text, improvements
    
    def _improve_sentence_structure(self, text: str) -> Tuple[str, List[str]]:
        """ë¬¸ì¥ êµ¬ì¡° ê°œì„ """
        improvements = []
        enhanced_text = text
        
        # ë¶ˆì™„ì „í•œ ë¬¸ì¥ ë³´ì™„
        sentences = re.split(r'[.!?]\s*', enhanced_text)
        improved_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # ì£¼ì–´ ì—†ëŠ” ë¬¸ì¥ ë³´ì™„
            if len(sentence) > 10 and not re.search(r'[ê°€-í£]+[ì€ëŠ”ì´ê°€]', sentence):
                if any(term in sentence for term in ['ê°€ê²©', 'ë¹„ìš©', 'í• ì¸']):
                    sentence = "ê°€ê²©ì´ " + sentence
                    improvements.append("ì£¼ì–´ ë³´ì™„: ê°€ê²© ê´€ë ¨")
                elif any(term in sentence for term in ['ì œí’ˆ', 'ìƒí’ˆ', 'ì£¼ì–¼ë¦¬']):
                    sentence = "ì œí’ˆì´ " + sentence
                    improvements.append("ì£¼ì–´ ë³´ì™„: ì œí’ˆ ê´€ë ¨")
            
            improved_sentences.append(sentence)
        
        enhanced_text = '. '.join(improved_sentences)
        if enhanced_text and not enhanced_text.endswith('.'):
            enhanced_text += '.'
        
        return enhanced_text, improvements
    
    def _sort_ocr_blocks_spatially(self, blocks: List[Dict]) -> List[Dict]:
        """OCR ë¸”ë¡ì„ ê³µê°„ì  ìˆœì„œë¡œ ì •ë ¬"""
        # bboxê°€ ìˆëŠ” ê²½ìš° ìƒí•˜ì¢Œìš° ìˆœì„œë¡œ ì •ë ¬
        def get_position(block):
            bbox = block.get('bbox', [])
            if len(bbox) >= 4:
                # bboxê°€ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]] í˜•íƒœì¸ ê²½ìš°
                if isinstance(bbox[0], list):
                    y_center = sum(point[1] for point in bbox) / len(bbox)
                    x_center = sum(point[0] for point in bbox) / len(bbox)
                else:
                    # bboxê°€ [x1, y1, x2, y2] í˜•íƒœì¸ ê²½ìš°
                    y_center = (bbox[1] + bbox[3]) / 2
                    x_center = (bbox[0] + bbox[2]) / 2
                return (int(y_center // 50) * 1000 + x_center)  # ì„¸ë¡œ ìš°ì„ , ê°€ë¡œ ë³´ì¡° ì •ë ¬
            return 0
        
        try:
            return sorted(blocks, key=get_position)
        except:
            return blocks  # ì •ë ¬ ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    
    def _correct_numbers_and_prices(self, text: str) -> Tuple[str, List[str]]:
        """ìˆ«ì ë° ê°€ê²© ì •ë³´ ë³´ì •"""
        improvements = []
        enhanced_text = text
        
        # ê°€ê²© í‘œê¸° ì •ê·œí™”
        price_patterns = [
            (r'(\d+)ì›', r'\1ì›'),  # ìˆ«ì+ì›
            (r'(\d+),(\d{3})', r'\1,\2'),  # ì²œ ë‹¨ìœ„ ì‰¼í‘œ
            (r'(\d+)ë§Œì›', r'\1ë§Œì›'),  # ë§Œì› ë‹¨ìœ„
            (r'(\d+)k', r'\1K'),  # K í‘œê¸° í†µì¼
        ]
        
        for pattern, replacement in price_patterns:
            if re.search(pattern, enhanced_text):
                enhanced_text = re.sub(pattern, replacement, enhanced_text)
                improvements.append("ê°€ê²© í‘œê¸° ì •ê·œí™”")
        
        return enhanced_text, improvements
    
    def _analyze_conversation_patterns(self, text: str) -> Dict[str, Any]:
        """ëŒ€í™” íŒ¨í„´ ë¶„ì„"""
        analysis = {
            "dominant_patterns": [],
            "conversation_type": "general",
            "intent_scores": {},
            "emotional_tone": "neutral"
        }
        
        text_lower = text.lower()
        
        # ê° íŒ¨í„´ë³„ ì ìˆ˜ ê³„ì‚°
        for pattern_name, keywords in self.conversation_patterns.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                analysis["intent_scores"][pattern_name] = score
        
        # ì£¼ìš” íŒ¨í„´ ê²°ì •
        if analysis["intent_scores"]:
            dominant_pattern = max(analysis["intent_scores"], key=analysis["intent_scores"].get)
            analysis["dominant_patterns"] = [dominant_pattern]
            analysis["conversation_type"] = dominant_pattern
        
        # ê°ì • í†¤ ë¶„ì„ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
        positive_words = ["ì¢‹ë‹¤", "ì˜ˆì˜ë‹¤", "ë§Œì¡±", "ê°ì‚¬", "ì¶”ì²œ"]
        negative_words = ["ì•ˆ ì¢‹", "ì‹¤ë§", "ë¬¸ì œ", "ë¶ˆë§Œ", "í™˜ë¶ˆ"]
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            analysis["emotional_tone"] = "positive"
        elif negative_count > positive_count:
            analysis["emotional_tone"] = "negative"
        
        return analysis
    
    def _extract_main_topics(self, text: str, context: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """í•µì‹¬ ì£¼ì œ ì¶”ì¶œ"""
        topics = []
        text_lower = text.lower()
        
        # ì£¼ì–¼ë¦¬ ê´€ë ¨ ì£¼ì œ ì‹ë³„
        for category, terms in self.jewelry_knowledge_base.items():
            if isinstance(terms, dict):
                for subcategory, term_list in terms.items():
                    mentions = [term for term in term_list if term.lower() in text_lower]
                    if mentions:
                        topics.append({
                            "category": category,
                            "subcategory": subcategory,
                            "mentioned_terms": mentions,
                            "relevance_score": len(mentions)
                        })
        
        # ê´€ë ¨ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        topics.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return topics[:5]  # ìƒìœ„ 5ê°œ ì£¼ì œë§Œ ë°˜í™˜
    
    def _derive_key_insights(self, text: str, conversation_analysis: Dict, main_topics: List, context: Dict = None) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
        insights = []
        
        # ëŒ€í™” íŒ¨í„´ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        dominant_pattern = conversation_analysis.get("conversation_type", "general")
        
        if dominant_pattern == "inquiry":
            insights.append("ğŸ’¡ ê³ ê°ì´ ì œí’ˆì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif dominant_pattern == "purchase_intent":
            insights.append("ğŸ›’ êµ¬ë§¤ ì˜í–¥ì´ ë†’ì€ ìƒíƒœì…ë‹ˆë‹¤. êµ¬ë§¤ ê²°ì •ì„ ë„ìš¸ ì •ë³´ ì œê³µì´ í•„ìš”í•©ë‹ˆë‹¤.")
        elif dominant_pattern == "comparison":
            insights.append("âš–ï¸ ì—¬ëŸ¬ ì˜µì…˜ì„ ë¹„êµ ê²€í†  ì¤‘ì…ë‹ˆë‹¤. ì°¨ë³„ì  ì„¤ëª…ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.")
        elif dominant_pattern == "complaint":
            insights.append("âš ï¸ ë¶ˆë§Œì‚¬í•­ì´ë‚˜ ë¬¸ì œì ì— ëŒ€í•œ í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        elif dominant_pattern == "satisfaction":
            insights.append("ğŸ˜Š ì œí’ˆì— ë§Œì¡±í•˜ê³  ìˆìœ¼ë©°, ì¬êµ¬ë§¤ë‚˜ ì¶”ì²œ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
        
        # ì£¼ì œ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        if main_topics:
            top_topic = main_topics[0]
            if top_topic["category"] == "materials":
                insights.append(f"ğŸ” {', '.join(top_topic['mentioned_terms'])} ì¬ì§ˆì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ìŠµë‹ˆë‹¤.")
            elif top_topic["category"] == "products":
                insights.append(f"ğŸ‘‘ {', '.join(top_topic['mentioned_terms'])} ì œí’ˆêµ°ì´ ì£¼ìš” ê´€ì‹¬ì‚¬ì…ë‹ˆë‹¤.")
            elif top_topic["category"] == "business_terms":
                insights.append("ğŸ’° ê°€ê²©ì´ë‚˜ ì„œë¹„ìŠ¤ ì¡°ê±´ì´ ì¤‘ìš”í•œ ê²°ì • ìš”ì†Œì…ë‹ˆë‹¤.")
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        if context and context.get('objective'):
            insights.append(f"ğŸ¯ '{context['objective']}' ëª©ì ìœ¼ë¡œ ì§„í–‰ëœ ëŒ€í™”ì…ë‹ˆë‹¤.")
        
        return insights
    
    def _generate_executive_summary(self, text: str, main_topics: List, key_insights: List, context: Dict = None) -> str:
        """ì‹¤ë¬´ì§„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ê²½ì˜ì§„ ìš”ì•½"""
        
        # ê¸°ë³¸ ìš”ì•½ í…œí”Œë¦¿
        summary_parts = []
        
        # 1. ìƒí™© ìš”ì•½
        if context and context.get('event_context'):
            summary_parts.append(f"ğŸ“ **ìƒí™©**: {context['event_context']}")
        
        # 2. ì£¼ìš” ë…¼ì˜ ì‚¬í•­
        if main_topics:
            top_categories = list(set([topic["category"] for topic in main_topics[:3]]))
            category_names = {
                "materials": "ì¬ì§ˆ ë° ì†Œì¬",
                "products": "ì œí’ˆ ì¢…ë¥˜",
                "quality_terms": "í’ˆì§ˆ ê¸°ì¤€",
                "business_terms": "ë¹„ì¦ˆë‹ˆìŠ¤ ì¡°ê±´"
            }
            discussed_items = [category_names.get(cat, cat) for cat in top_categories]
            summary_parts.append(f"ğŸ’¼ **ì£¼ìš” ë…¼ì˜**: {', '.join(discussed_items)}")
        
        # 3. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ìƒìœ„ 2ê°œ)
        if key_insights:
            summary_parts.append(f"ğŸ”‘ **í•µì‹¬ í¬ì¸íŠ¸**: {key_insights[0]}")
            if len(key_insights) > 1:
                summary_parts.append(f"ğŸ’¡ **ì¶”ê°€ ì¸ì‚¬ì´íŠ¸**: {key_insights[1]}")
        
        # 4. ê²°ë¡  ë˜ëŠ” ë‹¤ìŒ ì•¡ì…˜
        text_lower = text.lower()
        if any(word in text_lower for word in ["ê²°ì •", "ì„ íƒ", "êµ¬ë§¤", "ì£¼ë¬¸"]):
            summary_parts.append("âœ… **ìƒíƒœ**: êµ¬ë§¤ ê²°ì • ë‹¨ê³„ ì§„ì…")
        elif any(word in text_lower for word in ["ê³ ë¯¼", "ê²€í† ", "ìƒê°"]):
            summary_parts.append("ğŸ¤” **ìƒíƒœ**: ì¶”ê°€ ê²€í†  í•„ìš”")
        elif any(word in text_lower for word in ["ë¬¸ì˜", "ì§ˆë¬¸", "ê¶ê¸ˆ"]):
            summary_parts.append("â“ **ìƒíƒœ**: ì¶”ê°€ ì •ë³´ ì œê³µ í•„ìš”")
        
        return "\n".join(summary_parts) if summary_parts else "ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í–ˆìœ¼ë‚˜ ëª…í™•í•œ íŒ¨í„´ì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤."
    
    def _extract_action_items(self, text: str, conversation_analysis: Dict) -> List[str]:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        actions = []
        text_lower = text.lower()
        
        # ë¬¸ì˜ ì‚¬í•­ ê¸°ë°˜ ì•¡ì…˜
        if "ë¬¸ì˜" in text_lower or "ì§ˆë¬¸" in text_lower:
            actions.append("ğŸ“ ê³ ê° ë¬¸ì˜ì‚¬í•­ì— ëŒ€í•œ ìƒì„¸ ë‹µë³€ ì œê³µ")
        
        # ê°€ê²© ê´€ë ¨ ì•¡ì…˜
        if any(word in text_lower for word in ["ê°€ê²©", "í• ì¸", "ë¹„ìš©"]):
            actions.append("ğŸ’° ê°€ê²© ì •ë³´ ë° í• ì¸ í˜œíƒ ì•ˆë‚´")
        
        # ì œí’ˆ ì •ë³´ ê´€ë ¨ ì•¡ì…˜
        if any(word in text_lower for word in ["ì‚¬ì–‘", "ê·œê²©", "ì¬ì§ˆ"]):
            actions.append("ğŸ“‹ ì œí’ˆ ìƒì„¸ ìŠ¤í™ ë° ì¸ì¦ì„œ ì œê³µ")
        
        # êµ¬ë§¤ ê´€ë ¨ ì•¡ì…˜
        if conversation_analysis.get("conversation_type") == "purchase_intent":
            actions.append("ğŸ›’ êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤ ì•ˆë‚´ ë° ê²°ì œ ë°©ë²• ì„¤ëª…")
        
        # ë¹„êµ ê´€ë ¨ ì•¡ì…˜
        if conversation_analysis.get("conversation_type") == "comparison":
            actions.append("âš–ï¸ ì œí’ˆ ë¹„êµí‘œ ë° ì°¨ë³„ì  ìë£Œ ì¤€ë¹„")
        
        return actions
    
    def _calculate_text_confidence(self, original: str, enhanced: str) -> float:
        """í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not original or not enhanced:
            return 0.0
        
        # ê¸°ë³¸ ì‹ ë¢°ë„ëŠ” ê°œì„  ì •ë„ì— ë”°ë¼ ê²°ì •
        similarity = difflib.SequenceMatcher(None, original, enhanced).ratio()
        
        # ë„ˆë¬´ ë§ì´ ë°”ë€Œë©´ ì‹ ë¢°ë„ ë‚®ìŒ, ì ì ˆíˆ ê°œì„ ë˜ë©´ ì‹ ë¢°ë„ ë†’ìŒ
        if similarity > 0.9:
            confidence = 0.95  # ê±°ì˜ ë³€í™” ì—†ìŒ = ì›ë³¸ì´ ì¢‹ì•˜ìŒ
        elif similarity > 0.7:
            confidence = 0.85  # ì ì ˆí•œ ê°œì„ 
        elif similarity > 0.5:
            confidence = 0.70  # ìƒë‹¹í•œ ê°œì„ 
        else:
            confidence = 0.50  # ëŒ€í­ ìˆ˜ì • = ì›ë³¸ í’ˆì§ˆ ë‚®ìŒ
        
        return confidence
    
    def _calculate_summary_confidence(self, text: str, main_topics: List, key_insights: List) -> float:
        """ìš”ì•½ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.5  # ê¸°ë³¸ê°’
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ì‹ ë¢°ë„
        if len(text) > 500:
            confidence += 0.2
        elif len(text) > 200:
            confidence += 0.1
        
        # ì£¼ì œ ì‹ë³„ ì„±ê³µë„
        if len(main_topics) >= 3:
            confidence += 0.2
        elif len(main_topics) >= 1:
            confidence += 0.1
        
        # ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì„±ê³µë„
        if len(key_insights) >= 2:
            confidence += 0.1
        
        return min(1.0, confidence)

# ì „ì—­ í’ˆì§ˆ í–¥ìƒ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
global_quality_enhancer = AnalysisQualityEnhancer()

def enhance_analysis_quality(analysis_result: Dict[str, Any], context: Dict[str, Any] = None) -> Dict[str, Any]:
    """ë¶„ì„ ê²°ê³¼ í’ˆì§ˆ í†µí•© ê°œì„ """
    if analysis_result.get('status') != 'success':
        return analysis_result
    
    enhanced_result = analysis_result.copy()
    
    # STT ê²°ê³¼ ê°œì„ 
    if 'full_text' in analysis_result:
        stt_enhancement = global_quality_enhancer.enhance_stt_result(
            analysis_result['full_text'], context
        )
        enhanced_result['enhanced_text'] = stt_enhancement['enhanced_text']
        enhanced_result['text_improvements'] = stt_enhancement['improvements']
        enhanced_result['text_confidence'] = stt_enhancement['confidence_score']
        
        # ê°œì„ ëœ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½ ì¬ìƒì„±
        summary_enhancement = global_quality_enhancer.generate_meaningful_summary(
            stt_enhancement['enhanced_text'], context
        )
        enhanced_result['meaningful_summary'] = summary_enhancement
    
    # OCR ê²°ê³¼ ê°œì„ 
    elif 'detailed_results' in analysis_result:
        ocr_enhancement = global_quality_enhancer.enhance_ocr_result(
            analysis_result['detailed_results'], context
        )
        enhanced_result['enhanced_text'] = ocr_enhancement['enhanced_text']
        enhanced_result['enhanced_blocks'] = ocr_enhancement['enhanced_blocks']
        enhanced_result['ocr_improvements'] = ocr_enhancement['improvements']
        enhanced_result['ocr_confidence'] = ocr_enhancement['confidence_score']
        
        # ê°œì„ ëœ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½ ì¬ìƒì„±
        summary_enhancement = global_quality_enhancer.generate_meaningful_summary(
            ocr_enhancement['enhanced_text'], context
        )
        enhanced_result['meaningful_summary'] = summary_enhancement
    
    # ê¸°ì¡´ ìš”ì•½ì´ ìˆë‹¤ë©´ ì˜ë¯¸ìˆëŠ” ìš”ì•½ìœ¼ë¡œ êµì²´
    if 'summary' in analysis_result and 'meaningful_summary' in enhanced_result:
        enhanced_result['original_summary'] = analysis_result['summary']
        enhanced_result['summary'] = enhanced_result['meaningful_summary']['executive_summary']
    
    enhanced_result['quality_enhanced'] = True
    enhanced_result['enhancement_timestamp'] = datetime.now().isoformat()
    
    return enhanced_result

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§ª ë¶„ì„ í’ˆì§ˆ í–¥ìƒ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_stt = "ì–´ ì´ê²Œ ë‹¤ì´ì•„ ë°˜ì§€ì¸ê°€ìš”? ê°€ê²©ì´ ì–¼ë§ˆì—ìš”? í• ì¸ë„ ë˜ë‚˜ìš”?"
    test_context = {
        "event_context": "ì£¼ì–¼ë¦¬ ë§¤ì¥ ìƒë‹´",
        "objective": "ë°˜ì§€ êµ¬ë§¤ ìƒë‹´",
        "participants": "ê³ ê°(ê¹€ì˜í¬), ì§ì›(ì´ì² ìˆ˜)"
    }
    
    enhancer = AnalysisQualityEnhancer()
    
    # STT ê°œì„  í…ŒìŠ¤íŠ¸
    stt_result = enhancer.enhance_stt_result(test_stt, test_context)
    print(f"ì›ë³¸: {test_stt}")
    print(f"ê°œì„ : {stt_result['enhanced_text']}")
    print(f"ê°œì„ ì‚¬í•­: {stt_result['improvements']}")
    
    # ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸
    summary_result = enhancer.generate_meaningful_summary(stt_result['enhanced_text'], test_context)
    print(f"\nìš”ì•½: {summary_result['executive_summary']}")
    print(f"ì¸ì‚¬ì´íŠ¸: {summary_result['key_insights']}")