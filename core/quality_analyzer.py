"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - í’ˆì§ˆ ë¶„ì„ ì—”ì§„
í˜„ì¥ ë…¹í™”/ì‚¬ì§„ì˜ í’ˆì§ˆ ë¶„ì„, ë…¸ì´ì¦ˆ ê²€ì¶œ, PPT OCR í’ˆì§ˆ í‰ê°€
"""

import numpy as np
import cv2
from typing import Dict, List, Optional, Tuple, Any
import logging
from datetime import datetime
import json
import re
from pathlib import Path

# ìŒì„± ë¶„ì„ìš©
try:
    import librosa
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False

# ì´ë¯¸ì§€ ë¶„ì„ìš©
try:
    from PIL import Image, ImageStat, ImageFilter
    import pytesseract
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

class QualityAnalyzer:
    """í’ˆì§ˆ ë¶„ì„ ë° ê°œì„  ì œì•ˆ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # í’ˆì§ˆ ì„ê³„ê°’ ì„¤ì •
        self.quality_thresholds = {
            "audio": {
                "noise_level": 0.3,     # 30% ì´í•˜ê°€ ì–‘í˜¸
                "clarity_score": 0.7,   # 70% ì´ìƒì´ ì–‘í˜¸
                "volume_consistency": 0.8  # 80% ì´ìƒì´ ì–‘í˜¸
            },
            "image": {
                "blur_threshold": 100,   # ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°
                "brightness_range": (50, 200),  # ì ì • ë°ê¸°
                "contrast_min": 50,     # ìµœì†Œ ëŒ€ë¹„
                "text_confidence": 0.6  # OCR ì‹ ë¢°ë„
            },
            "ppt": {
                "text_density": 0.1,    # í…ìŠ¤íŠ¸ ë°€ë„ ìµœì†Œê°’
                "geometric_score": 0.7, # ê¸°í•˜í•™ì  êµ¬ì¡° ì ìˆ˜
                "color_contrast": 3.0   # ìƒ‰ìƒ ëŒ€ë¹„ ë¹„ìœ¨
            }
        }
        
        # PPT íŠ¹í™” íŒ¨í„´
        self.ppt_patterns = [
            r'\d+\.',  # ë²ˆí˜¸ ëª©ë¡
            r'[â–¶â–ªâ–ºâ€¢]',  # ë¶ˆë¦¿ í¬ì¸íŠ¸
            r'ì œ\s*\d+\s*ì¥',  # ì¥ ì œëª©
            r'ëª©\s*ì°¨|ê°œ\s*ìš”|ê²°\s*ë¡ ',  # ì¼ë°˜ì ì¸ PPT êµ¬ì¡°
            r'\d{4}ë…„|\d{1,2}ì›”|\d{1,2}ì¼',  # ë‚ ì§œ
            r'[A-Z]{2,}',  # ëŒ€ë¬¸ì ì•½ì–´
        ]
        
        logging.info("í’ˆì§ˆ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def analyze_audio_quality(self, 
                                  audio_data: bytes, 
                                  filename: str,
                                  sample_rate: int = 22050) -> Dict:
        """
        ìŒì„± í’ˆì§ˆ ë¶„ì„
        
        Args:
            audio_data: ìŒì„± ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            filename: íŒŒì¼ëª…
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            ìŒì„± í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        """
        if not LIBROSA_AVAILABLE:
            return {
                "success": False,
                "error": "librosaê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install librosaë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.",
                "filename": filename
            }
        
        try:
            print(f"ğŸ”Š ìŒì„± í’ˆì§ˆ ë¶„ì„ ì‹œì‘: {filename}")
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ë¶„ì„
            import tempfile
            import os
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_path = temp_file.name
            
            try:
                # librosaë¡œ ìŒì„± ë¡œë“œ
                y, sr = librosa.load(temp_path, sr=sample_rate)
                
                # 1. ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„
                noise_level = self._analyze_noise_level(y)
                
                # 2. ìŒì„± ëª…ë£Œë„ ë¶„ì„
                clarity_score = self._analyze_speech_clarity(y, sr)
                
                # 3. ë³¼ë¥¨ ì¼ê´€ì„± ë¶„ì„
                volume_consistency = self._analyze_volume_consistency(y)
                
                # 4. ì£¼íŒŒìˆ˜ ë¶„ì„
                frequency_analysis = self._analyze_frequency_spectrum(y, sr)
                
                # 5. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                overall_quality = self._calculate_audio_quality_score(
                    noise_level, clarity_score, volume_consistency
                )
                
                # 6. ê°œì„  ì œì•ˆ ìƒì„±
                improvement_suggestions = self._generate_audio_improvements(
                    noise_level, clarity_score, volume_consistency
                )
                
                result = {
                    "success": True,
                    "filename": filename,
                    "quality_metrics": {
                        "noise_level": round(noise_level, 3),
                        "clarity_score": round(clarity_score, 3),
                        "volume_consistency": round(volume_consistency, 3),
                        "overall_quality": round(overall_quality, 3)
                    },
                    "frequency_analysis": frequency_analysis,
                    "quality_assessment": self._assess_audio_quality(overall_quality),
                    "improvement_suggestions": improvement_suggestions,
                    "analysis_time": datetime.now().isoformat()
                }
                
                print(f"âœ… ìŒì„± í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: {overall_quality:.1%} í’ˆì§ˆ")
                return result
                
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.unlink(temp_path)
                except:
                    pass
                    
        except Exception as e:
            logging.error(f"ìŒì„± í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "filename": filename
            }
    
    def _analyze_noise_level(self, audio: np.ndarray) -> float:
        """ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„"""
        try:
            # RMS ì—ë„ˆì§€ ê³„ì‚°
            rms = librosa.feature.rms(y=audio)[0]
            
            # ì¡°ìš©í•œ êµ¬ê°„ (í•˜ìœ„ 10%) ì‹ë³„
            quiet_threshold = np.percentile(rms, 10)
            quiet_segments = rms < quiet_threshold
            
            if np.any(quiet_segments):
                noise_floor = np.mean(rms[quiet_segments])
                signal_peak = np.max(rms)
                
                # SNR ê³„ì‚° (ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„)
                if noise_floor > 0:
                    snr = signal_peak / noise_floor
                    noise_level = 1.0 / (1.0 + snr)  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
                else:
                    noise_level = 0.0
            else:
                noise_level = 0.5  # ê¸°ë³¸ê°’
            
            return min(noise_level, 1.0)
            
        except Exception as e:
            logging.warning(f"ë…¸ì´ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_speech_clarity(self, audio: np.ndarray, sr: int) -> float:
        """ìŒì„± ëª…ë£Œë„ ë¶„ì„"""
        try:
            # ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ (ëª…ë£Œë„ ì§€í‘œ)
            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
            
            # ì œë¡œ í¬ë¡œì‹± ë ˆì´íŠ¸ (ìŒì„± í™œë™ ì§€í‘œ)
            zcr = librosa.feature.zero_crossing_rate(audio)[0]
            
            # MFCC íŠ¹ì„± (ìŒì„± íŠ¹ì„±)
            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
            mfcc_variance = np.var(mfccs, axis=1)
            
            # ëª…ë£Œë„ ì ìˆ˜ ê³„ì‚°
            clarity = (
                np.mean(spectral_centroids) / 8000 * 0.4 +  # ê³ ì£¼íŒŒ ì„±ë¶„
                (1 - np.mean(zcr)) * 0.3 +  # ì•ˆì •ì„±
                np.mean(mfcc_variance) / 100 * 0.3  # íŠ¹ì„± ë‹¤ì–‘ì„±
            )
            
            return min(max(clarity, 0.0), 1.0)
            
        except Exception as e:
            logging.warning(f"ëª…ë£Œë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _analyze_volume_consistency(self, audio: np.ndarray) -> float:
        """ë³¼ë¥¨ ì¼ê´€ì„± ë¶„ì„"""
        try:
            # RMS ì—ë„ˆì§€ ê³„ì‚°
            rms = librosa.feature.rms(y=audio, hop_length=512)[0]
            
            # í™œì„± ìŒì„± êµ¬ê°„ë§Œ ì„ íƒ (ìƒìœ„ 50%)
            active_threshold = np.percentile(rms, 50)
            active_rms = rms[rms >= active_threshold]
            
            if len(active_rms) > 0:
                # í‘œì¤€í¸ì°¨ë¥¼ ì´ìš©í•œ ì¼ê´€ì„± ì¸¡ì •
                mean_rms = np.mean(active_rms)
                std_rms = np.std(active_rms)
                
                if mean_rms > 0:
                    consistency = 1.0 - (std_rms / mean_rms)
                    return max(consistency, 0.0)
            
            return 0.5
            
        except Exception as e:
            logging.warning(f"ë³¼ë¥¨ ì¼ê´€ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _analyze_frequency_spectrum(self, audio: np.ndarray, sr: int) -> Dict:
        """ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„"""
        try:
            # FFT ê³„ì‚°
            fft = np.fft.fft(audio)
            freqs = np.fft.fftfreq(len(fft), 1/sr)
            magnitude = np.abs(fft)
            
            # ì£¼ìš” ì£¼íŒŒìˆ˜ ëŒ€ì—­ ë¶„ì„
            low_freq = np.sum(magnitude[(freqs >= 80) & (freqs <= 250)])    # ì €ìŒ
            mid_freq = np.sum(magnitude[(freqs >= 250) & (freqs <= 2000)])  # ì¤‘ìŒ
            high_freq = np.sum(magnitude[(freqs >= 2000) & (freqs <= 8000)]) # ê³ ìŒ
            
            total_energy = low_freq + mid_freq + high_freq
            
            if total_energy > 0:
                return {
                    "low_frequency_ratio": round(low_freq / total_energy, 3),
                    "mid_frequency_ratio": round(mid_freq / total_energy, 3),
                    "high_frequency_ratio": round(high_freq / total_energy, 3),
                    "dominant_frequency": round(freqs[np.argmax(magnitude[:len(freqs)//2])], 1)
                }
            else:
                return {"error": "ì£¼íŒŒìˆ˜ ë¶„ì„ ì‹¤íŒ¨"}
                
        except Exception as e:
            logging.warning(f"ì£¼íŒŒìˆ˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _calculate_audio_quality_score(self, 
                                     noise_level: float, 
                                     clarity_score: float, 
                                     volume_consistency: float) -> float:
        """ì „ì²´ ìŒì„± í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¢…í•© ì ìˆ˜ ê³„ì‚°
        weights = {"noise": 0.3, "clarity": 0.4, "consistency": 0.3}
        
        quality_score = (
            (1.0 - noise_level) * weights["noise"] +
            clarity_score * weights["clarity"] +
            volume_consistency * weights["consistency"]
        )
        
        return quality_score
    
    def _assess_audio_quality(self, quality_score: float) -> str:
        """ìŒì„± í’ˆì§ˆ í‰ê°€"""
        if quality_score >= 0.8:
            return "ìš°ìˆ˜í•œ í’ˆì§ˆ - í˜„ì¥ ë…¹í™” ì¹˜ê³  ë§¤ìš° ì¢‹ìŒ"
        elif quality_score >= 0.6:
            return "ì–‘í˜¸í•œ í’ˆì§ˆ - ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€"
        elif quality_score >= 0.4:
            return "ë³´í†µ í’ˆì§ˆ - ë…¸ì´ì¦ˆ ì œê±° ê¶Œì¥"
        else:
            return "ë‚®ì€ í’ˆì§ˆ - ì¬ë…¹í™” ë˜ëŠ” ì „ë¬¸ ì²˜ë¦¬ í•„ìš”"
    
    def _generate_audio_improvements(self, 
                                   noise_level: float, 
                                   clarity_score: float, 
                                   volume_consistency: float) -> List[str]:
        """ìŒì„± ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        if noise_level > self.quality_thresholds["audio"]["noise_level"]:
            suggestions.append("ğŸ”§ ë…¸ì´ì¦ˆ ì œê±° í•„í„° ì ìš© ê¶Œì¥")
            suggestions.append("ğŸ“± ë‹¤ìŒì—ëŠ” ë§ˆì´í¬ë¥¼ í™”ìì—ê²Œ ë” ê°€ê¹Œì´ ì„¤ì¹˜")
        
        if clarity_score < self.quality_thresholds["audio"]["clarity_score"]:
            suggestions.append("ğŸšï¸ ê³ ì£¼íŒŒ ê°•í™” ë° ì´í€„ë¼ì´ì € ì¡°ì • ê¶Œì¥")
            suggestions.append("ğŸ—£ï¸ í™”ìê°€ ë” ëª…í™•í•˜ê²Œ ë°œìŒí•˜ë„ë¡ ì•ˆë‚´")
        
        if volume_consistency < self.quality_thresholds["audio"]["volume_consistency"]:
            suggestions.append("ğŸ“Š ìë™ ìŒëŸ‰ ì •ê·œí™” ì ìš© ê¶Œì¥")
            suggestions.append("ğŸ¤ ë§ˆì´í¬ ê±°ë¦¬ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€")
        
        if not suggestions:
            suggestions.append("âœ… í˜„ì¬ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤!")
        
        return suggestions
    
    async def analyze_image_quality(self, 
                                  image_data: bytes, 
                                  filename: str,
                                  is_ppt_screen: bool = False) -> Dict:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ (PPT í™”ë©´ íŠ¹í™” í¬í•¨)
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            filename: íŒŒì¼ëª…
            is_ppt_screen: PPT í™”ë©´ ì—¬ë¶€ (ìë™ ê°ì§€ë„ í¬í•¨)
            
        Returns:
            ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        """
        if not PIL_AVAILABLE:
            return {
                "success": False,
                "error": "PIL/Pillowê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "filename": filename
            }
        
        try:
            print(f"ğŸ“¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì‹œì‘: {filename}")
            
            # PIL Image ê°ì²´ ìƒì„±
            image = Image.open(io.BytesIO(image_data))
            
            # 1. ê¸°ë³¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„
            basic_quality = self._analyze_basic_image_quality(image)
            
            # 2. PPT í™”ë©´ ê°ì§€ ë° ë¶„ì„
            ppt_analysis = self._analyze_ppt_screen(image, is_ppt_screen)
            
            # 3. OCR í’ˆì§ˆ ë¶„ì„
            ocr_quality = self._analyze_ocr_quality(image, ppt_analysis["is_ppt_screen"])
            
            # 4. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            overall_quality = self._calculate_image_quality_score(
                basic_quality, ppt_analysis, ocr_quality
            )
            
            # 5. ê°œì„  ì œì•ˆ ìƒì„±
            improvement_suggestions = self._generate_image_improvements(
                basic_quality, ppt_analysis, ocr_quality
            )
            
            result = {
                "success": True,
                "filename": filename,
                "basic_quality": basic_quality,
                "ppt_analysis": ppt_analysis,
                "ocr_quality": ocr_quality,
                "overall_quality": round(overall_quality, 3),
                "quality_assessment": self._assess_image_quality(overall_quality, ppt_analysis["is_ppt_screen"]),
                "improvement_suggestions": improvement_suggestions,
                "analysis_time": datetime.now().isoformat()
            }
            
            print(f"âœ… ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: {overall_quality:.1%} í’ˆì§ˆ")
            return result
            
        except Exception as e:
            logging.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "filename": filename
            }
    
    def _analyze_basic_image_quality(self, image: Image) -> Dict:
        """ê¸°ë³¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        try:
            # RGBë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(image)
            
            # 1. ë¸”ëŸ¬ ê²€ì¶œ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # 2. ë°ê¸° ë¶„ì„
            brightness = np.mean(img_array)
            
            # 3. ëŒ€ë¹„ ë¶„ì„
            contrast = np.std(img_array)
            
            # 4. ë…¸ì´ì¦ˆ ë¶„ì„
            noise_level = self._estimate_noise_level(gray)
            
            # 5. í•´ìƒë„ ì²´í¬
            width, height = image.size
            resolution_score = min((width * height) / (1920 * 1080), 1.0)
            
            return {
                "blur_score": round(blur_score, 2),
                "brightness": round(brightness, 2),
                "contrast": round(contrast, 2),
                "noise_level": round(noise_level, 3),
                "resolution": {"width": width, "height": height},
                "resolution_score": round(resolution_score, 3)
            }
            
        except Exception as e:
            logging.warning(f"ê¸°ë³¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _analyze_ppt_screen(self, image: Image, is_ppt_hint: bool = False) -> Dict:
        """PPT í™”ë©´ ë¶„ì„"""
        try:
            # 1. PPT í™”ë©´ ê°ì§€
            is_ppt_screen = self._detect_ppt_screen(image) or is_ppt_hint
            
            if not is_ppt_screen:
                return {
                    "is_ppt_screen": False,
                    "confidence": 0.0,
                    "ppt_specific_analysis": {}
                }
            
            # 2. PPT íŠ¹í™” ë¶„ì„
            img_array = np.array(image.convert('RGB'))
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ë¹„ìœ¨
            text_density = self._calculate_text_density(image)
            
            # ê¸°í•˜í•™ì  êµ¬ì¡° ì ìˆ˜ (ì‚¬ê°í˜•, ì •ë ¬ ë“±)
            geometric_score = self._analyze_ppt_geometry(img_array)
            
            # ìƒ‰ìƒ ëŒ€ë¹„ ë¶„ì„
            color_contrast = self._analyze_color_contrast(img_array)
            
            # PPT íŒ¨í„´ ë§¤ì¹­
            pattern_score = self._match_ppt_patterns(image)
            
            return {
                "is_ppt_screen": True,
                "confidence": 0.8 if is_ppt_hint else 0.6,
                "ppt_specific_analysis": {
                    "text_density": round(text_density, 3),
                    "geometric_score": round(geometric_score, 3),
                    "color_contrast": round(color_contrast, 3),
                    "pattern_score": round(pattern_score, 3)
                }
            }
            
        except Exception as e:
            logging.warning(f"PPT ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "is_ppt_screen": False,
                "error": str(e)
            }
    
    def _detect_ppt_screen(self, image: Image) -> bool:
        """PPT í™”ë©´ ìë™ ê°ì§€"""
        try:
            # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ PPT ê°ì§€
            width, height = image.size
            aspect_ratio = width / height
            
            # ì¼ë°˜ì ì¸ PPT ë¹„ìœ¨ (4:3, 16:9, 16:10)
            ppt_ratios = [4/3, 16/9, 16/10]
            ratio_match = any(abs(aspect_ratio - ratio) < 0.1 for ratio in ppt_ratios)
            
            # í•´ìƒë„ê°€ í”„ë ˆì  í…Œì´ì…˜ì— ì í•©í•œì§€
            resolution_suitable = width >= 800 and height >= 600
            
            return ratio_match and resolution_suitable
            
        except Exception:
            return False
    
    def _calculate_text_density(self, image: Image) -> float:
        """í…ìŠ¤íŠ¸ ë°€ë„ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê°ì§€ (OCR ì—†ì´)
            gray = image.convert('L')
            img_array = np.array(gray)
            
            # ì—£ì§€ ê²€ì¶œë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì •
            edges = cv2.Canny(img_array, 50, 150)
            text_pixels = np.sum(edges > 0)
            total_pixels = img_array.size
            
            return text_pixels / total_pixels
            
        except Exception:
            return 0.1
    
    def _analyze_ppt_geometry(self, img_array: np.ndarray) -> float:
        """PPT ê¸°í•˜í•™ì  êµ¬ì¡° ë¶„ì„"""
        try:
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            
            # ì§ì„  ê²€ì¶œ
            edges = cv2.Canny(gray, 50, 150)
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            # ì‚¬ê°í˜• ê²€ì¶œ
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            rectangles = 0
            
            for contour in contours:
                approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)
                if len(approx) == 4:
                    rectangles += 1
            
            # êµ¬ì¡° ì ìˆ˜ ê³„ì‚°
            line_score = min(len(lines) / 20, 1.0) if lines is not None else 0
            rect_score = min(rectangles / 10, 1.0)
            
            return (line_score + rect_score) / 2
            
        except Exception:
            return 0.5
    
    def _analyze_color_contrast(self, img_array: np.ndarray) -> float:
        """ìƒ‰ìƒ ëŒ€ë¹„ ë¶„ì„"""
        try:
            # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
            lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
            l_channel = lab[:, :, 0]
            
            # ë°ê¸° ëŒ€ë¹„ ê³„ì‚°
            contrast_ratio = np.std(l_channel) / np.mean(l_channel)
            
            return min(contrast_ratio, 5.0)  # ìµœëŒ€ 5.0ìœ¼ë¡œ ì œí•œ
            
        except Exception:
            return 1.0
    
    def _match_ppt_patterns(self, image: Image) -> float:
        """PPT íŒ¨í„´ ë§¤ì¹­"""
        try:
            # OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°„ë‹¨íˆ)
            import pytesseract
            text = pytesseract.image_to_string(image, lang='kor+eng')
            
            # íŒ¨í„´ ë§¤ì¹­
            matches = 0
            for pattern in self.ppt_patterns:
                if re.search(pattern, text):
                    matches += 1
            
            return min(matches / len(self.ppt_patterns), 1.0)
            
        except Exception:
            return 0.3
    
    def _analyze_ocr_quality(self, image: Image, is_ppt: bool) -> Dict:
        """OCR í’ˆì§ˆ ë¶„ì„"""
        try:
            # OCR ìˆ˜í–‰
            import pytesseract
            
            # ì‹ ë¢°ë„ í¬í•¨ ë°ì´í„° ì¶”ì¶œ
            data = pytesseract.image_to_data(
                image, 
                lang='kor+eng',
                output_type=pytesseract.Output.DICT
            )
            
            # ì‹ ë¢°ë„ ë¶„ì„
            confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
            avg_confidence = np.mean(confidences) / 100 if confidences else 0.0
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = pytesseract.image_to_string(image, lang='kor+eng')
            word_count = len(text.split())
            
            # PPTìš© íŠ¹ë³„ ë¶„ì„
            if is_ppt:
                ppt_readability = self._analyze_ppt_readability(text, confidences)
            else:
                ppt_readability = {}
            
            return {
                "average_confidence": round(avg_confidence, 3),
                "word_count": word_count,
                "text_length": len(text.strip()),
                "high_confidence_ratio": len([c for c in confidences if c >= 80]) / max(len(confidences), 1),
                "ppt_readability": ppt_readability
            }
            
        except Exception as e:
            logging.warning(f"OCR í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "average_confidence": 0.0,
                "word_count": 0
            }
    
    def _analyze_ppt_readability(self, text: str, confidences: List[int]) -> Dict:
        """PPT ê°€ë…ì„± ë¶„ì„"""
        try:
            # ì œëª©/ë‚´ìš© êµ¬ë¶„
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            
            # í° ê¸€ì”¨ (ì œëª© ì¶”ì •) vs ì‘ì€ ê¸€ì”¨ (ë‚´ìš©)
            title_candidates = [line for line in lines if len(line) < 30 and any(c.isupper() for c in line)]
            content_lines = [line for line in lines if line not in title_candidates]
            
            # êµ¬ì¡°í™” ì •ë„
            structured_elements = len(re.findall(r'^\d+\.|\s*[â–¶â–ªâ–ºâ€¢]', text, re.MULTILINE))
            
            return {
                "title_count": len(title_candidates),
                "content_lines": len(content_lines),
                "structured_elements": structured_elements,
                "structure_score": min(structured_elements / max(len(lines), 1), 1.0)
            }
            
        except Exception:
            return {}
    
    def _estimate_noise_level(self, gray_image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì •"""
        try:
            # ê°€ìš°ì‹œì•ˆ í•„í„° ì ìš© í›„ ì°¨ì´ë¡œ ë…¸ì´ì¦ˆ ì¶”ì •
            blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)
            noise = gray_image.astype(np.float32) - blurred.astype(np.float32)
            noise_level = np.std(noise) / 255.0
            
            return min(noise_level, 1.0)
            
        except Exception:
            return 0.1
    
    def _calculate_image_quality_score(self, 
                                     basic_quality: Dict,
                                     ppt_analysis: Dict,
                                     ocr_quality: Dict) -> float:
        """ì´ë¯¸ì§€ ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜
            blur_ok = basic_quality.get("blur_score", 0) >= self.quality_thresholds["image"]["blur_threshold"]
            brightness_ok = self.quality_thresholds["image"]["brightness_range"][0] <= basic_quality.get("brightness", 0) <= self.quality_thresholds["image"]["brightness_range"][1]
            contrast_ok = basic_quality.get("contrast", 0) >= self.quality_thresholds["image"]["contrast_min"]
            
            basic_score = (int(blur_ok) + int(brightness_ok) + int(contrast_ok)) / 3
            
            # OCR í’ˆì§ˆ ì ìˆ˜
            ocr_score = ocr_quality.get("average_confidence", 0)
            
            # PPT íŠ¹í™” ì ìˆ˜
            if ppt_analysis.get("is_ppt_screen", False):
                ppt_specific = ppt_analysis.get("ppt_specific_analysis", {})
                ppt_score = (
                    ppt_specific.get("text_density", 0) * 0.3 +
                    ppt_specific.get("geometric_score", 0) * 0.3 +
                    ppt_specific.get("color_contrast", 0) / 5.0 * 0.2 +
                    ppt_specific.get("pattern_score", 0) * 0.2
                )
                
                # PPTì˜ ê²½ìš° ê°€ì¤‘ì¹˜ ì¡°ì •
                return basic_score * 0.4 + ocr_score * 0.4 + ppt_score * 0.2
            else:
                return basic_score * 0.6 + ocr_score * 0.4
                
        except Exception:
            return 0.5
    
    def _assess_image_quality(self, quality_score: float, is_ppt: bool) -> str:
        """ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€"""
        prefix = "PPT í™”ë©´" if is_ppt else "ì¼ë°˜ ì´ë¯¸ì§€"
        
        if quality_score >= 0.8:
            return f"ìš°ìˆ˜í•œ {prefix} - OCR í’ˆì§ˆ ë§¤ìš° ì¢‹ìŒ"
        elif quality_score >= 0.6:
            return f"ì–‘í˜¸í•œ {prefix} - ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€"
        elif quality_score >= 0.4:
            return f"ë³´í†µ {prefix} - ì¡°ëª…/ê°ë„ ê°œì„  í•„ìš”"
        else:
            return f"ë‚®ì€ {prefix} - ì¬ì´¬ì˜ ê¶Œì¥"
    
    def _generate_image_improvements(self, 
                                   basic_quality: Dict,
                                   ppt_analysis: Dict,
                                   ocr_quality: Dict) -> List[str]:
        """ì´ë¯¸ì§€ ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # ê¸°ë³¸ í’ˆì§ˆ ê°œì„ 
        blur_score = basic_quality.get("blur_score", 0)
        if blur_score < self.quality_thresholds["image"]["blur_threshold"]:
            suggestions.append("ğŸ“· í”ë“¤ë¦¼ ë°©ì§€ - ì‚¼ê°ëŒ€ ì‚¬ìš© ë˜ëŠ” ì–‘ì†ìœ¼ë¡œ ê³ ì •")
        
        brightness = basic_quality.get("brightness", 0)
        brightness_range = self.quality_thresholds["image"]["brightness_range"]
        if brightness < brightness_range[0]:
            suggestions.append("ğŸ’¡ ì¡°ëª… ê°œì„  - ë” ë°ì€ í™˜ê²½ì—ì„œ ì´¬ì˜")
        elif brightness > brightness_range[1]:
            suggestions.append("ğŸ”† ë…¸ì¶œ ì¡°ì • - í”Œë˜ì‹œ ë„ê¸° ë˜ëŠ” ê°„ì ‘ ì¡°ëª… ì‚¬ìš©")
        
        contrast = basic_quality.get("contrast", 0)
        if contrast < self.quality_thresholds["image"]["contrast_min"]:
            suggestions.append("ğŸ“Š ëŒ€ë¹„ ê°œì„  - ë°°ê²½ê³¼ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ì°¨ì´ í™•ë³´")
        
        # OCR í’ˆì§ˆ ê°œì„ 
        ocr_confidence = ocr_quality.get("average_confidence", 0)
        if ocr_confidence < self.quality_thresholds["image"]["text_confidence"]:
            suggestions.append("ğŸ”¤ í…ìŠ¤íŠ¸ ì¸ì‹ ê°œì„  - ì •ë©´ì—ì„œ ì´¬ì˜í•˜ê³  ê°ë„ ìµœì†Œí™”")
        
        # PPT íŠ¹í™” ê°œì„ 
        if ppt_analysis.get("is_ppt_screen", False):
            ppt_specific = ppt_analysis.get("ppt_specific_analysis", {})
            
            if ppt_specific.get("text_density", 0) < self.quality_thresholds["ppt"]["text_density"]:
                suggestions.append("ğŸ“± PPT í™”ë©´ í™•ëŒ€ - í…ìŠ¤íŠ¸ê°€ ë” í¬ê²Œ ë³´ì´ë„ë¡ ì´¬ì˜")
            
            if ppt_specific.get("geometric_score", 0) < self.quality_thresholds["ppt"]["geometric_score"]:
                suggestions.append("ğŸ“ í™”ë©´ ì •ë ¬ - ìŠ¤í¬ë¦°ì— ìˆ˜ì§ìœ¼ë¡œ ì´¬ì˜")
        
        if not suggestions:
            suggestions.append("âœ… í˜„ì¬ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤!")
        
        return suggestions


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_quality_analyzer_instance = None

def get_quality_analyzer() -> QualityAnalyzer:
    """ì „ì—­ í’ˆì§ˆ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _quality_analyzer_instance
    if _quality_analyzer_instance is None:
        _quality_analyzer_instance = QualityAnalyzer()
    return _quality_analyzer_instance

# í¸ì˜ í•¨ìˆ˜ë“¤
async def analyze_audio_quality(audio_data: bytes, filename: str) -> Dict:
    """ìŒì„± í’ˆì§ˆ ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    analyzer = get_quality_analyzer()
    return await analyzer.analyze_audio_quality(audio_data, filename)

async def analyze_image_quality(image_data: bytes, filename: str, is_ppt: bool = False) -> Dict:
    """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    analyzer = get_quality_analyzer()
    return await analyzer.analyze_image_quality(image_data, filename, is_ppt)

if __name__ == "__main__":
    print("í’ˆì§ˆ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ:", {"librosa": LIBROSA_AVAILABLE, "PIL": PIL_AVAILABLE})
