#!/usr/bin/env python3
"""
ğŸ¤– ë©€í‹°ëª¨ë‹¬ ì¸ì½”ë” - SOLOMOND AI ì§„ì •í•œ ë©€í‹°ëª¨ë‹¬ë¦¬í‹° êµ¬í˜„
True Multimodal Encoder: Images/Audio/Text â†’ 768-dimensional Latent Space

ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
1. í†µí•© ì¸ì½”ë”© - ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ 768ì°¨ì› ê³µí†µ ê³µê°„ìœ¼ë¡œ ë³€í™˜
2. ëª¨ë‹¬ë³„ ì „ì²˜ë¦¬ - ê° ëª¨ë‹¬ì— ìµœì í™”ëœ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
3. ì •ê·œí™” ì‹œìŠ¤í…œ - ëª¨ë‹¬ê°„ í¬ê¸° ë° ë¶„í¬ ì •ê·œí™”
4. ë°°ì¹˜ ì²˜ë¦¬ - ë‹¤ìˆ˜ íŒŒì¼ ë™ì‹œ ì¸ì½”ë”© ì§€ì›
5. ìºì‹± ì‹œìŠ¤í…œ - ì¤‘ë³µ ì¸ì½”ë”© ë°©ì§€ë¡œ ì„±ëŠ¥ ìµœì í™”
"""

import numpy as np
import torch
from typing import Dict, List, Any, Optional, Union, Tuple
from pathlib import Path
from dataclasses import dataclass
import logging
import hashlib
import time

# AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import whisper
    import easyocr
    import cv2
    from PIL import Image
    from sentence_transformers import SentenceTransformer
    import librosa
    from sklearn.preprocessing import StandardScaler
except ImportError as e:
    logging.error(f"í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")

# ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class EncodedResult:
    """ì¸ì½”ë”©ëœ ê²°ê³¼ êµ¬ì¡°"""
    file_path: str
    modality: str
    encoding: np.ndarray  # 768ì°¨ì› ë²¡í„°
    confidence: float
    metadata: Dict[str, Any]
    processing_time: float
    raw_content: str = ""

class MultimodalEncoder:
    """ì§„ì •í•œ ë©€í‹°ëª¨ë‹¬ ì¸ì½”ë” - ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ ê³µí†µ ê³µê°„ìœ¼ë¡œ"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        self.models = {}
        self.is_initialized = False
        self.cache = {}
        
        # ì •ê·œí™”ê¸°ë“¤
        self.scalers = {
            'image': StandardScaler(),
            'audio': StandardScaler(), 
            'text': StandardScaler()
        }
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.stats = {
            'encoded_files': 0,
            'cache_hits': 0,
            'encoding_times': [],
            'modality_counts': {'image': 0, 'audio': 0, 'text': 0}
        }
        
    def _get_default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            'target_dimensions': 768,
            'whisper_model': 'base',
            'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',
            'ocr_languages': ['ko', 'en'],
            'cache_enabled': True,
            'batch_size': 8,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu'
        }
    
    def initialize(self) -> None:
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.is_initialized:
            return
            
        logger.info("ğŸ¤– ë©€í‹°ëª¨ë‹¬ ì¸ì½”ë” ì´ˆê¸°í™” ì¤‘...")
        
        # 1. Sentence Transformer (í…ìŠ¤íŠ¸ + ê³µí†µ ì¸ì½”ë”)
        logger.info("ğŸ§  SentenceTransformer ë¡œë”©...")
        self.models['text_encoder'] = SentenceTransformer(
            self.config['embedding_model'],
            device=self.config['device']
        )
        
        # 2. Whisper (ì˜¤ë””ì˜¤)
        logger.info("ğŸµ Whisper STT ëª¨ë¸ ë¡œë”©...")
        self.models['whisper'] = whisper.load_model(self.config['whisper_model'])
        
        # 3. EasyOCR (ì´ë¯¸ì§€)
        logger.info("ğŸ‘ï¸ EasyOCR ëª¨ë¸ ë¡œë”©...")
        self.models['ocr'] = easyocr.Reader(self.config['ocr_languages'])
        
        self.is_initialized = True
        logger.info("âœ… ë©€í‹°ëª¨ë‹¬ ì¸ì½”ë” ì´ˆê¸°í™” ì™„ë£Œ!")
        
    def encode_batch(self, files: List[Path]) -> List[EncodedResult]:
        """ë°°ì¹˜ íŒŒì¼ ì¸ì½”ë”©"""
        if not self.is_initialized:
            self.initialize()
            
        logger.info(f"ğŸ“¦ ë°°ì¹˜ ì¸ì½”ë”© ì‹œì‘: {len(files)}ê°œ íŒŒì¼")
        start_time = time.time()
        
        results = []
        
        # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜ ë° ì¸ì½”ë”©
        for file_path in files:
            try:
                result = self.encode_single_file(file_path)
                if result:
                    results.append(result)
            except Exception as e:
                logger.error(f"âŒ íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨ {file_path}: {e}")
                
        batch_time = time.time() - start_time
        logger.info(f"âœ… ë°°ì¹˜ ì¸ì½”ë”© ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ, {batch_time:.2f}ì´ˆ")
        
        return results
    
    def encode_single_file(self, file_path: Path) -> Optional[EncodedResult]:
        """ë‹¨ì¼ íŒŒì¼ ì¸ì½”ë”©"""
        start_time = time.time()
        
        # ìºì‹œ í™•ì¸
        file_hash = self._get_file_hash(file_path)
        if self.config['cache_enabled'] and file_hash in self.cache:
            self.stats['cache_hits'] += 1
            return self.cache[file_hash]
            
        # íŒŒì¼ íƒ€ì… íŒë³„
        modality = self._detect_modality(file_path)
        
        if modality == 'image':
            result = self._encode_image(file_path)
        elif modality == 'audio':
            result = self._encode_audio(file_path)
        elif modality == 'text':
            result = self._encode_text(file_path)
        else:
            logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_path}")
            return None
            
        if result:
            result.processing_time = time.time() - start_time
            
            # ìºì‹±
            if self.config['cache_enabled']:
                self.cache[file_hash] = result
                
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['encoded_files'] += 1
            self.stats['modality_counts'][modality] += 1
            self.stats['encoding_times'].append(result.processing_time)
            
        return result
    
    def _encode_image(self, file_path: Path) -> Optional[EncodedResult]:
        """ì´ë¯¸ì§€ ì¸ì½”ë”©"""
        try:
            # OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            image = cv2.imread(str(file_path))
            if image is None:
                logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {file_path}")
                return None
                
            ocr_results = self.models['ocr'].readtext(image)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì‹ ë¢°ë„ ê³„ì‚°
            extracted_text = ""
            confidences = []
            
            for (bbox, text, confidence) in ocr_results:
                if confidence > 0.3:  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                    extracted_text += text + " "
                    confidences.append(confidence)
                    
            extracted_text = extracted_text.strip()
            avg_confidence = np.mean(confidences) if confidences else 0.0
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° í™œìš©
            if len(extracted_text) < 10:
                # íŒŒì¼ëª…, ê²½ë¡œ ì •ë³´ í™œìš©
                path_info = f"ì´ë¯¸ì§€ íŒŒì¼ {file_path.name} ê²½ë¡œ {file_path.parent.name}"
                extracted_text = f"{extracted_text} {path_info}".strip()
                
            # ì„ë² ë”© ìƒì„± (768ì°¨ì›)
            if extracted_text:
                encoding = self.models['text_encoder'].encode([extracted_text])[0]
            else:
                # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì œë¡œ ë²¡í„°
                encoding = np.zeros(self.config['target_dimensions'], dtype=np.float32)
                avg_confidence = 0.0
                
            return EncodedResult(
                file_path=str(file_path),
                modality='image',
                encoding=encoding,
                confidence=avg_confidence,
                raw_content=extracted_text,
                metadata={
                    'ocr_blocks': len(ocr_results),
                    'image_size': image.shape[:2],
                    'text_length': len(extracted_text),
                    'high_confidence_blocks': sum(1 for _, _, conf in ocr_results if conf > 0.7)
                },
                processing_time=0.0  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
            )
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨ {file_path}: {e}")
            return None
    
    def _encode_audio(self, file_path: Path) -> Optional[EncodedResult]:
        """ì˜¤ë””ì˜¤ ì¸ì½”ë”©"""
        try:
            # Whisperë¡œ ìŒì„± ì¸ì‹
            whisper_result = self.models['whisper'].transcribe(str(file_path))
            transcribed_text = whisper_result.get('text', '').strip()
            
            # ì–¸ì–´ ë° í’ˆì§ˆ ì •ë³´
            language = whisper_result.get('language', 'unknown')
            segments = whisper_result.get('segments', [])
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ì„¸ê·¸ë¨¼íŠ¸ í‰ê· )
            if segments:
                segment_probs = []
                for seg in segments:
                    if 'avg_logprob' in seg:
                        # ë¡œê·¸ í™•ë¥ ì„ í™•ë¥ ë¡œ ë³€í™˜
                        prob = np.exp(seg['avg_logprob'])
                        segment_probs.append(prob)
                avg_confidence = np.mean(segment_probs) if segment_probs else 0.8
            else:
                avg_confidence = 0.8  # Whisper ê¸°ë³¸ ì‹ ë¢°ë„
                
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë©”íƒ€ë°ì´í„° í™œìš©
            if len(transcribed_text) < 5:
                path_info = f"ì˜¤ë””ì˜¤ íŒŒì¼ {file_path.name}"
                transcribed_text = f"{transcribed_text} {path_info}".strip()
                
            # ì„ë² ë”© ìƒì„±
            if transcribed_text:
                encoding = self.models['text_encoder'].encode([transcribed_text])[0]
            else:
                encoding = np.zeros(self.config['target_dimensions'], dtype=np.float32)
                avg_confidence = 0.0
                
            return EncodedResult(
                file_path=str(file_path),
                modality='audio',
                encoding=encoding,
                confidence=avg_confidence,
                raw_content=transcribed_text,
                metadata={
                    'language': language,
                    'duration': whisper_result.get('duration', 0),
                    'segments_count': len(segments),
                    'text_length': len(transcribed_text),
                    'whisper_model': self.config['whisper_model']
                },
                processing_time=0.0
            )
            
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì¸ì½”ë”© ì‹¤íŒ¨ {file_path}: {e}")
            return None
    
    def _encode_text(self, file_path: Path) -> Optional[EncodedResult]:
        """í…ìŠ¤íŠ¸ ì¸ì½”ë”©"""
        try:
            # íŒŒì¼ ì½ê¸° (ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„)
            content = ""
            encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-16', 'latin-1']
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
                    
            if not content:
                logger.warning(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path}")
                content = f"í…ìŠ¤íŠ¸ íŒŒì¼ {file_path.name} ì¸ì½”ë”© ì˜¤ë¥˜"
                
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸´ ê²½ìš° ìš”ì•½)
            original_length = len(content)
            if len(content) > 2000:
                # ì•ë¶€ë¶„ê³¼ ë’·ë¶€ë¶„ì„ í•©ì³ì„œ ì‚¬ìš©
                content = content[:1000] + " ... " + content[-500:]
                
            # ì„ë² ë”© ìƒì„±
            encoding = self.models['text_encoder'].encode([content])[0]
            
            return EncodedResult(
                file_path=str(file_path),
                modality='text',
                encoding=encoding,
                confidence=1.0 if original_length > 10 else 0.3,
                raw_content=content,
                metadata={
                    'original_length': original_length,
                    'processed_length': len(content),
                    'word_count': len(content.split()),
                    'encoding_success': True
                },
                processing_time=0.0
            )
            
        except Exception as e:
            logger.error(f"âŒ í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì‹¤íŒ¨ {file_path}: {e}")
            return None
    
    def _detect_modality(self, file_path: Path) -> str:
        """íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ëª¨ë‹¬ë¦¬í‹° íŒë³„"""
        ext = file_path.suffix.lower()
        
        if ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif', '.webp']:
            return 'image'
        elif ext in ['.wav', '.mp3', '.m4a', '.ogg', '.flac', '.aac']:
            return 'audio'
        elif ext in ['.txt', '.md', '.doc', '.docx', '.pdf', '.json']:
            return 'text'
        else:
            return 'unknown'
    
    def _get_file_hash(self, file_path: Path) -> str:
        """ìºì‹œìš© íŒŒì¼ í•´ì‹œ ìƒì„±"""
        try:
            stat = file_path.stat()
            hash_input = f"{file_path}_{stat.st_mtime}_{stat.st_size}"
            return hashlib.md5(hash_input.encode()).hexdigest()
        except Exception:
            return str(hash(str(file_path)))
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        avg_time = np.mean(self.stats['encoding_times']) if self.stats['encoding_times'] else 0
        
        return {
            'encoded_files': self.stats['encoded_files'],
            'cache_hits': self.stats['cache_hits'],
            'cache_hit_rate': f"{(self.stats['cache_hits'] / max(1, self.stats['encoded_files'])) * 100:.1f}%",
            'average_encoding_time': f"{avg_time:.3f}ì´ˆ",
            'modality_distribution': self.stats['modality_counts'].copy(),
            'total_processing_time': sum(self.stats['encoding_times'])
        }
    
    def normalize_encodings(self, encodings: List[EncodedResult]) -> List[EncodedResult]:
        """ì¸ì½”ë”© ê²°ê³¼ ì •ê·œí™”"""
        if not encodings:
            return encodings
            
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ì •ê·œí™”
        modalities = set(enc.modality for enc in encodings)
        
        for modality in modalities:
            modality_encodings = [enc for enc in encodings if enc.modality == modality]
            if len(modality_encodings) < 2:
                continue
                
            # ì¸ì½”ë”© ë²¡í„°ë“¤ ìˆ˜ì§‘
            vectors = np.array([enc.encoding for enc in modality_encodings])
            
            # í‘œì¤€í™”
            if modality not in self.scalers:
                self.scalers[modality] = StandardScaler()
                
            normalized_vectors = self.scalers[modality].fit_transform(vectors)
            
            # ì •ê·œí™”ëœ ë²¡í„° ë‹¤ì‹œ í• ë‹¹
            for i, enc in enumerate(modality_encodings):
                enc.encoding = normalized_vectors[i].astype(np.float32)
                enc.metadata['normalized'] = True
                
        return encodings

# ì‚¬ìš© ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸ ì½”ë“œ
def main():
    """ì‚¬ìš© ì˜ˆì œ"""
    encoder = MultimodalEncoder()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        Path("test_image.jpg"),
        Path("test_audio.wav"), 
        Path("test_document.txt")
    ]
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë“¤ë§Œ í•„í„°ë§
    existing_files = [f for f in test_files if f.exists()]
    
    if existing_files:
        print("ğŸ¤– ë©€í‹°ëª¨ë‹¬ ì¸ì½”ë” í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # ë°°ì¹˜ ì¸ì½”ë”©
        results = encoder.encode_batch(existing_files)
        
        print(f"\nğŸ“Š ì¸ì½”ë”© ê²°ê³¼: {len(results)}ê°œ íŒŒì¼")
        
        for result in results:
            print(f"\nğŸ“„ {Path(result.file_path).name}")
            print(f"   ëª¨ë‹¬ë¦¬í‹°: {result.modality}")
            print(f"   ì„ë² ë”© ì°¨ì›: {result.encoding.shape}")
            print(f"   ì‹ ë¢°ë„: {result.confidence:.2f}")
            print(f"   ì²˜ë¦¬ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            print(f"   ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {result.raw_content[:100]}...")
            
        # ì„±ëŠ¥ í†µê³„
        stats = encoder.get_performance_stats()
        print(f"\nğŸ“ˆ ì„±ëŠ¥ í†µê³„:")
        for key, value in stats.items():
            print(f"   {key}: {value}")
            
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ íŒŒì¼ë“¤ì„ ìƒì„±í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”:")
        for file in test_files:
            print(f"   - {file}")

if __name__ == "__main__":
    main()