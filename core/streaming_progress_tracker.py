#!/usr/bin/env python3
"""
ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ v2.6
ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ ì¶”ì 
"""

import time
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import logging
import streamlit as st
from pathlib import Path

@dataclass
class FileProcessingStatus:
    """íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ"""
    file_name: str
    file_size_mb: float
    processed_mb: float = 0.0
    status: str = "pending"  # pending, processing, completed, failed
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    current_chunk: int = 0
    total_chunks: int = 0
    processing_speed_mbps: float = 0.0
    memory_usage_mb: float = 0.0
    error_message: Optional[str] = None
    optimization_level: str = "balanced"
    streaming_enabled: bool = False

@dataclass
class BatchProcessingStatus:
    """ë°°ì¹˜ ì²˜ë¦¬ ìƒíƒœ"""
    total_files: int
    completed_files: int = 0
    failed_files: int = 0
    current_file_index: int = 0
    overall_progress_percent: float = 0.0
    estimated_completion_time: Optional[datetime] = None
    total_size_mb: float = 0.0
    processed_size_mb: float = 0.0
    files: List[FileProcessingStatus] = field(default_factory=list)

class StreamingProgressTracker:
    """ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.lock = threading.RLock()
        self.logger = self._setup_logging()
        
        # í˜„ì¬ ì²˜ë¦¬ ìƒíƒœ
        self.current_batch: Optional[BatchProcessingStatus] = None
        self.current_file: Optional[FileProcessingStatus] = None
        
        # ì§„í–‰ë¥  ì½œë°±ë“¤
        self.progress_callbacks: List[Callable] = []
        self.update_callbacks: List[Callable] = []
        
        # ì„±ëŠ¥ í†µê³„
        self.session_stats = {
            'total_files_processed': 0,
            'total_size_processed_mb': 0.0,
            'total_processing_time_seconds': 0.0,
            'average_speed_mbps': 0.0,
            'session_start_time': datetime.now()
        }
        
        # UI ì—…ë°ì´íŠ¸ ìŠ¤ë ˆë“œ
        self.ui_update_thread = None
        self.stop_ui_updates = False
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(f'{__name__}.{self.__class__.__name__}')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | %(name)s | %(levelname)s | %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def start_batch_processing(self, file_paths: List[str]) -> str:
        """ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘"""
        with self.lock:
            batch_id = f"batch_{int(time.time())}"
            
            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
            files = []
            total_size_mb = 0.0
            
            for file_path in file_paths:
                try:
                    path = Path(file_path)
                    if path.exists():
                        size_mb = path.stat().st_size / (1024 * 1024)
                        total_size_mb += size_mb
                        
                        file_status = FileProcessingStatus(
                            file_name=path.name,
                            file_size_mb=size_mb
                        )
                        files.append(file_status)
                    else:
                        self.logger.warning(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
                
                except Exception as e:
                    self.logger.error(f"âŒ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ {file_path}: {e}")
            
            # ë°°ì¹˜ ìƒíƒœ ì´ˆê¸°í™”
            self.current_batch = BatchProcessingStatus(
                total_files=len(files),
                total_size_mb=total_size_mb,
                files=files
            )
            
            self.logger.info(f"ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(files)}ê°œ íŒŒì¼, {total_size_mb:.1f}MB")
            
            # UI ì—…ë°ì´íŠ¸ ìŠ¤ë ˆë“œ ì‹œì‘
            self._start_ui_updates()
            
            return batch_id
    
    def start_file_processing(self, file_index: int, streaming_enabled: bool = False, optimization_level: str = "balanced") -> None:
        """íŒŒì¼ ì²˜ë¦¬ ì‹œì‘"""
        with self.lock:
            if not self.current_batch or file_index >= len(self.current_batch.files):
                return
            
            self.current_batch.current_file_index = file_index
            self.current_file = self.current_batch.files[file_index]
            
            # íŒŒì¼ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.current_file.status = "processing"
            self.current_file.start_time = datetime.now()
            self.current_file.streaming_enabled = streaming_enabled
            self.current_file.optimization_level = optimization_level
            
            self.logger.info(f"ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {self.current_file.file_name} ({self.current_file.file_size_mb:.1f}MB)")
            
            # ì½œë°± í˜¸ì¶œ
            self._trigger_update_callbacks()
    
    def update_file_progress(self, processed_mb: float, chunk_id: int = 0, total_chunks: int = 0, 
                           memory_usage_mb: float = 0.0, speed_mbps: float = 0.0) -> None:
        """íŒŒì¼ ì²˜ë¦¬ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        with self.lock:
            if not self.current_file:
                return
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            self.current_file.processed_mb = min(processed_mb, self.current_file.file_size_mb)
            self.current_file.current_chunk = chunk_id
            self.current_file.total_chunks = total_chunks
            self.current_file.memory_usage_mb = memory_usage_mb
            self.current_file.processing_speed_mbps = speed_mbps
            
            # ë°°ì¹˜ ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
            if self.current_batch:
                # ì´ì „ íŒŒì¼ë“¤ì˜ í¬ê¸°
                prev_files_size = sum(
                    f.file_size_mb for f in self.current_batch.files[:self.current_batch.current_file_index]
                )
                
                # í˜„ì¬ê¹Œì§€ ì²˜ë¦¬ëœ ì´ í¬ê¸°
                total_processed = prev_files_size + self.current_file.processed_mb
                
                # ì „ì²´ ì§„í–‰ë¥ 
                if self.current_batch.total_size_mb > 0:
                    self.current_batch.overall_progress_percent = (total_processed / self.current_batch.total_size_mb) * 100
                    self.current_batch.processed_size_mb = total_processed
                
                # ì™„ë£Œ ì‹œê°„ ì˜ˆì¸¡
                if speed_mbps > 0:
                    remaining_mb = self.current_batch.total_size_mb - total_processed
                    remaining_time_seconds = remaining_mb / speed_mbps
                    self.current_batch.estimated_completion_time = datetime.now() + timedelta(seconds=remaining_time_seconds)
            
            # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
            self._trigger_progress_callbacks()
    
    def complete_file_processing(self, success: bool = True, error_message: Optional[str] = None) -> None:
        """íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ"""
        with self.lock:
            if not self.current_file:
                return
            
            # íŒŒì¼ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.current_file.end_time = datetime.now()
            self.current_file.status = "completed" if success else "failed"
            
            if error_message:
                self.current_file.error_message = error_message
            
            # ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸
            if success:
                if self.current_batch:
                    self.current_batch.completed_files += 1
                
                self.session_stats['total_files_processed'] += 1
                self.session_stats['total_size_processed_mb'] += self.current_file.file_size_mb
                
                # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                if self.current_file.start_time:
                    processing_time = (self.current_file.end_time - self.current_file.start_time).total_seconds()
                    self.session_stats['total_processing_time_seconds'] += processing_time
                    
                    # í‰ê·  ì†ë„ ì—…ë°ì´íŠ¸
                    if self.session_stats['total_processing_time_seconds'] > 0:
                        self.session_stats['average_speed_mbps'] = (
                            self.session_stats['total_size_processed_mb'] / 
                            self.session_stats['total_processing_time_seconds']
                        )
            else:
                if self.current_batch:
                    self.current_batch.failed_files += 1
            
            status_icon = "âœ…" if success else "âŒ"
            self.logger.info(f"{status_icon} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {self.current_file.file_name}")
            
            # ì½œë°± í˜¸ì¶œ
            self._trigger_update_callbacks()
            
            self.current_file = None
    
    def complete_batch_processing(self) -> None:
        """ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ"""
        with self.lock:
            if not self.current_batch:
                return
            
            self.logger.info(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {self.current_batch.completed_files}/{self.current_batch.total_files} ì„±ê³µ")
            
            # UI ì—…ë°ì´íŠ¸ ì¤‘ì§€
            self._stop_ui_updates()
            
            # ìµœì¢… ì½œë°± í˜¸ì¶œ
            self._trigger_update_callbacks()
            
            self.current_batch = None
    
    def add_progress_callback(self, callback: Callable) -> None:
        """ì§„í–‰ë¥  ì½œë°± ì¶”ê°€"""
        with self.lock:
            if callback not in self.progress_callbacks:
                self.progress_callbacks.append(callback)
    
    def add_update_callback(self, callback: Callable) -> None:
        """ì—…ë°ì´íŠ¸ ì½œë°± ì¶”ê°€"""
        with self.lock:
            if callback not in self.update_callbacks:
                self.update_callbacks.append(callback)
    
    def remove_progress_callback(self, callback: Callable) -> None:
        """ì§„í–‰ë¥  ì½œë°± ì œê±°"""
        with self.lock:
            if callback in self.progress_callbacks:
                self.progress_callbacks.remove(callback)
    
    def remove_update_callback(self, callback: Callable) -> None:
        """ì—…ë°ì´íŠ¸ ì½œë°± ì œê±°"""
        with self.lock:
            if callback in self.update_callbacks:
                self.update_callbacks.remove(callback)
    
    def _trigger_progress_callbacks(self) -> None:
        """ì§„í–‰ë¥  ì½œë°± íŠ¸ë¦¬ê±°"""
        for callback in self.progress_callbacks:
            try:
                callback(self.get_current_status())
            except Exception as e:
                self.logger.error(f"âŒ ì§„í–‰ë¥  ì½œë°± ì˜¤ë¥˜: {e}")
    
    def _trigger_update_callbacks(self) -> None:
        """ì—…ë°ì´íŠ¸ ì½œë°± íŠ¸ë¦¬ê±°"""
        for callback in self.update_callbacks:
            try:
                callback(self.get_current_status())
            except Exception as e:
                self.logger.error(f"âŒ ì—…ë°ì´íŠ¸ ì½œë°± ì˜¤ë¥˜: {e}")
    
    def _start_ui_updates(self) -> None:
        """UI ì—…ë°ì´íŠ¸ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if self.ui_update_thread and self.ui_update_thread.is_alive():
            return
        
        self.stop_ui_updates = False
        self.ui_update_thread = threading.Thread(target=self._ui_update_loop, daemon=True)
        self.ui_update_thread.start()
    
    def _stop_ui_updates(self) -> None:
        """UI ì—…ë°ì´íŠ¸ ì¤‘ì§€"""
        self.stop_ui_updates = True
        if self.ui_update_thread and self.ui_update_thread.is_alive():
            self.ui_update_thread.join(timeout=1.0)
    
    def _ui_update_loop(self) -> None:
        """UI ì—…ë°ì´íŠ¸ ë£¨í”„"""
        while not self.stop_ui_updates:
            try:
                # ì£¼ê¸°ì ìœ¼ë¡œ UI ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
                if self.current_file and self.current_file.status == "processing":
                    self._trigger_progress_callbacks()
                
                time.sleep(0.5)  # 0.5ì´ˆ ê°„ê²©
            
            except Exception as e:
                self.logger.error(f"âŒ UI ì—…ë°ì´íŠ¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
                break
    
    def get_current_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            status = {
                'has_batch': self.current_batch is not None,
                'has_current_file': self.current_file is not None,
                'session_stats': self.session_stats.copy()
            }
            
            if self.current_batch:
                status['batch'] = {
                    'total_files': self.current_batch.total_files,
                    'completed_files': self.current_batch.completed_files,
                    'failed_files': self.current_batch.failed_files,
                    'current_file_index': self.current_batch.current_file_index,
                    'overall_progress_percent': self.current_batch.overall_progress_percent,
                    'total_size_mb': self.current_batch.total_size_mb,
                    'processed_size_mb': self.current_batch.processed_size_mb,
                    'estimated_completion_time': self.current_batch.estimated_completion_time.isoformat() if self.current_batch.estimated_completion_time else None
                }
            
            if self.current_file:
                file_progress_percent = (self.current_file.processed_mb / self.current_file.file_size_mb * 100) if self.current_file.file_size_mb > 0 else 0
                
                processing_time_seconds = 0
                if self.current_file.start_time:
                    processing_time_seconds = (datetime.now() - self.current_file.start_time).total_seconds()
                
                status['current_file'] = {
                    'file_name': self.current_file.file_name,
                    'file_size_mb': self.current_file.file_size_mb,
                    'processed_mb': self.current_file.processed_mb,
                    'progress_percent': file_progress_percent,
                    'status': self.current_file.status,
                    'current_chunk': self.current_file.current_chunk,
                    'total_chunks': self.current_file.total_chunks,
                    'processing_speed_mbps': self.current_file.processing_speed_mbps,
                    'memory_usage_mb': self.current_file.memory_usage_mb,
                    'processing_time_seconds': processing_time_seconds,
                    'optimization_level': self.current_file.optimization_level,
                    'streaming_enabled': self.current_file.streaming_enabled,
                    'error_message': self.current_file.error_message
                }
            
            return status
    
    def get_detailed_file_status(self, file_index: int) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • íŒŒì¼ì˜ ìƒì„¸ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            if not self.current_batch or file_index >= len(self.current_batch.files):
                return None
            
            file_status = self.current_batch.files[file_index]
            
            return {
                'file_name': file_status.file_name,
                'file_size_mb': file_status.file_size_mb,
                'processed_mb': file_status.processed_mb,
                'status': file_status.status,
                'start_time': file_status.start_time.isoformat() if file_status.start_time else None,
                'end_time': file_status.end_time.isoformat() if file_status.end_time else None,
                'current_chunk': file_status.current_chunk,
                'total_chunks': file_status.total_chunks,
                'processing_speed_mbps': file_status.processing_speed_mbps,
                'memory_usage_mb': file_status.memory_usage_mb,
                'optimization_level': file_status.optimization_level,
                'streaming_enabled': file_status.streaming_enabled,
                'error_message': file_status.error_message
            }
    
    def reset_session(self) -> None:
        """ì„¸ì…˜ ë¦¬ì…‹"""
        with self.lock:
            self._stop_ui_updates()
            
            self.current_batch = None
            self.current_file = None
            
            self.session_stats = {
                'total_files_processed': 0,
                'total_size_processed_mb': 0.0,
                'total_processing_time_seconds': 0.0,
                'average_speed_mbps': 0.0,
                'session_start_time': datetime.now()
            }
            
            self.logger.info("ğŸ”„ ì§„í–‰ë¥  ì¶”ì  ì„¸ì…˜ ë¦¬ì…‹")

# ì „ì—­ ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ
_global_progress_tracker = None
_global_tracker_lock = threading.Lock()

def get_global_progress_tracker() -> StreamingProgressTracker:
    """ì „ì—­ ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ ê°€ì ¸ì˜¤ê¸°"""
    global _global_progress_tracker
    
    with _global_tracker_lock:
        if _global_progress_tracker is None:
            _global_progress_tracker = StreamingProgressTracker()
        return _global_progress_tracker

# Streamlit ì§„í–‰ë¥  í‘œì‹œ ì»´í¬ë„ŒíŠ¸
def render_streaming_progress(tracker: StreamingProgressTracker) -> None:
    """Streamlitì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ë¥  í‘œì‹œ"""
    status = tracker.get_current_status()
    
    if not status['has_batch']:
        st.info("ğŸ“Š í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    batch_info = status['batch']
    
    # ì „ì²´ ì§„í–‰ë¥ 
    st.subheader("ğŸ“Š ì „ì²´ ì§„í–‰ ìƒí™©")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ğŸ“ ì´ íŒŒì¼",
            f"{batch_info['total_files']}ê°œ"
        )
    
    with col2:
        st.metric(
            "âœ… ì™„ë£Œ",
            f"{batch_info['completed_files']}ê°œ"
        )
    
    with col3:
        st.metric(
            "âŒ ì‹¤íŒ¨",
            f"{batch_info['failed_files']}ê°œ"
        )
    
    with col4:
        st.metric(
            "ğŸ“Š ì „ì²´ ì§„í–‰ë¥ ",
            f"{batch_info['overall_progress_percent']:.1f}%"
        )
    
    # ì§„í–‰ë¥  ë°”
    progress_bar = st.progress(batch_info['overall_progress_percent'] / 100)
    
    # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
    if batch_info['estimated_completion_time']:
        completion_time = datetime.fromisoformat(batch_info['estimated_completion_time'])
        remaining_time = completion_time - datetime.now()
        if remaining_time.total_seconds() > 0:
            st.info(f"â±ï¸ ì˜ˆìƒ ì™„ë£Œ ì‹œê°„: {remaining_time.total_seconds()/60:.1f}ë¶„ í›„")
    
    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼
    if status['has_current_file']:
        current_file = status['current_file']
        
        st.subheader(f"ğŸ“ í˜„ì¬ ì²˜ë¦¬ ì¤‘: {current_file['file_name']}")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "ğŸ“ˆ íŒŒì¼ ì§„í–‰ë¥ ",
                f"{current_file['progress_percent']:.1f}%"
            )
        
        with col2:
            st.metric(
                "âš¡ ì²˜ë¦¬ ì†ë„",
                f"{current_file['processing_speed_mbps']:.1f}MB/s"
            )
        
        with col3:
            st.metric(
                "ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©",
                f"{current_file['memory_usage_mb']:.1f}MB"
            )
        
        # íŒŒì¼ ì§„í–‰ë¥  ë°”
        file_progress_bar = st.progress(current_file['progress_percent'] / 100)
        
        # ì²­í¬ ì •ë³´ (ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš© ì‹œ)
        if current_file['streaming_enabled'] and current_file['total_chunks'] > 0:
            st.info(f"ğŸ”„ ì²­í¬ ì§„í–‰: {current_file['current_chunk']}/{current_file['total_chunks']} ({current_file['optimization_level']} ìµœì í™”)")
        
        # ì—ëŸ¬ ë©”ì‹œì§€
        if current_file['error_message']:
            st.error(f"âŒ ì˜¤ë¥˜: {current_file['error_message']}")
    
    # ì„¸ì…˜ í†µê³„
    session_stats = status['session_stats']
    
    with st.expander("ğŸ“Š ì„¸ì…˜ í†µê³„"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                "ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼",
                f"{session_stats['total_files_processed']}ê°œ"
            )
            st.metric(
                "ğŸ’¾ ì²˜ë¦¬ëœ í¬ê¸°",
                f"{session_stats['total_size_processed_mb']:.1f}MB"
            )
        
        with col2:
            st.metric(
                "â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„",
                f"{session_stats['total_processing_time_seconds']/60:.1f}ë¶„"
            )
            st.metric(
                "ğŸ“Š í‰ê·  ì†ë„",
                f"{session_stats['average_speed_mbps']:.1f}MB/s"
            )

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì§„í–‰ë¥  ì¶”ì 
    tracker = StreamingProgressTracker()
    
    # ë°°ì¹˜ ì‹œì‘
    test_files = ["test1.mp4", "test2.wav", "test3.jpg"]
    batch_id = tracker.start_batch_processing(test_files)
    
    # íŒŒì¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    for i, file_path in enumerate(test_files):
        tracker.start_file_processing(i, streaming_enabled=True, optimization_level="balanced")
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
        for progress in range(0, 101, 10):
            tracker.update_file_progress(
                processed_mb=progress * 0.1,  # ê°€ìƒ í¬ê¸°
                chunk_id=progress // 10,
                total_chunks=10,
                memory_usage_mb=50 + progress * 0.5,
                speed_mbps=10.0
            )
            
            time.sleep(0.1)  # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ê°„ê²©
        
        tracker.complete_file_processing(success=True)
    
    # ë°°ì¹˜ ì™„ë£Œ
    tracker.complete_batch_processing()
    
    print("âœ… ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ë¥  ì¶”ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")