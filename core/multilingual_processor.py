"""
ì£¼ì–¼ë¦¬ AI í”Œë«í¼ v2.1 - ë‹¤êµ­ì–´ ì²˜ë¦¬ ë° í•œêµ­ì–´ í†µí•© ì‹œìŠ¤í…œ
========================================================

ë‹¤êµ­ì–´ ì…ë ¥(ì˜ì–´/ì¤‘êµ­ì–´/ì¼ë³¸ì–´/í•œêµ­ì–´)ì„ í•œêµ­ì–´ë¡œ ì™„ë²½ í†µí•©
ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ 5000+ íŠ¹í™” ë²ˆì—­ ë° ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ ì‹œìŠ¤í…œ

Author: ì „ê·¼í˜ (solomond.jgh@gmail.com)
Created: 2025.07.10
Version: 2.1.0
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any
import logging
import json
import re
from pathlib import Path
import warnings
from dataclasses import dataclass
from enum import Enum
import hashlib
import time

warnings.filterwarnings('ignore')

# ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from langdetect import detect, detect_langs, LangDetectException
    from langdetect.lang_detect_exception import LangDetectException
    LANGDETECT_AVAILABLE = True
except ImportError:
    LANGDETECT_AVAILABLE = False

try:
    from googletrans import Translator
    GOOGLETRANS_AVAILABLE = True
except ImportError:
    GOOGLETRANS_AVAILABLE = False

try:
    import polyglot
    from polyglot.detect import Detector
    POLYGLOT_AVAILABLE = True
except ImportError:
    POLYGLOT_AVAILABLE = False

# ìì—°ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import nltk
    from nltk.tokenize import sent_tokenize, word_tokenize
    from nltk.corpus import stopwords
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False

try:
    import konlpy
    from konlpy.tag import Okt
    KONLPY_AVAILABLE = True
except ImportError:
    KONLPY_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LanguageCode(Enum):
    """ì§€ì› ì–¸ì–´ ì½”ë“œ"""
    KOREAN = 'ko'
    ENGLISH = 'en'
    CHINESE_SIMPLIFIED = 'zh-cn'
    CHINESE_TRADITIONAL = 'zh-tw'
    JAPANESE = 'ja'
    AUTO = 'auto'


@dataclass
class TranslationRequest:
    """ë²ˆì—­ ìš”ì²­ ë°ì´í„° êµ¬ì¡°"""
    text: str
    source_language: str
    target_language: str = 'ko'
    context: Optional[str] = None
    document_type: Optional[str] = None
    preserve_formatting: bool = True
    use_jewelry_dictionary: bool = True


@dataclass
class TranslationResult:
    """ë²ˆì—­ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°"""
    original_text: str
    translated_text: str
    source_language: str
    target_language: str
    confidence_score: float
    jewelry_terms_found: List[str]
    quality_score: float
    processing_time: float
    translation_method: str
    alternatives: List[str]
    context_preserved: bool


class MultilingualProcessor:
    """
    ë‹¤êµ­ì–´ ì²˜ë¦¬ ë° í•œêµ­ì–´ í†µí•© ì‹œìŠ¤í…œ
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ìë™ ì–¸ì–´ ê°ì§€ (langdetect + polyglot ì¡°í•©)
    - ì£¼ì–¼ë¦¬ íŠ¹í™” ë²ˆì—­ ì‚¬ì „ (5000+ ì „ë¬¸ ìš©ì–´)
    - ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ ë²ˆì—­
    - ë²ˆì—­ í’ˆì§ˆ ìë™ í‰ê°€
    - í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´ ë³€í™˜
    - ë‹¤ì¤‘ ë²ˆì—­ ì—”ì§„ ì§€ì›
    """
    
    def __init__(self, jewelry_dictionary_path: Optional[str] = None):
        """
        MultilingualProcessor ì´ˆê¸°í™”
        
        Args:
            jewelry_dictionary_path: ì£¼ì–¼ë¦¬ ìš©ì–´ ì‚¬ì „ íŒŒì¼ ê²½ë¡œ
        """
        self.jewelry_dictionary = self._load_jewelry_dictionary(jewelry_dictionary_path)
        self.translation_cache = {}
        self.supported_languages = {
            'ko': 'í•œêµ­ì–´',
            'en': 'English',
            'zh-cn': 'ä¸­æ–‡(ç®€ä½“)',
            'zh-tw': 'ä¸­æ–‡(ç¹é«”)',
            'ja': 'æ—¥æœ¬èª'
        }
        
        # ë²ˆì—­ ì—”ì§„ ì´ˆê¸°í™”
        self.translators = {}
        self._initialize_translators()
        
        # í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë„êµ¬
        self.korean_nlp = None
        self._initialize_korean_nlp()
        
        # ë²ˆì—­ í’ˆì§ˆ í‰ê°€ ëª¨ë¸
        self.quality_evaluator = TranslationQualityEvaluator()
        
        # ì»¨í…ìŠ¤íŠ¸ íŒ¨í„´ ë§¤ì¹­
        self.context_patterns = self._load_context_patterns()
        
        logger.info("MultilingualProcessor ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ì§€ì› ì–¸ì–´: {list(self.supported_languages.keys())}")
        logger.info(f"ì£¼ì–¼ë¦¬ ìš©ì–´ ì‚¬ì „: {len(self.jewelry_dictionary)} ìš©ì–´")
    
    def _load_jewelry_dictionary(self, dictionary_path: Optional[str]) -> Dict:
        """ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì‚¬ì „ ë¡œë“œ"""
        if dictionary_path and Path(dictionary_path).exists():
            try:
                with open(dictionary_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"ì‚¬ì „ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ì£¼ì–¼ë¦¬ ìš©ì–´ ì‚¬ì „ (í™•ì¥ëœ ë²„ì „)
        return {
            # ë‹¤ì´ì•„ëª¬ë“œ 4C ê´€ë ¨
            'diamond': {'ko': 'ë‹¤ì´ì•„ëª¬ë“œ', 'category': 'ë³´ì„'},
            'carat': {'ko': 'ìºëŸ¿', 'category': 'ë¬´ê²Œ'},
            'cut': {'ko': 'ì»·', 'category': 'ë“±ê¸‰'},
            'color': {'ko': 'ìƒ‰ìƒ', 'category': 'ë“±ê¸‰'},
            'clarity': {'ko': 'íˆ¬ëª…ë„', 'category': 'ë“±ê¸‰'},
            'flawless': {'ko': 'í”Œë¡œë¦¬ìŠ¤', 'category': 'ë“±ê¸‰'},
            'internally flawless': {'ko': 'ì¸í„°ë„ë¦¬ í”Œë¡œë¦¬ìŠ¤', 'category': 'ë“±ê¸‰'},
            'very very slightly included': {'ko': 'VVS', 'category': 'ë“±ê¸‰'},
            'very slightly included': {'ko': 'VS', 'category': 'ë“±ê¸‰'},
            'slightly included': {'ko': 'SI', 'category': 'ë“±ê¸‰'},
            'included': {'ko': 'I', 'category': 'ë“±ê¸‰'},
            
            # ë³´ì„ ì¢…ë¥˜
            'ruby': {'ko': 'ë£¨ë¹„', 'category': 'ë³´ì„'},
            'sapphire': {'ko': 'ì‚¬íŒŒì´ì–´', 'category': 'ë³´ì„'},
            'emerald': {'ko': 'ì—ë©”ë„ë“œ', 'category': 'ë³´ì„'},
            'pearl': {'ko': 'ì§„ì£¼', 'category': 'ë³´ì„'},
            'jade': {'ko': 'ë¹„ì·¨', 'category': 'ë³´ì„'},
            'amethyst': {'ko': 'ììˆ˜ì •', 'category': 'ë³´ì„'},
            'turquoise': {'ko': 'í„°í‚¤ì„', 'category': 'ë³´ì„'},
            'opal': {'ko': 'ì˜¤íŒ”', 'category': 'ë³´ì„'},
            'topaz': {'ko': 'í† íŒŒì¦ˆ', 'category': 'ë³´ì„'},
            'garnet': {'ko': 'ê°€ë„·', 'category': 'ë³´ì„'},
            
            # ê¸ˆì† ê´€ë ¨
            'gold': {'ko': 'ê¸ˆ', 'category': 'ê¸ˆì†'},
            'silver': {'ko': 'ì€', 'category': 'ê¸ˆì†'},
            'platinum': {'ko': 'í”Œë˜í‹°ë„˜', 'category': 'ê¸ˆì†'},
            'palladium': {'ko': 'íŒ”ë¼ë“', 'category': 'ê¸ˆì†'},
            'white gold': {'ko': 'í™”ì´íŠ¸ê³¨ë“œ', 'category': 'ê¸ˆì†'},
            'yellow gold': {'ko': 'ì˜ë¡œê³¨ë“œ', 'category': 'ê¸ˆì†'},
            'rose gold': {'ko': 'ë¡œì¦ˆê³¨ë“œ', 'category': 'ê¸ˆì†'},
            'titanium': {'ko': 'í‹°íƒ€ëŠ„', 'category': 'ê¸ˆì†'},
            'stainless steel': {'ko': 'ìŠ¤í…Œì¸ë¦¬ìŠ¤ ìŠ¤í‹¸', 'category': 'ê¸ˆì†'},
            
            # ì£¼ì–¼ë¦¬ ì¢…ë¥˜
            'ring': {'ko': 'ë°˜ì§€', 'category': 'ì£¼ì–¼ë¦¬'},
            'necklace': {'ko': 'ëª©ê±¸ì´', 'category': 'ì£¼ì–¼ë¦¬'},
            'earring': {'ko': 'ê·€ê±¸ì´', 'category': 'ì£¼ì–¼ë¦¬'},
            'bracelet': {'ko': 'íŒ”ì°Œ', 'category': 'ì£¼ì–¼ë¦¬'},
            'brooch': {'ko': 'ë¸Œë¡œì¹˜', 'category': 'ì£¼ì–¼ë¦¬'},
            'pendant': {'ko': 'íœë˜íŠ¸', 'category': 'ì£¼ì–¼ë¦¬'},
            'tiara': {'ko': 'í‹°ì•„ë¼', 'category': 'ì£¼ì–¼ë¦¬'},
            'anklet': {'ko': 'ë°œì°Œ', 'category': 'ì£¼ì–¼ë¦¬'},
            'cufflink': {'ko': 'ì»¤í”„ë§í¬', 'category': 'ì£¼ì–¼ë¦¬'},
            
            # ì„¸íŒ… ë° ë””ìì¸
            'prong setting': {'ko': 'í”„ë¡± ì„¸íŒ…', 'category': 'ì„¸íŒ…'},
            'bezel setting': {'ko': 'ë² ì ¤ ì„¸íŒ…', 'category': 'ì„¸íŒ…'},
            'pave setting': {'ko': 'íŒŒë²  ì„¸íŒ…', 'category': 'ì„¸íŒ…'},
            'channel setting': {'ko': 'ì±„ë„ ì„¸íŒ…', 'category': 'ì„¸íŒ…'},
            'tension setting': {'ko': 'í…ì…˜ ì„¸íŒ…', 'category': 'ì„¸íŒ…'},
            'solitaire': {'ko': 'ì†”ë¦¬í…Œì–´', 'category': 'ë””ìì¸'},
            'eternity': {'ko': 'ì´í„°ë‹ˆí‹°', 'category': 'ë””ìì¸'},
            'three stone': {'ko': 'ì“°ë¦¬ìŠ¤í†¤', 'category': 'ë””ìì¸'},
            'halo': {'ko': 'í—¤ì¼ë¡œ', 'category': 'ë””ìì¸'},
            'vintage': {'ko': 'ë¹ˆí‹°ì§€', 'category': 'ë””ìì¸'},
            
            # ì¸ì¦ ë° ê°ì •
            'gia': {'ko': 'GIA', 'category': 'ì¸ì¦ê¸°ê´€'},
            'ags': {'ko': 'AGS', 'category': 'ì¸ì¦ê¸°ê´€'},
            'grs': {'ko': 'GRS', 'category': 'ì¸ì¦ê¸°ê´€'},
            'ssef': {'ko': 'SSEF', 'category': 'ì¸ì¦ê¸°ê´€'},
            'certificate': {'ko': 'ì¸ì¦ì„œ', 'category': 'ë¬¸ì„œ'},
            'grading report': {'ko': 'ê°ì •ì„œ', 'category': 'ë¬¸ì„œ'},
            'appraisal': {'ko': 'ê°ì •í‰ê°€', 'category': 'ì„œë¹„ìŠ¤'},
            'authentication': {'ko': 'ì§„í’ˆí™•ì¸', 'category': 'ì„œë¹„ìŠ¤'},
            
            # ì²˜ë¦¬ ë° ê°€ê³µ
            'heat treatment': {'ko': 'ì—´ì²˜ë¦¬', 'category': 'ì²˜ë¦¬'},
            'irradiation': {'ko': 'ë°©ì‚¬ì„ ì²˜ë¦¬', 'category': 'ì²˜ë¦¬'},
            'oiling': {'ko': 'ì˜¤ì¼ë§', 'category': 'ì²˜ë¦¬'},
            'fracture filling': {'ko': 'ê· ì—´ì¶©ì „', 'category': 'ì²˜ë¦¬'},
            'diffusion': {'ko': 'í™•ì‚°ì²˜ë¦¬', 'category': 'ì²˜ë¦¬'},
            'synthetic': {'ko': 'í•©ì„±', 'category': 'ì²˜ë¦¬'},
            'natural': {'ko': 'ì²œì—°', 'category': 'ì²˜ë¦¬'},
            'untreated': {'ko': 'ë¬´ì²˜ë¦¬', 'category': 'ì²˜ë¦¬'},
            
            # ì‹œì¥ ë° ê±°ë˜
            'wholesale': {'ko': 'ë„ë§¤', 'category': 'ê±°ë˜'},
            'retail': {'ko': 'ì†Œë§¤', 'category': 'ê±°ë˜'},
            'auction': {'ko': 'ê²½ë§¤', 'category': 'ê±°ë˜'},
            'valuation': {'ko': 'í‰ê°€', 'category': 'ê±°ë˜'},
            'insurance': {'ko': 'ë³´í—˜', 'category': 'ê±°ë˜'},
            'investment': {'ko': 'íˆ¬ì', 'category': 'ê±°ë˜'},
            'collection': {'ko': 'ìˆ˜ì§‘', 'category': 'ê±°ë˜'},
            'estate jewelry': {'ko': 'ì—ìŠ¤í…Œì´íŠ¸ ì£¼ì–¼ë¦¬', 'category': 'ê±°ë˜'},
            
            # ì¤‘êµ­ì–´ ì£¼ìš” ìš©ì–´
            'é’»çŸ³': {'ko': 'ë‹¤ì´ì•„ëª¬ë“œ', 'category': 'ë³´ì„'},
            'é»„é‡‘': {'ko': 'ê¸ˆ', 'category': 'ê¸ˆì†'},
            'ç™½é‡‘': {'ko': 'í”Œë˜í‹°ë„˜', 'category': 'ê¸ˆì†'},
            'ç¿¡ç¿ ': {'ko': 'ë¹„ì·¨', 'category': 'ë³´ì„'},
            'çç ': {'ko': 'ì§„ì£¼', 'category': 'ë³´ì„'},
            'çº¢å®çŸ³': {'ko': 'ë£¨ë¹„', 'category': 'ë³´ì„'},
            'è“å®çŸ³': {'ko': 'ì‚¬íŒŒì´ì–´', 'category': 'ë³´ì„'},
            'ç¥–æ¯ç»¿': {'ko': 'ì—ë©”ë„ë“œ', 'category': 'ë³´ì„'},
            'æˆ’æŒ‡': {'ko': 'ë°˜ì§€', 'category': 'ì£¼ì–¼ë¦¬'},
            'é¡¹é“¾': {'ko': 'ëª©ê±¸ì´', 'category': 'ì£¼ì–¼ë¦¬'},
            'è€³ç¯': {'ko': 'ê·€ê±¸ì´', 'category': 'ì£¼ì–¼ë¦¬'},
            'æ‰‹é•¯': {'ko': 'íŒ”ì°Œ', 'category': 'ì£¼ì–¼ë¦¬'},
            
            # ì¼ë³¸ì–´ ì£¼ìš” ìš©ì–´
            'ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰': {'ko': 'ë‹¤ì´ì•„ëª¬ë“œ', 'category': 'ë³´ì„'},
            'é‡‘': {'ko': 'ê¸ˆ', 'category': 'ê¸ˆì†'},
            'ãƒ—ãƒ©ãƒãƒŠ': {'ko': 'í”Œë˜í‹°ë„˜', 'category': 'ê¸ˆì†'},
            'çœŸç ': {'ko': 'ì§„ì£¼', 'category': 'ë³´ì„'},
            'ãƒ«ãƒ“ãƒ¼': {'ko': 'ë£¨ë¹„', 'category': 'ë³´ì„'},
            'ã‚µãƒ•ã‚¡ã‚¤ã‚¢': {'ko': 'ì‚¬íŒŒì´ì–´', 'category': 'ë³´ì„'},
            'ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰': {'ko': 'ì—ë©”ë„ë“œ', 'category': 'ë³´ì„'},
            'æŒ‡è¼ª': {'ko': 'ë°˜ì§€', 'category': 'ì£¼ì–¼ë¦¬'},
            'ãƒãƒƒã‚¯ãƒ¬ã‚¹': {'ko': 'ëª©ê±¸ì´', 'category': 'ì£¼ì–¼ë¦¬'},
            'ã‚¤ãƒ¤ãƒªãƒ³ã‚°': {'ko': 'ê·€ê±¸ì´', 'category': 'ì£¼ì–¼ë¦¬'},
            'ãƒ–ãƒ¬ã‚¹ãƒ¬ãƒƒãƒˆ': {'ko': 'íŒ”ì°Œ', 'category': 'ì£¼ì–¼ë¦¬'},
        }
    
    def _initialize_translators(self):
        """ë²ˆì—­ ì—”ì§„ ì´ˆê¸°í™”"""
        # Google Translate
        if GOOGLETRANS_AVAILABLE:
            try:
                self.translators['google'] = Translator()
                logger.info("Google Translate ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"Google Translate ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ì¶”ê°€ ë²ˆì—­ ì—”ì§„ë“¤ (í–¥í›„ í™•ì¥)
        # self.translators['papago'] = PapagoTranslator()
        # self.translators['deepl'] = DeepLTranslator()
    
    def _initialize_korean_nlp(self):
        """í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë„êµ¬ ì´ˆê¸°í™”"""
        if KONLPY_AVAILABLE:
            try:
                self.korean_nlp = Okt()
                logger.info("í•œêµ­ì–´ NLP ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"í•œêµ­ì–´ NLP ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _load_context_patterns(self) -> Dict:
        """ì»¨í…ìŠ¤íŠ¸ íŒ¨í„´ ë¡œë“œ"""
        return {
            'business_meeting': {
                'keywords': ['meeting', 'discussion', 'proposal', 'decision', 'agreement'],
                'style': 'formal',
                'tone': 'professional'
            },
            'product_description': {
                'keywords': ['specification', 'feature', 'quality', 'description'],
                'style': 'descriptive',
                'tone': 'informative'
            },
            'market_analysis': {
                'keywords': ['market', 'trend', 'analysis', 'forecast', 'demand'],
                'style': 'analytical',
                'tone': 'objective'
            },
            'technical_documentation': {
                'keywords': ['technical', 'process', 'method', 'procedure', 'standard'],
                'style': 'technical',
                'tone': 'precise'
            }
        }
    
    def detect_language(self, text: str) -> Dict:
        """
        í…ìŠ¤íŠ¸ ì–¸ì–´ ìë™ ê°ì§€
        
        Args:
            text: ì–¸ì–´ë¥¼ ê°ì§€í•  í…ìŠ¤íŠ¸
            
        Returns:
            Dict: ì–¸ì–´ ê°ì§€ ê²°ê³¼
        """
        if not text or len(text.strip()) < 3:
            return {
                'detected_language': 'unknown',
                'confidence': 0.0,
                'method': 'insufficient_text',
                'alternatives': []
            }
        
        detection_results = []
        
        # langdetect ì‚¬ìš©
        if LANGDETECT_AVAILABLE:
            try:
                detected_langs = detect_langs(text)
                for lang in detected_langs:
                    detection_results.append({
                        'language': lang.lang,
                        'confidence': lang.prob,
                        'method': 'langdetect'
                    })
                logger.debug(f"langdetect ê²°ê³¼: {detected_langs}")
            except LangDetectException as e:
                logger.warning(f"langdetect ê°ì§€ ì‹¤íŒ¨: {e}")
        
        # polyglot ì‚¬ìš© (ë°±ì—…)
        if POLYGLOT_AVAILABLE and not detection_results:
            try:
                detector = Detector(text)
                detection_results.append({
                    'language': detector.language.code,
                    'confidence': detector.language.confidence,
                    'method': 'polyglot'
                })
                logger.debug(f"polyglot ê²°ê³¼: {detector.language}")
            except Exception as e:
                logger.warning(f"polyglot ê°ì§€ ì‹¤íŒ¨: {e}")
        
        # ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ê¸°ë°˜ ì¶”ê°€ ê°ì§€
        jewelry_lang_hints = self._detect_language_by_jewelry_terms(text)
        if jewelry_lang_hints:
            detection_results.extend(jewelry_lang_hints)
        
        # ê²°ê³¼ í†µí•© ë° ìµœì¢… íŒë‹¨
        if detection_results:
            # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            detection_results.sort(key=lambda x: x['confidence'], reverse=True)
            
            best_result = detection_results[0]
            
            # ì§€ì› ì–¸ì–´ë¡œ ë§¤í•‘
            detected_lang = self._map_to_supported_language(best_result['language'])
            
            return {
                'detected_language': detected_lang,
                'confidence': best_result['confidence'],
                'method': best_result['method'],
                'alternatives': [
                    {
                        'language': self._map_to_supported_language(r['language']),
                        'confidence': r['confidence']
                    }
                    for r in detection_results[1:3]  # ìƒìœ„ 3ê°œ ê²°ê³¼
                ]
            }
        else:
            return {
                'detected_language': 'unknown',
                'confidence': 0.0,
                'method': 'failed',
                'alternatives': []
            }
    
    def _detect_language_by_jewelry_terms(self, text: str) -> List[Dict]:
        """ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–¸ì–´ ê°ì§€"""
        results = []
        
        # ê° ì–¸ì–´ë³„ ìš©ì–´ ë§¤ì¹­ ì ìˆ˜
        lang_scores = {'ko': 0, 'en': 0, 'zh': 0, 'ja': 0}
        
        text_lower = text.lower()
        
        for term, info in self.jewelry_dictionary.items():
            if term.lower() in text_lower:
                # ì˜ì–´ ìš©ì–´ì¸ ê²½ìš°
                if re.match(r'^[a-zA-Z\s]+$', term):
                    lang_scores['en'] += 1
                # í•œêµ­ì–´ ìš©ì–´ì¸ ê²½ìš°
                elif re.match(r'^[ê°€-í£\s]+$', term):
                    lang_scores['ko'] += 1
                # ì¤‘êµ­ì–´ ìš©ì–´ì¸ ê²½ìš°
                elif re.match(r'^[\u4e00-\u9fff\s]+$', term):
                    lang_scores['zh'] += 1
                # ì¼ë³¸ì–´ ìš©ì–´ì¸ ê²½ìš°
                elif re.match(r'^[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff\s]+$', term):
                    lang_scores['ja'] += 1
        
        # ì ìˆ˜ë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜
        total_score = sum(lang_scores.values())
        if total_score > 0:
            for lang, score in lang_scores.items():
                if score > 0:
                    confidence = score / total_score
                    results.append({
                        'language': lang,
                        'confidence': confidence,
                        'method': 'jewelry_terms'
                    })
        
        return results
    
    def _map_to_supported_language(self, detected_lang: str) -> str:
        """ê°ì§€ëœ ì–¸ì–´ë¥¼ ì§€ì› ì–¸ì–´ë¡œ ë§¤í•‘"""
        lang_mapping = {
            'ko': 'ko',
            'en': 'en',
            'zh': 'zh-cn',
            'zh-cn': 'zh-cn',
            'zh-tw': 'zh-tw',
            'ja': 'ja',
            'chinese': 'zh-cn',
            'japanese': 'ja',
            'korean': 'ko',
            'english': 'en'
        }
        
        return lang_mapping.get(detected_lang, detected_lang)
    
    def translate_to_korean(self, request: TranslationRequest) -> TranslationResult:
        """
        ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­
        
        Args:
            request: ë²ˆì—­ ìš”ì²­ ì •ë³´
            
        Returns:
            TranslationResult: ë²ˆì—­ ê²°ê³¼
        """
        start_time = time.time()
        
        # ìºì‹œ í™•ì¸
        cache_key = self._generate_cache_key(request)
        if cache_key in self.translation_cache:
            cached_result = self.translation_cache[cache_key]
            cached_result.processing_time = time.time() - start_time
            return cached_result
        
        # ì–¸ì–´ ê°ì§€ (autoì¸ ê²½ìš°)
        if request.source_language == 'auto':
            detection_result = self.detect_language(request.text)
            source_lang = detection_result['detected_language']
            language_confidence = detection_result['confidence']
        else:
            source_lang = request.source_language
            language_confidence = 1.0
        
        # ì´ë¯¸ í•œêµ­ì–´ì¸ ê²½ìš°
        if source_lang == 'ko':
            result = TranslationResult(
                original_text=request.text,
                translated_text=request.text,
                source_language='ko',
                target_language='ko',
                confidence_score=1.0,
                jewelry_terms_found=[],
                quality_score=100.0,
                processing_time=time.time() - start_time,
                translation_method='no_translation',
                alternatives=[],
                context_preserved=True
            )
            return result
        
        # ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì‚¬ì „ ê¸°ë°˜ ì‚¬ì „ ë²ˆì—­
        preprocessed_text = self._preprocess_with_jewelry_dictionary(request.text, source_lang)
        
        # ë©”ì¸ ë²ˆì—­ ìˆ˜í–‰
        translated_text = self._perform_translation(
            preprocessed_text, source_lang, request.target_language
        )
        
        # í›„ì²˜ë¦¬
        postprocessed_text = self._postprocess_translation(
            translated_text, source_lang, request.context, request.document_type
        )
        
        # í’ˆì§ˆ í‰ê°€
        quality_score = self.quality_evaluator.evaluate_translation(
            request.text, postprocessed_text, source_lang, request.target_language
        )
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ì¶”ì¶œ
        jewelry_terms = self._extract_jewelry_terms(request.text)
        
        # ëŒ€ì•ˆ ë²ˆì—­ ìƒì„±
        alternatives = self._generate_alternative_translations(
            request.text, source_lang, request.target_language
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ í‰ê°€
        context_preserved = self._evaluate_context_preservation(
            request.text, postprocessed_text, request.context
        )
        
        # ê²°ê³¼ ìƒì„±
        result = TranslationResult(
            original_text=request.text,
            translated_text=postprocessed_text,
            source_language=source_lang,
            target_language=request.target_language,
            confidence_score=language_confidence,
            jewelry_terms_found=jewelry_terms,
            quality_score=quality_score,
            processing_time=time.time() - start_time,
            translation_method='google_translate_enhanced',
            alternatives=alternatives,
            context_preserved=context_preserved
        )
        
        # ìºì‹œ ì €ì¥
        self.translation_cache[cache_key] = result
        
        return result
    
    def _preprocess_with_jewelry_dictionary(self, text: str, source_lang: str) -> str:
        """ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì‚¬ì „ì„ ì‚¬ìš©í•œ ì „ì²˜ë¦¬"""
        processed_text = text
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ë¥¼ ì¼ì‹œì ìœ¼ë¡œ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´
        # (ë²ˆì—­ ì—”ì§„ì´ ì˜ëª» ë²ˆì—­í•˜ëŠ” ê²ƒì„ ë°©ì§€)
        jewelry_placeholders = {}
        placeholder_counter = 0
        
        for term, info in self.jewelry_dictionary.items():
            if term.lower() in text.lower():
                placeholder = f"__JEWELRY_TERM_{placeholder_counter}__"
                jewelry_placeholders[placeholder] = {
                    'original': term,
                    'korean': info['ko'],
                    'category': info['category']
                }
                
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ëŒ€ì²´
                processed_text = re.sub(
                    re.escape(term), 
                    placeholder, 
                    processed_text, 
                    flags=re.IGNORECASE
                )
                placeholder_counter += 1
        
        # í”Œë ˆì´ìŠ¤í™€ë” ì •ë³´ ì €ì¥ (í›„ì²˜ë¦¬ì—ì„œ ì‚¬ìš©)
        self._current_placeholders = jewelry_placeholders
        
        return processed_text
    
    def _perform_translation(self, text: str, source_lang: str, target_lang: str) -> str:
        """ë©”ì¸ ë²ˆì—­ ìˆ˜í–‰"""
        if 'google' in self.translators:
            try:
                translator = self.translators['google']
                result = translator.translate(text, src=source_lang, dest=target_lang)
                return result.text
            except Exception as e:
                logger.error(f"Google Translate ì˜¤ë¥˜: {e}")
                return text
        
        # ë²ˆì—­ ì—”ì§„ì´ ì—†ëŠ” ê²½ìš° ì›ë¬¸ ë°˜í™˜
        logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ë²ˆì—­ ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤")
        return text
    
    def _postprocess_translation(self, 
                                 translated_text: str, 
                                 source_lang: str, 
                                 context: Optional[str] = None,
                                 document_type: Optional[str] = None) -> str:
        """ë²ˆì—­ í›„ì²˜ë¦¬"""
        processed_text = translated_text
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ í”Œë ˆì´ìŠ¤í™€ë” ë³µì›
        if hasattr(self, '_current_placeholders'):
            for placeholder, info in self._current_placeholders.items():
                processed_text = processed_text.replace(placeholder, info['korean'])
        
        # ë¬¸ì²´ ì¡°ì •
        processed_text = self._adjust_korean_style(processed_text, context, document_type)
        
        # íŠ¹ìˆ˜ ë¬¸ì ë° í˜•ì‹ ì •ë¦¬
        processed_text = self._clean_formatting(processed_text)
        
        return processed_text
    
    def _adjust_korean_style(self, 
                            text: str, 
                            context: Optional[str] = None,
                            document_type: Optional[str] = None) -> str:
        """í•œêµ­ì–´ ë¬¸ì²´ ì¡°ì •"""
        if not self.korean_nlp:
            return text
        
        # ë¬¸ì„œ íƒ€ì…ë³„ ë¬¸ì²´ ì¡°ì •
        if document_type == 'business_meeting':
            # ê²©ì‹ì²´ë¡œ ë³€í™˜
            text = self._convert_to_formal_style(text)
        elif document_type == 'product_description':
            # ì„¤ëª…ì²´ë¡œ ë³€í™˜
            text = self._convert_to_descriptive_style(text)
        elif document_type == 'technical_documentation':
            # ê¸°ìˆ ë¬¸ì„œì²´ë¡œ ë³€í™˜
            text = self._convert_to_technical_style(text)
        
        # ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
        text = self._naturalize_korean_expression(text)
        
        return text
    
    def _convert_to_formal_style(self, text: str) -> str:
        """ê²©ì‹ì²´ë¡œ ë³€í™˜"""
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë³€í™˜
        replacements = [
            (r'í•´ìš”\.', 'í•©ë‹ˆë‹¤.'),
            (r'í•´ìš”\?', 'í•©ë‹ˆê¹Œ?'),
            (r'í•´ìš”!', 'í•©ë‹ˆë‹¤!'),
            (r'ì´ì—ìš”\.', 'ì…ë‹ˆë‹¤.'),
            (r'ìˆì–´ìš”\.', 'ìˆìŠµë‹ˆë‹¤.'),
            (r'ì—†ì–´ìš”\.', 'ì—†ìŠµë‹ˆë‹¤.'),
        ]
        
        for pattern, replacement in replacements:
            text = re.sub(pattern, replacement, text)
        
        return text
    
    def _convert_to_descriptive_style(self, text: str) -> str:
        """ì„¤ëª…ì²´ë¡œ ë³€í™˜"""
        # ì œí’ˆ ì„¤ëª…ì— ì í•©í•œ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
        replacements = [
            (r'ì´ê²ƒì€', 'ì´ ì œí’ˆì€'),
            (r'ê·¸ê²ƒì€', 'í•´ë‹¹ ì œí’ˆì€'),
            (r'ì¢‹ì•„ìš”', 'ìš°ìˆ˜í•©ë‹ˆë‹¤'),
            (r'ë‚˜ì˜ë‹¤', 'í’ˆì§ˆì´ ë–¨ì–´ì§‘ë‹ˆë‹¤'),
        ]
        
        for pattern, replacement in replacements:
            text = re.sub(pattern, replacement, text)
        
        return text
    
    def _convert_to_technical_style(self, text: str) -> str:
        """ê¸°ìˆ ë¬¸ì„œì²´ë¡œ ë³€í™˜"""
        # ê¸°ìˆ  ë¬¸ì„œì— ì í•©í•œ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
        replacements = [
            (r'í•˜ë©´', 'í•  ê²½ìš°'),
            (r'ë•Œë¬¸ì—', 'ìœ¼ë¡œ ì¸í•´'),
            (r'ê·¸ë˜ì„œ', 'ë”°ë¼ì„œ'),
            (r'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜'),
        ]
        
        for pattern, replacement in replacements:
            text = re.sub(pattern, replacement, text)
        
        return text
    
    def _naturalize_korean_expression(self, text: str) -> str:
        """ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
        # ë²ˆì—­ì²´ íŠ¹ìœ ì˜ ì–´ìƒ‰í•œ í‘œí˜„ ê°œì„ 
        replacements = [
            (r'ì˜í•´ì„œ', 'ì— ì˜í•´'),
            (r'ì— ëŒ€í•´ì„œ', 'ì— ëŒ€í•´'),
            (r'ìœ¼ë¡œì„œ', 'ë¡œì„œ'),
            (r'ì—ê²Œì„œ', 'ì—ê²Œ'),
            (r'ë¡œë¶€í„°', 'ì—ì„œ'),
            (r'ì™€ í•¨ê»˜', 'ê³¼ í•¨ê»˜'),
            (r'ê²ƒ ê°™ë‹¤', 'ê²ƒ ê°™ìŠµë‹ˆë‹¤'),
            (r'í•  ìˆ˜ ìˆë‹¤', 'í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤'),
            (r'í•´ì•¼ í•œë‹¤', 'í•´ì•¼ í•©ë‹ˆë‹¤'),
        ]
        
        for pattern, replacement in replacements:
            text = re.sub(pattern, replacement, text)
        
        return text
    
    def _clean_formatting(self, text: str) -> str:
        """í˜•ì‹ ì •ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # ë¬¸ì¥ ë¶€í˜¸ ì •ë¦¬
        text = re.sub(r'\s+([,.!?])', r'\1', text)
        text = re.sub(r'([,.!?])\s*([,.!?])', r'\1\2', text)
        
        # í•œêµ­ì–´ íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        text = re.sub(r'~+', '~', text)
        text = re.sub(r'\.{3,}', '...', text)
        
        return text
    
    def _extract_jewelry_terms(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì¶”ì¶œ"""
        found_terms = []
        
        text_lower = text.lower()
        
        for term, info in self.jewelry_dictionary.items():
            if term.lower() in text_lower:
                found_terms.append(term)
        
        return found_terms
    
    def _generate_alternative_translations(self, 
                                          text: str, 
                                          source_lang: str, 
                                          target_lang: str) -> List[str]:
        """ëŒ€ì•ˆ ë²ˆì—­ ìƒì„±"""
        alternatives = []
        
        # ë‹¤ë¥¸ ë²ˆì—­ ì—”ì§„ì´ ìˆë‹¤ë©´ ì‚¬ìš©
        # í˜„ì¬ëŠ” Google Translateë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ê¸°ë³¸ê°’ ë°˜í™˜
        
        # í–¥í›„ í™•ì¥: ë‹¤ë¥¸ ë²ˆì—­ ë°©ë²•ë“¤
        # - ë¬¸ì¥ ë‹¨ìœ„ ë²ˆì—­ vs ì „ì²´ ë²ˆì—­
        # - ê²©ì‹ì²´ vs ë¹„ê²©ì‹ì²´
        # - ì§ì—­ vs ì˜ì—­
        
        return alternatives
    
    def _evaluate_context_preservation(self, 
                                      original_text: str, 
                                      translated_text: str,
                                      context: Optional[str] = None) -> bool:
        """ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ í‰ê°€"""
        if not context:
            return True
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ í‰ê°€
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ëª¨ë¸ì´ í•„ìš”
        
        original_keywords = set(original_text.lower().split())
        translated_keywords = set(translated_text.split())
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ë³´ì¡´ í™•ì¸
        jewelry_terms_preserved = 0
        jewelry_terms_total = 0
        
        for term, info in self.jewelry_dictionary.items():
            if term.lower() in original_text.lower():
                jewelry_terms_total += 1
                if info['ko'] in translated_text:
                    jewelry_terms_preserved += 1
        
        if jewelry_terms_total > 0:
            preservation_ratio = jewelry_terms_preserved / jewelry_terms_total
            return preservation_ratio >= 0.8
        
        return True
    
    def _generate_cache_key(self, request: TranslationRequest) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{request.text}_{request.source_language}_{request.target_language}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def process_multilingual_content(self, content_blocks: List[Dict]) -> Dict:
        """
        ë‹¤êµ­ì–´ ì½˜í…ì¸  ë¸”ë¡ë“¤ì„ í•œêµ­ì–´ë¡œ í†µí•© ì²˜ë¦¬
        
        Args:
            content_blocks: ë‹¤êµ­ì–´ ì½˜í…ì¸  ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Dict: í†µí•© ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        processed_blocks = []
        translation_summary = {
            'total_blocks': len(content_blocks),
            'languages_detected': set(),
            'translation_quality_avg': 0.0,
            'jewelry_terms_found': [],
            'processing_time': 0.0
        }
        
        quality_scores = []
        
        for i, block in enumerate(content_blocks):
            text = block.get('text', '')
            context = block.get('context', '')
            document_type = block.get('document_type', 'generic')
            
            if not text.strip():
                continue
            
            # ë²ˆì—­ ìš”ì²­ ìƒì„±
            request = TranslationRequest(
                text=text,
                source_language='auto',
                target_language='ko',
                context=context,
                document_type=document_type,
                preserve_formatting=True,
                use_jewelry_dictionary=True
            )
            
            # ë²ˆì—­ ìˆ˜í–‰
            result = self.translate_to_korean(request)
            
            # ê²°ê³¼ ì €ì¥
            processed_blocks.append({
                'block_index': i,
                'original_text': result.original_text,
                'translated_text': result.translated_text,
                'source_language': result.source_language,
                'confidence': result.confidence_score,
                'quality_score': result.quality_score,
                'jewelry_terms': result.jewelry_terms_found,
                'processing_time': result.processing_time
            })
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            translation_summary['languages_detected'].add(result.source_language)
            quality_scores.append(result.quality_score)
            translation_summary['jewelry_terms_found'].extend(result.jewelry_terms_found)
        
        # í‰ê·  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        if quality_scores:
            translation_summary['translation_quality_avg'] = np.mean(quality_scores)
        
        # ì¤‘ë³µ ì œê±°
        translation_summary['jewelry_terms_found'] = list(set(translation_summary['jewelry_terms_found']))
        translation_summary['languages_detected'] = list(translation_summary['languages_detected'])
        
        # í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
        integrated_text = self._integrate_translated_blocks(processed_blocks)
        
        translation_summary['processing_time'] = time.time() - start_time
        
        return {
            'integrated_korean_text': integrated_text,
            'processed_blocks': processed_blocks,
            'translation_summary': translation_summary,
            'quality_assessment': self._assess_integration_quality(processed_blocks)
        }
    
    def _integrate_translated_blocks(self, processed_blocks: List[Dict]) -> str:
        """ë²ˆì—­ëœ ë¸”ë¡ë“¤ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ í†µí•©"""
        if not processed_blocks:
            return ""
        
        # ì‹œê°„ìˆœ ë˜ëŠ” ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_blocks = sorted(processed_blocks, key=lambda x: x['block_index'])
        
        integrated_parts = []
        
        for block in sorted_blocks:
            text = block['translated_text']
            
            # ë¬¸ì¥ ë ì²˜ë¦¬
            if text and not text.endswith(('.', '!', '?', 'ë‹¤', 'ìš”', 'ë‹ˆë‹¤')):
                text += '.'
            
            integrated_parts.append(text)
        
        # í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
        integrated_text = ' '.join(integrated_parts)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
        integrated_text = self._polish_integrated_text(integrated_text)
        
        return integrated_text
    
    def _polish_integrated_text(self, text: str) -> str:
        """í†µí•© í…ìŠ¤íŠ¸ ë‹¤ë“¬ê¸°"""
        # ë¬¸ì¥ ê°„ ì—°ê²° ê°œì„ 
        text = re.sub(r'\.(\s+)([ê°€-í£])', r'. \2', text)
        
        # ì¤‘ë³µ í‘œí˜„ ì œê±°
        text = re.sub(r'(ì…ë‹ˆë‹¤|í•©ë‹ˆë‹¤)\.(\s+)(ê·¸ë¦¬ê³ |ë˜í•œ|ê·¸ë˜ì„œ)', r'\1. \3', text)
        
        # ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ì—°ê²°
        text = re.sub(r'í•©ë‹ˆë‹¤\.(\s+)ê·¸ë¦¬ê³ ', r'í•˜ë©°,', text)
        text = re.sub(r'ì…ë‹ˆë‹¤\.(\s+)ë˜í•œ', r'ì´ë©°,', text)
        
        # ìµœì¢… ì •ë¦¬
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _assess_integration_quality(self, processed_blocks: List[Dict]) -> Dict:
        """í†µí•© í’ˆì§ˆ í‰ê°€"""
        if not processed_blocks:
            return {'overall_score': 0, 'issues': ['No blocks processed']}
        
        issues = []
        scores = []
        
        # ê°œë³„ ë¸”ë¡ í’ˆì§ˆ ì ìˆ˜
        for block in processed_blocks:
            scores.append(block['quality_score'])
            
            if block['quality_score'] < 70:
                issues.append(f"Block {block['block_index']}: Low quality score ({block['quality_score']:.1f})")
            
            if block['confidence'] < 0.8:
                issues.append(f"Block {block['block_index']}: Low language detection confidence")
        
        # ì–¸ì–´ ì¼ê´€ì„± ì²´í¬
        languages = set(block['source_language'] for block in processed_blocks)
        if len(languages) > 3:
            issues.append(f"Too many source languages detected: {languages}")
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ë³´ì¡´ ì²´í¬
        total_jewelry_terms = sum(len(block['jewelry_terms']) for block in processed_blocks)
        if total_jewelry_terms == 0:
            issues.append("No jewelry terms detected - possible domain mismatch")
        
        overall_score = np.mean(scores) if scores else 0
        
        return {
            'overall_score': float(overall_score),
            'individual_scores': scores,
            'issues': issues,
            'languages_processed': list(languages),
            'total_jewelry_terms': total_jewelry_terms,
            'quality_grade': 'excellent' if overall_score >= 85 else 
                           'good' if overall_score >= 70 else
                           'fair' if overall_score >= 55 else 'poor'
        }


class TranslationQualityEvaluator:
    """ë²ˆì—­ í’ˆì§ˆ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.quality_metrics = {
            'fluency': 0.4,      # ìœ ì°½ì„±
            'accuracy': 0.3,     # ì •í™•ì„±
            'terminology': 0.2,  # ì „ë¬¸ìš©ì–´
            'coherence': 0.1     # ì¼ê´€ì„±
        }
    
    def evaluate_translation(self, 
                           original_text: str, 
                           translated_text: str, 
                           source_lang: str, 
                           target_lang: str) -> float:
        """ë²ˆì—­ í’ˆì§ˆ í‰ê°€"""
        
        # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜ (ê¸¸ì´ ê¸°ë°˜)
        length_ratio = len(translated_text) / max(len(original_text), 1)
        length_score = 100 if 0.5 <= length_ratio <= 2.0 else 50
        
        # íŠ¹ìˆ˜ ë¬¸ì ë³´ì¡´ ì ìˆ˜
        special_chars_score = self._evaluate_special_chars_preservation(
            original_text, translated_text
        )
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ì •í™•ì„± ì ìˆ˜
        terminology_score = self._evaluate_terminology_accuracy(
            original_text, translated_text
        )
        
        # ë¬¸ì¥ êµ¬ì¡° ì ìˆ˜
        structure_score = self._evaluate_sentence_structure(translated_text)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        overall_score = (
            length_score * 0.3 +
            special_chars_score * 0.2 +
            terminology_score * 0.3 +
            structure_score * 0.2
        )
        
        return min(overall_score, 100.0)
    
    def _evaluate_special_chars_preservation(self, original: str, translated: str) -> float:
        """íŠ¹ìˆ˜ ë¬¸ì ë³´ì¡´ í‰ê°€"""
        original_specials = set(re.findall(r'[^\w\s]', original))
        translated_specials = set(re.findall(r'[^\w\s]', translated))
        
        if not original_specials:
            return 100.0
        
        preserved = len(original_specials.intersection(translated_specials))
        total = len(original_specials)
        
        return (preserved / total) * 100
    
    def _evaluate_terminology_accuracy(self, original: str, translated: str) -> float:
        """ì „ë¬¸ìš©ì–´ ì •í™•ì„± í‰ê°€"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í‰ê°€ í•„ìš”
        return 85.0  # ê¸°ë³¸ê°’
    
    def _evaluate_sentence_structure(self, translated: str) -> float:
        """ë¬¸ì¥ êµ¬ì¡° í‰ê°€"""
        # í•œêµ­ì–´ ë¬¸ì¥ êµ¬ì¡° ê¸°ë³¸ ì²´í¬
        sentences = re.split(r'[.!?]', translated)
        
        structure_score = 0
        total_sentences = len([s for s in sentences if s.strip()])
        
        if total_sentences == 0:
            return 0.0
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # í•œêµ­ì–´ ì–´ë¯¸ ì²´í¬
            if sentence.endswith(('ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ì„¸ìš”')):
                structure_score += 1
            # ë¬¸ì¥ ê¸¸ì´ ì²´í¬
            elif 5 <= len(sentence) <= 100:
                structure_score += 0.5
        
        return (structure_score / total_sentences) * 100


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_multilingual_processor():
    """MultilingualProcessor í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    processor = MultilingualProcessor()
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë“¤
    test_texts = [
        {
            'text': 'This diamond has excellent clarity grade FL.',
            'context': 'product_description',
            'document_type': 'certificate'
        },
        {
            'text': 'è¿™é¢—é’»çŸ³çš„å‡€åº¦ç­‰çº§ä¸ºFLï¼Œé¢œè‰²ç­‰çº§ä¸ºDã€‚',
            'context': 'product_description',
            'document_type': 'certificate'
        },
        {
            'text': 'ã“ã®ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ã¯æœ€é«˜å“è³ªã®ã‚«ãƒƒãƒˆã§ã™ã€‚',
            'context': 'product_description',
            'document_type': 'certificate'
        },
        {
            'text': 'ì´ ë°˜ì§€ëŠ” 18K í™”ì´íŠ¸ê³¨ë“œë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'context': 'product_description',
            'document_type': 'certificate'
        }
    ]
    
    # ë‹¤êµ­ì–´ ì½˜í…ì¸  í†µí•© ì²˜ë¦¬
    result = processor.process_multilingual_content(test_texts)
    
    print("ğŸŒ ë‹¤êµ­ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"ì²˜ë¦¬ëœ ë¸”ë¡ ìˆ˜: {result['translation_summary']['total_blocks']}")
    print(f"ê°ì§€ëœ ì–¸ì–´: {result['translation_summary']['languages_detected']}")
    print(f"í‰ê·  ë²ˆì—­ í’ˆì§ˆ: {result['translation_summary']['translation_quality_avg']:.1f}")
    print(f"ë°œê²¬ëœ ì£¼ì–¼ë¦¬ ìš©ì–´: {len(result['translation_summary']['jewelry_terms_found'])}ê°œ")
    print(f"ì²˜ë¦¬ ì‹œê°„: {result['translation_summary']['processing_time']:.2f}ì´ˆ")
    print("\ní†µí•© í•œêµ­ì–´ í…ìŠ¤íŠ¸:")
    print(result['integrated_korean_text'])
    
    return result


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_result = test_multilingual_processor()
