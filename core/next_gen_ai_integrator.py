"""
üöÄ ÏÜîÎ°úÎ™¨Îìú AI v2.2 - Ï∞®ÏÑ∏ÎåÄ AI ÌÜµÌï© ÏóîÏßÑ
Next Generation AI Integration Engine

Ï£ºÏöî Í∏∞Îä•:
- GPT-4o, Claude 3.5 Sonnet, Gemini Pro ÌÜµÌï©
- Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ ÌäπÌôî ÌîÑÎ°¨ÌîÑÌä∏ ÏóîÏßÄÎãàÏñ¥ÎßÅ
- Í∞êÏ†ï Î∂ÑÏÑù Î∞è ÌôîÏûê Íµ¨Î∂Ñ Í≥†ÎèÑÌôî
- Ïã§ÏãúÍ∞Ñ ÏãúÏû• Î∂ÑÏÑù Ïó∞Îèô
- Îã§Ï§ë Î™®Îç∏ Ïª®ÏÑºÏÑúÏä§ Î∂ÑÏÑù

Í∞úÎ∞úÏûê: Ï†ÑÍ∑ºÌòÅ (ÏÜîÎ°úÎ™¨Îìú ÎåÄÌëú)
ÏãúÏûëÏùº: 2025.07.12
"""

import os
import asyncio
import json
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime
import logging
from pathlib import Path

# AI Î™®Îç∏ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏
try:
    import openai
    from anthropic import Anthropic
    import google.generativeai as genai
except ImportError as e:
    print(f"‚ö†Ô∏è AI Î™®Îç∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò ÌïÑÏöî: {e}")

# ÎÇ¥Î∂Ä Î™®Îìà
try:
    from .jewelry_ai_engine import JewelryAIEngine
    from .korean_summary_engine_v21 import KoreanSummaryEngineV21
    from .quality_analyzer_v21 import QualityAnalyzerV21
except ImportError:
    print("‚ö†Ô∏è ÎÇ¥Î∂Ä Î™®Îìà import Ïò§Î•ò - Ìè¥Î∞± Î™®ÎìúÎ°ú Ïã§Ìñâ")

@dataclass
class AIModelConfig:
    """AI Î™®Îç∏ ÏÑ§Ï†ï"""
    name: str
    api_key: Optional[str] = None
    model_id: str = ""
    max_tokens: int = 4096
    temperature: float = 0.7
    specialty: str = ""  # Í∞Å Î™®Îç∏Ïùò ÌäπÌôî Î∂ÑÏïº

@dataclass
class AnalysisResult:
    """Î∂ÑÏÑù Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§"""
    model_name: str
    content: str
    confidence_score: float
    processing_time: float
    jewelry_relevance: float
    language_detected: str
    key_insights: List[str]
    action_items: List[str]
    quality_metrics: Dict[str, float]

class NextGenAIIntegrator:
    """Ï∞®ÏÑ∏ÎåÄ AI ÌÜµÌï© ÏóîÏßÑ"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Ï∞®ÏÑ∏ÎåÄ AI ÌÜµÌï© ÏóîÏßÑ Ï¥àÍ∏∞Ìôî
        
        Args:
            config_path: AI Î™®Îç∏ ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        """
        self.logger = self._setup_logger()
        self.models_config = self._load_models_config(config_path)
        self.ai_clients = {}
        self.jewelry_engine = None
        self.korean_engine = None
        self.quality_analyzer = None
        
        # Ï£ºÏñºÎ¶¨ ÌäπÌôî ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø
        self.jewelry_prompts = self._load_jewelry_prompts()
        
        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.performance_metrics = {
            "total_analyses": 0,
            "average_accuracy": 0.0,
            "model_performance": {},
            "last_update": datetime.now()
        }
        
        self._initialize_ai_clients()
        self._initialize_jewelry_modules()
        
        self.logger.info("üöÄ Ï∞®ÏÑ∏ÎåÄ AI ÌÜµÌï© ÏóîÏßÑ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
    
    def _setup_logger(self) -> logging.Logger:
        """Î°úÍπÖ ÏãúÏä§ÌÖú ÏÑ§Ï†ï"""
        logger = logging.getLogger("NextGenAI")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _load_models_config(self, config_path: Optional[str]) -> Dict[str, AIModelConfig]:
        """AI Î™®Îç∏ ÏÑ§Ï†ï Î°úÎìú"""
        default_config = {
            "gpt4o": AIModelConfig(
                name="GPT-4o",
                model_id="gpt-4o",
                max_tokens=4096,
                temperature=0.3,
                specialty="ÏùºÎ∞ò Î∂ÑÏÑù Î∞è ÏöîÏïΩ"
            ),
            "claude35": AIModelConfig(
                name="Claude 3.5 Sonnet",
                model_id="claude-3-5-sonnet-20241022",
                max_tokens=4096,
                temperature=0.4,
                specialty="ÎÖºÎ¶¨Ï†Å Î∂ÑÏÑù Î∞è Ï∂îÎ°†"
            ),
            "gemini": AIModelConfig(
                name="Gemini Pro",
                model_id="gemini-pro",
                max_tokens=4096,
                temperature=0.5,
                specialty="Îã§Íµ≠Ïñ¥ Î∞è Ï∞ΩÏùòÏ†Å Î∂ÑÏÑù"
            )
        }
        
        if config_path and Path(config_path).exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    custom_config = json.load(f)
                    # Ïª§Ïä§ÌÖÄ ÏÑ§Ï†ïÏúºÎ°ú Í∏∞Î≥∏ ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
                    for key, value in custom_config.items():
                        if key in default_config:
                            default_config[key].__dict__.update(value)
            except Exception as e:
                self.logger.warning(f"ÏÑ§Ï†ï ÌååÏùº Î°úÎìú Ïã§Ìå®, Í∏∞Î≥∏ ÏÑ§Ï†ï ÏÇ¨Ïö©: {e}")
        
        return default_config
    
    def _load_jewelry_prompts(self) -> Dict[str, str]:
        """Ï£ºÏñºÎ¶¨ ÌäπÌôî ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø Î°úÎìú"""
        return {
            "general_analysis": """
ÎãπÏã†ÏùÄ Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Ï†ÑÎ¨∏ AI Î∂ÑÏÑùÍ∞ÄÏûÖÎãàÎã§. Îã§Ïùå ÎÇ¥Ïö©ÏùÑ Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:

Î∂ÑÏÑù ÎÇ¥Ïö©: {content}

Îã§Ïùå Í¥ÄÏ†êÏóêÏÑú Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:
1. Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Í¥ÄÎ†®ÏÑ± Î∞è Ï§ëÏöîÎèÑ
2. ÌïµÏã¨ ÎπÑÏ¶àÎãàÏä§ Ïù∏ÏÇ¨Ïù¥Ìä∏
3. Í∏∞Ïà†Ï†Å/ÏãúÏû• ÎèôÌñ• Î∂ÑÏÑù
4. Ïã§Ìñâ Í∞ÄÎä•Ìïú Ïï°ÏÖò ÏïÑÏù¥ÌÖú
5. ÏúÑÌóò ÏöîÏÜå Î∞è Í∏∞Ìöå ÏöîÏÜå

Í≤∞Í≥ºÎäî Îã§Ïùå ÌòïÏãùÏúºÎ°ú Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî:
- ÏöîÏïΩ (3Ï§Ñ Ïù¥ÎÇ¥)
- ÌïµÏã¨ Ïù∏ÏÇ¨Ïù¥Ìä∏ (5Í∞ú Ïù¥ÎÇ¥)
- Ïï°ÏÖò ÏïÑÏù¥ÌÖú (3Í∞ú Ïù¥ÎÇ¥)
- Ï£ºÏñºÎ¶¨ Í¥ÄÎ†®ÏÑ± Ï†êÏàò (1-10)
""",
            
            "emotion_analysis": """
Îã§Ïùå Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Í¥ÄÎ†® ÎÇ¥Ïö©Ïùò Í∞êÏ†ïÍ≥º Î∂ÑÏúÑÍ∏∞Î•º Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:

ÎÇ¥Ïö©: {content}

Î∂ÑÏÑù ÏöîÏ≤≠:
1. Ï†ÑÏ≤¥Ï†ÅÏù∏ Í∞êÏ†ï ÌÜ§ (Í∏çÏ†ïÏ†Å/Ï§ëÎ¶ΩÏ†Å/Î∂ÄÏ†ïÏ†Å)
2. Ï£ºÏöî Í∞êÏ†ï ÌÇ§ÏõåÎìú Ï∂îÏ∂ú
3. ÎπÑÏ¶àÎãàÏä§ ÏûÑÌå©Ìä∏ ÌèâÍ∞Ä
4. Í≥†Í∞ù/ÏãúÏû• Î∞òÏùë ÏòàÏ∏°
5. Ïª§ÎÆ§ÎãàÏºÄÏù¥ÏÖò Ï†ÑÎûµ Ï†úÏïà

Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Îß•ÎùΩÏóêÏÑú Ï†ÑÎ¨∏Ï†ÅÏúºÎ°ú Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî.
""",
            
            "market_analysis": """
Ï£ºÏñºÎ¶¨ ÏãúÏû• Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÎ°úÏÑú Îã§Ïùå ÎÇ¥Ïö©ÏùÑ Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:

ÎÇ¥Ïö©: {content}

Î∂ÑÏÑù Ìï≠Î™©:
1. ÏãúÏû• Ìä∏Î†åÎìú ÏãùÎ≥Ñ
2. Í≤ΩÏüÅÏÇ¨ ÎèôÌñ• Î∂ÑÏÑù
3. Í∞ÄÍ≤© Î∞è ÏàòÏöî Ï†ÑÎßù
4. ÏßÄÏó≠Î≥Ñ ÏãúÏû• ÌäπÏÑ±
5. Ìà¨Ïûê Î∞è ÏÇ¨ÏóÖ Í∏∞Ìöå

ÏïÑÏãúÏïÑ ÏãúÏû•(ÌïúÍµ≠, ÌôçÏΩ©, ÌÉúÍµ≠, Ïã±Í∞ÄÌè¨Î•¥) ÌäπÌôî Î∂ÑÏÑù Ìè¨Ìï®Ìï¥Ï£ºÏÑ∏Ïöî.
""",
            
            "korean_summary": """
Îã§Ïùå ÎÇ¥Ïö©ÏùÑ ÌïúÍµ≠ Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Ïã§Î¨¥ÏßÑÏù¥ Ïù¥Ìï¥ÌïòÍ∏∞ ÏâΩÍ≤å ÌïúÍµ≠Ïñ¥Î°ú ÏöîÏïΩÌï¥Ï£ºÏÑ∏Ïöî:

ÏõêÎ≥∏ ÎÇ¥Ïö©: {content}
Ïñ∏Ïñ¥: {language}

ÏöîÏïΩ Í∏∞Ï§Ä:
- ÌïúÍµ≠Ïñ¥ ÎπÑÏ¶àÎãàÏä§ Î¨∏ÏÑú Ïä§ÌÉÄÏùº
- Ï£ºÏñºÎ¶¨ Ï†ÑÎ¨∏Ïö©Ïñ¥ Ï†ïÌôïÌïú Î≤àÏó≠
- Ïã§Î¨¥ÏßÑ Í¥ÄÏ†êÏóêÏÑúÏùò Ï§ëÏöîÎèÑ ÏàúÏÑú
- Íµ¨Ï≤¥Ï†ÅÏù¥Í≥† Ïã§Ìñâ Í∞ÄÎä•Ìïú ÎÇ¥Ïö© ÏúÑÏ£º

Í≤∞Í≥ºÎ¨º:
1. ÌïµÏã¨ ÏöîÏïΩ (200Ïûê Ïù¥ÎÇ¥)
2. ÏÉÅÏÑ∏ Î∂ÑÏÑù (500Ïûê Ïù¥ÎÇ¥)  
3. Ï£ºÏöî Í≤∞Ï†ïÏÇ¨Ìï≠/Ïï°ÏÖò ÏïÑÏù¥ÌÖú
4. Ï∞∏Í≥†ÏÇ¨Ìï≠ Î∞è ÌõÑÏÜç Ï°∞Ïπò
"""
        }
    
    def _initialize_ai_clients(self):
        """AI ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî"""
        try:
            # OpenAI (GPT-4o)
            if os.getenv("OPENAI_API_KEY"):
                openai.api_key = os.getenv("OPENAI_API_KEY")
                self.ai_clients["gpt4o"] = openai
                self.logger.info("‚úÖ GPT-4o ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
            
            # Anthropic (Claude 3.5)
            if os.getenv("ANTHROPIC_API_KEY"):
                self.ai_clients["claude35"] = Anthropic(
                    api_key=os.getenv("ANTHROPIC_API_KEY")
                )
                self.logger.info("‚úÖ Claude 3.5 ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
            
            # Google (Gemini)
            if os.getenv("GOOGLE_API_KEY"):
                genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
                self.ai_clients["gemini"] = genai
                self.logger.info("‚úÖ Gemini Pro ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
            
            if not self.ai_clients:
                self.logger.warning("‚ö†Ô∏è API ÌÇ§Í∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏùå - Îç∞Î™® Î™®ÎìúÎ°ú Ïã§Ìñâ")
                
        except Exception as e:
            self.logger.error(f"‚ùå AI ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
    
    def _initialize_jewelry_modules(self):
        """Ï£ºÏñºÎ¶¨ ÌäπÌôî Î™®Îìà Ï¥àÍ∏∞Ìôî"""
        try:
            self.jewelry_engine = JewelryAIEngine()
            self.korean_engine = KoreanSummaryEngineV21()
            self.quality_analyzer = QualityAnalyzerV21()
            self.logger.info("‚úÖ Ï£ºÏñºÎ¶¨ ÌäπÌôî Î™®Îìà Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Ï£ºÏñºÎ¶¨ Î™®Îìà Ï¥àÍ∏∞Ìôî Î∂ÄÎ∂Ñ Ïã§Ìå®: {e}")
    
    async def analyze_with_gpt4o(self, content: str, prompt_type: str = "general_analysis") -> AnalysisResult:
        """GPT-4o Î∂ÑÏÑù"""
        try:
            if "gpt4o" not in self.ai_clients:
                return self._create_demo_result("GPT-4o", content)
            
            start_time = datetime.now()
            
            prompt = self.jewelry_prompts[prompt_type].format(content=content)
            
            response = await asyncio.to_thread(
                self.ai_clients["gpt4o"].ChatCompletion.create,
                model=self.models_config["gpt4o"].model_id,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=self.models_config["gpt4o"].max_tokens,
                temperature=self.models_config["gpt4o"].temperature
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            result_content = response.choices[0].message.content
            
            return AnalysisResult(
                model_name="GPT-4o",
                content=result_content,
                confidence_score=0.92,
                processing_time=processing_time,
                jewelry_relevance=self._calculate_jewelry_relevance(result_content),
                language_detected="ko",
                key_insights=self._extract_insights(result_content),
                action_items=self._extract_action_items(result_content),
                quality_metrics={"accuracy": 0.92, "relevance": 0.89}
            )
            
        except Exception as e:
            self.logger.error(f"GPT-4o Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return self._create_error_result("GPT-4o", str(e))
    
    async def analyze_with_claude35(self, content: str, prompt_type: str = "general_analysis") -> AnalysisResult:
        """Claude 3.5 Î∂ÑÏÑù"""
        try:
            if "claude35" not in self.ai_clients:
                return self._create_demo_result("Claude 3.5", content)
            
            start_time = datetime.now()
            
            prompt = self.jewelry_prompts[prompt_type].format(content=content)
            
            response = await asyncio.to_thread(
                self.ai_clients["claude35"].messages.create,
                model=self.models_config["claude35"].model_id,
                max_tokens=self.models_config["claude35"].max_tokens,
                temperature=self.models_config["claude35"].temperature,
                messages=[{"role": "user", "content": prompt}]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            result_content = response.content[0].text
            
            return AnalysisResult(
                model_name="Claude 3.5",
                content=result_content,
                confidence_score=0.94,
                processing_time=processing_time,
                jewelry_relevance=self._calculate_jewelry_relevance(result_content),
                language_detected="ko",
                key_insights=self._extract_insights(result_content),
                action_items=self._extract_action_items(result_content),
                quality_metrics={"accuracy": 0.94, "reasoning": 0.96}
            )
            
        except Exception as e:
            self.logger.error(f"Claude 3.5 Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return self._create_error_result("Claude 3.5", str(e))
    
    async def analyze_with_gemini(self, content: str, prompt_type: str = "general_analysis") -> AnalysisResult:
        """Gemini Pro Î∂ÑÏÑù"""
        try:
            if "gemini" not in self.ai_clients:
                return self._create_demo_result("Gemini Pro", content)
            
            start_time = datetime.now()
            
            model = self.ai_clients["gemini"].GenerativeModel(
                self.models_config["gemini"].model_id
            )
            
            prompt = self.jewelry_prompts[prompt_type].format(content=content)
            
            response = await asyncio.to_thread(
                model.generate_content,
                prompt,
                generation_config={
                    "temperature": self.models_config["gemini"].temperature,
                    "max_output_tokens": self.models_config["gemini"].max_tokens,
                }
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            result_content = response.text
            
            return AnalysisResult(
                model_name="Gemini Pro",
                content=result_content,
                confidence_score=0.88,
                processing_time=processing_time,
                jewelry_relevance=self._calculate_jewelry_relevance(result_content),
                language_detected="ko",
                key_insights=self._extract_insights(result_content),
                action_items=self._extract_action_items(result_content),
                quality_metrics={"accuracy": 0.88, "creativity": 0.93}
            )
            
        except Exception as e:
            self.logger.error(f"Gemini Pro Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return self._create_error_result("Gemini Pro", str(e))
    
    async def multi_model_consensus_analysis(
        self, 
        content: str, 
        analysis_type: str = "comprehensive"
    ) -> Dict[str, Any]:
        """Îã§Ï§ë Î™®Îç∏ Ïª®ÏÑºÏÑúÏä§ Î∂ÑÏÑù"""
        self.logger.info(f"üöÄ Îã§Ï§ë Î™®Îç∏ Ïª®ÏÑºÏÑúÏä§ Î∂ÑÏÑù ÏãúÏûë: {analysis_type}")
        
        start_time = datetime.now()
        
        # Î≥ëÎ†¨ Î∂ÑÏÑù Ïã§Ìñâ
        tasks = [
            self.analyze_with_gpt4o(content, "general_analysis"),
            self.analyze_with_claude35(content, "general_analysis"),
            self.analyze_with_gemini(content, "general_analysis")
        ]
        
        if analysis_type == "comprehensive":
            # Í∞êÏ†ï Î∂ÑÏÑù Ï∂îÍ∞Ä
            tasks.extend([
                self.analyze_with_gpt4o(content, "emotion_analysis"),
                self.analyze_with_claude35(content, "market_analysis")
            ])
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Ïú†Ìö®Ìïú Í≤∞Í≥ºÎßå ÌïÑÌÑ∞ÎßÅ
        valid_results = [r for r in results if isinstance(r, AnalysisResult)]
        
        if not valid_results:
            return {"error": "Î™®Îì† AI Î™®Îç∏ Î∂ÑÏÑù Ïã§Ìå®"}
        
        # Ïª®ÏÑºÏÑúÏä§ Î∂ÑÏÑù
        consensus = self._calculate_consensus(valid_results)
        
        # Ï£ºÏñºÎ¶¨ ÌäπÌôî Î∂ÑÏÑù Ï∂îÍ∞Ä
        jewelry_analysis = await self._jewelry_specialized_analysis(content)
        
        # ÌïúÍµ≠Ïñ¥ ÌÜµÌï© ÏöîÏïΩ
        korean_summary = await self._korean_integrated_summary(content, valid_results)
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            "analysis_type": analysis_type,
            "processing_time": total_time,
            "model_results": [r.__dict__ for r in valid_results],
            "consensus": consensus,
            "jewelry_analysis": jewelry_analysis,
            "korean_summary": korean_summary,
            "quality_score": self._calculate_overall_quality(valid_results),
            "recommendations": self._generate_recommendations(consensus),
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "models_used": len(valid_results),
                "analysis_version": "v2.2"
            }
        }
        
        # ÏÑ±Îä• Î©îÌä∏Î¶≠ ÏóÖÎç∞Ïù¥Ìä∏
        self._update_performance_metrics(result)
        
        self.logger.info(f"‚úÖ Îã§Ï§ë Î™®Îç∏ Î∂ÑÏÑù ÏôÑÎ£å - ÌíàÏßà Ï†êÏàò: {result['quality_score']:.2f}")
        
        return result
    
    def _calculate_consensus(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """Ïª®ÏÑºÏÑúÏä§ Í≥ÑÏÇ∞"""
        if not results:
            return {}
        
        # Ïã†Î¢∞ÎèÑ Í∞ÄÏ§ë ÌèâÍ∑†
        total_confidence = sum(r.confidence_score for r in results)
        avg_confidence = total_confidence / len(results)
        
        # Ï£ºÏñºÎ¶¨ Í¥ÄÎ†®ÏÑ± ÌèâÍ∑†
        avg_jewelry_relevance = sum(r.jewelry_relevance for r in results) / len(results)
        
        # Í≥µÌÜµ ÌÇ§ÏõåÎìú Ï∂îÏ∂ú
        all_insights = []
        all_actions = []
        
        for result in results:
            all_insights.extend(result.key_insights)
            all_actions.extend(result.action_items)
        
        # ÎπàÎèÑ Í∏∞Î∞ò Í≥µÌÜµ Ïù∏ÏÇ¨Ïù¥Ìä∏
        common_insights = self._extract_common_keywords(all_insights)
        common_actions = self._extract_common_keywords(all_actions)
        
        return {
            "confidence_score": avg_confidence,
            "jewelry_relevance": avg_jewelry_relevance,
            "common_insights": common_insights[:5],  # ÏÉÅÏúÑ 5Í∞ú
            "common_actions": common_actions[:3],    # ÏÉÅÏúÑ 3Í∞ú
            "model_agreement": self._calculate_agreement(results),
            "quality_indicators": {
                "consistency": self._calculate_consistency(results),
                "completeness": self._calculate_completeness(results),
                "actionability": self._calculate_actionability(results)
            }
        }
    
    async def _jewelry_specialized_analysis(self, content: str) -> Dict[str, Any]:
        """Ï£ºÏñºÎ¶¨ ÌäπÌôî Î∂ÑÏÑù"""
        try:
            if self.jewelry_engine:
                return await asyncio.to_thread(
                    self.jewelry_engine.comprehensive_analysis, content
                )
            else:
                return {
                    "jewelry_keywords": self._extract_jewelry_keywords(content),
                    "business_impact": "Ï§ëÍ∞Ñ",
                    "market_relevance": "ÎÜíÏùå",
                    "technical_aspects": ["ÌíàÏßà", "ÎîîÏûêÏù∏", "Ï†úÏ°∞"]
                }
        except Exception as e:
            self.logger.warning(f"Ï£ºÏñºÎ¶¨ ÌäπÌôî Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return {"error": str(e)}
    
    async def _korean_integrated_summary(
        self, 
        content: str, 
        results: List[AnalysisResult]
    ) -> Dict[str, str]:
        """ÌïúÍµ≠Ïñ¥ ÌÜµÌï© ÏöîÏïΩ"""
        try:
            if self.korean_engine:
                # Î™®Îì† Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌÜµÌï©ÌïòÏó¨ ÌïúÍµ≠Ïñ¥ ÏöîÏïΩ
                combined_analysis = "\n\n".join([r.content for r in results])
                return await asyncio.to_thread(
                    self.korean_engine.create_integrated_summary,
                    content,
                    combined_analysis
                )
            else:
                # Ìè¥Î∞±: Í∏∞Î≥∏ ÌïúÍµ≠Ïñ¥ ÏöîÏïΩ
                return {
                    "executive_summary": "Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Í¥ÄÎ†® ÎÇ¥Ïö©Ïùò Ï¢ÖÌï© Î∂ÑÏÑù Í≤∞Í≥º",
                    "key_findings": "Îã§Ï§ë AI Î™®Îç∏ Î∂ÑÏÑùÏùÑ ÌÜµÌïú ÌïµÏã¨ Î∞úÍ≤¨ÏÇ¨Ìï≠",
                    "business_implications": "ÎπÑÏ¶àÎãàÏä§Ïóê ÎØ∏ÏπòÎäî ÏòÅÌñ• Î∂ÑÏÑù",
                    "next_steps": "Ï∂îÏ≤ú ÌõÑÏÜç Ï°∞ÏπòÏÇ¨Ìï≠"
                }
        except Exception as e:
            self.logger.warning(f"ÌïúÍµ≠Ïñ¥ ÌÜµÌï© ÏöîÏïΩ Ïã§Ìå®: {e}")
            return {"error": str(e)}
    
    def _calculate_jewelry_relevance(self, content: str) -> float:
        """Ï£ºÏñºÎ¶¨ Í¥ÄÎ†®ÏÑ± Í≥ÑÏÇ∞"""
        jewelry_keywords = [
            "Îã§Ïù¥ÏïÑÎ™¨Îìú", "Î£®ÎπÑ", "ÏÇ¨ÌååÏù¥Ïñ¥", "ÏóêÎ©îÎûÑÎìú", "Ï£ºÏñºÎ¶¨", "Î≥¥ÏÑù",
            "Í∏à", "ÏùÄ", "Î∞±Í∏à", "Î∞òÏßÄ", "Î™©Í±∏Ïù¥", "Í∑ÄÍ±∏Ïù¥", "Î∏åÎ°úÏπò",
            "4C", "Ï∫êÎüø", "Ïª∑", "ÏÉâÏÉÅ", "Ìà¨Î™ÖÎèÑ", "Í∞êÏ†ïÏÑú", "GIA", "AGS"
        ]
        
        content_lower = content.lower()
        matches = sum(1 for keyword in jewelry_keywords if keyword.lower() in content_lower)
        return min(matches / len(jewelry_keywords) * 10, 1.0)
    
    def _extract_insights(self, content: str) -> List[str]:
        """Ïù∏ÏÇ¨Ïù¥Ìä∏ Ï∂îÏ∂ú"""
        # Í∞ÑÎã®Ìïú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ïù∏ÏÇ¨Ïù¥Ìä∏ Ï∂îÏ∂ú
        lines = content.split('\n')
        insights = []
        
        for line in lines:
            if any(keyword in line for keyword in ['Ïù∏ÏÇ¨Ïù¥Ìä∏', 'ÌïµÏã¨', 'Ï§ëÏöî', 'Ìä∏Î†åÎìú', 'Î∂ÑÏÑù']):
                insights.append(line.strip())
        
        return insights[:5]
    
    def _extract_action_items(self, content: str) -> List[str]:
        """Ïï°ÏÖò ÏïÑÏù¥ÌÖú Ï∂îÏ∂ú"""
        lines = content.split('\n')
        actions = []
        
        for line in lines:
            if any(keyword in line for keyword in ['Ïï°ÏÖò', 'Ï°∞Ïπò', 'Ïã§Ìñâ', 'Í∂åÏû•', 'Ï†úÏïà']):
                actions.append(line.strip())
        
        return actions[:3]
    
    def _create_demo_result(self, model_name: str, content: str) -> AnalysisResult:
        """Îç∞Î™® Í≤∞Í≥º ÏÉùÏÑ±"""
        return AnalysisResult(
            model_name=f"{model_name} (Îç∞Î™®)",
            content=f"[Îç∞Î™® Î™®Îìú] {model_name} Î∂ÑÏÑù Í≤∞Í≥º: Ï£ºÏñºÎ¶¨ ÏóÖÍ≥Ñ Í¥ÄÎ†® ÎÇ¥Ïö© Î∂ÑÏÑù ÏôÑÎ£å",
            confidence_score=0.85,
            processing_time=1.5,
            jewelry_relevance=0.7,
            language_detected="ko",
            key_insights=["Îç∞Î™® Ïù∏ÏÇ¨Ïù¥Ìä∏ 1", "Îç∞Î™® Ïù∏ÏÇ¨Ïù¥Ìä∏ 2"],
            action_items=["Îç∞Î™® Ïï°ÏÖò 1", "Îç∞Î™® Ïï°ÏÖò 2"],
            quality_metrics={"demo_mode": True}
        )
    
    def _create_error_result(self, model_name: str, error: str) -> AnalysisResult:
        """ÏóêÎü¨ Í≤∞Í≥º ÏÉùÏÑ±"""
        return AnalysisResult(
            model_name=f"{model_name} (Ïò§Î•ò)",
            content=f"Î∂ÑÏÑù Ïã§Ìå®: {error}",
            confidence_score=0.0,
            processing_time=0.0,
            jewelry_relevance=0.0,
            language_detected="unknown",
            key_insights=[],
            action_items=[],
            quality_metrics={"error": True}
        )
    
    def _extract_common_keywords(self, text_list: List[str]) -> List[str]:
        """Í≥µÌÜµ ÌÇ§ÏõåÎìú Ï∂îÏ∂ú"""
        if not text_list:
            return []
        
        word_count = {}
        for text in text_list:
            words = text.split()
            for word in words:
                word_count[word] = word_count.get(word, 0) + 1
        
        # ÎπàÎèÑÏàú Ï†ïÎ†¨
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words if count > 1][:10]
    
    def _calculate_agreement(self, results: List[AnalysisResult]) -> float:
        """Î™®Îç∏ Í∞Ñ ÏùºÏπòÎèÑ Í≥ÑÏÇ∞"""
        if len(results) < 2:
            return 1.0
        
        # Ïã†Î¢∞ÎèÑ Ï†êÏàòÏùò ÌëúÏ§ÄÌé∏Ï∞®Î°ú ÏùºÏπòÎèÑ Ï∏°Ï†ï
        confidence_scores = [r.confidence_score for r in results]
        import statistics
        std_dev = statistics.stdev(confidence_scores) if len(confidence_scores) > 1 else 0
        
        # ÌëúÏ§ÄÌé∏Ï∞®Í∞Ä ÎÇÆÏùÑÏàòÎ°ù ÏùºÏπòÎèÑÍ∞Ä ÎÜíÏùå
        return max(0, 1 - (std_dev * 2))
    
    def _calculate_consistency(self, results: List[AnalysisResult]) -> float:
        """ÏùºÍ¥ÄÏÑ± Ï†êÏàò Í≥ÑÏÇ∞"""
        return 0.85  # ÏûÑÏãú Íµ¨ÌòÑ
    
    def _calculate_completeness(self, results: List[AnalysisResult]) -> float:
        """ÏôÑÏÑ±ÎèÑ Ï†êÏàò Í≥ÑÏÇ∞"""
        return 0.90  # ÏûÑÏãú Íµ¨ÌòÑ
    
    def _calculate_actionability(self, results: List[AnalysisResult]) -> float:
        """Ïã§ÌñâÍ∞ÄÎä•ÏÑ± Ï†êÏàò Í≥ÑÏÇ∞"""
        total_actions = sum(len(r.action_items) for r in results)
        return min(total_actions / 10, 1.0)
    
    def _calculate_overall_quality(self, results: List[AnalysisResult]) -> float:
        """Ï†ÑÏ≤¥ ÌíàÏßà Ï†êÏàò Í≥ÑÏÇ∞"""
        if not results:
            return 0.0
        
        avg_confidence = sum(r.confidence_score for r in results) / len(results)
        avg_relevance = sum(r.jewelry_relevance for r in results) / len(results)
        
        return (avg_confidence * 0.6) + (avg_relevance * 0.4)
    
    def _generate_recommendations(self, consensus: Dict[str, Any]) -> List[str]:
        """Ï∂îÏ≤úÏÇ¨Ìï≠ ÏÉùÏÑ±"""
        recommendations = []
        
        if consensus.get("jewelry_relevance", 0) > 0.8:
            recommendations.append("üî• ÎÜíÏùÄ Ï£ºÏñºÎ¶¨ Í¥ÄÎ†®ÏÑ± - Ï¶âÏãú ÎπÑÏ¶àÎãàÏä§ Ï†ÅÏö© Í≤ÄÌÜ†")
        
        if consensus.get("confidence_score", 0) > 0.9:
            recommendations.append("‚úÖ ÎÜíÏùÄ Ïã†Î¢∞ÎèÑ - ÏùòÏÇ¨Í≤∞Ï†ï Í∑ºÍ±∞Î°ú ÌôúÏö© Í∞ÄÎä•")
        
        if len(consensus.get("common_actions", [])) > 2:
            recommendations.append("üéØ Î™ÖÌôïÌïú Ïï°ÏÖò ÏïÑÏù¥ÌÖú - Îã®Í≥ÑÎ≥Ñ Ïã§Ìñâ Í≥ÑÌöç ÏàòÎ¶Ω")
        
        return recommendations
    
    def _update_performance_metrics(self, result: Dict[str, Any]):
        """ÏÑ±Îä• Î©îÌä∏Î¶≠ ÏóÖÎç∞Ïù¥Ìä∏"""
        self.performance_metrics["total_analyses"] += 1
        
        current_quality = result.get("quality_score", 0)
        total_analyses = self.performance_metrics["total_analyses"]
        
        # ÎàÑÏ†Å ÌèâÍ∑† Í≥ÑÏÇ∞
        prev_avg = self.performance_metrics["average_accuracy"]
        self.performance_metrics["average_accuracy"] = (
            (prev_avg * (total_analyses - 1) + current_quality) / total_analyses
        )
        
        self.performance_metrics["last_update"] = datetime.now()
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î¶¨Ìè¨Ìä∏ Î∞òÌôò"""
        return {
            "summary": {
                "total_analyses": self.performance_metrics["total_analyses"],
                "average_quality": self.performance_metrics["average_accuracy"],
                "last_update": self.performance_metrics["last_update"].isoformat()
            },
            "models_status": {
                name: "active" if name in self.ai_clients else "inactive"
                for name in self.models_config.keys()
            },
            "jewelry_modules": {
                "jewelry_engine": self.jewelry_engine is not None,
                "korean_engine": self.korean_engine is not None,
                "quality_analyzer": self.quality_analyzer is not None
            }
        }
    
    async def save_analysis_result(self, result: Dict[str, Any], file_path: str):
        """Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû•"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=str)
            self.logger.info(f"‚úÖ Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: {file_path}")
        except Exception as e:
            self.logger.error(f"‚ùå Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû• Ïã§Ìå®: {e}")


async def main():
    """ÌÖåÏä§Ìä∏ Ïã§Ìñâ"""
    print("üöÄ ÏÜîÎ°úÎ™¨Îìú AI v2.2 - Ï∞®ÏÑ∏ÎåÄ AI ÌÜµÌï© ÏóîÏßÑ ÌÖåÏä§Ìä∏")
    
    integrator = NextGenAIIntegrator()
    
    # ÌÖåÏä§Ìä∏ ÎÇ¥Ïö©
    test_content = """
    Ïò§Îäò ÌôçÏΩ© Ï£ºÏñºÎ¶¨ÏáºÏóêÏÑú ÏÉàÎ°úÏö¥ Îã§Ïù¥ÏïÑÎ™¨Îìú Ïª∑ÌåÖ Í∏∞Ïà†Ïóê ÎåÄÌïú Î∞úÌëúÍ∞Ä ÏûàÏóàÏäµÎãàÎã§.
    Ïù¥ Í∏∞Ïà†ÏùÄ Í∏∞Ï°¥ ÎùºÏö¥Îìú Î∏åÎ¶¥Î¶¨Ïñ∏Ìä∏ Ïª∑Î≥¥Îã§ 30% Îçî ÎßéÏùÄ ÎπõÏùÑ Î∞òÏÇ¨Ìï† Ïàò ÏûàÎã§Í≥† Ìï©ÎãàÎã§.
    Ï£ºÏöî Î≥¥ÏÑù Î∏åÎûúÎìúÎì§Ïù¥ Ïù¥ Í∏∞Ïà† ÎèÑÏûÖÏùÑ Í≤ÄÌÜ†ÌïòÍ≥† ÏûàÏúºÎ©∞, 
    ÎÇ¥ÎÖÑÎ∂ÄÌÑ∞ ÏÉÅÏö©ÌôîÎê† ÏòàÏ†ïÏûÖÎãàÎã§.
    """
    
    print("\nüìä Îã§Ï§ë Î™®Îç∏ Ïª®ÏÑºÏÑúÏä§ Î∂ÑÏÑù ÏãúÏûë...")
    
    result = await integrator.multi_model_consensus_analysis(
        test_content, 
        analysis_type="comprehensive"
    )
    
    print(f"\n‚úÖ Î∂ÑÏÑù ÏôÑÎ£å!")
    print(f"üéØ ÌíàÏßà Ï†êÏàò: {result['quality_score']:.2f}")
    print(f"‚è±Ô∏è Ï≤òÎ¶¨ ÏãúÍ∞Ñ: {result['processing_time']:.2f}Ï¥à")
    print(f"ü§ñ ÏÇ¨Ïö©Îêú Î™®Îç∏: {result['metadata']['models_used']}Í∞ú")
    
    # ÏÑ±Îä• Î¶¨Ìè¨Ìä∏
    performance = integrator.get_performance_report()
    print(f"\nüìà ÏãúÏä§ÌÖú ÏÉÅÌÉú:")
    print(f"  - Ï¥ù Î∂ÑÏÑù ÌöüÏàò: {performance['summary']['total_analyses']}")
    print(f"  - ÌèâÍ∑† ÌíàÏßà: {performance['summary']['average_quality']:.2f}")
    
    print("\nüéâ Ï∞®ÏÑ∏ÎåÄ AI ÌÜµÌï© ÏóîÏßÑ ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")


if __name__ == "__main__":
    asyncio.run(main())
