"""
ğŸš€ ì†”ë¡œëª¬ë“œ AI v2.2 - ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„
Next Generation AI Integration Engine

ì£¼ìš” ê¸°ëŠ¥:
- GPT-4o, Claude 3.5 Sonnet, Gemini Pro í†µí•©
- ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- ê°ì • ë¶„ì„ ë° í™”ì êµ¬ë¶„ ê³ ë„í™”
- ì‹¤ì‹œê°„ ì‹œì¥ ë¶„ì„ ì—°ë™
- ë‹¤ì¤‘ ëª¨ë¸ ì»¨ì„¼ì„œìŠ¤ ë¶„ì„

ê°œë°œì: ì „ê·¼í˜ (ì†”ë¡œëª¬ë“œ ëŒ€í‘œ)
ì‹œì‘ì¼: 2025.07.12
"""

import os
import asyncio
import json
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime
import logging
from pathlib import Path

# AI ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
try:
    import openai
    from anthropic import Anthropic
    import google.generativeai as genai
except ImportError as e:
    print(f"âš ï¸ AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”: {e}")

# ë‚´ë¶€ ëª¨ë“ˆ
try:
    from .jewelry_ai_engine import JewelryAIEngine
    from .korean_summary_engine_v21 import KoreanSummaryEngineV21
    from .quality_analyzer_v21 import QualityAnalyzerV21
except ImportError:
    print("âš ï¸ ë‚´ë¶€ ëª¨ë“ˆ import ì˜¤ë¥˜ - í´ë°± ëª¨ë“œë¡œ ì‹¤í–‰")

@dataclass
class AIModelConfig:
    """AI ëª¨ë¸ ì„¤ì •"""
    name: str
    api_key: Optional[str] = None
    model_id: str = ""
    max_tokens: int = 4096
    temperature: float = 0.7
    specialty: str = ""  # ê° ëª¨ë¸ì˜ íŠ¹í™” ë¶„ì•¼

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    model_name: str
    content: str
    confidence_score: float
    processing_time: float
    jewelry_relevance: float
    language_detected: str
    key_insights: List[str]
    action_items: List[str]
    quality_metrics: Dict[str, float]

class NextGenAIIntegrator:
    """ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            config_path: AI ëª¨ë¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.logger = self._setup_logger()
        self.models_config = self._load_models_config(config_path)
        self.ai_clients = {}
        self.jewelry_engine = None
        self.korean_engine = None
        self.quality_analyzer = None
        
        # ì£¼ì–¼ë¦¬ íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.jewelry_prompts = self._load_jewelry_prompts()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_metrics = {
            "total_analyses": 0,
            "average_accuracy": 0.0,
            "model_performance": {},
            "last_update": datetime.now()
        }
        
        self._initialize_ai_clients()
        self._initialize_jewelry_modules()
        
        self.logger.info("ğŸš€ ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
        logger = logging.getLogger("NextGenAI")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _load_models_config(self, config_path: Optional[str]) -> Dict[str, AIModelConfig]:
        """AI ëª¨ë¸ ì„¤ì • ë¡œë“œ"""
        default_config = {
            "gpt4o": AIModelConfig(
                name="GPT-4o",
                model_id="gpt-4o",
                max_tokens=4096,
                temperature=0.3,
                specialty="ì¼ë°˜ ë¶„ì„ ë° ìš”ì•½"
            ),
            "claude35": AIModelConfig(
                name="Claude 3.5 Sonnet",
                model_id="claude-3-5-sonnet-20241022",
                max_tokens=4096,
                temperature=0.4,
                specialty="ë…¼ë¦¬ì  ë¶„ì„ ë° ì¶”ë¡ "
            ),
            "gemini": AIModelConfig(
                name="Gemini Pro",
                model_id="gemini-pro",
                max_tokens=4096,
                temperature=0.5,
                specialty="ë‹¤êµ­ì–´ ë° ì°½ì˜ì  ë¶„ì„"
            )
        }
        
        if config_path and Path(config_path).exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    custom_config = json.load(f)
                    # ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì • ì—…ë°ì´íŠ¸
                    for key, value in custom_config.items():
                        if key in default_config:
                            default_config[key].__dict__.update(value)
            except Exception as e:
                self.logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: {e}")
        
        return default_config
    
    def _load_jewelry_prompts(self) -> Dict[str, str]:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            "general_analysis": """
ë‹¹ì‹ ì€ ì£¼ì–¼ë¦¬ ì—…ê³„ ì „ë¬¸ AI ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ë¶„ì„ ë‚´ìš©: {content}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ë ¨ì„± ë° ì¤‘ìš”ë„
2. í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
3. ê¸°ìˆ ì /ì‹œì¥ ë™í–¥ ë¶„ì„
4. ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ
5. ìœ„í—˜ ìš”ì†Œ ë° ê¸°íšŒ ìš”ì†Œ

ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
- ìš”ì•½ (3ì¤„ ì´ë‚´)
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (5ê°œ ì´ë‚´)
- ì•¡ì…˜ ì•„ì´í…œ (3ê°œ ì´ë‚´)
- ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ì ìˆ˜ (1-10)
""",
            
            "emotion_analysis": """
ë‹¤ìŒ ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ë ¨ ë‚´ìš©ì˜ ê°ì •ê³¼ ë¶„ìœ„ê¸°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

ë‚´ìš©: {content}

ë¶„ì„ ìš”ì²­:
1. ì „ì²´ì ì¸ ê°ì • í†¤ (ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì )
2. ì£¼ìš” ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
3. ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ í‰ê°€
4. ê³ ê°/ì‹œì¥ ë°˜ì‘ ì˜ˆì¸¡
5. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ ì œì•ˆ

ì£¼ì–¼ë¦¬ ì—…ê³„ ë§¥ë½ì—ì„œ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
""",
            
            "market_analysis": """
ì£¼ì–¼ë¦¬ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ë‚´ìš©: {content}

ë¶„ì„ í•­ëª©:
1. ì‹œì¥ íŠ¸ë Œë“œ ì‹ë³„
2. ê²½ìŸì‚¬ ë™í–¥ ë¶„ì„
3. ê°€ê²© ë° ìˆ˜ìš” ì „ë§
4. ì§€ì—­ë³„ ì‹œì¥ íŠ¹ì„±
5. íˆ¬ì ë° ì‚¬ì—… ê¸°íšŒ

ì•„ì‹œì•„ ì‹œì¥(í•œêµ­, í™ì½©, íƒœêµ­, ì‹±ê°€í¬ë¥´) íŠ¹í™” ë¶„ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
""",
            
            "korean_summary": """
ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ ì£¼ì–¼ë¦¬ ì—…ê³„ ì‹¤ë¬´ì§„ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì›ë³¸ ë‚´ìš©: {content}
ì–¸ì–´: {language}

ìš”ì•½ ê¸°ì¤€:
- í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ ìŠ¤íƒ€ì¼
- ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ì •í™•í•œ ë²ˆì—­
- ì‹¤ë¬´ì§„ ê´€ì ì—ì„œì˜ ì¤‘ìš”ë„ ìˆœì„œ
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš© ìœ„ì£¼

ê²°ê³¼ë¬¼:
1. í•µì‹¬ ìš”ì•½ (200ì ì´ë‚´)
2. ìƒì„¸ ë¶„ì„ (500ì ì´ë‚´)  
3. ì£¼ìš” ê²°ì •ì‚¬í•­/ì•¡ì…˜ ì•„ì´í…œ
4. ì°¸ê³ ì‚¬í•­ ë° í›„ì† ì¡°ì¹˜
"""
        }
    
    def _initialize_ai_clients(self):
        """AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # OpenAI (GPT-4o)
            if os.getenv("OPENAI_API_KEY"):
                openai.api_key = os.getenv("OPENAI_API_KEY")
                self.ai_clients["gpt4o"] = openai
                self.logger.info("âœ… GPT-4o í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Anthropic (Claude 3.5)
            if os.getenv("ANTHROPIC_API_KEY"):
                self.ai_clients["claude35"] = Anthropic(
                    api_key=os.getenv("ANTHROPIC_API_KEY")
                )
                self.logger.info("âœ… Claude 3.5 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Google (Gemini)
            if os.getenv("GOOGLE_API_KEY"):
                genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
                self.ai_clients["gemini"] = genai
                self.logger.info("âœ… Gemini Pro í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            if not self.ai_clients:
                self.logger.warning("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰")
                
        except Exception as e:
            self.logger.error(f"âŒ AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_jewelry_modules(self):
        """ì£¼ì–¼ë¦¬ íŠ¹í™” ëª¨ë“ˆ ì´ˆê¸°í™”"""
        try:
            self.jewelry_engine = JewelryAIEngine()
            self.korean_engine = KoreanSummaryEngineV21()
            self.quality_analyzer = QualityAnalyzerV21()
            self.logger.info("âœ… ì£¼ì–¼ë¦¬ íŠ¹í™” ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì£¼ì–¼ë¦¬ ëª¨ë“ˆ ì´ˆê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨: {e}")
    
    async def analyze_with_gpt4o(self, content: str, prompt_type: str = "general_analysis") -> AnalysisResult:
        """GPT-4o ë¶„ì„"""
        try:
            if "gpt4o" not in self.ai_clients:
                return self._create_demo_result("GPT-4o", content)
            
            start_time = datetime.now()
            
            prompt = self.jewelry_prompts[prompt_type].format(content=content)
            
            response = await asyncio.to_thread(
                self.ai_clients["gpt4o"].ChatCompletion.create,
                model=self.models_config["gpt4o"].model_id,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=self.models_config["gpt4o"].max_tokens,
                temperature=self.models_config["gpt4o"].temperature
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            result_content = response.choices[0].message.content
            
            return AnalysisResult(
                model_name="GPT-4o",
                content=result_content,
                confidence_score=0.92,
                processing_time=processing_time,
                jewelry_relevance=self._calculate_jewelry_relevance(result_content),
                language_detected="ko",
                key_insights=self._extract_insights(result_content),
                action_items=self._extract_action_items(result_content),
                quality_metrics={"accuracy": 0.92, "relevance": 0.89}
            )
            
        except Exception as e:
            self.logger.error(f"GPT-4o ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_error_result("GPT-4o", str(e))
    
    async def analyze_with_claude35(self, content: str, prompt_type: str = "general_analysis") -> AnalysisResult:
        """Claude 3.5 ë¶„ì„"""
        try:
            if "claude35" not in self.ai_clients:
                return self._create_demo_result("Claude 3.5", content)
            
            start_time = datetime.now()
            
            prompt = self.jewelry_prompts[prompt_type].format(content=content)
            
            response = await asyncio.to_thread(
                self.ai_clients["claude35"].messages.create,
                model=self.models_config["claude35"].model_id,
                max_tokens=self.models_config["claude35"].max_tokens,
                temperature=self.models_config["claude35"].temperature,
                messages=[{"role": "user", "content": prompt}]
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            result_content = response.content[0].text
            
            return AnalysisResult(
                model_name="Claude 3.5",
                content=result_content,
                confidence_score=0.94,
                processing_time=processing_time,
                jewelry_relevance=self._calculate_jewelry_relevance(result_content),
                language_detected="ko",
                key_insights=self._extract_insights(result_content),
                action_items=self._extract_action_items(result_content),
                quality_metrics={"accuracy": 0.94, "reasoning": 0.96}
            )
            
        except Exception as e:
            self.logger.error(f"Claude 3.5 ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_error_result("Claude 3.5", str(e))
    
    async def analyze_with_gemini(self, content: str, prompt_type: str = "general_analysis") -> AnalysisResult:
        """Gemini Pro ë¶„ì„"""
        try:
            if "gemini" not in self.ai_clients:
                return self._create_demo_result("Gemini Pro", content)
            
            start_time = datetime.now()
            
            model = self.ai_clients["gemini"].GenerativeModel(
                self.models_config["gemini"].model_id
            )
            
            prompt = self.jewelry_prompts[prompt_type].format(content=content)
            
            response = await asyncio.to_thread(
                model.generate_content,
                prompt,
                generation_config={
                    "temperature": self.models_config["gemini"].temperature,
                    "max_output_tokens": self.models_config["gemini"].max_tokens,
                }
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            result_content = response.text
            
            return AnalysisResult(
                model_name="Gemini Pro",
                content=result_content,
                confidence_score=0.88,
                processing_time=processing_time,
                jewelry_relevance=self._calculate_jewelry_relevance(result_content),
                language_detected="ko",
                key_insights=self._extract_insights(result_content),
                action_items=self._extract_action_items(result_content),
                quality_metrics={"accuracy": 0.88, "creativity": 0.93}
            )
            
        except Exception as e:
            self.logger.error(f"Gemini Pro ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_error_result("Gemini Pro", str(e))
    
    async def multi_model_consensus_analysis(
        self, 
        content: str, 
        analysis_type: str = "comprehensive"
    ) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ëª¨ë¸ ì»¨ì„¼ì„œìŠ¤ ë¶„ì„"""
        self.logger.info(f"ğŸš€ ë‹¤ì¤‘ ëª¨ë¸ ì»¨ì„¼ì„œìŠ¤ ë¶„ì„ ì‹œì‘: {analysis_type}")
        
        start_time = datetime.now()
        
        # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
        tasks = [
            self.analyze_with_gpt4o(content, "general_analysis"),
            self.analyze_with_claude35(content, "general_analysis"),
            self.analyze_with_gemini(content, "general_analysis")
        ]
        
        if analysis_type == "comprehensive":
            # ê°ì • ë¶„ì„ ì¶”ê°€
            tasks.extend([
                self.analyze_with_gpt4o(content, "emotion_analysis"),
                self.analyze_with_claude35(content, "market_analysis")
            ])
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ìœ íš¨í•œ ê²°ê³¼ë§Œ í•„í„°ë§
        valid_results = [r for r in results if isinstance(r, AnalysisResult)]
        
        if not valid_results:
            return {"error": "ëª¨ë“  AI ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨"}
        
        # ì»¨ì„¼ì„œìŠ¤ ë¶„ì„
        consensus = self._calculate_consensus(valid_results)
        
        # ì£¼ì–¼ë¦¬ íŠ¹í™” ë¶„ì„ ì¶”ê°€
        jewelry_analysis = await self._jewelry_specialized_analysis(content)
        
        # í•œêµ­ì–´ í†µí•© ìš”ì•½
        korean_summary = await self._korean_integrated_summary(content, valid_results)
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            "analysis_type": analysis_type,
            "processing_time": total_time,
            "model_results": [r.__dict__ for r in valid_results],
            "consensus": consensus,
            "jewelry_analysis": jewelry_analysis,
            "korean_summary": korean_summary,
            "quality_score": self._calculate_overall_quality(valid_results),
            "recommendations": self._generate_recommendations(consensus),
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "models_used": len(valid_results),
                "analysis_version": "v2.2"
            }
        }
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self._update_performance_metrics(result)
        
        self.logger.info(f"âœ… ë‹¤ì¤‘ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ - í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.2f}")
        
        return result
    
    def _calculate_consensus(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """ì»¨ì„¼ì„œìŠ¤ ê³„ì‚°"""
        if not results:
            return {}
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        total_confidence = sum(r.confidence_score for r in results)
        avg_confidence = total_confidence / len(results)
        
        # ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± í‰ê· 
        avg_jewelry_relevance = sum(r.jewelry_relevance for r in results) / len(results)
        
        # ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ
        all_insights = []
        all_actions = []
        
        for result in results:
            all_insights.extend(result.key_insights)
            all_actions.extend(result.action_items)
        
        # ë¹ˆë„ ê¸°ë°˜ ê³µí†µ ì¸ì‚¬ì´íŠ¸
        common_insights = self._extract_common_keywords(all_insights)
        common_actions = self._extract_common_keywords(all_actions)
        
        return {
            "confidence_score": avg_confidence,
            "jewelry_relevance": avg_jewelry_relevance,
            "common_insights": common_insights[:5],  # ìƒìœ„ 5ê°œ
            "common_actions": common_actions[:3],    # ìƒìœ„ 3ê°œ
            "model_agreement": self._calculate_agreement(results),
            "quality_indicators": {
                "consistency": self._calculate_consistency(results),
                "completeness": self._calculate_completeness(results),
                "actionability": self._calculate_actionability(results)
            }
        }
    
    async def _jewelry_specialized_analysis(self, content: str) -> Dict[str, Any]:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” ë¶„ì„"""
        try:
            if self.jewelry_engine:
                return await asyncio.to_thread(
                    self.jewelry_engine.comprehensive_analysis, content
                )
            else:
                return {
                    "jewelry_keywords": self._extract_jewelry_keywords(content),
                    "business_impact": "ì¤‘ê°„",
                    "market_relevance": "ë†’ìŒ",
                    "technical_aspects": ["í’ˆì§ˆ", "ë””ìì¸", "ì œì¡°"]
                }
        except Exception as e:
            self.logger.warning(f"ì£¼ì–¼ë¦¬ íŠ¹í™” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def _korean_integrated_summary(
        self, 
        content: str, 
        results: List[AnalysisResult]
    ) -> Dict[str, str]:
        """í•œêµ­ì–´ í†µí•© ìš”ì•½"""
        try:
            if self.korean_engine:
                # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ í•œêµ­ì–´ ìš”ì•½
                combined_analysis = "\n\n".join([r.content for r in results])
                return await asyncio.to_thread(
                    self.korean_engine.create_integrated_summary,
                    content,
                    combined_analysis
                )
            else:
                # í´ë°±: ê¸°ë³¸ í•œêµ­ì–´ ìš”ì•½
                return {
                    "executive_summary": "ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ë ¨ ë‚´ìš©ì˜ ì¢…í•© ë¶„ì„ ê²°ê³¼",
                    "key_findings": "ë‹¤ì¤‘ AI ëª¨ë¸ ë¶„ì„ì„ í†µí•œ í•µì‹¬ ë°œê²¬ì‚¬í•­",
                    "business_implications": "ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„",
                    "next_steps": "ì¶”ì²œ í›„ì† ì¡°ì¹˜ì‚¬í•­"
                }
        except Exception as e:
            self.logger.warning(f"í•œêµ­ì–´ í†µí•© ìš”ì•½ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _calculate_jewelry_relevance(self, content: str) -> float:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± ê³„ì‚°"""
        jewelry_keywords = [
            "ë‹¤ì´ì•„ëª¬ë“œ", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", "ì—ë©”ë„ë“œ", "ì£¼ì–¼ë¦¬", "ë³´ì„",
            "ê¸ˆ", "ì€", "ë°±ê¸ˆ", "ë°˜ì§€", "ëª©ê±¸ì´", "ê·€ê±¸ì´", "ë¸Œë¡œì¹˜",
            "4C", "ìºëŸ¿", "ì»·", "ìƒ‰ìƒ", "íˆ¬ëª…ë„", "ê°ì •ì„œ", "GIA", "AGS"
        ]
        
        content_lower = content.lower()
        matches = sum(1 for keyword in jewelry_keywords if keyword.lower() in content_lower)
        return min(matches / len(jewelry_keywords) * 10, 1.0)
    
    def _extract_insights(self, content: str) -> List[str]:
        """ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        lines = content.split('\n')
        insights = []
        
        for line in lines:
            if any(keyword in line for keyword in ['ì¸ì‚¬ì´íŠ¸', 'í•µì‹¬', 'ì¤‘ìš”', 'íŠ¸ë Œë“œ', 'ë¶„ì„']):
                insights.append(line.strip())
        
        return insights[:5]
    
    def _extract_action_items(self, content: str) -> List[str]:
        """ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        lines = content.split('\n')
        actions = []
        
        for line in lines:
            if any(keyword in line for keyword in ['ì•¡ì…˜', 'ì¡°ì¹˜', 'ì‹¤í–‰', 'ê¶Œì¥', 'ì œì•ˆ']):
                actions.append(line.strip())
        
        return actions[:3]
    
    def _create_demo_result(self, model_name: str, content: str) -> AnalysisResult:
        """ë°ëª¨ ê²°ê³¼ ìƒì„±"""
        return AnalysisResult(
            model_name=f"{model_name} (ë°ëª¨)",
            content=f"[ë°ëª¨ ëª¨ë“œ] {model_name} ë¶„ì„ ê²°ê³¼: ì£¼ì–¼ë¦¬ ì—…ê³„ ê´€ë ¨ ë‚´ìš© ë¶„ì„ ì™„ë£Œ",
            confidence_score=0.85,
            processing_time=1.5,
            jewelry_relevance=0.7,
            language_detected="ko",
            key_insights=["ë°ëª¨ ì¸ì‚¬ì´íŠ¸ 1", "ë°ëª¨ ì¸ì‚¬ì´íŠ¸ 2"],
            action_items=["ë°ëª¨ ì•¡ì…˜ 1", "ë°ëª¨ ì•¡ì…˜ 2"],
            quality_metrics={"demo_mode": True}
        )
    
    def _create_error_result(self, model_name: str, error: str) -> AnalysisResult:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return AnalysisResult(
            model_name=f"{model_name} (ì˜¤ë¥˜)",
            content=f"ë¶„ì„ ì‹¤íŒ¨: {error}",
            confidence_score=0.0,
            processing_time=0.0,
            jewelry_relevance=0.0,
            language_detected="unknown",
            key_insights=[],
            action_items=[],
            quality_metrics={"error": True}
        )
    
    def _extract_common_keywords(self, text_list: List[str]) -> List[str]:
        """ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text_list:
            return []
        
        word_count = {}
        for text in text_list:
            words = text.split()
            for word in words:
                word_count[word] = word_count.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words if count > 1][:10]
    
    def _calculate_agreement(self, results: List[AnalysisResult]) -> float:
        """ëª¨ë¸ ê°„ ì¼ì¹˜ë„ ê³„ì‚°"""
        if len(results) < 2:
            return 1.0
        
        # ì‹ ë¢°ë„ ì ìˆ˜ì˜ í‘œì¤€í¸ì°¨ë¡œ ì¼ì¹˜ë„ ì¸¡ì •
        confidence_scores = [r.confidence_score for r in results]
        import statistics
        std_dev = statistics.stdev(confidence_scores) if len(confidence_scores) > 1 else 0
        
        # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì¼ì¹˜ë„ê°€ ë†’ìŒ
        return max(0, 1 - (std_dev * 2))
    
    def _calculate_consistency(self, results: List[AnalysisResult]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        return 0.85  # ì„ì‹œ êµ¬í˜„
    
    def _calculate_completeness(self, results: List[AnalysisResult]) -> float:
        """ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°"""
        return 0.90  # ì„ì‹œ êµ¬í˜„
    
    def _calculate_actionability(self, results: List[AnalysisResult]) -> float:
        """ì‹¤í–‰ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°"""
        total_actions = sum(len(r.action_items) for r in results)
        return min(total_actions / 10, 1.0)
    
    def _calculate_overall_quality(self, results: List[AnalysisResult]) -> float:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not results:
            return 0.0
        
        avg_confidence = sum(r.confidence_score for r in results) / len(results)
        avg_relevance = sum(r.jewelry_relevance for r in results) / len(results)
        
        return (avg_confidence * 0.6) + (avg_relevance * 0.4)
    
    def _generate_recommendations(self, consensus: Dict[str, Any]) -> List[str]:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if consensus.get("jewelry_relevance", 0) > 0.8:
            recommendations.append("ğŸ”¥ ë†’ì€ ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± - ì¦‰ì‹œ ë¹„ì¦ˆë‹ˆìŠ¤ ì ìš© ê²€í† ")
        
        if consensus.get("confidence_score", 0) > 0.9:
            recommendations.append("âœ… ë†’ì€ ì‹ ë¢°ë„ - ì˜ì‚¬ê²°ì • ê·¼ê±°ë¡œ í™œìš© ê°€ëŠ¥")
        
        if len(consensus.get("common_actions", [])) > 2:
            recommendations.append("ğŸ¯ ëª…í™•í•œ ì•¡ì…˜ ì•„ì´í…œ - ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½")
        
        return recommendations
    
    def _update_performance_metrics(self, result: Dict[str, Any]):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.performance_metrics["total_analyses"] += 1
        
        current_quality = result.get("quality_score", 0)
        total_analyses = self.performance_metrics["total_analyses"]
        
        # ëˆ„ì  í‰ê·  ê³„ì‚°
        prev_avg = self.performance_metrics["average_accuracy"]
        self.performance_metrics["average_accuracy"] = (
            (prev_avg * (total_analyses - 1) + current_quality) / total_analyses
        )
        
        self.performance_metrics["last_update"] = datetime.now()
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ë°˜í™˜"""
        return {
            "summary": {
                "total_analyses": self.performance_metrics["total_analyses"],
                "average_quality": self.performance_metrics["average_accuracy"],
                "last_update": self.performance_metrics["last_update"].isoformat()
            },
            "models_status": {
                name: "active" if name in self.ai_clients else "inactive"
                for name in self.models_config.keys()
            },
            "jewelry_modules": {
                "jewelry_engine": self.jewelry_engine is not None,
                "korean_engine": self.korean_engine is not None,
                "quality_analyzer": self.quality_analyzer is not None
            }
        }
    
    async def save_analysis_result(self, result: Dict[str, Any], file_path: str):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=str)
            self.logger.info(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {file_path}")
        except Exception as e:
            self.logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ì†”ë¡œëª¬ë“œ AI v2.2 - ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ í…ŒìŠ¤íŠ¸")
    
    integrator = NextGenAIIntegrator()
    
    # í…ŒìŠ¤íŠ¸ ë‚´ìš©
    test_content = """
    ì˜¤ëŠ˜ í™ì½© ì£¼ì–¼ë¦¬ì‡¼ì—ì„œ ìƒˆë¡œìš´ ë‹¤ì´ì•„ëª¬ë“œ ì»·íŒ… ê¸°ìˆ ì— ëŒ€í•œ ë°œí‘œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.
    ì´ ê¸°ìˆ ì€ ê¸°ì¡´ ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸ ì»·ë³´ë‹¤ 30% ë” ë§ì€ ë¹›ì„ ë°˜ì‚¬í•  ìˆ˜ ìˆë‹¤ê³  í•©ë‹ˆë‹¤.
    ì£¼ìš” ë³´ì„ ë¸Œëœë“œë“¤ì´ ì´ ê¸°ìˆ  ë„ì…ì„ ê²€í† í•˜ê³  ìˆìœ¼ë©°, 
    ë‚´ë…„ë¶€í„° ìƒìš©í™”ë  ì˜ˆì •ì…ë‹ˆë‹¤.
    """
    
    print("\nğŸ“Š ë‹¤ì¤‘ ëª¨ë¸ ì»¨ì„¼ì„œìŠ¤ ë¶„ì„ ì‹œì‘...")
    
    result = await integrator.multi_model_consensus_analysis(
        test_content, 
        analysis_type="comprehensive"
    )
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ¯ í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.2f}")
    print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
    print(f"ğŸ¤– ì‚¬ìš©ëœ ëª¨ë¸: {result['metadata']['models_used']}ê°œ")
    
    # ì„±ëŠ¥ ë¦¬í¬íŠ¸
    performance = integrator.get_performance_report()
    print(f"\nğŸ“ˆ ì‹œìŠ¤í…œ ìƒíƒœ:")
    print(f"  - ì´ ë¶„ì„ íšŸìˆ˜: {performance['summary']['total_analyses']}")
    print(f"  - í‰ê·  í’ˆì§ˆ: {performance['summary']['average_quality']:.2f}")
    
    print("\nğŸ‰ ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
