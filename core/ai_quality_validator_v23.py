"""
AI Quality Validator v2.3 for Solomond Jewelry AI Platform
AI í’ˆì§ˆ ê²€ì¦ê¸° v2.3 - 99.2% ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•œ ì‹¤ì‹œê°„ í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ

ğŸ¯ ëª©í‘œ: 99.2% ë¶„ì„ ì •í™•ë„ ë‹¬ì„±
ğŸ“… ê°œë°œê¸°ê°„: 2025.07.13 - 2025.08.03 (3ì£¼)
ğŸ‘¨â€ğŸ’¼ í”„ë¡œì íŠ¸ ë¦¬ë”: ì „ê·¼í˜ (ì†”ë¡œëª¬ë“œ ëŒ€í‘œ)

í•µì‹¬ ê¸°ëŠ¥:
- ì‹¤ì‹œê°„ AI ì‘ë‹µ í’ˆì§ˆ ê²€ì¦
- ì£¼ì–¼ë¦¬ ì „ë¬¸ì„± ì ìˆ˜ ì¸¡ì •
- ìë™ ì¬ë¶„ì„ íŠ¸ë¦¬ê±° ì‹œìŠ¤í…œ
- ë‹¤ì¤‘ ê²€ì¦ ë ˆì´ì–´ (ë…¼ë¦¬ì„±, ì •í™•ì„±, ì „ë¬¸ì„±)
- í•™ìŠµ ê¸°ë°˜ í’ˆì§ˆ ê°œì„ 
- êµ­ì œ ê°ì • ê¸°ì¤€ ì¤€ìˆ˜ ê²€ì¦
"""

import asyncio
import logging
import json
import time
import re
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
from datetime import datetime, timedelta
import statistics
from collections import defaultdict, deque
import hashlib

# ìì—°ì–´ ì²˜ë¦¬
try:
    import nltk
    from nltk.sentiment import SentimentIntensityAnalyzer
    from nltk.tokenize import word_tokenize, sent_tokenize
    from nltk.corpus import stopwords
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False

# ê¸°ê³„í•™ìŠµ
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# ê¸°ì¡´ ì†”ë¡œëª¬ë“œ ëª¨ë“ˆ
try:
    from core.hybrid_llm_manager_v23 import HybridLLMManagerV23, HybridResult, ModelResult, AIModelType
    from core.jewelry_specialized_prompts_v23 import JewelryPromptOptimizerV23, JewelryCategory
    SOLOMOND_V23_AVAILABLE = True
except ImportError as e:
    logging.warning(f"ì†”ë¡œëª¬ë“œ v2.3 ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    SOLOMOND_V23_AVAILABLE = False

class QualityDimension(Enum):
    """í’ˆì§ˆ í‰ê°€ ì°¨ì›"""
    ACCURACY = "accuracy"              # ì •í™•ì„±
    COMPLETENESS = "completeness"      # ì™„ì„±ë„
    RELEVANCE = "relevance"           # ê´€ë ¨ì„±
    PROFESSIONALISM = "professionalism"  # ì „ë¬¸ì„±
    CONSISTENCY = "consistency"        # ì¼ê´€ì„±
    CLARITY = "clarity"               # ëª…í™•ì„±
    ACTIONABILITY = "actionability"    # ì‹¤í–‰ê°€ëŠ¥ì„±

class ValidationLevel(Enum):
    """ê²€ì¦ ìˆ˜ì¤€"""
    BASIC = "basic"           # ê¸°ë³¸ ê²€ì¦
    STANDARD = "standard"     # í‘œì¤€ ê²€ì¦
    EXPERT = "expert"         # ì „ë¬¸ê°€ ê²€ì¦
    CERTIFICATION = "certification"  # ê°ì •ì„œ ìˆ˜ì¤€ ê²€ì¦

class QualityStatus(Enum):
    """í’ˆì§ˆ ìƒíƒœ"""
    EXCELLENT = "excellent"   # 99.5% ì´ìƒ
    GOOD = "good"            # 95-99.4%
    ACCEPTABLE = "acceptable" # 90-94.9%
    NEEDS_IMPROVEMENT = "needs_improvement"  # 85-89.9%
    POOR = "poor"            # 85% ë¯¸ë§Œ

@dataclass
class QualityMetrics:
    """í’ˆì§ˆ ë©”íŠ¸ë¦­"""
    accuracy_score: float
    completeness_score: float
    relevance_score: float
    professionalism_score: float
    consistency_score: float
    clarity_score: float
    actionability_score: float
    overall_score: float
    confidence_level: float
    validation_timestamp: datetime

@dataclass
class ValidationRule:
    """ê²€ì¦ ê·œì¹™"""
    rule_id: str
    category: JewelryCategory
    dimension: QualityDimension
    validation_function: str
    weight: float
    threshold: float
    error_message: str
    improvement_suggestion: str

@dataclass
class QualityIssue:
    """í’ˆì§ˆ ì´ìŠˆ"""
    issue_id: str
    dimension: QualityDimension
    severity: str  # critical, major, minor
    description: str
    location: str  # ë¬¸ì œ ë°œìƒ ìœ„ì¹˜
    suggestion: str
    auto_fixable: bool

@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    content_id: str
    overall_quality: QualityStatus
    metrics: QualityMetrics
    issues: List[QualityIssue]
    passed_rules: List[str]
    failed_rules: List[str]
    improvement_recommendations: List[str]
    reanalysis_required: bool
    validation_time: float

class JewelryKnowledgeBase:
    """ì£¼ì–¼ë¦¬ ì§€ì‹ ë² ì´ìŠ¤"""
    
    def __init__(self):
        self.diamond_standards = self._load_diamond_standards()
        self.gemstone_standards = self._load_gemstone_standards()
        self.business_terms = self._load_business_terms()
        self.quality_indicators = self._load_quality_indicators()
    
    def _load_diamond_standards(self) -> Dict[str, Any]:
        """ë‹¤ì´ì•„ëª¬ë“œ ê¸°ì¤€ ë¡œë“œ"""
        return {
            "gia_color_scale": ["D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"],
            "gia_clarity_scale": ["FL", "IF", "VVS1", "VVS2", "VS1", "VS2", "SI1", "SI2", "I1", "I2", "I3"],
            "gia_cut_grades": ["Excellent", "Very Good", "Good", "Fair", "Poor"],
            "ags_scale": ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10"],
            "carat_ranges": {
                "melee": (0.01, 0.17),
                "small": (0.18, 0.49),
                "medium": (0.50, 0.99),
                "large": (1.00, 2.99),
                "very_large": (3.00, float('inf'))
            },
            "price_factors": ["carat", "color", "clarity", "cut", "fluorescence", "polish", "symmetry"],
            "required_terms": ["ìºëŸ¿", "ì»¬ëŸ¬", "í´ë˜ë¦¬í‹°", "ì»·", "4C", "GIA", "ë“±ê¸‰"]
        }
    
    def _load_gemstone_standards(self) -> Dict[str, Any]:
        """ìœ ìƒ‰ë³´ì„ ê¸°ì¤€ ë¡œë“œ"""
        return {
            "major_gemstones": ["ruby", "sapphire", "emerald", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", "ì—ë©”ë„ë“œ"],
            "origins": {
                "ruby": ["Myanmar", "Thailand", "Sri Lanka", "Madagascar", "Mozambique", "ë¯¸ì–€ë§ˆ", "íƒœêµ­"],
                "sapphire": ["Kashmir", "Sri Lanka", "Myanmar", "Madagascar", "Australia", "ì¹´ì‹œë¯¸ë¥´"],
                "emerald": ["Colombia", "Zambia", "Brazil", "Afghanistan", "ì½œë¡¬ë¹„ì•„", "ì ë¹„ì•„"]
            },
            "treatments": {
                "heating": ["heated", "unheated", "ê°€ì—´", "ë¬´ê°€ì—´"],
                "oiling": ["minor", "moderate", "significant", "ì˜¤ì¼ë§"],
                "other": ["fracture_filling", "diffusion", "irradiation", "ê· ì—´ì¶©ì „", "í™•ì‚°"]
            },
            "certification_labs": ["SSEF", "GÃ¼belin", "GIA", "AGL", "Lotus"],
            "quality_terms": ["pigeon_blood", "cornflower", "royal_blue", "padparadscha", "í”¼ì£¤ë¸”ëŸ¬ë“œ"],
            "required_terms": ["ì›ì‚°ì§€", "ì²˜ë¦¬", "ê°ì •ì„œ", "í’ˆì§ˆ", "í¬ì†Œì„±"]
        }
    
    def _load_business_terms(self) -> Dict[str, Any]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ ë¡œë“œ"""
        return {
            "financial_terms": ["ê°€ê²©", "ì‹œì¥ê°€ì¹˜", "íˆ¬ì", "ìˆ˜ìµë¥ ", "ROI", "ë§ˆì§„", "ë¹„ìš©"],
            "market_terms": ["íŠ¸ë Œë“œ", "ìˆ˜ìš”", "ê³µê¸‰", "ê²½ìŸ", "ì ìœ ìœ¨", "ì„±ì¥ë¥ ", "ì˜ˆì¸¡"],
            "strategy_terms": ["ì „ëµ", "ê¸°íšŒ", "ìœ„í—˜", "ë¶„ì„", "ê³„íš", "ì‹¤í–‰", "KPI"],
            "customer_terms": ["ê³ ê°", "ì†Œë¹„ì", "ì„¸ê·¸ë¨¼íŠ¸", "ë‹ˆì¦ˆ", "ì„ í˜¸ë„", "í–‰ë™íŒ¨í„´"],
            "operational_terms": ["ìš´ì˜", "í”„ë¡œì„¸ìŠ¤", "íš¨ìœ¨ì„±", "í’ˆì§ˆê´€ë¦¬", "ê³µê¸‰ë§", "ìœ í†µ"],
            "required_metrics": ["ì‹œì¥ê·œëª¨", "ì„±ì¥ë¥ ", "ìˆ˜ìµì„±", "ê²½ìŸë¶„ì„", "ì¶”ì²œì‚¬í•­"]
        }
    
    def _load_quality_indicators(self) -> Dict[str, Any]:
        """í’ˆì§ˆ ì§€í‘œ ë¡œë“œ"""
        return {
            "high_quality_phrases": [
                "ì „ë¬¸ê°€", "ì •í™•í•œ", "ìƒì„¸í•œ", "ì¢…í•©ì ì¸", "ì²´ê³„ì ì¸", "ë…¼ë¦¬ì ì¸",
                "ê·¼ê±°ìˆëŠ”", "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”", "ì—…ê³„ í‘œì¤€", "êµ­ì œ ê¸°ì¤€"
            ],
            "low_quality_indicators": [
                "ì¶”ì¸¡", "ëŒ€ëµ", "ì•„ë§ˆë„", "í™•ì‹¤í•˜ì§€ ì•Šì€", "ë¶ˆëª…í™•í•œ",
                "ì¼ë°˜ì ì¸", "ê¸°ë³¸ì ì¸", "ë‹¨ìˆœí•œ"
            ],
            "completeness_indicators": [
                "ê²°ë¡ ", "ìš”ì•½", "ê¶Œì¥ì‚¬í•­", "êµ¬ì²´ì ", "ì„¸ë¶€ì‚¬í•­",
                "ë¶„ì„ê²°ê³¼", "í‰ê°€", "ì˜ê²¬"
            ],
            "professionalism_indicators": [
                "GIA", "AGS", "SSEF", "GÃ¼belin", "ê°ì •ì„œ", "ì¸ì¦ì„œ",
                "ë“±ê¸‰", "ê¸°ì¤€", "í‘œì¤€", "ê·œì •"
            ]
        }

class ContentAnalyzer:
    """ì½˜í…ì¸  ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.knowledge_base = JewelryKnowledgeBase()
        if SKLEARN_AVAILABLE:
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        if NLTK_AVAILABLE:
            try:
                self.sentiment_analyzer = SentimentIntensityAnalyzer()
            except:
                self.sentiment_analyzer = None
    
    def analyze_content_structure(self, content: str) -> Dict[str, Any]:
        """ì½˜í…ì¸  êµ¬ì¡° ë¶„ì„"""
        
        # ê¸°ë³¸ í†µê³„
        word_count = len(content.split())
        sentence_count = len([s for s in content.split('.') if s.strip()])
        paragraph_count = len([p for p in content.split('\n\n') if p.strip()])
        
        # ì„¹ì…˜ ë¶„ì„
        sections = self._identify_sections(content)
        
        # ë¦¬ìŠ¤íŠ¸/êµ¬ì¡° ë¶„ì„
        has_bullets = bool(re.search(r'[â€¢\-\*]\s', content))
        has_numbers = bool(re.search(r'\d+\.\s', content))
        has_headers = bool(re.search(r'^#{1,6}\s', content, re.MULTILINE))
        
        return {
            "word_count": word_count,
            "sentence_count": sentence_count,
            "paragraph_count": paragraph_count,
            "sections": sections,
            "has_structure": {
                "bullets": has_bullets,
                "numbers": has_numbers,
                "headers": has_headers
            },
            "avg_sentence_length": word_count / max(sentence_count, 1),
            "readability_score": self._calculate_readability(content)
        }
    
    def _identify_sections(self, content: str) -> List[str]:
        """ì„¹ì…˜ ì‹ë³„"""
        sections = []
        
        # í—¤ë” íŒ¨í„´
        header_patterns = [
            r'^#{1,6}\s+(.+)$',
            r'^\*\*(.+)\*\*$',
            r'^ã€(.+)ã€‘$',
            r'^â– \s*(.+)$',
            r'^â–¶\s*(.+)$'
        ]
        
        for line in content.split('\n'):
            line = line.strip()
            for pattern in header_patterns:
                match = re.search(pattern, line, re.MULTILINE)
                if match:
                    sections.append(match.group(1))
                    break
        
        return sections
    
    def _calculate_readability(self, content: str) -> float:
        """ê°€ë…ì„± ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)"""
        
        words = content.split()
        sentences = [s for s in content.split('.') if s.strip()]
        
        if not sentences:
            return 0.0
        
        avg_sentence_length = len(words) / len(sentences)
        
        # ë³µì¡í•œ ë‹¨ì–´ ë¹„ìœ¨
        complex_words = [w for w in words if len(w) > 6]
        complex_ratio = len(complex_words) / len(words) if words else 0
        
        # ê°„ë‹¨í•œ ê°€ë…ì„± ì ìˆ˜ (0-100)
        score = 100 - (avg_sentence_length * 1.5) - (complex_ratio * 100)
        return max(0, min(100, score))
    
    def analyze_jewelry_terminology(self, content: str, category: JewelryCategory) -> Dict[str, Any]:
        """ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ë¶„ì„"""
        
        content_lower = content.lower()
        
        if category == JewelryCategory.DIAMOND_4C:
            standards = self.knowledge_base.diamond_standards
            required_terms = standards["required_terms"]
            
            # 4C ìš©ì–´ í™•ì¸
            four_c_coverage = {
                "carat": any(term in content_lower for term in ["ìºëŸ¿", "carat", "ì¤‘ëŸ‰"]),
                "color": any(term in content_lower for term in ["ì»¬ëŸ¬", "color", "ìƒ‰ìƒ"]),
                "clarity": any(term in content_lower for term in ["í´ë˜ë¦¬í‹°", "clarity", "íˆ¬ëª…ë„"]),
                "cut": any(term in content_lower for term in ["ì»·", "cut", "ì—°ë§ˆ"])
            }
            
            # GIA ë“±ê¸‰ í™•ì¸
            gia_terms_found = []
            for grade in standards["gia_color_scale"] + standards["gia_clarity_scale"] + standards["gia_cut_grades"]:
                if grade.lower() in content_lower:
                    gia_terms_found.append(grade)
            
            return {
                "category_relevance": sum(four_c_coverage.values()) / 4,
                "four_c_coverage": four_c_coverage,
                "gia_terms_found": gia_terms_found,
                "required_terms_count": sum(1 for term in required_terms if term in content_lower),
                "professional_depth": len(gia_terms_found) / 10  # ì •ê·œí™”
            }
        
        elif category == JewelryCategory.COLORED_GEMSTONE:
            standards = self.knowledge_base.gemstone_standards
            
            # ì£¼ìš” ë³´ì„ í™•ì¸
            gemstones_mentioned = []
            for gem in standards["major_gemstones"]:
                if gem.lower() in content_lower:
                    gemstones_mentioned.append(gem)
            
            # ì›ì‚°ì§€ í™•ì¸
            origins_mentioned = []
            for gem_type, origins in standards["origins"].items():
                for origin in origins:
                    if origin.lower() in content_lower:
                        origins_mentioned.append(origin)
            
            # ì²˜ë¦¬ í™•ì¸
            treatments_mentioned = []
            for treatment_type, treatments in standards["treatments"].items():
                for treatment in treatments:
                    if treatment.lower() in content_lower:
                        treatments_mentioned.append(treatment)
            
            return {
                "category_relevance": min(1.0, len(gemstones_mentioned) / 2),
                "gemstones_mentioned": gemstones_mentioned,
                "origins_mentioned": origins_mentioned,
                "treatments_mentioned": treatments_mentioned,
                "certification_mentioned": any(lab in content for lab in standards["certification_labs"]),
                "professional_depth": (len(origins_mentioned) + len(treatments_mentioned)) / 10
            }
        
        elif category == JewelryCategory.BUSINESS_INSIGHT:
            standards = self.knowledge_base.business_terms
            
            term_counts = {}
            for term_type, terms in standards.items():
                count = sum(1 for term in terms if term in content_lower)
                term_counts[term_type] = count
            
            total_business_terms = sum(term_counts.values())
            
            return {
                "category_relevance": min(1.0, total_business_terms / 20),
                "term_distribution": term_counts,
                "strategic_depth": term_counts.get("strategy_terms", 0) / 5,
                "analytical_depth": term_counts.get("market_terms", 0) / 5,
                "actionability": term_counts.get("operational_terms", 0) / 5
            }
        
        else:
            # ê¸°ë³¸ ë¶„ì„
            return {
                "category_relevance": 0.5,
                "professional_depth": 0.5,
                "term_coverage": 0.5
            }
    
    def detect_logical_inconsistencies(self, content: str) -> List[str]:
        """ë…¼ë¦¬ì  ë¶ˆì¼ì¹˜ ê°ì§€"""
        
        inconsistencies = []
        
        # ëª¨ìˆœë˜ëŠ” í‘œí˜„ ê²€ì‚¬
        contradiction_patterns = [
            (r'ìµœê³ \s*ë“±ê¸‰', r'ë‚®ì€\s*í’ˆì§ˆ'),
            (r'ë¬´ê°€ì—´', r'ê°€ì—´\s*ì²˜ë¦¬'),
            (r'FL\s*ë“±ê¸‰', r'ë‚´í¬ë¬¼'),
            (r'íˆ¬ì\s*ê°€ì¹˜\s*ë†’ìŒ', r'í’ˆì§ˆ\s*ë‚®ìŒ'),
            (r'í¬ê·€', r'í”í•¨|ì¼ë°˜ì ')
        ]
        
        for positive_pattern, negative_pattern in contradiction_patterns:
            if re.search(positive_pattern, content, re.IGNORECASE) and re.search(negative_pattern, content, re.IGNORECASE):
                inconsistencies.append(f"ëª¨ìˆœëœ í‘œí˜„ ë°œê²¬: '{positive_pattern}' vs '{negative_pattern}'")
        
        # ìˆ«ì ë¶ˆì¼ì¹˜ ê²€ì‚¬
        price_numbers = re.findall(r'\$[\d,]+', content)
        carat_numbers = re.findall(r'([\d.]+)\s*(?:ìºëŸ¿|carat)', content, re.IGNORECASE)
        
        if len(price_numbers) > 1:
            # ê°€ê²© ë²”ìœ„ ì¼ê´€ì„± ê²€ì‚¬
            prices = [int(p.replace('$', '').replace(',', '')) for p in price_numbers]
            if max(prices) < min(prices):
                inconsistencies.append("ê°€ê²© ë²”ìœ„ê°€ ë…¼ë¦¬ì ì´ì§€ ì•ŠìŒ")
        
        return inconsistencies

class QualityRuleEngine:
    """í’ˆì§ˆ ê·œì¹™ ì—”ì§„"""
    
    def __init__(self):
        self.rules = self._load_validation_rules()
        self.analyzer = ContentAnalyzer()
    
    def _load_validation_rules(self) -> List[ValidationRule]:
        """ê²€ì¦ ê·œì¹™ ë¡œë“œ"""
        
        rules = []
        
        # ì •í™•ì„± ê·œì¹™
        rules.extend([
            ValidationRule(
                rule_id="ACC_001",
                category=JewelryCategory.DIAMOND_4C,
                dimension=QualityDimension.ACCURACY,
                validation_function="validate_diamond_grades",
                weight=0.25,
                threshold=0.9,
                error_message="ë‹¤ì´ì•„ëª¬ë“œ ë“±ê¸‰ì´ GIA í‘œì¤€ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ",
                improvement_suggestion="GIA ê³µì‹ ë“±ê¸‰ ì²´ê³„ë¥¼ í™•ì¸í•˜ì—¬ ì •í™•í•œ ë“±ê¸‰ì„ ì‚¬ìš©í•˜ì„¸ìš”"
            ),
            ValidationRule(
                rule_id="ACC_002",
                category=JewelryCategory.COLORED_GEMSTONE,
                dimension=QualityDimension.ACCURACY,
                validation_function="validate_gemstone_origins",
                weight=0.3,
                threshold=0.85,
                error_message="ë³´ì„ ì›ì‚°ì§€ ì •ë³´ê°€ ë¶€ì •í™•í•˜ê±°ë‚˜ ëˆ„ë½ë¨",
                improvement_suggestion="SSEF/GÃ¼belin ê¸°ì¤€ì˜ ì •í™•í•œ ì›ì‚°ì§€ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”"
            ),
            ValidationRule(
                rule_id="ACC_003",
                category=JewelryCategory.BUSINESS_INSIGHT,
                dimension=QualityDimension.ACCURACY,
                validation_function="validate_market_data",
                weight=0.2,
                threshold=0.8,
                error_message="ì‹œì¥ ë°ì´í„°ê°€ í˜„ì‹¤ì ì´ì§€ ì•Šê±°ë‚˜ ê·¼ê±°ê°€ ë¶€ì¡±í•¨",
                improvement_suggestion="ìµœì‹  ì‹œì¥ ë°ì´í„°ì™€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ë¥¼ ì¸ìš©í•˜ì„¸ìš”"
            )
        ])
        
        # ì™„ì„±ë„ ê·œì¹™
        rules.extend([
            ValidationRule(
                rule_id="COMP_001",
                category=JewelryCategory.DIAMOND_4C,
                dimension=QualityDimension.COMPLETENESS,
                validation_function="validate_4c_completeness",
                weight=0.2,
                threshold=0.95,
                error_message="4C ë¶„ì„ì´ ë¶ˆì™„ì „í•¨ (ì¼ë¶€ ìš”ì†Œ ëˆ„ë½)",
                improvement_suggestion="Carat, Color, Clarity, Cut ëª¨ë“  ìš”ì†Œë¥¼ í¬í•¨í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”"
            ),
            ValidationRule(
                rule_id="COMP_002",
                category=JewelryCategory.BUSINESS_INSIGHT,
                dimension=QualityDimension.COMPLETENESS,
                validation_function="validate_business_completeness",
                weight=0.25,
                threshold=0.9,
                error_message="ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ì´ ë¶ˆì™„ì „í•¨ (í•µì‹¬ ìš”ì†Œ ëˆ„ë½)",
                improvement_suggestion="ì‹œì¥ë¶„ì„, ê²½ìŸë¶„ì„, ì¬ë¬´ë¶„ì„, ì‹¤í–‰ê³„íšì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”"
            )
        ])
        
        # ì „ë¬¸ì„± ê·œì¹™
        rules.extend([
            ValidationRule(
                rule_id="PROF_001",
                category=JewelryCategory.DIAMOND_4C,
                dimension=QualityDimension.PROFESSIONALISM,
                validation_function="validate_professional_terminology",
                weight=0.2,
                threshold=0.9,
                error_message="ì „ë¬¸ ìš©ì–´ ì‚¬ìš©ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ë¶€ì •í™•í•¨",
                improvement_suggestion="GIA, AGS ë“± êµ­ì œ ê¸°ì¤€ì˜ ì •í™•í•œ ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
            ),
            ValidationRule(
                rule_id="PROF_002",
                category=JewelryCategory.COLORED_GEMSTONE,
                dimension=QualityDimension.PROFESSIONALISM,
                validation_function="validate_gemstone_expertise",
                weight=0.25,
                threshold=0.85,
                error_message="ìœ ìƒ‰ë³´ì„ ì „ë¬¸ ì§€ì‹ì´ ë¶€ì¡±í•¨",
                improvement_suggestion="SSEF, GÃ¼belin ë“± ì „ë¬¸ ê°ì • ê¸°ê´€ì˜ ê¸°ì¤€ì„ ì ìš©í•˜ì„¸ìš”"
            )
        ])
        
        return rules
    
    def validate_content(self, content: str, category: JewelryCategory, 
                        validation_level: ValidationLevel = ValidationLevel.STANDARD) -> List[QualityIssue]:
        """ì½˜í…ì¸  ê²€ì¦"""
        
        issues = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê·œì¹™ í•„í„°ë§
        applicable_rules = [r for r in self.rules if r.category == category]
        
        # ê²€ì¦ ìˆ˜ì¤€ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •
        threshold_multiplier = {
            ValidationLevel.BASIC: 0.8,
            ValidationLevel.STANDARD: 1.0,
            ValidationLevel.EXPERT: 1.1,
            ValidationLevel.CERTIFICATION: 1.2
        }[validation_level]
        
        for rule in applicable_rules:
            try:
                score = self._execute_validation_function(rule.validation_function, content, category)
                adjusted_threshold = rule.threshold * threshold_multiplier
                
                if score < adjusted_threshold:
                    severity = self._determine_severity(score, adjusted_threshold, rule.weight)
                    
                    issue = QualityIssue(
                        issue_id=f"{rule.rule_id}_{int(time.time())}",
                        dimension=rule.dimension,
                        severity=severity,
                        description=rule.error_message,
                        location=self._find_issue_location(content, rule),
                        suggestion=rule.improvement_suggestion,
                        auto_fixable=self._is_auto_fixable(rule)
                    )
                    issues.append(issue)
            
            except Exception as e:
                logging.error(f"ê²€ì¦ ê·œì¹™ {rule.rule_id} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        
        return issues
    
    def _execute_validation_function(self, function_name: str, content: str, category: JewelryCategory) -> float:
        """ê²€ì¦ í•¨ìˆ˜ ì‹¤í–‰"""
        
        if function_name == "validate_diamond_grades":
            return self._validate_diamond_grades(content)
        elif function_name == "validate_gemstone_origins":
            return self._validate_gemstone_origins(content)
        elif function_name == "validate_market_data":
            return self._validate_market_data(content)
        elif function_name == "validate_4c_completeness":
            return self._validate_4c_completeness(content)
        elif function_name == "validate_business_completeness":
            return self._validate_business_completeness(content)
        elif function_name == "validate_professional_terminology":
            return self._validate_professional_terminology(content, category)
        elif function_name == "validate_gemstone_expertise":
            return self._validate_gemstone_expertise(content)
        else:
            return 0.5  # ê¸°ë³¸ê°’
    
    def _validate_diamond_grades(self, content: str) -> float:
        """ë‹¤ì´ì•„ëª¬ë“œ ë“±ê¸‰ ê²€ì¦"""
        
        standards = self.analyzer.knowledge_base.diamond_standards
        content_upper = content.upper()
        
        # GIA ë“±ê¸‰ ì²´ê³„ í™•ì¸
        valid_grades = 0
        total_grades = 0
        
        # ì»¬ëŸ¬ ë“±ê¸‰ ê²€ì¦
        color_mentions = re.findall(r'\b([D-Z])\s*(?:ì»¬ëŸ¬|ìƒ‰ìƒ|color)', content_upper)
        for color in color_mentions:
            total_grades += 1
            if color in standards["gia_color_scale"]:
                valid_grades += 1
        
        # í´ë˜ë¦¬í‹° ë“±ê¸‰ ê²€ì¦
        clarity_pattern = r'\b(FL|IF|VVS[12]|VS[12]|SI[12]|I[123])\b'
        clarity_mentions = re.findall(clarity_pattern, content_upper)
        for clarity in clarity_mentions:
            total_grades += 1
            if clarity in standards["gia_clarity_scale"]:
                valid_grades += 1
        
        # ì»· ë“±ê¸‰ ê²€ì¦
        cut_pattern = r'\b(EXCELLENT|VERY\s*GOOD|GOOD|FAIR|POOR)\b'
        cut_mentions = re.findall(cut_pattern, content_upper)
        for cut in cut_mentions:
            total_grades += 1
            if cut.replace(' ', ' ') in [g.upper() for g in standards["gia_cut_grades"]]:
                valid_grades += 1
        
        if total_grades == 0:
            return 0.5  # ë“±ê¸‰ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
        
        return valid_grades / total_grades
    
    def _validate_gemstone_origins(self, content: str) -> float:
        """ë³´ì„ ì›ì‚°ì§€ ê²€ì¦"""
        
        standards = self.analyzer.knowledge_base.gemstone_standards
        content_lower = content.lower()
        
        score = 0.0
        mentions = 0
        
        # ê° ë³´ì„ë³„ ì›ì‚°ì§€ í™•ì¸
        for gemstone, valid_origins in standards["origins"].items():
            if gemstone in content_lower:
                mentions += 1
                # í•´ë‹¹ ë³´ì„ì˜ ìœ íš¨í•œ ì›ì‚°ì§€ê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                origin_found = any(origin.lower() in content_lower for origin in valid_origins)
                if origin_found:
                    score += 1
        
        if mentions == 0:
            return 0.8  # ì›ì‚°ì§€ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì ìˆ˜
        
        return score / mentions
    
    def _validate_market_data(self, content: str) -> float:
        """ì‹œì¥ ë°ì´í„° ê²€ì¦"""
        
        score_factors = []
        
        # ê°€ê²© ì •ë³´ì˜ í˜„ì‹¤ì„± ê²€ì‚¬
        price_pattern = r'\$[\d,]+'
        prices = re.findall(price_pattern, content)
        if prices:
            # ê°€ê²© ë²”ìœ„ê°€ í˜„ì‹¤ì ì¸ì§€ í™•ì¸
            price_values = [int(p.replace('$', '').replace(',', '')) for p in prices]
            if all(100 <= p <= 10000000 for p in price_values):  # í˜„ì‹¤ì ì¸ ë²”ìœ„
                score_factors.append(1.0)
            else:
                score_factors.append(0.3)
        
        # ì„±ì¥ë¥  ì •ë³´ì˜ í˜„ì‹¤ì„±
        growth_pattern = r'(\d+(?:\.\d+)?)\s*%'
        growth_rates = re.findall(growth_pattern, content)
        if growth_rates:
            rates = [float(r) for r in growth_rates]
            if all(-50 <= r <= 100 for r in rates):  # í˜„ì‹¤ì ì¸ ì„±ì¥ë¥ 
                score_factors.append(1.0)
            else:
                score_factors.append(0.4)
        
        # ê·¼ê±° ì œì‹œ ì—¬ë¶€
        evidence_keywords = ["ì¶œì²˜", "ë°ì´í„°", "ì¡°ì‚¬", "ì—°êµ¬", "ë³´ê³ ì„œ", "í†µê³„"]
        if any(keyword in content for keyword in evidence_keywords):
            score_factors.append(1.0)
        else:
            score_factors.append(0.6)
        
        return statistics.mean(score_factors) if score_factors else 0.5
    
    def _validate_4c_completeness(self, content: str) -> float:
        """4C ì™„ì„±ë„ ê²€ì¦"""
        
        content_lower = content.lower()
        
        # 4C ìš”ì†Œë³„ ì²´í¬
        four_c_coverage = {
            "carat": any(term in content_lower for term in ["ìºëŸ¿", "carat", "ì¤‘ëŸ‰", "ë¬´ê²Œ"]),
            "color": any(term in content_lower for term in ["ì»¬ëŸ¬", "color", "ìƒ‰ìƒ", "ìƒ‰ê¹”"]),
            "clarity": any(term in content_lower for term in ["í´ë˜ë¦¬í‹°", "clarity", "íˆ¬ëª…ë„", "ë‚´í¬ë¬¼"]),
            "cut": any(term in content_lower for term in ["ì»·", "cut", "ì—°ë§ˆ", "í´ë¦¬ì‹œ", "ì‹œë©”íŠ¸ë¦¬"])
        }
        
        # ê° Cì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ì²´í¬
        detailed_analysis = 0
        
        if four_c_coverage["carat"]:
            if re.search(r'\d+\.?\d*\s*(?:ìºëŸ¿|carat)', content_lower):
                detailed_analysis += 0.25
        
        if four_c_coverage["color"]:
            if re.search(r'\b[D-Z]\s*(?:ì»¬ëŸ¬|ìƒ‰ìƒ)', content, re.IGNORECASE):
                detailed_analysis += 0.25
        
        if four_c_coverage["clarity"]:
            if re.search(r'\b(?:FL|IF|VVS|VS|SI|I)\d?\b', content, re.IGNORECASE):
                detailed_analysis += 0.25
        
        if four_c_coverage["cut"]:
            if re.search(r'(?:excellent|very good|good|fair|poor)', content, re.IGNORECASE):
                detailed_analysis += 0.25
        
        basic_coverage = sum(four_c_coverage.values()) / 4
        return (basic_coverage * 0.6) + (detailed_analysis * 0.4)
    
    def _validate_business_completeness(self, content: str) -> float:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì™„ì„±ë„ ê²€ì¦"""
        
        content_lower = content.lower()
        
        # í•„ìˆ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì†Œë“¤
        business_elements = {
            "market_analysis": any(term in content_lower for term in ["ì‹œì¥", "ë¶„ì„", "ê·œëª¨", "ì„±ì¥"]),
            "competition": any(term in content_lower for term in ["ê²½ìŸ", "ê²½ìŸì‚¬", "ê²½ìŸë¶„ì„", "ë¸Œëœë“œ"]),
            "financial": any(term in content_lower for term in ["ë§¤ì¶œ", "ìˆ˜ìµ", "ê°€ê²©", "ë¹„ìš©", "roi"]),
            "strategy": any(term in content_lower for term in ["ì „ëµ", "ê³„íš", "ëª©í‘œ", "ì‹¤í–‰"]),
            "recommendations": any(term in content_lower for term in ["ê¶Œì¥", "ì¶”ì²œ", "ì œì•ˆ", "ê²°ë¡ "])
        }
        
        # ì •ëŸ‰ì  ë°ì´í„° í¬í•¨ ì—¬ë¶€
        has_numbers = bool(re.search(r'\d+\.?\d*\s*%', content))
        has_financial_data = bool(re.search(r'\$[\d,]+', content))
        
        basic_score = sum(business_elements.values()) / len(business_elements)
        data_bonus = 0.1 if has_numbers else 0
        financial_bonus = 0.1 if has_financial_data else 0
        
        return min(1.0, basic_score + data_bonus + financial_bonus)
    
    def _validate_professional_terminology(self, content: str, category: JewelryCategory) -> float:
        """ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ê²€ì¦"""
        
        if category == JewelryCategory.DIAMOND_4C:
            professional_terms = [
                "GIA", "AGS", "ê°ì •ì„œ", "ì¸ì¦ì„œ", "ë“±ê¸‰", "í´ë¦¬ì‹œ", "ì‹œë©”íŠ¸ë¦¬",
                "í˜•ê´‘ì„±", "ê±°ë“¤", "í˜ë¦¿", "í”„ë¡œí¬ì…˜"
            ]
        elif category == JewelryCategory.COLORED_GEMSTONE:
            professional_terms = [
                "SSEF", "GÃ¼belin", "ì›ì‚°ì§€", "ê°€ì—´", "ë¬´ê°€ì—´", "ì˜¤ì¼ë§", "ì²˜ë¦¬",
                "ë‚´í¬ë¬¼", "í”¼ì£¤ë¸”ëŸ¬ë“œ", "ì½”ë¥¸í”Œë¼ì›Œë¸”ë£¨", "íŒ¨ë“œíŒŒë¼ì°¨"
            ]
        else:
            professional_terms = [
                "ë¶„ì„", "í‰ê°€", "ì „ëµ", "ì‹œì¥", "ê²½ìŸ", "ìˆ˜ìµì„±", "ROI",
                "KPI", "ë²¤ì¹˜ë§ˆí¬", "ìµœì í™”"
            ]
        
        content_lower = content.lower()
        terms_found = sum(1 for term in professional_terms if term.lower() in content_lower)
        
        return min(1.0, terms_found / len(professional_terms) * 2)
    
    def _validate_gemstone_expertise(self, content: str) -> float:
        """ìœ ìƒ‰ë³´ì„ ì „ë¬¸ì„± ê²€ì¦"""
        
        content_lower = content.lower()
        
        expertise_indicators = [
            # ì²˜ë¦¬ ê´€ë ¨ ì „ë¬¸ ì§€ì‹
            ("ì²˜ë¦¬", ["ê°€ì—´", "ë¬´ê°€ì—´", "ì˜¤ì¼ë§", "ìˆ˜ì§€", "í™•ì‚°", "ì¡°ì‚¬"]),
            # ì›ì‚°ì§€ ê´€ë ¨ ì§€ì‹  
            ("ì›ì‚°ì§€", ["ë¯¸ì–€ë§ˆ", "ì¹´ì‹œë¯¸ë¥´", "ì½œë¡¬ë¹„ì•„", "ì‹¤ë¡ ", "ë§ˆë‹¤ê°€ìŠ¤ì¹´ë¥´"]),
            # í’ˆì§ˆ ìš©ì–´
            ("í’ˆì§ˆ", ["í”¼ì£¤ë¸”ëŸ¬ë“œ", "ì½”ë¥¸í”Œë¼ì›Œ", "íŒ¨ë“œíŒŒë¼ì°¨", "ë¡œì–„ë¸”ë£¨"]),
            # ê°ì • ê¸°ê´€
            ("ê°ì •", ["SSEF", "GÃ¼belin", "GIA", "AGL", "Lotus"])
        ]
        
        scores = []
        for category, terms in expertise_indicators:
            found_terms = sum(1 for term in terms if term in content_lower)
            category_score = min(1.0, found_terms / len(terms) * 2)
            scores.append(category_score)
        
        return statistics.mean(scores) if scores else 0.5
    
    def _determine_severity(self, score: float, threshold: float, weight: float) -> str:
        """ì‹¬ê°ë„ ê²°ì •"""
        
        gap = threshold - score
        weighted_gap = gap * weight
        
        if weighted_gap > 0.3:
            return "critical"
        elif weighted_gap > 0.15:
            return "major"
        else:
            return "minor"
    
    def _find_issue_location(self, content: str, rule: ValidationRule) -> str:
        """ì´ìŠˆ ìœ„ì¹˜ ì°¾ê¸°"""
        
        # ê°„ë‹¨í•œ ìœ„ì¹˜ ì¶”ì •
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if any(keyword in line.lower() for keyword in ["grade", "ë“±ê¸‰", "í’ˆì§ˆ", "market", "ì‹œì¥"]):
                return f"Line {i+1}"
        
        return "ì „ì²´ ë‚´ìš©"
    
    def _is_auto_fixable(self, rule: ValidationRule) -> bool:
        """ìë™ ìˆ˜ì • ê°€ëŠ¥ ì—¬ë¶€"""
        
        # ì¼ë¶€ ê·œì¹™ì€ ìë™ ìˆ˜ì • ê°€ëŠ¥
        auto_fixable_rules = ["COMP_001", "PROF_001"]
        return rule.rule_id in auto_fixable_rules

class AIQualityValidatorV23:
    """AI í’ˆì§ˆ ê²€ì¦ê¸° v2.3 - 99.2% ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•œ í•µì‹¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config_path: str = "config/quality_validator_v23.json"):
        self.config_path = config_path
        self.rule_engine = QualityRuleEngine()
        self.content_analyzer = ContentAnalyzer()
        
        # ì„±ëŠ¥ ì¶”ì 
        self.validation_history = deque(maxlen=1000)
        self.performance_metrics = defaultdict(list)
        
        # í•˜ì´ë¸Œë¦¬ë“œ LLM ë§¤ë‹ˆì € ì—°ë™
        if SOLOMOND_V23_AVAILABLE:
            try:
                self.llm_manager = HybridLLMManagerV23()
                self.prompt_optimizer = JewelryPromptOptimizerV23()
                self.llm_integration = True
            except Exception as e:
                logging.warning(f"LLM ë§¤ë‹ˆì € ì—°ë™ ì‹¤íŒ¨: {e}")
                self.llm_integration = False
        else:
            self.llm_integration = False
        
        # í•™ìŠµ ê¸°ë°˜ ê°œì„ 
        self.quality_patterns = {}
        self.improvement_suggestions = {}
        
        logging.info("ğŸ” AI í’ˆì§ˆ ê²€ì¦ê¸° v2.3 ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def validate_ai_response(self, 
                                 content: str,
                                 category: JewelryCategory,
                                 expected_accuracy: float = 0.992,
                                 validation_level: ValidationLevel = ValidationLevel.EXPERT) -> ValidationResult:
        """AI ì‘ë‹µ í’ˆì§ˆ ê²€ì¦ - ë©”ì¸ ì§„ì…ì """
        
        start_time = time.time()
        content_id = hashlib.md5(content.encode()).hexdigest()[:12]
        
        # 1. ê¸°ë³¸ ì½˜í…ì¸  ë¶„ì„
        structure_analysis = self.content_analyzer.analyze_content_structure(content)
        terminology_analysis = self.content_analyzer.analyze_jewelry_terminology(content, category)
        logical_issues = self.content_analyzer.detect_logical_inconsistencies(content)
        
        # 2. ê·œì¹™ ê¸°ë°˜ ê²€ì¦
        quality_issues = self.rule_engine.validate_content(content, category, validation_level)
        
        # 3. ì°¨ì›ë³„ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = self._calculate_quality_metrics(
            content, category, structure_analysis, terminology_analysis, quality_issues
        )
        
        # 4. ì „ì²´ í’ˆì§ˆ ìƒíƒœ ê²°ì •
        overall_quality = self._determine_overall_quality(metrics.overall_score, expected_accuracy)
        
        # 5. ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
        improvement_recommendations = self._generate_improvement_recommendations(
            quality_issues, metrics, category
        )
        
        # 6. ì¬ë¶„ì„ í•„ìš” ì—¬ë¶€ íŒë‹¨
        reanalysis_required = self._should_reanalyze(metrics.overall_score, expected_accuracy, quality_issues)
        
        # 7. ê²€ì¦ ê²°ê³¼ ìƒì„±
        validation_result = ValidationResult(
            content_id=content_id,
            overall_quality=overall_quality,
            metrics=metrics,
            issues=quality_issues,
            passed_rules=[],  # TODO: í†µê³¼í•œ ê·œì¹™ ì¶”ì 
            failed_rules=[issue.issue_id for issue in quality_issues],
            improvement_recommendations=improvement_recommendations,
            reanalysis_required=reanalysis_required,
            validation_time=time.time() - start_time
        )
        
        # 8. ì„±ëŠ¥ ì¶”ì  ì—…ë°ì´íŠ¸
        self._update_performance_tracking(validation_result, category)
        
        # 9. í•™ìŠµ ê¸°ë°˜ ê°œì„ 
        await self._update_quality_patterns(content, category, validation_result)
        
        logging.info(f"ğŸ” í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ - ID: {content_id}, ì ìˆ˜: {metrics.overall_score:.3f}, ìƒíƒœ: {overall_quality.value}")
        
        return validation_result
    
    def _calculate_quality_metrics(self, 
                                 content: str,
                                 category: JewelryCategory,
                                 structure_analysis: Dict[str, Any],
                                 terminology_analysis: Dict[str, Any],
                                 quality_issues: List[QualityIssue]) -> QualityMetrics:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        
        # ê¸°ë³¸ ì ìˆ˜ë“¤
        accuracy_score = self._calculate_accuracy_score(content, category, terminology_analysis)
        completeness_score = self._calculate_completeness_score(content, category, structure_analysis)
        relevance_score = terminology_analysis.get("category_relevance", 0.5)
        professionalism_score = terminology_analysis.get("professional_depth", 0.5)
        consistency_score = self._calculate_consistency_score(content, quality_issues)
        clarity_score = structure_analysis.get("readability_score", 50) / 100
        actionability_score = self._calculate_actionability_score(content, category)
        
        # ì´ìŠˆ ê¸°ë°˜ ì ìˆ˜ ì¡°ì •
        issue_penalty = self._calculate_issue_penalty(quality_issues)
        
        # ì¡°ì •ëœ ì ìˆ˜ë“¤
        adjusted_scores = {
            "accuracy": max(0, accuracy_score - issue_penalty * 0.3),
            "completeness": max(0, completeness_score - issue_penalty * 0.2),
            "relevance": max(0, relevance_score - issue_penalty * 0.1),
            "professionalism": max(0, professionalism_score - issue_penalty * 0.25),
            "consistency": max(0, consistency_score - issue_penalty * 0.4),
            "clarity": max(0, clarity_score - issue_penalty * 0.15),
            "actionability": max(0, actionability_score - issue_penalty * 0.2)
        }
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ì ìˆ˜ ê³„ì‚°
        weights = {
            "accuracy": 0.25,
            "completeness": 0.20,
            "relevance": 0.15,
            "professionalism": 0.20,
            "consistency": 0.10,
            "clarity": 0.05,
            "actionability": 0.05
        }
        
        overall_score = sum(score * weights[dim] for dim, score in adjusted_scores.items())
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_level = self._calculate_confidence_level(adjusted_scores, quality_issues)
        
        return QualityMetrics(
            accuracy_score=adjusted_scores["accuracy"],
            completeness_score=adjusted_scores["completeness"],
            relevance_score=adjusted_scores["relevance"],
            professionalism_score=adjusted_scores["professionalism"],
            consistency_score=adjusted_scores["consistency"],
            clarity_score=adjusted_scores["clarity"],
            actionability_score=adjusted_scores["actionability"],
            overall_score=overall_score,
            confidence_level=confidence_level,
            validation_timestamp=datetime.now()
        )
    
    def _calculate_accuracy_score(self, content: str, category: JewelryCategory, 
                                terminology_analysis: Dict[str, Any]) -> float:
        """ì •í™•ì„± ì ìˆ˜ ê³„ì‚°"""
        
        base_score = 0.7  # ê¸°ë³¸ ì ìˆ˜
        
        # ì „ë¬¸ ìš©ì–´ ì •í™•ì„±
        terminology_bonus = terminology_analysis.get("professional_depth", 0) * 0.2
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ìˆ˜ ê²€ì¦
        if category == JewelryCategory.DIAMOND_4C:
            # GIA ë“±ê¸‰ ì²´ê³„ ì •í™•ì„±
            gia_accuracy = self.rule_engine._validate_diamond_grades(content)
            base_score += gia_accuracy * 0.2
        
        elif category == JewelryCategory.COLORED_GEMSTONE:
            # ì›ì‚°ì§€ ì •í™•ì„±
            origin_accuracy = self.rule_engine._validate_gemstone_origins(content)
            base_score += origin_accuracy * 0.2
        
        elif category == JewelryCategory.BUSINESS_INSIGHT:
            # ì‹œì¥ ë°ì´í„° í˜„ì‹¤ì„±
            market_accuracy = self.rule_engine._validate_market_data(content)
            base_score += market_accuracy * 0.2
        
        return min(1.0, base_score + terminology_bonus)
    
    def _calculate_completeness_score(self, content: str, category: JewelryCategory,
                                    structure_analysis: Dict[str, Any]) -> float:
        """ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°"""
        
        # êµ¬ì¡°ì  ì™„ì„±ë„
        structure_score = 0.5
        
        if structure_analysis["sections"]:
            structure_score += 0.2
        if structure_analysis["has_structure"]["bullets"] or structure_analysis["has_structure"]["numbers"]:
            structure_score += 0.1
        if structure_analysis["word_count"] > 200:
            structure_score += 0.2
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì™„ì„±ë„
        if category == JewelryCategory.DIAMOND_4C:
            completeness = self.rule_engine._validate_4c_completeness(content)
        elif category == JewelryCategory.BUSINESS_INSIGHT:
            completeness = self.rule_engine._validate_business_completeness(content)
        else:
            completeness = 0.8  # ê¸°ë³¸ê°’
        
        return (structure_score * 0.3) + (completeness * 0.7)
    
    def _calculate_consistency_score(self, content: str, quality_issues: List[QualityIssue]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        
        # ë…¼ë¦¬ì  ë¶ˆì¼ì¹˜ í™•ì¸
        logical_issues = self.content_analyzer.detect_logical_inconsistencies(content)
        
        base_score = 1.0
        
        # ë…¼ë¦¬ì  ë¶ˆì¼ì¹˜ í˜ë„í‹°
        if logical_issues:
            base_score -= len(logical_issues) * 0.2
        
        # í’ˆì§ˆ ì´ìŠˆ ì¤‘ ì¼ê´€ì„± ê´€ë ¨ í˜ë„í‹°
        consistency_issues = [issue for issue in quality_issues if issue.dimension == QualityDimension.CONSISTENCY]
        if consistency_issues:
            base_score -= len(consistency_issues) * 0.15
        
        return max(0, base_score)
    
    def _calculate_actionability_score(self, content: str, category: JewelryCategory) -> float:
        """ì‹¤í–‰ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°"""
        
        content_lower = content.lower()
        
        # ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ í‚¤ì›Œë“œ
        actionable_keywords = [
            "ê¶Œì¥", "ì¶”ì²œ", "ì œì•ˆ", "ë°©ë²•", "ì „ëµ", "ê³„íš", "ë‹¨ê³„", "ì‹¤í–‰",
            "êµ¬ì²´ì ", "ì„¸ë¶€", "ë°©ì•ˆ", "í•´ê²°", "ê°œì„ ", "ìµœì í™”"
        ]
        
        actionable_count = sum(1 for keyword in actionable_keywords if keyword in content_lower)
        base_score = min(1.0, actionable_count / 10)
        
        # êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë°©ë²• ì œì‹œ
        has_specific_numbers = bool(re.search(r'\d+\.?\d*\s*%', content))
        has_step_by_step = bool(re.search(r'\d+\.\s', content))
        
        if has_specific_numbers:
            base_score += 0.2
        if has_step_by_step:
            base_score += 0.2
        
        return min(1.0, base_score)
    
    def _calculate_issue_penalty(self, quality_issues: List[QualityIssue]) -> float:
        """ì´ìŠˆ ê¸°ë°˜ í˜ë„í‹° ê³„ì‚°"""
        
        if not quality_issues:
            return 0.0
        
        penalty = 0.0
        
        for issue in quality_issues:
            if issue.severity == "critical":
                penalty += 0.3
            elif issue.severity == "major":
                penalty += 0.15
            elif issue.severity == "minor":
                penalty += 0.05
        
        return min(1.0, penalty)
    
    def _calculate_confidence_level(self, scores: Dict[str, float], quality_issues: List[QualityIssue]) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        
        # ì ìˆ˜ë“¤ì˜ ë¶„ì‚° ê³„ì‚°
        score_values = list(scores.values())
        score_variance = statistics.variance(score_values) if len(score_values) > 1 else 0
        
        # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        variance_factor = max(0, 1 - score_variance * 4)
        
        # ì´ìŠˆ ê°œìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •
        issue_factor = max(0, 1 - len(quality_issues) * 0.1)
        
        # ìµœì†Œ ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì‹ ë¢°ë„ í•˜ë½
        min_score = min(score_values)
        min_score_factor = min_score if min_score > 0.5 else min_score * 0.5
        
        confidence = (variance_factor * 0.4) + (issue_factor * 0.3) + (min_score_factor * 0.3)
        
        return max(0.1, min(1.0, confidence))
    
    def _determine_overall_quality(self, overall_score: float, expected_accuracy: float) -> QualityStatus:
        """ì „ì²´ í’ˆì§ˆ ìƒíƒœ ê²°ì •"""
        
        if overall_score >= expected_accuracy:
            return QualityStatus.EXCELLENT
        elif overall_score >= expected_accuracy * 0.97:
            return QualityStatus.GOOD
        elif overall_score >= expected_accuracy * 0.93:
            return QualityStatus.ACCEPTABLE
        elif overall_score >= expected_accuracy * 0.88:
            return QualityStatus.NEEDS_IMPROVEMENT
        else:
            return QualityStatus.POOR
    
    def _should_reanalyze(self, overall_score: float, expected_accuracy: float, 
                         quality_issues: List[QualityIssue]) -> bool:
        """ì¬ë¶„ì„ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        
        # ëª©í‘œ ì •í™•ë„ì— í¬ê²Œ ë¯¸ë‹¬í•˜ëŠ” ê²½ìš°
        if overall_score < expected_accuracy * 0.9:
            return True
        
        # ì‹¬ê°í•œ ì´ìŠˆê°€ ìˆëŠ” ê²½ìš°
        critical_issues = [issue for issue in quality_issues if issue.severity == "critical"]
        if critical_issues:
            return True
        
        # ì£¼ìš” ì´ìŠˆê°€ ë§ì€ ê²½ìš°
        major_issues = [issue for issue in quality_issues if issue.severity == "major"]
        if len(major_issues) >= 3:
            return True
        
        return False
    
    def _generate_improvement_recommendations(self, 
                                            quality_issues: List[QualityIssue],
                                            metrics: QualityMetrics,
                                            category: JewelryCategory) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # ì´ìŠˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        for issue in quality_issues:
            if issue.severity in ["critical", "major"]:
                recommendations.append(issue.suggestion)
        
        # ë©”íŠ¸ë¦­ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if metrics.accuracy_score < 0.9:
            recommendations.append("ì „ë¬¸ ìš©ì–´ì™€ ì—…ê³„ í‘œì¤€ì„ ë” ì •í™•íˆ ì ìš©í•˜ì„¸ìš”")
        
        if metrics.completeness_score < 0.85:
            recommendations.append("ë¶„ì„ì˜ ì™„ì„±ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ëˆ„ë½ëœ ìš”ì†Œë“¤ì„ ì¶”ê°€í•˜ì„¸ìš”")
        
        if metrics.professionalism_score < 0.8:
            recommendations.append("êµ­ì œ ê°ì • ê¸°ì¤€(GIA, SSEF ë“±)ì„ ë” ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”")
        
        if metrics.clarity_score < 0.7:
            recommendations.append("ë‚´ìš©ì„ ë” ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”")
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ê¶Œì¥ì‚¬í•­
        if category == JewelryCategory.DIAMOND_4C:
            if metrics.completeness_score < 0.9:
                recommendations.append("4C(Carat, Color, Clarity, Cut) ëª¨ë“  ìš”ì†Œì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”")
        
        elif category == JewelryCategory.COLORED_GEMSTONE:
            if metrics.professionalism_score < 0.85:
                recommendations.append("ì›ì‚°ì§€, ì²˜ë¦¬ ì—¬ë¶€, ê°ì • ê¸°ê´€ ì •ë³´ë¥¼ í¬í•¨í•œ ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”")
        
        elif category == JewelryCategory.BUSINESS_INSIGHT:
            if metrics.actionability_score < 0.7:
                recommendations.append("ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì „ëµê³¼ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íšì„ ì œì‹œí•˜ì„¸ìš”")
        
        # ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        unique_recommendations = list(dict.fromkeys(recommendations))
        
        return unique_recommendations[:5]  # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
    
    async def trigger_reanalysis(self, original_content: str, 
                               category: JewelryCategory,
                               validation_result: ValidationResult) -> Optional[str]:
        """ìë™ ì¬ë¶„ì„ íŠ¸ë¦¬ê±°"""
        
        if not self.llm_integration:
            logging.warning("LLM í†µí•©ì´ ë¹„í™œì„±í™”ë˜ì–´ ì¬ë¶„ì„ ë¶ˆê°€")
            return None
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        improved_prompt = self._generate_improved_prompt(original_content, category, validation_result)
        
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ LLMìœ¼ë¡œ ì¬ë¶„ì„
            from core.hybrid_llm_manager_v23 import AnalysisRequest
            
            reanalysis_request = AnalysisRequest(
                content_type="text",
                data={"content": original_content},
                analysis_type=category.value,
                quality_threshold=0.995,  # ë” ë†’ì€ í’ˆì§ˆ ìš”êµ¬
                max_cost=0.08,
                language="ko"
            )
            
            hybrid_result = await self.llm_manager.analyze_with_hybrid_ai(reanalysis_request)
            
            # ì¬ë¶„ì„ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
            revalidation_result = await self.validate_ai_response(
                hybrid_result.best_result.content,
                category,
                expected_accuracy=0.995
            )
            
            # ê°œì„ ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if revalidation_result.metrics.overall_score > validation_result.metrics.overall_score:
                logging.info(f"âœ… ì¬ë¶„ì„ ì„±ê³µ - í’ˆì§ˆ ê°œì„ : {validation_result.metrics.overall_score:.3f} â†’ {revalidation_result.metrics.overall_score:.3f}")
                return hybrid_result.best_result.content
            else:
                logging.warning("âš ï¸ ì¬ë¶„ì„í–ˆìœ¼ë‚˜ í’ˆì§ˆì´ ê°œì„ ë˜ì§€ ì•ŠìŒ")
                return None
                
        except Exception as e:
            logging.error(f"ì¬ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def _generate_improved_prompt(self, content: str, category: JewelryCategory,
                                validation_result: ValidationResult) -> str:
        """ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ê¸°ì¡´ ì´ìŠˆë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì§€ì¹¨
        improvement_instructions = []
        
        for issue in validation_result.issues:
            if issue.severity in ["critical", "major"]:
                improvement_instructions.append(f"â€¢ {issue.suggestion}")
        
        for recommendation in validation_result.improvement_recommendations:
            improvement_instructions.append(f"â€¢ {recommendation}")
        
        improved_instruction = f"""
ì´ì „ ë¶„ì„ì—ì„œ ë°œê²¬ëœ ê°œì„ ì ë“¤ì„ ë°˜ì˜í•˜ì—¬ ë‹¤ì‹œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{chr(10).join(improvement_instructions)}

ëª©í‘œ ì •í™•ë„: 99.5% ì´ìƒ
í˜„ì¬ ì ìˆ˜: {validation_result.metrics.overall_score:.1%}

ë”ìš± ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        return improved_instruction
    
    def _update_performance_tracking(self, validation_result: ValidationResult, 
                                   category: JewelryCategory):
        """ì„±ëŠ¥ ì¶”ì  ì—…ë°ì´íŠ¸"""
        
        # ê²€ì¦ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.validation_history.append({
            "timestamp": datetime.now(),
            "category": category.value,
            "overall_score": validation_result.metrics.overall_score,
            "quality_status": validation_result.overall_quality.value,
            "issue_count": len(validation_result.issues),
            "validation_time": validation_result.validation_time
        })
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        category_key = category.value
        self.performance_metrics[category_key].append(validation_result.metrics.overall_score)
        
        # ìµœê·¼ 100ê°œ ê¸°ë¡ë§Œ ìœ ì§€
        if len(self.performance_metrics[category_key]) > 100:
            self.performance_metrics[category_key] = self.performance_metrics[category_key][-100:]
    
    async def _update_quality_patterns(self, content: str, category: JewelryCategory,
                                     validation_result: ValidationResult):
        """í’ˆì§ˆ íŒ¨í„´ í•™ìŠµ ì—…ë°ì´íŠ¸"""
        
        # ê³ í’ˆì§ˆ íŒ¨í„´ í•™ìŠµ
        if validation_result.metrics.overall_score >= 0.95:
            pattern_key = f"{category.value}_high_quality"
            if pattern_key not in self.quality_patterns:
                self.quality_patterns[pattern_key] = []
            
            # ê³ í’ˆì§ˆ ì½˜í…ì¸ ì˜ íŠ¹ì„± ì¶”ì¶œ
            structure = self.content_analyzer.analyze_content_structure(content)
            terminology = self.content_analyzer.analyze_jewelry_terminology(content, category)
            
            pattern_features = {
                "word_count": structure["word_count"],
                "sections": len(structure["sections"]),
                "readability": structure["readability_score"],
                "professional_depth": terminology.get("professional_depth", 0),
                "category_relevance": terminology.get("category_relevance", 0)
            }
            
            self.quality_patterns[pattern_key].append(pattern_features)
        
        # ê°œì„  ì œì•ˆ íŒ¨í„´ í•™ìŠµ
        if validation_result.improvement_recommendations:
            improvement_key = f"{category.value}_improvements"
            if improvement_key not in self.improvement_suggestions:
                self.improvement_suggestions[improvement_key] = defaultdict(int)
            
            for recommendation in validation_result.improvement_recommendations:
                self.improvement_suggestions[improvement_key][recommendation] += 1
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not self.validation_history:
            return {"status": "ë°ì´í„° ì—†ìŒ"}
        
        recent_validations = list(self.validation_history)[-50:]  # ìµœê·¼ 50ê°œ
        
        # ì „ì²´ í†µê³„
        overall_scores = [v["overall_score"] for v in recent_validations]
        avg_score = statistics.mean(overall_scores)
        median_score = statistics.median(overall_scores)
        
        # í’ˆì§ˆ ìƒíƒœ ë¶„í¬
        quality_distribution = defaultdict(int)
        for validation in recent_validations:
            quality_distribution[validation["quality_status"]] += 1
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥
        category_performance = {}
        for category, scores in self.performance_metrics.items():
            if scores:
                category_performance[category] = {
                    "average_score": statistics.mean(scores),
                    "best_score": max(scores),
                    "recent_score": scores[-1] if scores else 0,
                    "total_validations": len(scores),
                    "trend": "improving" if len(scores) > 5 and scores[-5:] > scores[-10:-5] else "stable"
                }
        
        # ì‹œê°„ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ
        validation_times = [v["validation_time"] for v in recent_validations]
        avg_validation_time = statistics.mean(validation_times) if validation_times else 0
        
        return {
            "overall_performance": {
                "average_score": avg_score,
                "median_score": median_score,
                "target_achievement_rate": len([s for s in overall_scores if s >= 0.992]) / len(overall_scores) * 100,
                "total_validations": len(self.validation_history)
            },
            "quality_distribution": dict(quality_distribution),
            "category_performance": category_performance,
            "system_performance": {
                "avg_validation_time": avg_validation_time,
                "llm_integration_status": self.llm_integration,
                "quality_patterns_learned": len(self.quality_patterns)
            },
            "improvement_insights": {
                "most_common_issues": self._get_most_common_issues(recent_validations),
                "success_factors": self._identify_success_factors()
            }
        }
    
    def _get_most_common_issues(self, validations: List[Dict[str, Any]]) -> List[str]:
        """ê°€ì¥ í”í•œ ì´ìŠˆë“¤ ì¶”ì¶œ"""
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” validation ê¸°ë¡ì—ì„œ ì´ìŠˆë“¤ì„ ì¶”ì¶œí•´ì•¼ í•¨
        common_issues = [
            "ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ë¶€ì¡±",
            "ë¶„ì„ ì™„ì„±ë„ ë¯¸í¡", 
            "êµ¬ì²´ì ì¸ ê·¼ê±° ë¶€ì¡±",
            "ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ ë¶€ì¡±"
        ]
        
        return common_issues[:3]
    
    def _identify_success_factors(self) -> List[str]:
        """ì„±ê³µ ìš”ì¸ ì‹ë³„"""
        
        success_factors = [
            "êµ­ì œ ê°ì • ê¸°ì¤€ ì •í™•í•œ ì ìš©",
            "ì²´ê³„ì ì¸ êµ¬ì¡°ì™€ ëª…í™•í•œ ì„¹ì…˜ êµ¬ë¶„",
            "êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„° ì œì‹œ",
            "ì‹¤ë¬´ì§„ì„ ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­"
        ]
        
        return success_factors

# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ í•¨ìˆ˜
async def demo_ai_quality_validator_v23():
    """AI í’ˆì§ˆ ê²€ì¦ê¸° v2.3 ë°ëª¨"""
    
    print("ğŸ” ì†”ë¡œëª¬ë“œ AI í’ˆì§ˆ ê²€ì¦ê¸° v2.3 ë°ëª¨ ì‹œì‘")
    print("=" * 60)
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    validator = AIQualityValidatorV23()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ê³ í’ˆì§ˆ ë‹¤ì´ì•„ëª¬ë“œ ë¶„ì„
    print("\nğŸ’ í…ŒìŠ¤íŠ¸ 1: ê³ í’ˆì§ˆ ë‹¤ì´ì•„ëª¬ë“œ ë¶„ì„ ê²€ì¦")
    print("-" * 50)
    
    high_quality_content = """
ğŸ’ ë‹¤ì´ì•„ëª¬ë“œ 4C ì „ë¬¸ ë¶„ì„ ë³´ê³ ì„œ

ğŸ“Š ê¸°ë³¸ ì •ë³´
- í˜•íƒœ: ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸ ì»·
- ê°ì • ê¸°ê´€: GIA
- ê°ì •ì„œ ë²ˆí˜¸: 2171234567

ğŸ“ CARAT (ìºëŸ¿)
- ì¤‘ëŸ‰: 1.52ct
- ë“±ê¸‰: Large (1.0ct ì´ìƒ)
- ì‹œì¥ í¬ì†Œì„±: ì¤‘ìƒ

ğŸ¨ COLOR (ì»¬ëŸ¬)
- GIA ë“±ê¸‰: F
- ìƒì„¸ ì„¤ëª…: Near Colorless, í”„ë¦¬ë¯¸ì—„ ë“±ê¸‰
- ì‹œì¥ í‰ê°€: í”„ë¦¬ë¯¸ì—„

ğŸ” CLARITY (í´ë˜ë¦¬í‹°)
- GIA ë“±ê¸‰: VVS1
- ë‚´í¬ë¬¼ ìœ„ì¹˜: í¬ë¼ìš´ ë¶€ë¶„ì— ë¯¸ì„¸í•œ í¬ë¦¬ìŠ¤íƒˆ
- ì•„ì´í´ë¦°: Yes

âœ¨ CUT (ì»·)
- ì»· ë“±ê¸‰: Excellent
- í´ë¦¬ì‹œ: Excellent
- ì‹œë©”íŠ¸ë¦¬: Excellent
- ë¹„ìœ¨ ë¶„ì„: í…Œì´ë¸” 57%, ê¹Šì´ 61.5%

ğŸ’° ì‹œì¥ ê°€ì¹˜ í‰ê°€
- ë„ë§¤ê°€: $18,000-20,000 (â‚©23,400,000-26,000,000)
- ì†Œë§¤ê°€: $25,000-28,000 (â‚©32,500,000-36,400,000)
- íˆ¬ì ì „ë§: ì•ˆì •ì  ìƒìŠ¹

ğŸ¯ ì¢…í•© í‰ê°€
- ì¢…í•© ë“±ê¸‰: AAA
- ê°•ì : ë›°ì–´ë‚œ íˆ¬ëª…ë„ì™€ ì™„ë²½í•œ ì»· í’ˆì§ˆ
- ì¶”ì²œ ìš©ë„: í”„ë¦¬ë¯¸ì—„ ì•½í˜¼ë°˜ì§€

ğŸ“‹ ì „ë¬¸ê°€ ì˜ê²¬
GIA ê°ì •ì„œê°€ ìˆëŠ” ê³ í’ˆì§ˆ ë‹¤ì´ì•„ëª¬ë“œë¡œ, 4C ëª¨ë“  ìš”ì†Œì—ì„œ ìš°ìˆ˜í•œ ë“±ê¸‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""
    
    result1 = await validator.validate_ai_response(
        high_quality_content,
        JewelryCategory.DIAMOND_4C,
        expected_accuracy=0.992
    )
    
    print(f"âœ… ì „ì²´ í’ˆì§ˆ: {result1.overall_quality.value}")
    print(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {result1.metrics.overall_score:.3f}")
    print(f"ğŸ¯ ì •í™•ì„±: {result1.metrics.accuracy_score:.3f}")
    print(f"ğŸ“‹ ì™„ì„±ë„: {result1.metrics.completeness_score:.3f}")
    print(f"ğŸ’¡ ì „ë¬¸ì„±: {result1.metrics.professionalism_score:.3f}")
    print(f"âš ï¸ ë°œê²¬ëœ ì´ìŠˆ: {len(result1.issues)}ê°œ")
    print(f"ğŸ”„ ì¬ë¶„ì„ í•„ìš”: {'ì˜ˆ' if result1.reanalysis_required else 'ì•„ë‹ˆì˜¤'}")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë‚®ì€ í’ˆì§ˆ ë¶„ì„
    print("\n\nğŸ”´ í…ŒìŠ¤íŠ¸ 2: ë‚®ì€ í’ˆì§ˆ ë¶„ì„ ê²€ì¦")
    print("-" * 50)
    
    low_quality_content = """
ë‹¤ì´ì•„ëª¬ë“œëŠ” ì¢‹ì€ ë³´ì„ì…ë‹ˆë‹¤. ì´ ë‹¤ì´ì•„ëª¬ë“œëŠ” í¬ê¸°ê°€ ì¢€ í¬ê³  ìƒ‰ê¹”ë„ ê´œì°®ìŠµë‹ˆë‹¤. 
íˆ¬ëª…ë„ë„ ë‚˜ì˜ì§€ ì•Šê³  ì»·ë„ ì˜ ë˜ì–´ ìˆëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. 
ê°€ê²©ì€ ëŒ€ëµ ë¹„ìŒ€ ê²ƒ ê°™ê³  íˆ¬ì ê°€ì¹˜ë„ ìˆì„ ê²ƒì…ë‹ˆë‹¤.
ì¶”ì²œí•©ë‹ˆë‹¤.
"""
    
    result2 = await validator.validate_ai_response(
        low_quality_content,
        JewelryCategory.DIAMOND_4C,
        expected_accuracy=0.992
    )
    
    print(f"âŒ ì „ì²´ í’ˆì§ˆ: {result2.overall_quality.value}")
    print(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {result2.metrics.overall_score:.3f}")
    print(f"âš ï¸ ë°œê²¬ëœ ì´ìŠˆ: {len(result2.issues)}ê°œ")
    print(f"ğŸ”„ ì¬ë¶„ì„ í•„ìš”: {'ì˜ˆ' if result2.reanalysis_required else 'ì•„ë‹ˆì˜¤'}")
    
    if result2.improvement_recommendations:
        print("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(result2.improvement_recommendations[:3], 1):
            print(f"   {i}. {rec}")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ì¬ë¶„ì„ í…ŒìŠ¤íŠ¸
    if result2.reanalysis_required and validator.llm_integration:
        print("\n\nğŸ”„ í…ŒìŠ¤íŠ¸ 3: ìë™ ì¬ë¶„ì„")
        print("-" * 50)
        
        reanalyzed_content = await validator.trigger_reanalysis(
            low_quality_content,
            JewelryCategory.DIAMOND_4C,
            result2
        )
        
        if reanalyzed_content:
            print("âœ… ì¬ë¶„ì„ ì„±ê³µ")
            print(f"ğŸ“ ì¬ë¶„ì„ ë‚´ìš© (ì¼ë¶€): {reanalyzed_content[:200]}...")
        else:
            print("âš ï¸ ì¬ë¶„ì„ ì‹¤íŒ¨ ë˜ëŠ” ê°œì„ ë˜ì§€ ì•ŠìŒ")
    
    # ì„±ëŠ¥ ë¦¬í¬íŠ¸
    print("\n\nğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸")
    print("-" * 50)
    performance = validator.get_performance_report()
    
    if "overall_performance" in performance:
        overall = performance["overall_performance"]
        print(f"í‰ê·  ì ìˆ˜: {overall['average_score']:.3f}")
        print(f"ëª©í‘œ ë‹¬ì„±ë¥ : {overall['target_achievement_rate']:.1f}%")
        print(f"ì´ ê²€ì¦ ìˆ˜: {overall['total_validations']}")
    
    print("\nğŸ¯ AI í’ˆì§ˆ ê²€ì¦ê¸° v2.3 ë°ëª¨ ì™„ë£Œ!")
    print("ğŸ† 99.2% ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•œ í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(demo_ai_quality_validator_v23())
