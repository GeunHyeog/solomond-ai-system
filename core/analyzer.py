"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - STT ë¶„ì„ ì—”ì§„
OpenAI Whisper ê¸°ë°˜ ìŒì„± ì¸ì‹ ëª¨ë“ˆ (Phase 3.2 ë‹¤êµ­ì–´ í™•ì¥)
"""

import os
import time
import tempfile
from pathlib import Path
from typing import Dict, Optional, Union, List
import asyncio

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

class AudioAnalyzer:
    """ìŒì„± ë¶„ì„ ì—”ì§„ í´ë˜ìŠ¤ (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    def __init__(self, model_size: str = "base"):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_size: Whisper ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large)
        """
        self.model_size = model_size
        self.model = None
        self.supported_formats = ['.mp3', '.wav', '.m4a']
        
        # ğŸŒ Phase 3.2: ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡
        self.supported_languages = {
            "auto": {"name": "ìë™ ê°ì§€", "code": None, "flag": "ğŸŒ"},
            "ko": {"name": "í•œêµ­ì–´", "code": "ko", "flag": "ğŸ‡°ğŸ‡·"},
            "en": {"name": "English", "code": "en", "flag": "ğŸ‡ºğŸ‡¸"},
            "zh": {"name": "ä¸­æ–‡", "code": "zh", "flag": "ğŸ‡¨ğŸ‡³"},
            "ja": {"name": "æ—¥æœ¬èª", "code": "ja", "flag": "ğŸ‡¯ğŸ‡µ"},
            "es": {"name": "EspaÃ±ol", "code": "es", "flag": "ğŸ‡ªğŸ‡¸"},
            "fr": {"name": "FranÃ§ais", "code": "fr", "flag": "ğŸ‡«ğŸ‡·"},
            "de": {"name": "Deutsch", "code": "de", "flag": "ğŸ‡©ğŸ‡ª"},
            "ru": {"name": "Ğ ÑƒÑÑĞºĞ¸Ğ¹", "code": "ru", "flag": "ğŸ‡·ğŸ‡º"},
            "pt": {"name": "PortuguÃªs", "code": "pt", "flag": "ğŸ‡µğŸ‡¹"},
            "it": {"name": "Italiano", "code": "it", "flag": "ğŸ‡®ğŸ‡¹"}
        }
        
    def load_model(self) -> bool:
        """Whisper ëª¨ë¸ ë¡œë“œ"""
        if not WHISPER_AVAILABLE:
            return False
            
        try:
            print(f"ğŸ¤ Whisper ëª¨ë¸ ë¡œë”©... ({self.model_size})")
            self.model = whisper.load_model(self.model_size)
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model_size}")
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def is_supported_format(self, filename: str) -> bool:
        """ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ì¸ì§€ í™•ì¸"""
        file_ext = Path(filename).suffix.lower()
        return file_ext in self.supported_formats
    
    def get_supported_languages(self) -> Dict:
        """ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ ë°˜í™˜"""
        return self.supported_languages
    
    def detect_language(self, audio_path: str) -> Dict:
        """
        ğŸ†• ìë™ ì–¸ì–´ ê°ì§€ ê¸°ëŠ¥
        
        Args:
            audio_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ê°ì§€ëœ ì–¸ì–´ ì •ë³´
        """
        try:
            if self.model is None:
                if not self.load_model():
                    return {"success": False, "error": "ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"}
            
            # Whisperì˜ ì–¸ì–´ ê°ì§€ ê¸°ëŠ¥ ì‚¬ìš©
            audio = whisper.load_audio(audio_path)
            audio = whisper.pad_or_trim(audio)
            mel = whisper.log_mel_spectrogram(audio).to(self.model.device)
            
            # ì–¸ì–´ ê°ì§€ ì‹¤í–‰
            _, probs = self.model.detect_language(mel)
            detected_lang = max(probs, key=probs.get)
            confidence = probs[detected_lang]
            
            # ì§€ì›í•˜ëŠ” ì–¸ì–´ì¸ì§€ í™•ì¸
            lang_info = self.supported_languages.get(detected_lang, {
                "name": f"Unknown ({detected_lang})", 
                "code": detected_lang, 
                "flag": "â“"
            })
            
            print(f"ğŸŒ ì–¸ì–´ ê°ì§€: {lang_info['name']} (ì‹ ë¢°ë„: {confidence:.2f})")
            
            return {
                "success": True,
                "detected_language": detected_lang,
                "confidence": confidence,
                "language_info": lang_info,
                "all_probabilities": dict(sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5])
            }
            
        except Exception as e:
            print(f"âŒ ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "detected_language": "ko",  # ê¸°ë³¸ê°’
                "confidence": 0.0
            }
    
    async def analyze_audio_file(self, 
                                file_path: str, 
                                language: str = "auto") -> Dict:
        """
        ìŒì„± íŒŒì¼ ë¶„ì„ (ë‹¤êµ­ì–´ ì§€ì›)
        
        Args:
            file_path: ë¶„ì„í•  ìŒì„± íŒŒì¼ ê²½ë¡œ
            language: ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (auto, ko, en, zh, ja ë“±)
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        try:
            # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ
            if self.model is None:
                if not self.load_model():
                    return {
                        "success": False,
                        "error": "Whisper ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "whisper_available": WHISPER_AVAILABLE
                    }
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "error": f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}"
                }
            
            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
            file_size_bytes = os.path.getsize(file_path)
            file_size_mb = round(file_size_bytes / (1024 * 1024), 2)
            
            print(f"ğŸ” ìŒì„± ì¸ì‹ ì‹œì‘: {Path(file_path).name}")
            
            # ğŸ†• ìë™ ì–¸ì–´ ê°ì§€
            target_language = language
            if language == "auto":
                detection_result = self.detect_language(file_path)
                if detection_result["success"]:
                    target_language = detection_result["detected_language"]
                    print(f"ğŸŒ ìë™ ê°ì§€ëœ ì–¸ì–´: {target_language}")
                else:
                    target_language = "ko"  # ê¸°ë³¸ê°’
                    print("âš ï¸ ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨, í•œêµ­ì–´ë¡œ ì„¤ì •")
            
            # Whisperë¡œ ìŒì„± ì¸ì‹ ì‹¤í–‰
            whisper_options = {
                "verbose": False,
                "task": "transcribe"
            }
            
            # ìë™ ê°ì§€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì–¸ì–´ ì§€ì •
            if target_language != "auto" and target_language in self.supported_languages:
                lang_code = self.supported_languages[target_language]["code"]
                if lang_code:
                    whisper_options["language"] = lang_code
            
            result = self.model.transcribe(file_path, **whisper_options)
            
            transcribed_text = result["text"].strip()
            processing_time = round(time.time() - start_time, 2)
            detected_language = result.get("language", target_language)
            
            print(f"âœ… ì¸ì‹ ì™„ë£Œ: {processing_time}ì´ˆ")
            print(f"ğŸ“ ê²°ê³¼: {transcribed_text[:100]}...")
            
            # ğŸ†• ì–¸ì–´ ì •ë³´ ì¶”ê°€
            lang_info = self.supported_languages.get(detected_language, {
                "name": f"Unknown ({detected_language})", 
                "code": detected_language, 
                "flag": "â“"
            })
            
            return {
                "success": True,
                "transcribed_text": transcribed_text,
                "processing_time": processing_time,
                "file_size_mb": file_size_mb,
                "detected_language": detected_language,
                "language_info": lang_info,
                "requested_language": language,
                "confidence": result.get("confidence", 0.0),
                "segments": result.get("segments", [])
            }
            
        except Exception as e:
            processing_time = round(time.time() - start_time, 2)
            error_msg = str(e)
            
            print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {error_msg}")
            
            return {
                "success": False,
                "error": error_msg,
                "processing_time": processing_time,
                "requested_language": language
            }
    
    async def analyze_uploaded_file(self, 
                                   file_content: bytes,
                                   filename: str,
                                   language: str = "auto") -> Dict:
        """
        ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ì„ (ë‹¤êµ­ì–´ ì§€ì›)
        
        Args:
            file_content: íŒŒì¼ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            filename: ì›ë³¸ íŒŒì¼ëª…
            language: ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (auto, ko, en, zh, ja ë“±)
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_supported_format(filename):
            return {
                "success": False,
                "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {Path(filename).suffix}. {', '.join(self.supported_formats)}ë§Œ ì§€ì›í•©ë‹ˆë‹¤."
            }
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        file_ext = Path(filename).suffix.lower()
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file.write(file_content)
            temp_path = temp_file.name
        
        try:
            # ë¶„ì„ ì‹¤í–‰
            result = await self.analyze_audio_file(temp_path, language)
            
            # ì„±ê³µí•œ ê²½ìš° íŒŒì¼ ì •ë³´ ì¶”ê°€
            if result["success"]:
                result["filename"] = filename
                result["file_size"] = f"{result['file_size_mb']} MB"
            
            return result
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(temp_path)
            except:
                pass
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜ (ë‹¤êµ­ì–´ ì •ë³´ í¬í•¨)"""
        return {
            "model_size": self.model_size,
            "model_loaded": self.model is not None,
            "whisper_available": WHISPER_AVAILABLE,
            "supported_formats": self.supported_formats,
            "supported_languages": self.supported_languages,
            "default_language": "auto",
            "phase": "3.2 - Multilingual Support"
        }
    
    def translate_to_korean(self, text: str, source_lang: str = "en") -> str:
        """
        ë‹¤ë¥¸ ì–¸ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (í™•ì¥ëœ êµ¬í˜„)
        
        Args:
            text: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            source_lang: ì›ë³¸ ì–¸ì–´ ì½”ë“œ
            
        Returns:
            ë²ˆì—­ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸
        """
        # ì„ì‹œ êµ¬í˜„: í™•ì¥ëœ í‚¤ì›Œë“œ ë²ˆì—­
        translations = {
            "en": {
                "hello": "ì•ˆë…•í•˜ì„¸ìš”",
                "thank you": "ê°ì‚¬í•©ë‹ˆë‹¤",
                "yes": "ë„¤",
                "no": "ì•„ë‹ˆì˜¤",
                "good morning": "ì¢‹ì€ ì•„ì¹¨",
                "good evening": "ì¢‹ì€ ì €ë…",
                "how are you": "ì•ˆë…•í•˜ì„¸ìš”",
                "nice to meet you": "ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤"
            },
            "zh": {
                "ä½ å¥½": "ì•ˆë…•í•˜ì„¸ìš”",
                "è°¢è°¢": "ê°ì‚¬í•©ë‹ˆë‹¤",
                "æ˜¯": "ë„¤",
                "ä¸æ˜¯": "ì•„ë‹ˆì˜¤"
            },
            "ja": {
                "ã“ã‚“ã«ã¡ã¯": "ì•ˆë…•í•˜ì„¸ìš”",
                "ã‚ã‚ŠãŒã¨ã†": "ê°ì‚¬í•©ë‹ˆë‹¤",
                "ã¯ã„": "ë„¤",
                "ã„ã„ãˆ": "ì•„ë‹ˆì˜¤"
            }
        }
        
        if source_lang in translations:
            result = text
            for foreign, korean in translations[source_lang].items():
                result = result.replace(foreign, korean)
            return result
        
        return text  # ë²ˆì—­ ì‚¬ì „ì— ì—†ìœ¼ë©´ ì›ë¬¸ ë°˜í™˜

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_analyzer_instance = None

def get_analyzer(model_size: str = "base") -> AudioAnalyzer:
    """ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = AudioAnalyzer(model_size)
    return _analyzer_instance

# í¸ì˜ í•¨ìˆ˜ë“¤
async def quick_analyze(file_path: str, language: str = "auto") -> Dict:
    """ë¹ ë¥¸ ë¶„ì„ í•¨ìˆ˜"""
    analyzer = get_analyzer()
    return await analyzer.analyze_audio_file(file_path, language)

def check_whisper_status() -> Dict:
    """Whisper ìƒíƒœ í™•ì¸"""
    return {
        "whisper_available": WHISPER_AVAILABLE,
        "import_error": None if WHISPER_AVAILABLE else "openai-whisper íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install openai-whisper"
    }

def get_language_support() -> Dict:
    """ì§€ì› ì–¸ì–´ ì •ë³´ ë°˜í™˜"""
    analyzer = get_analyzer()
    return {
        "supported_languages": analyzer.get_supported_languages(),
        "auto_detection": True,
        "default_language": "auto",
        "phase": "3.2 - Multilingual Support"
    }
