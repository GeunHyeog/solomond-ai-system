"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - STT ë¶„ì„ ì—”ì§„
OpenAI Whisper ê¸°ë°˜ ìŒì„± ì¸ì‹ ëª¨ë“ˆ
"""

import os
import time
import tempfile
from pathlib import Path
from typing import Dict, Optional, Union
import asyncio

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

class AudioAnalyzer:
    """ìŒì„± ë¶„ì„ ì—”ì§„ í´ë˜ìŠ¤"""
    
    def __init__(self, model_size: str = "base"):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_size: Whisper ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large)
        """
        self.model_size = model_size
        self.model = None
        self.supported_formats = ['.mp3', '.wav', '.m4a']
        
    def load_model(self) -> bool:
        """Whisper ëª¨ë¸ ë¡œë“œ"""
        if not WHISPER_AVAILABLE:
            return False
            
        try:
            print(f"ğŸ¤ Whisper ëª¨ë¸ ë¡œë”©... ({self.model_size})")
            self.model = whisper.load_model(self.model_size)
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model_size}")
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def is_supported_format(self, filename: str) -> bool:
        """ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ì¸ì§€ í™•ì¸"""
        file_ext = Path(filename).suffix.lower()
        return file_ext in self.supported_formats
    
    async def analyze_audio_file(self, 
                                file_path: str, 
                                language: str = "ko") -> Dict:
        """
        ìŒì„± íŒŒì¼ ë¶„ì„
        
        Args:
            file_path: ë¶„ì„í•  ìŒì„± íŒŒì¼ ê²½ë¡œ
            language: ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: í•œêµ­ì–´)
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        try:
            # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ
            if self.model is None:
                if not self.load_model():
                    return {
                        "success": False,
                        "error": "Whisper ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "whisper_available": WHISPER_AVAILABLE
                    }
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "error": f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}"
                }
            
            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
            file_size_bytes = os.path.getsize(file_path)
            file_size_mb = round(file_size_bytes / (1024 * 1024), 2)
            
            print(f"ğŸ” ìŒì„± ì¸ì‹ ì‹œì‘: {Path(file_path).name}")
            
            # Whisperë¡œ ìŒì„± ì¸ì‹ ì‹¤í–‰
            result = self.model.transcribe(file_path, language=language)
            
            transcribed_text = result["text"].strip()
            processing_time = round(time.time() - start_time, 2)
            
            print(f"âœ… ì¸ì‹ ì™„ë£Œ: {processing_time}ì´ˆ")
            print(f"ğŸ“ ê²°ê³¼: {transcribed_text[:100]}...")
            
            return {
                "success": True,
                "transcribed_text": transcribed_text,
                "processing_time": processing_time,
                "file_size_mb": file_size_mb,
                "detected_language": result.get("language", "unknown"),
                "confidence": result.get("confidence", 0.0),
                "segments": result.get("segments", [])
            }
            
        except Exception as e:
            processing_time = round(time.time() - start_time, 2)
            error_msg = str(e)
            
            print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {error_msg}")
            
            return {
                "success": False,
                "error": error_msg,
                "processing_time": processing_time
            }
    
    async def analyze_uploaded_file(self, 
                                   file_content: bytes,
                                   filename: str,
                                   language: str = "ko") -> Dict:
        """
        ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ì„ (ì„ì‹œ íŒŒì¼ ìƒì„± í›„ ë¶„ì„)
        
        Args:
            file_content: íŒŒì¼ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            filename: ì›ë³¸ íŒŒì¼ëª…
            language: ì¸ì‹í•  ì–¸ì–´ ì½”ë“œ
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_supported_format(filename):
            return {
                "success": False,
                "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {Path(filename).suffix}. {', '.join(self.supported_formats)}ë§Œ ì§€ì›í•©ë‹ˆë‹¤."
            }
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        file_ext = Path(filename).suffix.lower()
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file.write(file_content)
            temp_path = temp_file.name
        
        try:
            # ë¶„ì„ ì‹¤í–‰
            result = await self.analyze_audio_file(temp_path, language)
            
            # ì„±ê³µí•œ ê²½ìš° íŒŒì¼ ì •ë³´ ì¶”ê°€
            if result["success"]:
                result["filename"] = filename
                result["file_size"] = f"{result['file_size_mb']} MB"
            
            return result
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(temp_path)
            except:
                pass
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "model_size": self.model_size,
            "model_loaded": self.model is not None,
            "whisper_available": WHISPER_AVAILABLE,
            "supported_formats": self.supported_formats
        }
    
    def translate_to_korean(self, text: str) -> str:
        """
        ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (ê¸°ë³¸ êµ¬í˜„)
        ì¶”í›„ ë²ˆì—­ APIë‚˜ ëª¨ë¸ë¡œ ëŒ€ì²´ ì˜ˆì •
        """
        # ì„ì‹œ êµ¬í˜„: ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë²ˆì—­
        translations = {
            "hello": "ì•ˆë…•í•˜ì„¸ìš”",
            "thank you": "ê°ì‚¬í•©ë‹ˆë‹¤",
            "yes": "ë„¤",
            "no": "ì•„ë‹ˆì˜¤"
        }
        
        result = text
        for eng, kor in translations.items():
            result = result.replace(eng, kor)
        
        return result

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_analyzer_instance = None

def get_analyzer(model_size: str = "base") -> AudioAnalyzer:
    """ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = AudioAnalyzer(model_size)
    return _analyzer_instance

# í¸ì˜ í•¨ìˆ˜ë“¤
async def quick_analyze(file_path: str, language: str = "ko") -> Dict:
    """ë¹ ë¥¸ ë¶„ì„ í•¨ìˆ˜"""
    analyzer = get_analyzer()
    return await analyzer.analyze_audio_file(file_path, language)

def check_whisper_status() -> Dict:
    """Whisper ìƒíƒœ í™•ì¸"""
    return {
        "whisper_available": WHISPER_AVAILABLE,
        "import_error": None if WHISPER_AVAILABLE else "openai-whisper íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install openai-whisper"
    }
