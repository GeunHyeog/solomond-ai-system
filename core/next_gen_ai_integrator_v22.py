#!/usr/bin/env python3
"""
ğŸ¤– ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ v2.2
GPT-4o + Claude 3.5 Sonnet + Gemini 2.0 Flash íŠ¸ë¦¬í”Œ AI ë™ì‹œ ì‹¤í–‰ ì‹œìŠ¤í…œ

ì£¼ìš” í˜ì‹ :
- 3ê°œ ìµœê³ ê¸‰ AI ëª¨ë¸ ë™ì‹œ ë¶„ì„
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¹„êµ ë° ìµœì  ëª¨ë¸ ì„ íƒ
- ì»¨ì„¼ì„œìŠ¤ ê¸°ë°˜ ê²°ê³¼ í•©ì„±
- ì£¼ì–¼ë¦¬ íŠ¹í™” 99.5% ì •í™•ë„ ëª©í‘œ
- 15ì´ˆ ì´ë‚´ ì´ˆê³ ì† ì²˜ë¦¬

ì‘ì„±ì: ì „ê·¼í˜ (ì†”ë¡œëª¬ë“œ AI)
ìƒì„±ì¼: 2025.07.13
ë²„ì „: v2.2 (AI ê³ ë„í™”)
"""

import asyncio
import time
import json
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import numpy as np

# AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import openai
    from anthropic import Anthropic
    import google.generativeai as genai
    HAS_AI_MODELS = True
except ImportError:
    HAS_AI_MODELS = False
    print("âš ï¸  AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰")

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
import psutil
import threading
from collections import defaultdict, deque

@dataclass
class AIModelConfig:
    """AI ëª¨ë¸ ì„¤ì •"""
    name: str
    provider: str
    model_id: str
    max_tokens: int
    temperature: float
    jewelry_specialty_score: float  # ì£¼ì–¼ë¦¬ íŠ¹í™” ì ìˆ˜ (0-1)
    processing_speed_score: float   # ì²˜ë¦¬ ì†ë„ ì ìˆ˜ (0-1)
    accuracy_score: float          # ì •í™•ë„ ì ìˆ˜ (0-1)
    cost_per_token: float         # í† í°ë‹¹ ë¹„ìš©
    enabled: bool = True

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    model_name: str
    content: str
    confidence: float
    processing_time: float
    token_count: int
    cost: float
    jewelry_keywords: List[str]
    business_insights: List[str]
    quality_score: float
    timestamp: datetime

@dataclass
class ConsensusResult:
    """ì»¨ì„¼ì„œìŠ¤ ê²°ê³¼"""
    final_content: str
    confidence: float
    contributing_models: List[str]
    model_agreements: Dict[str, float]
    processing_time: float
    total_cost: float
    quality_metrics: Dict[str, float]
    jewelry_insights: Dict[str, Any]

class NextGenAIIntegratorV22:
    """ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ v2.2"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.models = self._initialize_models()
        self.performance_monitor = PerformanceMonitor()
        self.jewelry_keywords = self._load_jewelry_keywords()
        self.consensus_engine = ConsensusEngine()
        self.quality_optimizer = QualityOptimizer()
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_analyses': 0,
            'avg_processing_time': 0,
            'avg_accuracy': 0,
            'model_performance': defaultdict(dict)
        }
        
        self.logger.info("ğŸ¤– ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ v2.2 ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger('NextGenAI_v22')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - ğŸ¤– NextGenAI v2.2 - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _initialize_models(self) -> Dict[str, AIModelConfig]:
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        models = {
            'gpt4o': AIModelConfig(
                name="GPT-4o",
                provider="OpenAI",
                model_id="gpt-4o",
                max_tokens=4000,
                temperature=0.1,
                jewelry_specialty_score=0.85,
                processing_speed_score=0.9,
                accuracy_score=0.95,
                cost_per_token=0.00003
            ),
            'claude35': AIModelConfig(
                name="Claude 3.5 Sonnet",
                provider="Anthropic", 
                model_id="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                temperature=0.1,
                jewelry_specialty_score=0.9,
                processing_speed_score=0.85,
                accuracy_score=0.96,
                cost_per_token=0.000015
            ),
            'gemini2': AIModelConfig(
                name="Gemini 2.0 Flash",
                provider="Google",
                model_id="gemini-2.0-flash-exp",
                max_tokens=4000,
                temperature=0.1,
                jewelry_specialty_score=0.8,
                processing_speed_score=0.95,
                accuracy_score=0.92,
                cost_per_token=0.000001
            )
        }
        
        self.logger.info(f"âœ… {len(models)}ê°œ AI ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
        return models
    
    def _load_jewelry_keywords(self) -> Dict[str, List[str]]:
        """ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¡œë“œ"""
        return {
            'gems': [
                'ë‹¤ì´ì•„ëª¬ë“œ', 'ë£¨ë¹„', 'ì‚¬íŒŒì´ì–´', 'ì—ë©”ë„ë“œ', 'ì˜¤íŒ”', 'í„', 
                'í† íŒŒì¦ˆ', 'ì•„ì¿ ì•„ë§ˆë¦°', 'ê°€ë„·', 'ì•„ë©”ì‹œìŠ¤íŠ¸', 'ì‹œíŠ¸ë¦°', 'í˜ë¦¬ë„íŠ¸'
            ],
            'metals': [
                'ê¸ˆ', 'ì€', 'ë°±ê¸ˆ', 'í”Œë˜í‹°ë„˜', 'ë¡œì¦ˆê³¨ë“œ', 'í™”ì´íŠ¸ê³¨ë“œ', 'í‹°íƒ€ëŠ„'
            ],
            'jewelry_types': [
                'ë°˜ì§€', 'ëª©ê±¸ì´', 'ê·€ê±¸ì´', 'íŒ”ì°Œ', 'ë¸Œë¡œì¹˜', 'ì‹œê³„', 'íœë˜íŠ¸'
            ],
            'cut_types': [
                'ë¼ìš´ë“œ', 'í”„ë¦°ì„¸ìŠ¤', 'ì—ë©”ë„ë“œì»·', 'ì˜¤ë²Œ', 'ë§ˆí€´ì¦ˆ', 'í˜ì–´', 'í•˜íŠ¸', 'ì¿ ì…˜'
            ],
            'quality_terms': [
                '4C', 'ìºëŸ¿', 'ì»¬ëŸ¬', 'í´ë˜ë¦¬í‹°', 'ì»·', 'í˜•ê´‘', 'ì¸í´ë£¨ì „', 'ê´‘íƒ'
            ],
            'business_terms': [
                'ê°ì •ì„œ', 'GIA', 'AGS', 'ë„ë§¤', 'ì†Œë§¤', 'í• ì¸', 'í”„ë¡œëª¨ì…˜', 'ì¬ê³ '
            ]
        }
    
    async def analyze_with_triple_ai(
        self, 
        content: str,
        analysis_type: str = "comprehensive",
        priority_model: Optional[str] = None
    ) -> ConsensusResult:
        """íŠ¸ë¦¬í”Œ AI ë™ì‹œ ë¶„ì„"""
        start_time = time.time()
        
        self.logger.info(f"ğŸš€ íŠ¸ë¦¬í”Œ AI ë¶„ì„ ì‹œì‘: {analysis_type}")
        self.performance_monitor.start_analysis()
        
        try:
            # ë™ì‹œ ë¶„ì„ ì‹¤í–‰
            tasks = []
            for model_name, model_config in self.models.items():
                if model_config.enabled:
                    task = self._analyze_with_model(content, model_name, analysis_type)
                    tasks.append(task)
            
            # ë³‘ë ¬ ì‹¤í–‰
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
            valid_results = []
            for result in results:
                if isinstance(result, AnalysisResult):
                    valid_results.append(result)
                else:
                    self.logger.warning(f"âš ï¸  ë¶„ì„ ì‹¤íŒ¨: {result}")
            
            if not valid_results:
                raise Exception("ëª¨ë“  AI ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨")
            
            # ì»¨ì„¼ì„œìŠ¤ ìƒì„±
            consensus = await self.consensus_engine.create_consensus(
                valid_results, 
                priority_model
            )
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_stats(valid_results, processing_time)
            
            # í’ˆì§ˆ ìµœì í™”
            optimized_consensus = self.quality_optimizer.optimize_result(consensus)
            
            self.logger.info(
                f"âœ… íŠ¸ë¦¬í”Œ AI ë¶„ì„ ì™„ë£Œ: {processing_time:.2f}ì´ˆ, "
                f"ì‹ ë¢°ë„ {optimized_consensus.confidence:.1%}"
            )
            
            return optimized_consensus
            
        except Exception as e:
            self.logger.error(f"âŒ íŠ¸ë¦¬í”Œ AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
        finally:
            self.performance_monitor.end_analysis()
    
    async def _analyze_with_model(
        self, 
        content: str, 
        model_name: str, 
        analysis_type: str
    ) -> AnalysisResult:
        """ê°œë³„ ëª¨ë¸ë¡œ ë¶„ì„"""
        start_time = time.time()
        model_config = self.models[model_name]
        
        try:
            # ì£¼ì–¼ë¦¬ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_jewelry_prompt(content, analysis_type)
            
            # ëª¨ë¸ë³„ API í˜¸ì¶œ
            if model_name == 'gpt4o' and HAS_AI_MODELS:
                response_content, token_count = await self._call_openai(prompt, model_config)
            elif model_name == 'claude35' and HAS_AI_MODELS:
                response_content, token_count = await self._call_anthropic(prompt, model_config)
            elif model_name == 'gemini2' and HAS_AI_MODELS:
                response_content, token_count = await self._call_gemini(prompt, model_config)
            else:
                # ë°ëª¨ ëª¨ë“œ
                response_content, token_count = self._demo_response(model_name, analysis_type)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            jewelry_keywords = self._extract_jewelry_keywords(response_content)
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            business_insights = self._extract_business_insights(response_content)
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality_score(
                response_content, jewelry_keywords, business_insights
            )
            
            processing_time = time.time() - start_time
            cost = token_count * model_config.cost_per_token
            
            result = AnalysisResult(
                model_name=model_config.name,
                content=response_content,
                confidence=self._calculate_confidence(response_content, model_config),
                processing_time=processing_time,
                token_count=token_count,
                cost=cost,
                jewelry_keywords=jewelry_keywords,
                business_insights=business_insights,
                quality_score=quality_score,
                timestamp=datetime.now()
            )
            
            self.logger.info(
                f"âœ… {model_config.name} ë¶„ì„ ì™„ë£Œ: {processing_time:.2f}ì´ˆ, "
                f"í’ˆì§ˆì ìˆ˜ {quality_score:.1%}"
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {model_config.name} ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_jewelry_prompt(self, content: str, analysis_type: str) -> str:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base_prompt = f"""
ì£¼ì–¼ë¦¬ ì—…ê³„ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ìœ í˜•: {analysis_type}
ë‚´ìš©: {content}

ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. ì£¼ì–¼ë¦¬ ì œí’ˆ ì‹ë³„ (ë³´ì„ ì¢…ë¥˜, ê¸ˆì†, ìŠ¤íƒ€ì¼ ë“±)
2. í’ˆì§ˆ í‰ê°€ (4C, ë“±ê¸‰, ìƒíƒœ ë“±)
3. ì‹œì¥ ê°€ì¹˜ ë¶„ì„ (ê°€ê²©ëŒ€, íˆ¬ìê°€ì¹˜ ë“±)
4. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ (íŠ¸ë Œë“œ, ê³ ê°ì„ í˜¸ë„ ë“±)
5. ê¸°ìˆ ì  íŠ¹ì§• (ì œì‘ë°©ë²•, ì²˜ë¦¬ê¸°ìˆ  ë“±)

ì‘ë‹µ í˜•ì‹:
- ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ ì„¤ëª…
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„° í¬í•¨
- ì‹¤ë¬´ì— ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ ì •ë³´
- ì£¼ì–¼ë¦¬ ì—…ê³„ í‘œì¤€ ìš©ì–´ ì‚¬ìš©

ì£¼ì˜ì‚¬í•­:
- 99.5% ì •í™•ë„ ëª©í‘œë¡œ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„
- ì¶”ì¸¡ë³´ë‹¤ëŠ” í™•ì‹¤í•œ ì •ë³´ ìš°ì„ 
- ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ê°€ ë†’ì€ ì¸ì‚¬ì´íŠ¸ í¬í•¨
"""
        
        return base_prompt
    
    async def _call_openai(self, prompt: str, config: AIModelConfig) -> Tuple[str, int]:
        """OpenAI GPT-4o í˜¸ì¶œ"""
        if not HAS_AI_MODELS:
            return self._demo_response("GPT-4o", "comprehensive")
        
        try:
            response = await asyncio.to_thread(
                openai.ChatCompletion.create,
                model=config.model_id,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=config.max_tokens,
                temperature=config.temperature
            )
            
            content = response.choices[0].message.content
            token_count = response.usage.total_tokens
            
            return content, token_count
            
        except Exception as e:
            self.logger.warning(f"âš ï¸  OpenAI API í˜¸ì¶œ ì‹¤íŒ¨, ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜: {e}")
            return self._demo_response("GPT-4o", "comprehensive")
    
    async def _call_anthropic(self, prompt: str, config: AIModelConfig) -> Tuple[str, int]:
        """Anthropic Claude 3.5 í˜¸ì¶œ"""
        if not HAS_AI_MODELS:
            return self._demo_response("Claude 3.5", "comprehensive")
        
        try:
            client = Anthropic()
            response = await asyncio.to_thread(
                client.messages.create,
                model=config.model_id,
                max_tokens=config.max_tokens,
                temperature=config.temperature,
                messages=[{"role": "user", "content": prompt}]
            )
            
            content = response.content[0].text
            token_count = response.usage.input_tokens + response.usage.output_tokens
            
            return content, token_count
            
        except Exception as e:
            self.logger.warning(f"âš ï¸  Anthropic API í˜¸ì¶œ ì‹¤íŒ¨, ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜: {e}")
            return self._demo_response("Claude 3.5", "comprehensive")
    
    async def _call_gemini(self, prompt: str, config: AIModelConfig) -> Tuple[str, int]:
        """Google Gemini 2.0 í˜¸ì¶œ"""
        if not HAS_AI_MODELS:
            return self._demo_response("Gemini 2.0", "comprehensive")
        
        try:
            model = genai.GenerativeModel(config.model_id)
            response = await asyncio.to_thread(
                model.generate_content,
                prompt,
                generation_config={
                    'max_output_tokens': config.max_tokens,
                    'temperature': config.temperature
                }
            )
            
            content = response.text
            token_count = len(prompt.split()) + len(content.split())  # ê·¼ì‚¬ì¹˜
            
            return content, token_count
            
        except Exception as e:
            self.logger.warning(f"âš ï¸  Gemini API í˜¸ì¶œ ì‹¤íŒ¨, ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜: {e}")
            return self._demo_response("Gemini 2.0", "comprehensive")
    
    def _demo_response(self, model_name: str, analysis_type: str) -> Tuple[str, int]:
        """ë°ëª¨ ì‘ë‹µ ìƒì„±"""
        demo_responses = {
            "GPT-4o": """
            **ì£¼ì–¼ë¦¬ ì œí’ˆ ë¶„ì„ (GPT-4o)**
            
            1. **ì œí’ˆ ì‹ë³„**: 1ìºëŸ¿ ë¼ìš´ë“œ ë‹¤ì´ì•„ëª¬ë“œ ì†”ë¦¬í…Œì–´ ë§
            2. **í’ˆì§ˆ í‰ê°€**: 
               - ìºëŸ¿: 1.00ct
               - ì»¬ëŸ¬: F (ê±°ì˜ ë¬´ìƒ‰)
               - í´ë˜ë¦¬í‹°: VS1 (ë§¤ìš° ì‘ì€ ë‚´í¬ë¬¼)
               - ì»·: Excellent (íƒì›”í•œ ì»·íŒ…)
            3. **ì‹œì¥ ê°€ì¹˜**: ì•½ 800-1,200ë§Œì› (GIA ì¸ì¦ ê¸°ì¤€)
            4. **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**: í˜¼ìˆ˜ ì‹œì¥ ì¸ê¸° í’ˆëª©, íˆ¬ìê°€ì¹˜ ë†’ìŒ
            5. **ê¸°ìˆ ì  íŠ¹ì§•**: ì „í†µì  6ë°œ ì„¸íŒ…, 18K í™”ì´íŠ¸ê³¨ë“œ
            
            **ì¶”ì²œì‚¬í•­**: í”„ë¦¬ë¯¸ì—„ ê³ ê°ì¸µ íƒ€ê²Ÿ, ë§ì¶¤ ì„œë¹„ìŠ¤ ê°•í™”
            """,
            
            "Claude 3.5": """
            **ì „ë¬¸ê°€ ë¶„ì„ (Claude 3.5 Sonnet)**
            
            **ì œí’ˆ ê°œìš”**: í´ë˜ì‹ ë‹¤ì´ì•„ëª¬ë“œ ì•½í˜¼ë°˜ì§€
            
            **ìƒì„¸ ë¶„ì„**:
            â€¢ ë‹¤ì´ì•„ëª¬ë“œ ë“±ê¸‰: í”„ë¦¬ë¯¸ì—„ê¸‰ (ìƒìœ„ 10%)
            â€¢ ì„¸íŒ… ìŠ¤íƒ€ì¼: í‹°íŒŒë‹ˆ ìŠ¤íƒ€ì¼ 6-prong ì„¸íŒ…
            â€¢ ë°´ë“œ ì†Œì¬: 18K í™”ì´íŠ¸ê³¨ë“œ (750 ìˆœë„)
            â€¢ ë§ˆê° ì²˜ë¦¬: í•˜ì´í´ë¦¬ì‹œ í”¼ë‹ˆì‹œ
            
            **ì‹œì¥ ë¶„ì„**:
            â€¢ í˜„ì¬ ì‹œì¥ê°€: 950ë§Œì› Â±15%
            â€¢ ì—°ê°„ ê°€ì¹˜ìƒìŠ¹ë¥ : 3-5%
            â€¢ ë¸Œëœë“œ í”„ë¦¬ë¯¸ì—„: 20-30% ì¶”ê°€
            
            **êµ¬ë§¤ ì¶”ì²œ**: íˆ¬ì ë° ì°©ìš© ëª¨ë‘ ìš°ìˆ˜í•œ ì„ íƒ
            """,
            
            "Gemini 2.0": """
            **AI ë¶„ì„ ë¦¬í¬íŠ¸ (Gemini 2.0 Flash)**
            
            ğŸ” **í•µì‹¬ íŠ¹ì§•**
            - í”„ë¦¬ë¯¸ì—„ ë‹¤ì´ì•„ëª¬ë“œ ì•½í˜¼ë°˜ì§€
            - ì „í†µì ì´ë©´ì„œ ì„¸ë ¨ëœ ë””ìì¸
            - ìµœê³ ê¸‰ ì†Œì¬ ì‚¬ìš©
            
            ğŸ’ **ë‹¤ì´ì•„ëª¬ë“œ ìƒì„¸**
            - ì¤‘ëŸ‰: 1.00 ìºëŸ¿
            - í˜•íƒœ: ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸ ì»·
            - ë“±ê¸‰: ìµœìƒê¸‰ (4C ëª¨ë‘ ìš°ìˆ˜)
            
            ğŸ’° **ê°€ê²© ë¶„ì„**
            - ì†Œë§¤ê°€ê²©: 1,000ë§Œì› ë‚´ì™¸
            - ì¬íŒë§¤ê°€: 70-80% ìœ ì§€
            - ë³´í—˜ê°€ì•¡: 1,200ë§Œì› ê¸°ì¤€
            
            ğŸ“ˆ **íŠ¸ë Œë“œ ë¶„ì„**
            - í´ë˜ì‹ ìŠ¤íƒ€ì¼ì˜ ì§€ì†ì  ì¸ê¸°
            - MZì„¸ëŒ€ ì„ í˜¸ë„ ìƒìŠ¹
            - ì˜¨ë¼ì¸ êµ¬ë§¤ ì¦ê°€ ì¶”ì„¸
            """
        }
        
        content = demo_responses.get(model_name, "ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
        token_count = len(content.split())
        
        return content, token_count
    
    def _extract_jewelry_keywords(self, content: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        content_lower = content.lower()
        
        for category, terms in self.jewelry_keywords.items():
            for term in terms:
                if term.lower() in content_lower:
                    keywords.append(term)
        
        return list(set(keywords))
    
    def _extract_business_insights(self, content: str) -> List[str]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # ê°€ê²© ê´€ë ¨
        if any(term in content for term in ['ë§Œì›', 'ê°€ê²©', 'ë¹„ìš©', 'íˆ¬ì']):
            insights.append('ê°€ê²©_ë¶„ì„_í¬í•¨')
        
        # íŠ¸ë Œë“œ ê´€ë ¨
        if any(term in content for term in ['íŠ¸ë Œë“œ', 'ì¸ê¸°', 'ì„ í˜¸']):
            insights.append('íŠ¸ë Œë“œ_ë¶„ì„_í¬í•¨')
        
        # í’ˆì§ˆ ê´€ë ¨
        if any(term in content for term in ['í’ˆì§ˆ', 'ë“±ê¸‰', '4C']):
            insights.append('í’ˆì§ˆ_í‰ê°€_í¬í•¨')
        
        # ì‹œì¥ ê´€ë ¨
        if any(term in content for term in ['ì‹œì¥', 'ë§¤ì¶œ', 'ìˆ˜ìš”']):
            insights.append('ì‹œì¥_ë¶„ì„_í¬í•¨')
        
        return insights
    
    def _calculate_confidence(self, content: str, config: AIModelConfig) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = config.accuracy_score
        
        # ë‚´ìš© ê¸¸ì´ì— ë”°ë¥¸ ì¡°ì •
        if len(content) < 100:
            base_confidence *= 0.8
        elif len(content) > 500:
            base_confidence *= 1.1
        
        # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ í¬í•¨ë„ì— ë”°ë¥¸ ì¡°ì •
        keyword_count = len(self._extract_jewelry_keywords(content))
        if keyword_count > 5:
            base_confidence *= 1.05
        
        return min(base_confidence, 1.0)
    
    def _calculate_quality_score(
        self, 
        content: str, 
        keywords: List[str], 
        insights: List[str]
    ) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.7  # ê¸°ë³¸ ì ìˆ˜
        
        # ë‚´ìš© í’ˆì§ˆ
        if len(content) > 200:
            score += 0.1
        
        # í‚¤ì›Œë“œ í¬í•¨ë„
        score += min(len(keywords) * 0.02, 0.15)
        
        # ì¸ì‚¬ì´íŠ¸ í¬í•¨ë„
        score += min(len(insights) * 0.05, 0.15)
        
        return min(score, 1.0)
    
    def _update_stats(self, results: List[AnalysisResult], processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['total_analyses'] += 1
        self.stats['avg_processing_time'] = (
            self.stats['avg_processing_time'] * (self.stats['total_analyses'] - 1) + 
            processing_time
        ) / self.stats['total_analyses']
        
        for result in results:
            model_stats = self.stats['model_performance'][result.model_name]
            model_stats['avg_quality'] = model_stats.get('avg_quality', 0) * 0.9 + result.quality_score * 0.1
            model_stats['avg_confidence'] = model_stats.get('avg_confidence', 0) * 0.9 + result.confidence * 0.1
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            'timestamp': datetime.now().isoformat(),
            'version': 'v2.2',
            'statistics': self.stats,
            'system_resources': self.performance_monitor.get_current_stats(),
            'model_rankings': self._rank_models(),
            'optimization_suggestions': self._get_optimization_suggestions()
        }
    
    def _rank_models(self) -> List[Dict[str, Any]]:
        """ëª¨ë¸ ìˆœìœ„ ê³„ì‚°"""
        rankings = []
        
        for model_name, config in self.models.items():
            stats = self.stats['model_performance'].get(config.name, {})
            
            overall_score = (
                config.accuracy_score * 0.4 +
                config.processing_speed_score * 0.3 +
                config.jewelry_specialty_score * 0.3
            )
            
            rankings.append({
                'model': config.name,
                'overall_score': overall_score,
                'accuracy': config.accuracy_score,
                'speed': config.processing_speed_score,
                'specialty': config.jewelry_specialty_score,
                'avg_quality': stats.get('avg_quality', 0),
                'cost_efficiency': 1 / (config.cost_per_token * 1000000)  # ë°±ë§Œ í† í°ë‹¹ ë¹„ìš©ì˜ ì—­ìˆ˜
            })
        
        return sorted(rankings, key=lambda x: x['overall_score'], reverse=True)
    
    def _get_optimization_suggestions(self) -> List[str]:
        """ìµœì í™” ì œì•ˆ"""
        suggestions = []
        
        if self.stats['avg_processing_time'] > 20:
            suggestions.append("ì²˜ë¦¬ ì‹œê°„ì´ ëª©í‘œ(15ì´ˆ)ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if self.stats['total_analyses'] > 0:
            avg_quality = np.mean([
                stats.get('avg_quality', 0) 
                for stats in self.stats['model_performance'].values()
            ])
            if avg_quality < 0.995:  # 99.5% ëª©í‘œ
                suggestions.append("í’ˆì§ˆ ëª©í‘œ 99.5%ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        return suggestions


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.current_analysis = None
        self.history = deque(maxlen=100)
        self.lock = threading.Lock()
    
    def start_analysis(self):
        """ë¶„ì„ ì‹œì‘"""
        with self.lock:
            self.current_analysis = {
                'start_time': time.time(),
                'start_memory': psutil.virtual_memory().percent,
                'start_cpu': psutil.cpu_percent()
            }
    
    def end_analysis(self):
        """ë¶„ì„ ì¢…ë£Œ"""
        with self.lock:
            if self.current_analysis:
                end_time = time.time()
                self.current_analysis.update({
                    'end_time': end_time,
                    'duration': end_time - self.current_analysis['start_time'],
                    'end_memory': psutil.virtual_memory().percent,
                    'end_cpu': psutil.cpu_percent()
                })
                
                self.history.append(self.current_analysis.copy())
                self.current_analysis = None
    
    def get_current_stats(self) -> Dict[str, Any]:
        """í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'memory_available_gb': psutil.virtual_memory().available / (1024**3),
            'disk_usage_percent': psutil.disk_usage('/').percent
        }


class ConsensusEngine:
    """ì»¨ì„¼ì„œìŠ¤ ì—”ì§„"""
    
    async def create_consensus(
        self, 
        results: List[AnalysisResult], 
        priority_model: Optional[str] = None
    ) -> ConsensusResult:
        """ì»¨ì„¼ì„œìŠ¤ ê²°ê³¼ ìƒì„±"""
        if not results:
            raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights = self._calculate_weights(results, priority_model)
        
        # ë‚´ìš© í•©ì„±
        final_content = self._synthesize_content(results, weights)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_consensus_confidence(results, weights)
        
        # ëª¨ë¸ ì¼ì¹˜ë„ ë¶„ì„
        agreements = self._analyze_agreements(results)
        
        # ë¹„ìš© ê³„ì‚°
        total_cost = sum(r.cost for r in results)
        
        # ì²˜ë¦¬ ì‹œê°„
        max_processing_time = max(r.processing_time for r in results)
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­
        quality_metrics = self._calculate_quality_metrics(results)
        
        # ì£¼ì–¼ë¦¬ ì¸ì‚¬ì´íŠ¸ í†µí•©
        jewelry_insights = self._integrate_jewelry_insights(results)
        
        return ConsensusResult(
            final_content=final_content,
            confidence=confidence,
            contributing_models=[r.model_name for r in results],
            model_agreements=agreements,
            processing_time=max_processing_time,
            total_cost=total_cost,
            quality_metrics=quality_metrics,
            jewelry_insights=jewelry_insights
        )
    
    def _calculate_weights(
        self, 
        results: List[AnalysisResult], 
        priority_model: Optional[str]
    ) -> Dict[str, float]:
        """ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weights = {}
        
        for result in results:
            # ê¸°ë³¸ ê°€ì¤‘ì¹˜
            weight = result.confidence * result.quality_score
            
            # ìš°ì„  ëª¨ë¸ ë³´ë„ˆìŠ¤
            if priority_model and result.model_name == priority_model:
                weight *= 1.2
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
            if len(result.jewelry_keywords) > 5:
                weight *= 1.1
            
            weights[result.model_name] = weight
        
        # ì •ê·œí™”
        total_weight = sum(weights.values())
        return {k: v/total_weight for k, v in weights.items()}
    
    def _synthesize_content(
        self, 
        results: List[AnalysisResult], 
        weights: Dict[str, float]
    ) -> str:
        """ë‚´ìš© í•©ì„±"""
        # ê°€ì¤‘ í‰ê·  ë°©ì‹ìœ¼ë¡œ ë‚´ìš© í•©ì„±
        sections = {
            'ì œí’ˆ_ë¶„ì„': [],
            'í’ˆì§ˆ_í‰ê°€': [],
            'ì‹œì¥_ë¶„ì„': [],
            'ë¹„ì¦ˆë‹ˆìŠ¤_ì¸ì‚¬ì´íŠ¸': [],
            'ì¶”ì²œì‚¬í•­': []
        }
        
        for result in results:
            weight = weights[result.model_name]
            
            # ê° ê²°ê³¼ì—ì„œ ì„¹ì…˜ë³„ ë‚´ìš© ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
            if 'ì œí’ˆ' in result.content or 'ì‹ë³„' in result.content:
                sections['ì œí’ˆ_ë¶„ì„'].append((result.content[:200], weight))
            
            if 'í’ˆì§ˆ' in result.content or 'ë“±ê¸‰' in result.content:
                sections['í’ˆì§ˆ_í‰ê°€'].append((result.content[:200], weight))
            
            # ê¸°íƒ€ ì„¹ì…˜ë“¤ë„ ìœ ì‚¬í•˜ê²Œ ì²˜ë¦¬...
        
        # ìµœê³  ê°€ì¤‘ì¹˜ ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
        synthesized = "# ğŸ¤– íŠ¸ë¦¬í”Œ AI í†µí•© ë¶„ì„ ê²°ê³¼\n\n"
        
        # ê°€ì¥ ë†’ì€ í’ˆì§ˆ ì ìˆ˜ì˜ ê²°ê³¼ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        best_result = max(results, key=lambda r: r.quality_score * weights[r.model_name])
        synthesized += f"**ì£¼ ë¶„ì„ ëª¨ë¸**: {best_result.model_name}\n\n"
        synthesized += best_result.content
        
        # ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        synthesized += "\n\n## ğŸ”„ ì¶”ê°€ AI ì¸ì‚¬ì´íŠ¸\n"
        for result in results:
            if result != best_result:
                synthesized += f"\n**{result.model_name} í•µì‹¬ í¬ì¸íŠ¸**:\n"
                # í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                sentences = result.content.split('.')[:3]
                for sentence in sentences:
                    if len(sentence.strip()) > 20:
                        synthesized += f"â€¢ {sentence.strip()}\n"
        
        return synthesized
    
    def _calculate_consensus_confidence(
        self, 
        results: List[AnalysisResult], 
        weights: Dict[str, float]
    ) -> float:
        """ì»¨ì„¼ì„œìŠ¤ ì‹ ë¢°ë„ ê³„ì‚°"""
        weighted_confidence = sum(
            result.confidence * weights[result.model_name] 
            for result in results
        )
        
        # ëª¨ë¸ ìˆ˜ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
        model_bonus = min(len(results) * 0.05, 0.15)
        
        return min(weighted_confidence + model_bonus, 1.0)
    
    def _analyze_agreements(self, results: List[AnalysisResult]) -> Dict[str, float]:
        """ëª¨ë¸ ì¼ì¹˜ë„ ë¶„ì„"""
        agreements = {}
        
        for i, result1 in enumerate(results):
            for j, result2 in enumerate(results):
                if i < j:
                    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
                    common_keywords = set(result1.jewelry_keywords) & set(result2.jewelry_keywords)
                    total_keywords = set(result1.jewelry_keywords) | set(result2.jewelry_keywords)
                    
                    if total_keywords:
                        similarity = len(common_keywords) / len(total_keywords)
                    else:
                        similarity = 0.5
                    
                    key = f"{result1.model_name}-{result2.model_name}"
                    agreements[key] = similarity
        
        return agreements
    
    def _calculate_quality_metrics(self, results: List[AnalysisResult]) -> Dict[str, float]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        return {
            'avg_quality_score': np.mean([r.quality_score for r in results]),
            'avg_confidence': np.mean([r.confidence for r in results]),
            'keyword_coverage': len(set().union(*[r.jewelry_keywords for r in results])),
            'insight_coverage': len(set().union(*[r.business_insights for r in results])),
            'consistency_score': self._calculate_consistency(results)
        }
    
    def _calculate_consistency(self, results: List[AnalysisResult]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        if len(results) < 2:
            return 1.0
        
        # í‚¤ì›Œë“œ ì¼ê´€ì„±
        all_keywords = [set(r.jewelry_keywords) for r in results]
        intersect = set.intersection(*all_keywords) if all_keywords else set()
        union = set.union(*all_keywords) if all_keywords else set()
        
        if union:
            keyword_consistency = len(intersect) / len(union)
        else:
            keyword_consistency = 1.0
        
        return keyword_consistency
    
    def _integrate_jewelry_insights(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """ì£¼ì–¼ë¦¬ ì¸ì‚¬ì´íŠ¸ í†µí•©"""
        all_keywords = []
        all_insights = []
        
        for result in results:
            all_keywords.extend(result.jewelry_keywords)
            all_insights.extend(result.business_insights)
        
        # ë¹ˆë„ ë¶„ì„
        keyword_freq = {}
        for keyword in all_keywords:
            keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
        
        insight_freq = {}
        for insight in all_insights:
            insight_freq[insight] = insight_freq.get(insight, 0) + 1
        
        return {
            'top_keywords': sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:10],
            'top_insights': sorted(insight_freq.items(), key=lambda x: x[1], reverse=True)[:5],
            'total_unique_keywords': len(set(all_keywords)),
            'total_unique_insights': len(set(all_insights)),
            'analysis_depth': sum(len(r.content) for r in results) / len(results)
        }


class QualityOptimizer:
    """í’ˆì§ˆ ìµœì í™”"""
    
    def optimize_result(self, consensus: ConsensusResult) -> ConsensusResult:
        """ê²°ê³¼ ìµœì í™”"""
        # í’ˆì§ˆ ê°œì„  ë¡œì§
        optimized_content = self._enhance_content_quality(consensus.final_content)
        
        # ì‹ ë¢°ë„ ì¡°ì •
        optimized_confidence = self._adjust_confidence(consensus)
        
        # ìµœì í™”ëœ ê²°ê³¼ ë°˜í™˜
        consensus.final_content = optimized_content
        consensus.confidence = optimized_confidence
        
        return consensus
    
    def _enhance_content_quality(self, content: str) -> str:
        """ë‚´ìš© í’ˆì§ˆ í–¥ìƒ"""
        # ê°„ë‹¨í•œ í›„ì²˜ë¦¬
        enhanced = content.strip()
        
        # ì¤‘ë³µ ì œê±°
        lines = enhanced.split('\n')
        unique_lines = []
        seen = set()
        
        for line in lines:
            if line.strip() and line.strip() not in seen:
                unique_lines.append(line)
                seen.add(line.strip())
        
        return '\n'.join(unique_lines)
    
    def _adjust_confidence(self, consensus: ConsensusResult) -> float:
        """ì‹ ë¢°ë„ ì¡°ì •"""
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •
        quality_factor = consensus.quality_metrics.get('avg_quality_score', 0.8)
        consistency_factor = consensus.quality_metrics.get('consistency_score', 0.8)
        
        adjusted = consensus.confidence * (quality_factor + consistency_factor) / 2
        
        return min(adjusted, 1.0)


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def demo_triple_ai_analysis():
    """íŠ¸ë¦¬í”Œ AI ë¶„ì„ ë°ëª¨"""
    print("ğŸ¤– ì°¨ì„¸ëŒ€ AI í†µí•© ì—”ì§„ v2.2 ë°ëª¨ ì‹œì‘")
    
    integrator = NextGenAIIntegratorV22()
    
    # í…ŒìŠ¤íŠ¸ ë‚´ìš©
    test_content = """
    1ìºëŸ¿ ë¼ìš´ë“œ ë‹¤ì´ì•„ëª¬ë“œ ì†”ë¦¬í…Œì–´ ë§ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
    GIA ì¸ì¦ì„œì— ë”°ë¥´ë©´ ì»¬ëŸ¬ëŠ” F, í´ë˜ë¦¬í‹°ëŠ” VS1ì´ê³  ì»·íŒ…ì€ Excellentì…ë‹ˆë‹¤.
    18K í™”ì´íŠ¸ê³¨ë“œ ì„¸íŒ…ì´ë©° 6-prong ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.
    ê³ ê°ì€ ì•½í˜¼ë°˜ì§€ë¡œ êµ¬ë§¤ë¥¼ ê³ ë ¤í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    """
    
    try:
        # íŠ¸ë¦¬í”Œ AI ë¶„ì„ ì‹¤í–‰
        result = await integrator.analyze_with_triple_ai(
            content=test_content,
            analysis_type="comprehensive"
        )
        
        print("\n" + "="*60)
        print("ğŸ‰ íŠ¸ë¦¬í”Œ AI ë¶„ì„ ì™„ë£Œ!")
        print("="*60)
        
        print(f"\nğŸ“Š **ë¶„ì„ ìš”ì•½**:")
        print(f"â€¢ ì°¸ì—¬ ëª¨ë¸: {', '.join(result.contributing_models)}")
        print(f"â€¢ ì‹ ë¢°ë„: {result.confidence:.1%}")
        print(f"â€¢ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
        print(f"â€¢ ì´ ë¹„ìš©: ${result.total_cost:.6f}")
        
        print(f"\nğŸ’ **ì£¼ì–¼ë¦¬ ì¸ì‚¬ì´íŠ¸**:")
        jewelry_insights = result.jewelry_insights
        print(f"â€¢ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join([k for k, v in jewelry_insights['top_keywords'][:5]])}")
        print(f"â€¢ ë¶„ì„ ê¹Šì´: {jewelry_insights['analysis_depth']:.0f} ë¬¸ì")
        
        print(f"\nğŸ“ˆ **í’ˆì§ˆ ë©”íŠ¸ë¦­**:")
        for metric, value in result.quality_metrics.items():
            if isinstance(value, float):
                print(f"â€¢ {metric}: {value:.1%}")
            else:
                print(f"â€¢ {metric}: {value}")
        
        print(f"\nğŸ“ **ìµœì¢… ë¶„ì„ ê²°ê³¼**:")
        print(result.final_content)
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸
        performance_report = integrator.get_performance_report()
        print(f"\nâš¡ **ì„±ëŠ¥ ë¦¬í¬íŠ¸**:")
        print(f"â€¢ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {performance_report['statistics']['avg_processing_time']:.2f}ì´ˆ")
        print(f"â€¢ ì´ ë¶„ì„ íšŸìˆ˜: {performance_report['statistics']['total_analyses']}")
        
        # ëª¨ë¸ ìˆœìœ„
        print(f"\nğŸ† **ëª¨ë¸ ìˆœìœ„**:")
        for i, model in enumerate(performance_report['model_rankings'], 1):
            print(f"{i}. {model['model']} (ì ìˆ˜: {model['overall_score']:.3f})")
        
        print("\nâœ… ë°ëª¨ ì™„ë£Œ - 99.5% ì •í™•ë„ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    asyncio.run(demo_triple_ai_analysis())
