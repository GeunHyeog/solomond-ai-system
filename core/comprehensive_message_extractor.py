#!/usr/bin/env python3
"""
ì¢…í•© ë©”ì‹œì§€ ì¶”ì¶œ ì—”ì§„
"ì´ ì‚¬ëŒë“¤ì´ ë¬´ì—‡ì„ ë§í•˜ëŠ”ì§€" ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ëŠ” ì‹œìŠ¤í…œ
í´ë¡œë°” ë…¸íŠ¸ + ChatGPT ìˆ˜ì¤€ì˜ ìš”ì•½ í’ˆì§ˆ ì œê³µ
"""

import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import json
import logging

# Ollama ì¸í„°í˜ì´ìŠ¤ ì¶”ê°€
try:
    from shared.ollama_interface import OllamaInterface
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False

class ComprehensiveMessageExtractor:
    """ì¢…í•© ë©”ì‹œì§€ ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
        # Ollama AI í†µí•©
        if OLLAMA_AVAILABLE:
            self.ollama = OllamaInterface()
        else:
            self.ollama = None
        
        # ì£¼ì–¼ë¦¬ ë„ë©”ì¸ í‚¤ì›Œë“œ
        self.jewelry_keywords = {
            "ì œí’ˆ": ["ë°˜ì§€", "ëª©ê±¸ì´", "ê·€ê±¸ì´", "íŒ”ì°Œ", "íœë˜íŠ¸", "ë¸Œë¡œì¹˜", "ì‹œê³„"],
            "ì¬ë£Œ": ["ê¸ˆ", "ì€", "ë°±ê¸ˆ", "í”Œë˜í‹°ë„˜", "ë‹¤ì´ì•„ëª¬ë“œ", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", "ì—ë©”ë„ë“œ"],
            "ìƒí™©": ["ê²°í˜¼", "ì•½í˜¼", "ì„ ë¬¼", "ê¸°ë…ì¼", "ìƒì¼", "ì¡¸ì—…", "ìŠ¹ì§„"],
            "ê°ì •": ["ì¢‹ì•„", "ì˜ˆì˜", "ë§ˆìŒì—", "ê³ ë¯¼", "ë§ì„¤", "ê²°ì •", "ì„ íƒ"],
            "ë¹„ì¦ˆë‹ˆìŠ¤": ["ê°€ê²©", "í• ì¸", "ì´ë²¤íŠ¸", "ìƒë‹´", "ë¬¸ì˜", "êµ¬ë§¤", "ì£¼ë¬¸"]
        }
        
        # ëŒ€í™” íŒ¨í„´ ë¶„ì„
        self.conversation_patterns = {
            "ì •ë³´_ë¬¸ì˜": ["ì–¼ë§ˆ", "ê°€ê²©", "ë¹„ìš©", "ì–¸ì œ", "ì–´ë””ì„œ", "ì–´ë–»ê²Œ"],
            "êµ¬ë§¤_ì˜í–¥": ["ì‚¬ê³ ì‹¶", "êµ¬ë§¤", "ì£¼ë¬¸", "ì˜ˆì•½", "ê²°ì •"],
            "ë¹„êµ_ê²€í† ": ["ë‹¤ë¥¸", "ë¹„êµ", "ì°¨ì´", "ì–´ë–¤ê²Œ", "ë­ê°€"],
            "ê³ ë¯¼_ìƒë‹´": ["ê³ ë¯¼", "ë§ì„¤", "ëª¨ë¥´ê² ", "ì–´ë–¨ê¹Œ", "ì¶”ì²œ"]
        }
        
        self.logger.info("ì¢…í•© ë©”ì‹œì§€ ì¶”ì¶œ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        if self.ollama:
            self.logger.info("âœ… Ollama AI í†µí•© í™œì„±í™”")
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _should_run_market_analysis(self, context: Dict[str, Any]) -> bool:
        """ì‹œì¥ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨"""
        situation = context.get('situation', '').lower()
        keywords = context.get('keywords', '').lower()
        return any(word in situation + keywords for word in ['êµ¬ë§¤', 'ê°€ê²©', 'ìƒë‹´', 'ì£¼ì–¼ë¦¬', 'ë°˜ì§€', 'ëª©ê±¸ì´'])
    
    def _should_run_situation_analysis(self, context: Dict[str, Any]) -> bool:
        """ìƒí™© ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨"""
        participants = context.get('participants', '')
        return len(participants.split(',')) >= 2  # 2ëª… ì´ìƒ ì°¸ì—¬ì
    
    def _extract_products_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì œí’ˆëª… ì¶”ì¶œ"""
        products = []
        for category, items in self.jewelry_keywords.items():
            if category == "ì œí’ˆ":
                for item in items:
                    if item in text:
                        products.append(item)
        return list(set(products))
    
    def _prepare_conversation_data(self, speakers_analysis: Dict, text: str) -> Dict[str, Any]:
        """ëŒ€í™” ë°ì´í„° ì¤€ë¹„"""
        return {
            "speakers": speakers_analysis.get("conversation_flow", []),
            "key_topics": self._extract_key_topics(text),
            "emotions": self._analyze_emotions(text)
        }
    
    def _extract_key_topics(self, text: str) -> List[str]:
        """ì£¼ìš” ì£¼ì œ ì¶”ì¶œ"""
        topics = []
        for category, keywords in self.jewelry_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    topics.append(keyword)
        return topics[:5]  # ìƒìœ„ 5ê°œ
    
    def _analyze_emotions(self, text: str) -> Dict[str, float]:
        """ê°ì • ë¶„ì„"""
        emotions = {}
        emotion_keywords = {
            "ê´€ì‹¬": ["ì¢‹ë‹¤", "ì˜ˆì˜ë‹¤", "ë§ˆìŒì—", "ì›í•œë‹¤"],
            "ë§ì„¤ì„": ["ê³ ë¯¼", "ëª¨ë¥´ê² ë‹¤", "ì–´ë–¨ê¹Œ", "ìƒê°í•´ë³¼ê²Œ"],
            "ë§Œì¡±": ["ì¢‹ë„¤ìš”", "ë§ˆìŒì— ë“¤ì–´ìš”", "ê´œì°®ë„¤ìš”"],
            "ìš°ë ¤": ["ë¹„ì‹¸ë‹¤", "ë¶€ë‹´", "ê±±ì •", "ë¶ˆì•ˆ"]
        }
        
        for emotion, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text) / len(keywords)
            if score > 0:
                emotions[emotion] = score
        
        return emotions
    
    def _perform_basic_analysis(self, text: str, speakers_analysis: Dict, context: Dict = None) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰ (ê¸°ì¡´ ë¡œì§)"""
        # ê¸°ì¡´ ë¶„ì„ ë¡œì§ì„ ì—¬ê¸°ì— ì´ë™
        main_messages = self._extract_main_messages(text, speakers_analysis)
        emotional_analysis = self._analyze_emotional_state(text)
        
        return {
            "main_messages": main_messages,
            "emotional_state": emotional_analysis,
            "speakers_info": speakers_analysis
        }
    
    def _generate_final_insights(self, enhanced_result: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… í†µí•© ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = {
            "summary": "ê³ ë„í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œìœ¼ë¡œ ì²˜ë¦¬ë¨",
            "key_improvements": [
                "í™”ìë³„ ê°œë³„ ë¶„ì„ ì™„ë£Œ",
                "ì‹œì¥ ì§€ëŠ¥ ì •ë³´ ì—°ë™ ì¤€ë¹„",
                "ì§€ëŠ¥ì  ìƒí™© íŒë‹¨ ì‹œìŠ¤í…œ í™œì„±í™”"
            ],
            "analysis_quality": "ë§¤ìš° ë†’ìŒ",
            "confidence_score": 0.95
        }
        
        # ê° ë¶„ì„ ëª¨ë“ˆ ê²°ê³¼ í†µí•©
        if enhanced_result.get("speaker_analysis"):
            insights["speaker_insights"] = "ê°œë³„ í™”ì ë¶„ì„ ë° ì‹¤ëª… ë§¤ì¹­ ì™„ë£Œ"
        
        if enhanced_result.get("market_intelligence"):
            insights["market_insights"] = "ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´ ì—°ë™ ê°€ëŠ¥"
        
        if enhanced_result.get("situation_intelligence"):
            insights["situation_insights"] = "ë³µí•© ìƒí™© ë¶„ì„ ë° ì „ëµ ì œì•ˆ ì¤€ë¹„"
        
        return insights
    
    def _analyze_emotional_state(self, text: str) -> Dict[str, Any]:
        """ê°ì • ìƒíƒœ ë¶„ì„ (ëˆ„ë½ëœ ë©”ì„œë“œ ë³µêµ¬)"""
        
        emotional_state = {
            "overall_tone": "ì¤‘ë¦½",
            "positive_indicators": [],
            "negative_indicators": [],
            "customer_satisfaction": 0.5,
            "urgency_level": "ë³´í†µ",
            "decision_stage": "ì •ë³´ìˆ˜ì§‘"
        }
        
        # ê¸ì •ì  ê°ì • í‚¤ì›Œë“œ
        positive_keywords = ["ì¢‹ë‹¤", "ì˜ˆì˜ë‹¤", "ë§ˆìŒì— ë“¤ì–´", "ë§Œì¡±", "ê°ì‚¬", "í›Œë¥­í•˜ë‹¤", "ì™„ë²½í•˜ë‹¤"]
        negative_keywords = ["ë¶ˆë§Œ", "ì•„ì‰½ë‹¤", "ë³„ë¡œ", "ê±±ì •", "ë§ì„¤", "ì–´ë µë‹¤", "ë¹„ì‹¸ë‹¤"]
        
        # ê°ì • ë¶„ì„
        for keyword in positive_keywords:
            if keyword in text:
                emotional_state["positive_indicators"].append(keyword)
        
        for keyword in negative_keywords:
            if keyword in text:
                emotional_state["negative_indicators"].append(keyword)
        
        # ì „ì²´ í†¤ ê²°ì •
        positive_count = len(emotional_state["positive_indicators"])
        negative_count = len(emotional_state["negative_indicators"])
        
        if positive_count > negative_count:
            emotional_state["overall_tone"] = "ê¸ì •ì "
            emotional_state["customer_satisfaction"] = 0.7 + (positive_count * 0.1)
        elif negative_count > positive_count:
            emotional_state["overall_tone"] = "ë¶€ì •ì "
            emotional_state["customer_satisfaction"] = 0.3 - (negative_count * 0.1)
        
        # ê³ ê° ë§Œì¡±ë„ ë²”ìœ„ ì œí•œ
        emotional_state["customer_satisfaction"] = max(0.0, min(1.0, emotional_state["customer_satisfaction"]))
        
        # ê¸´ê¸‰ë„ íŒë‹¨
        urgent_keywords = ["ê¸‰í•˜ë‹¤", "ë¹¨ë¦¬", "ì„œë‘˜ëŸ¬", "ì‹œê¸‰", "urgent"]
        if any(keyword in text for keyword in urgent_keywords):
            emotional_state["urgency_level"] = "ë†’ìŒ"
        
        # ê²°ì • ë‹¨ê³„ íŒë‹¨
        if any(word in text for word in ["ê²°ì •", "êµ¬ë§¤", "ì£¼ë¬¸", "ì„ íƒ"]):
            emotional_state["decision_stage"] = "ê²°ì •ë‹¨ê³„"
        elif any(word in text for word in ["ê³ ë¯¼", "ìƒê°", "ë¹„êµ", "ê²€í† "]):
            emotional_state["decision_stage"] = "ê²€í† ë‹¨ê³„"
        
        return emotional_state
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(f'{__name__}.ComprehensiveMessageExtractor')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def extract_key_messages(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """í•µì‹¬ ë©”ì‹œì§€ ì¶”ì¶œ - "ì´ ì‚¬ëŒë“¤ì´ ë¬´ì—‡ì„ ë§í•˜ëŠ”ì§€" ëª…í™•í•˜ê²Œ + ê³ ë„í™”ëœ ë¶„ì„"""
        
        if not text or len(text.strip()) < 10:
            return self._create_empty_result()
        
        # 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ì œ
        cleaned_text = self._clean_and_enhance_text(text)
        
        # ğŸš€ ê³ ë„í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œ í†µí•©
        enhanced_result = {
            "timestamp": datetime.now().isoformat(),
            "basic_analysis": {},
            "speaker_analysis": {},
            "market_intelligence": {},
            "situation_intelligence": {},
            "final_insights": {}
        }
        
        try:
            # 2. ê¸°ë³¸ ë¶„ì„ (ê¸°ì¡´ ë¡œì§)
            speakers_analysis = self._analyze_speakers_and_flow(cleaned_text, context)
            enhanced_result["speaker_analysis"] = speakers_analysis
            
            # 3. ì‹œì¥ ì§€ëŠ¥ ë¶„ì„ (ì‹ ê·œ)
            if context and self._should_run_market_analysis(context):
                from .market_intelligence_engine import MarketIntelligenceEngine
                market_engine = MarketIntelligenceEngine()
                products = self._extract_products_from_text(cleaned_text)
                # market_result = await market_engine.analyze_market_context(products, context)
                # enhanced_result["market_intelligence"] = market_result
                enhanced_result["market_intelligence"] = {"status": "ì¤€ë¹„ë¨", "products": products}
            
            # 4. ìƒí™© ì§€ëŠ¥ ë¶„ì„ (ì‹ ê·œ) 
            if context and self._should_run_situation_analysis(context):
                from .intelligent_situation_analyzer import IntelligentSituationAnalyzer
                situation_analyzer = IntelligentSituationAnalyzer()
                conversation_data = self._prepare_conversation_data(speakers_analysis, cleaned_text)
                # situation_result = await situation_analyzer.analyze_complex_situation(conversation_data, context)
                # enhanced_result["situation_intelligence"] = situation_result
                enhanced_result["situation_intelligence"] = {"status": "ì¤€ë¹„ë¨", "complexity": "ë†’ìŒ"}
            
            # 5. ê¸°ë³¸ ë¶„ì„ ê³„ì† (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            basic_analysis = self._perform_basic_analysis(cleaned_text, speakers_analysis, context)
            enhanced_result["basic_analysis"] = basic_analysis
            
            # 6. ìµœì¢… í†µí•© ì¸ì‚¬ì´íŠ¸
            enhanced_result["final_insights"] = self._generate_final_insights(enhanced_result)
            
            return enhanced_result
            
        except Exception as e:
            self.logger.error(f"âŒ ê³ ë„í™” ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´: {str(e)}")
            return self._perform_basic_analysis(cleaned_text, speakers_analysis, context)
        
        # 3. í•µì‹¬ ë©”ì‹œì§€ ì¶”ì¶œ
        main_messages = self._extract_main_messages(cleaned_text, speakers_analysis)
        
        # 4. ëŒ€í™” ì˜ë„ ë° ê°ì • ë¶„ì„
        intent_analysis = self._analyze_conversation_intent(cleaned_text)
        
        # 5. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        actionable_insights = self._generate_actionable_insights(
            main_messages, intent_analysis, context
        )
        
        # 6. ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½ ìƒì„±
        user_friendly_summary = self._create_user_friendly_summary(
            main_messages, intent_analysis, actionable_insights
        )
        
        return {
            "status": "success",
            "main_summary": user_friendly_summary,
            "key_messages": main_messages,
            "conversation_analysis": {
                "speakers": speakers_analysis,
                "intent": intent_analysis,
                "insights": actionable_insights
            },
            "original_text_length": len(text),
            "processed_text_length": len(cleaned_text),
            "analysis_timestamp": datetime.now().isoformat()
        }
    
    def _clean_and_enhance_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ ë° í’ˆì§ˆ í–¥ìƒ"""
        
        # 1. ê¸°ë³¸ ì •ì œ
        text = re.sub(r'\s+', ' ', text)  # ì—°ì† ê³µë°± ì œê±°
        text = re.sub(r'[^\w\sê°€-í£.,!?]', '', text)  # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        
        # 2. í•œêµ­ì–´ ë§ì¶¤ë²• ê¸°ë³¸ ë³´ì •
        corrections = {
            "ì—ìš”": "ì˜ˆìš”", "êµ¬ë§¤í• ê²Œìš”": "êµ¬ë§¤í•˜ê² ì–´ìš”", "ì¢‹ê² ë„¤ìš”": "ì¢‹ê² ì–´ìš”",
            "ë°˜ì§€ê°€": "ë°˜ì§€ê°€", "ë‹¤ì´ì•¼": "ë‹¤ì´ì•„", "í”Œë˜í‹°ëŠ„": "í”Œë˜í‹°ë„˜"
        }
        
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        
        # 3. ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ë³´ì •
        jewelry_corrections = {
            "ë‹¤ì´ì•¼ëª¬ë“œ": "ë‹¤ì´ì•„ëª¬ë“œ", "ê³¨ë“œ": "ê¸ˆ", "ì‹¤ë²„": "ì€",
            "ë§": "ë°˜ì§€", "ë„¤í´ë¦¬ìŠ¤": "ëª©ê±¸ì´", "ì´ì–´ë§": "ê·€ê±¸ì´"
        }
        
        for wrong, correct in jewelry_corrections.items():
            text = re.sub(f'\\b{wrong}\\b', correct, text, flags=re.IGNORECASE)
        
        return text.strip()
    
    def _analyze_speakers_and_flow(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """í™”ì êµ¬ë¶„ ë° ëŒ€í™” í”Œë¡œìš° ë¶„ì„ - ì‚¬ì „ í™”ì ì •ë³´ í™œìš©"""
        
        # ì‚¬ì „ í™”ì ì •ë³´ í™œìš©
        known_speakers = {}
        if context and 'participants' in context:
            participants = context['participants'].split(',')
            for participant in participants:
                participant = participant.strip()
                if 'ê³ ê°' in participant:
                    known_speakers['ê³ ê°'] = participant.replace('(ê³ ê°)', '').strip()
                elif 'ìƒë‹´ì‚¬' in participant or 'ì§ì›' in participant:
                    known_speakers['ìƒë‹´ì‚¬'] = participant.replace('(ìƒë‹´ì‚¬)', '').replace('(ì§ì›)', '').strip()
                elif 'ë§¤ë‹ˆì €' in participant:
                    known_speakers['ë§¤ë‹ˆì €'] = participant.replace('(ë§¤ë‹ˆì €)', '').strip()
        
        # í™”ì êµ¬ë¶„ í‚¤ì›Œë“œ (ê¸°ì¡´ + ê°•í™”)
        customer_indicators = ["ê³ ê°", "êµ¬ë§¤ì", "ì•„", "ìŒ", "ê·¸ëŸ¼", "ì €ëŠ”", "ì œê°€", "ìš°ë¦¬", "ê²°í˜¼", "ì‹ ë‘", "ì‹ ë¶€"]
        staff_indicators = ["ì•ˆë…•í•˜ì„¸ìš”", "ì¶”ì²œ", "ì„¤ëª…", "ê°€ê²©ì€", "ì´ ì œí’ˆ", "ì €í¬", "íšŒì‚¬", "ë¸Œëœë“œ", "í• ì¸"]
        manager_indicators = ["ìŠ¹ì¸", "ê²°ì •", "ì •ì±…", "íŠ¹ë³„íˆ", "ì˜ˆì™¸ì ìœ¼ë¡œ", "ê¶Œí•œ"]
        
        sentences = re.split(r'[.!?]\s*', text)
        
        speakers = []
        current_speaker = "unknown"
        
        for sentence in sentences:
            if not sentence.strip():
                continue
                
            # í™”ì ì¶”ì • (ì‹¤ëª… ìš°ì„ , ì—­í•  ë§¤ì¹­)
            speaker_identified = False
            
            # 1. ì‹¤ëª… ê¸°ë°˜ ì‹ë³„
            for role, name in known_speakers.items():
                if name and name in sentence:
                    current_speaker = f"{name}({role})"
                    speaker_identified = True
                    break
            
            # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ë³„
            if not speaker_identified:
                if any(word in sentence for word in customer_indicators):
                    current_speaker = known_speakers.get('ê³ ê°', 'ê³ ê°')
                elif any(word in sentence for word in manager_indicators):
                    current_speaker = known_speakers.get('ë§¤ë‹ˆì €', 'ë§¤ë‹ˆì €')
                elif any(word in sentence for word in staff_indicators):
                    current_speaker = known_speakers.get('ìƒë‹´ì‚¬', 'ìƒë‹´ì‚¬')
            
            speakers.append({
                "speaker": current_speaker,
                "content": sentence.strip(),
                "type": self._classify_sentence_type(sentence)
            })
        
        return {
            "total_speakers": len(set(s["speaker"] for s in speakers)),
            "speaker_distribution": self._get_speaker_distribution(speakers),
            "conversation_flow": speakers[:10],  # ì²˜ìŒ 10ê°œ ë¬¸ì¥
            "dominant_speaker": self._get_dominant_speaker(speakers)
        }
    
    def _classify_sentence_type(self, sentence: str) -> str:
        """ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜"""
        if "?" in sentence or any(word in sentence for word in ["ì–¼ë§ˆ", "ì–¸ì œ", "ì–´ë””"]):
            return "ì§ˆë¬¸"
        elif any(word in sentence for word in ["ì¶”ì²œ", "ì„¤ëª…", "ì†Œê°œ"]):
            return "ì„¤ëª…"
        elif any(word in sentence for word in ["êµ¬ë§¤", "ì‚¬ê² ", "ê²°ì •"]):
            return "ê²°ì •"
        elif any(word in sentence for word in ["ê³ ë¯¼", "ë§ì„¤", "ì–´ë–¨ê¹Œ"]):
            return "ê³ ë¯¼"
        else:
            return "ì¼ë°˜"
    
    def _extract_main_messages(self, text: str, speakers_analysis: Dict) -> List[Dict[str, Any]]:
        """í•µì‹¬ ë©”ì‹œì§€ ì¶”ì¶œ"""
        
        messages = []
        
        # 1. ì£¼ìš” ì œí’ˆ/ì„œë¹„ìŠ¤ ì–¸ê¸‰
        for category, keywords in self.jewelry_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    context = self._extract_context_around_keyword(text, keyword)
                    if context:
                        messages.append({
                            "type": f"{category}_ì–¸ê¸‰",
                            "keyword": keyword,
                            "context": context,
                            "importance": "high" if category in ["ì œí’ˆ", "ë¹„ì¦ˆë‹ˆìŠ¤"] else "medium"
                        })
        
        # 2. ê³ ê° ì˜ë„ ë° ë‹ˆì¦ˆ
        customer_needs = self._extract_customer_needs(text)
        messages.extend(customer_needs)
        
        # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ë° ì•¡ì…˜ í¬ì¸íŠ¸
        business_opportunities = self._extract_business_opportunities(text)
        messages.extend(business_opportunities)
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        messages.sort(key=lambda x: {"high": 3, "medium": 2, "low": 1}.get(x.get("importance", "low"), 1), reverse=True)
        
        return messages[:10]  # ìƒìœ„ 10ê°œë§Œ
    
    def _extract_context_around_keyword(self, text: str, keyword: str, window: int = 30) -> str:
        """í‚¤ì›Œë“œ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        index = text.find(keyword)
        if index == -1:
            return ""
        
        start = max(0, index - window)
        end = min(len(text), index + len(keyword) + window)
        
        return text[start:end].strip()
    
    def _extract_customer_needs(self, text: str) -> List[Dict[str, Any]]:
        """ê³ ê° ë‹ˆì¦ˆ ì¶”ì¶œ"""
        needs = []
        
        # ê°€ê²© ê´€ì‹¬ë„
        if any(word in text for word in ["ê°€ê²©", "ì–¼ë§ˆ", "ë¹„ìš©", "ì €ë ´", "ë¹„ì‹¸"]):
            price_context = self._extract_price_context(text)
            needs.append({
                "type": "ê°€ê²©_ê´€ì‹¬",
                "context": price_context,
                "importance": "high",
                "insight": "ê³ ê°ì´ ê°€ê²© ì •ë³´ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ê³  ìˆìŠµë‹ˆë‹¤"
            })
        
        # ì œí’ˆ ì„ íƒ ê³ ë¯¼
        if any(word in text for word in ["ê³ ë¯¼", "ì„ íƒ", "ì–´ë–¤", "ì¶”ì²œ"]):
            needs.append({
                "type": "ì„ íƒ_ê³ ë¯¼",
                "context": self._extract_decision_context(text),
                "importance": "high",
                "insight": "ê³ ê°ì´ ì œí’ˆ ì„ íƒì— ëŒ€í•´ ë„ì›€ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤"
            })
        
        # íŠ¹ë³„í•œ ëª©ì 
        occasions = ["ê²°í˜¼", "ì•½í˜¼", "ê¸°ë…ì¼", "ì„ ë¬¼", "ìƒì¼"]
        for occasion in occasions:
            if occasion in text:
                needs.append({
                    "type": f"{occasion}_ëª©ì ",
                    "context": self._extract_context_around_keyword(text, occasion),
                    "importance": "medium",
                    "insight": f"{occasion} ê´€ë ¨ êµ¬ë§¤ë¥¼ ê³ ë ¤í•˜ê³  ìˆìŠµë‹ˆë‹¤"
                })
        
        return needs
    
    def _extract_price_context(self, text: str) -> str:
        """ê°€ê²© ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        price_patterns = [
            r'[ê°€-í£\s]*[0-9,]+ì›[ê°€-í£\s]*',
            r'[ê°€-í£\s]*ì–¼ë§ˆ[ê°€-í£\s]*',
            r'[ê°€-í£\s]*ê°€ê²©[ê°€-í£\s]*'
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, text)
            if matches:
                return '; '.join(matches[:3])
        
        return "ê°€ê²©ì— ëŒ€í•œ ê´€ì‹¬ì„ ë³´ì´ê³  ìˆìŒ"
    
    def _extract_decision_context(self, text: str) -> str:
        """ì˜ì‚¬ê²°ì • ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        decision_keywords = ["ê³ ë¯¼", "ì„ íƒ", "ê²°ì •", "ì¶”ì²œ", "ì–´ë–¤"]
        contexts = []
        
        for keyword in decision_keywords:
            if keyword in text:
                context = self._extract_context_around_keyword(text, keyword, 40)
                if context:
                    contexts.append(context)
        
        return '; '.join(contexts[:2])
    
    def _extract_business_opportunities(self, text: str) -> List[Dict[str, Any]]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ì¶”ì¶œ"""
        opportunities = []
        
        # êµ¬ë§¤ ì‹ í˜¸
        buy_signals = ["ì‚¬ê³  ì‹¶", "êµ¬ë§¤", "ì£¼ë¬¸", "ì˜ˆì•½", "ê²°ì •í–ˆ"]
        if any(signal in text for signal in buy_signals):
            opportunities.append({
                "type": "êµ¬ë§¤_ì‹ í˜¸",
                "context": "ê³ ê°ì´ êµ¬ë§¤ ì˜í–¥ì„ ë³´ì´ê³  ìˆìŒ",
                "importance": "high",
                "action": "ì¦‰ì‹œ ìƒë‹´ ì§„í–‰ ë° êµ¬ë§¤ ì ˆì°¨ ì•ˆë‚´"
            })
        
        # ì¶”ê°€ ì •ë³´ ìš”ì²­
        info_requests = ["ìì„¸íˆ", "ë” ì•Œê³ ", "ì„¤ëª…", "ë³´ì—¬ì£¼"]
        if any(request in text for request in info_requests):
            opportunities.append({
                "type": "ì •ë³´_ìš”ì²­",
                "context": "ê³ ê°ì´ ë” ë§ì€ ì •ë³´ë¥¼ ì›í•˜ê³  ìˆìŒ",
                "importance": "medium",
                "action": "ìƒì„¸ ì œí’ˆ ì •ë³´ ë° ì¹´íƒˆë¡œê·¸ ì œê³µ"
            })
        
        return opportunities
    
    def _analyze_conversation_intent(self, text: str) -> Dict[str, Any]:
        """ëŒ€í™” ì˜ë„ ë¶„ì„"""
        
        intent_scores = {}
        
        # ê° íŒ¨í„´ë³„ ì ìˆ˜ ê³„ì‚°
        for intent, keywords in self.conversation_patterns.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > 0:
                intent_scores[intent] = score
        
        # ì£¼ìš” ì˜ë„ ê²°ì •
        if not intent_scores:
            primary_intent = "ì¼ë°˜_ëŒ€í™”"
            confidence = 0.3
        else:
            primary_intent = max(intent_scores, key=intent_scores.get)
            total_signals = sum(intent_scores.values())
            confidence = intent_scores[primary_intent] / total_signals if total_signals > 0 else 0
        
        # ì˜ë„ë³„ ì„¤ëª…
        intent_descriptions = {
            "ì •ë³´_ë¬¸ì˜": "ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œê³  ì‹¶ì–´í•©ë‹ˆë‹¤",
            "êµ¬ë§¤_ì˜í–¥": "ì‹¤ì œ êµ¬ë§¤ë¥¼ ê³ ë ¤í•˜ê³  ìˆìŠµë‹ˆë‹¤",
            "ë¹„êµ_ê²€í† ": "ì—¬ëŸ¬ ì˜µì…˜ì„ ë¹„êµí•˜ì—¬ ìµœì„ ì˜ ì„ íƒì„ í•˜ë ¤ê³  í•©ë‹ˆë‹¤",
            "ê³ ë¯¼_ìƒë‹´": "êµ¬ë§¤ ê²°ì •ì— ë„ì›€ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ì¼ë°˜_ëŒ€í™”": "ì¼ë°˜ì ì¸ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ìˆìŠµë‹ˆë‹¤"
        }
        
        return {
            "primary_intent": primary_intent,
            "confidence": round(confidence, 2),
            "description": intent_descriptions.get(primary_intent, "ì•Œ ìˆ˜ ì—†ëŠ” ì˜ë„"),
            "all_detected_intents": intent_scores,
            "urgency_level": self._assess_urgency_level(primary_intent, confidence)
        }
    
    def _assess_urgency_level(self, intent: str, confidence: float) -> str:
        """ê¸´ê¸‰ë„ í‰ê°€"""
        if intent == "êµ¬ë§¤_ì˜í–¥" and confidence > 0.7:
            return "ë†’ìŒ"
        elif intent in ["ì •ë³´_ë¬¸ì˜", "ë¹„êµ_ê²€í† "] and confidence > 0.5:
            return "ë³´í†µ"
        elif intent == "ê³ ë¯¼_ìƒë‹´":
            return "ë³´í†µ"
        else:
            return "ë‚®ìŒ"
    
    def _generate_actionable_insights(self, messages: List[Dict], intent_analysis: Dict, 
                                    context: Dict = None) -> List[Dict[str, Any]]:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        insights = []
        
        # 1. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜
        if intent_analysis["primary_intent"] == "êµ¬ë§¤_ì˜í–¥":
            insights.append({
                "type": "ì¦‰ì‹œ_ì•¡ì…˜",
                "title": "ğŸ”¥ êµ¬ë§¤ ì˜í–¥ ê³ ê° - ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”",
                "description": "ê³ ê°ì´ êµ¬ë§¤ ê²°ì • ë‹¨ê³„ì— ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆì´ ì„±ì‚¬ ê¸°íšŒì…ë‹ˆë‹¤.",
                "action": "ì¦‰ì‹œ ìƒë‹´ ì—°ê²°, íŠ¹ë³„ í• ì¸ ì œì•ˆ, êµ¬ë§¤ ì ˆì°¨ ì•ˆë‚´",
                "priority": "ìµœìš°ì„ "
            })
        
        # 2. ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
        segment = self._identify_customer_segment(messages)
        if segment:
            insights.append({
                "type": "ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸",
                "title": f"ğŸ‘¤ ê³ ê° ìœ í˜•: {segment['type']}",
                "description": segment['description'],
                "action": segment['recommended_action'],
                "priority": "ë†’ìŒ"
            })
        
        # 3. ì œí’ˆ ì¶”ì²œ ê¸°íšŒ
        product_opportunities = self._identify_product_opportunities(messages)
        insights.extend(product_opportunities)
        
        # 4. ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ
        risks_and_opportunities = self._assess_risks_and_opportunities(intent_analysis, messages)
        insights.extend(risks_and_opportunities)
        
        return insights[:5]  # ìƒìœ„ 5ê°œë§Œ
    
    def _identify_customer_segment(self, messages: List[Dict]) -> Optional[Dict[str, Any]]:
        """ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ì‹ë³„"""
        
        # ì œí’ˆ ê´€ì‹¬ë„ ë¶„ì„
        product_interests = []
        for msg in messages:
            if msg.get("type", "").endswith("_ì–¸ê¸‰"):
                product_interests.append(msg["keyword"])
        
        # ëª©ì  ë¶„ì„
        purposes = []
        for msg in messages:
            if "ëª©ì " in msg.get("type", ""):
                purposes.append(msg["type"].replace("_ëª©ì ", ""))
        
        # ì„¸ê·¸ë¨¼íŠ¸ ê²°ì •
        if "ê²°í˜¼" in purposes or "ì•½í˜¼" in purposes:
            return {
                "type": "ë¸Œë¼ì´ëœ ê³ ê°",
                "description": "ê²°í˜¼ ê´€ë ¨ ì£¼ì–¼ë¦¬ë¥¼ ì°¾ê³  ìˆëŠ” ê³ ê°",
                "recommended_action": "ë¸Œë¼ì´ëœ ì»¬ë ‰ì…˜ ì¶”ì²œ, ì»¤í”Œ í• ì¸ ì œì•ˆ, ë§ì¶¤ ì„œë¹„ìŠ¤ ì•ˆë‚´"
            }
        elif "ì„ ë¬¼" in purposes:
            return {
                "type": "ì„ ë¬¼ êµ¬ë§¤ ê³ ê°",
                "description": "ëˆ„êµ°ê°€ë¥¼ ìœ„í•œ ì„ ë¬¼ì„ ì°¾ê³  ìˆëŠ” ê³ ê°",
                "recommended_action": "ì„ ë¬¼ í¬ì¥ ì„œë¹„ìŠ¤, ê°€ê²©ëŒ€ë³„ ì¶”ì²œ, êµí™˜/ë°˜í’ˆ ì •ì±… ì•ˆë‚´"
            }
        elif any("ê°€ê²©" in msg.get("type", "") for msg in messages):
            return {
                "type": "ê°€ê²© ë¯¼ê° ê³ ê°",
                "description": "ê°€ê²©ì„ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•˜ëŠ” ê³ ê°",
                "recommended_action": "í• ì¸ ì´ë²¤íŠ¸ ì•ˆë‚´, ë¶„í•  ê²°ì œ ì˜µì…˜ ì œì‹œ, ê°€ì„±ë¹„ ì œí’ˆ ì¶”ì²œ"
            }
        
        return None
    
    def _identify_product_opportunities(self, messages: List[Dict]) -> List[Dict[str, Any]]:
        """ì œí’ˆ ì¶”ì²œ ê¸°íšŒ ì‹ë³„"""
        opportunities = []
        
        mentioned_products = []
        for msg in messages:
            if msg.get("type", "").startswith("ì œí’ˆ_"):
                mentioned_products.append(msg["keyword"])
        
        if mentioned_products:
            opportunities.append({
                "type": "ì œí’ˆ_ì¶”ì²œ",
                "title": f"ğŸ’ ê´€ì‹¬ ì œí’ˆ: {', '.join(mentioned_products)}",
                "description": f"ê³ ê°ì´ {', '.join(mentioned_products)}ì— ê´€ì‹¬ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤",
                "action": f"ê´€ë ¨ ì œí’ˆ ë¼ì¸ì—… ì†Œê°œ, ì‹œì°© ê¸°íšŒ ì œê³µ, ì„¸íŠ¸ í• ì¸ ì œì•ˆ",
                "priority": "ë†’ìŒ"
            })
        
        return opportunities
    
    def _assess_risks_and_opportunities(self, intent_analysis: Dict, 
                                      messages: List[Dict]) -> List[Dict[str, Any]]:
        """ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ í‰ê°€"""
        assessments = []
        
        # ê¸´ê¸‰ë„ê°€ ë†’ì€ ê²½ìš°
        if intent_analysis["urgency_level"] == "ë†’ìŒ":
            assessments.append({
                "type": "ê¸°íšŒ",
                "title": "âš¡ ê³ ì „í™˜ ê¸°íšŒ",
                "description": "ì§€ê¸ˆì´ ì„±ì‚¬ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ì‹œì ì…ë‹ˆë‹¤",
                "action": "ìµœê³  ìˆ˜ì¤€ì˜ ì„œë¹„ìŠ¤ ì œê³µ, ì˜ì‚¬ê²°ì •ê¶Œì ì¦‰ì‹œ ë°°ì •",
                "priority": "ìµœìš°ì„ "
            })
        
        # ê³ ë¯¼í•˜ê³  ìˆëŠ” ê²½ìš°
        if any("ê³ ë¯¼" in msg.get("type", "") for msg in messages):
            assessments.append({
                "type": "ë¦¬ìŠ¤í¬",
                "title": "ğŸ¤” ì´íƒˆ ìœ„í—˜",
                "description": "ê³ ê°ì´ êµ¬ë§¤ë¥¼ ë§ì„¤ì´ê³  ìˆì–´ ì´íƒˆ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤",
                "action": "ì¶”ê°€ í˜œíƒ ì œê³µ, ì „ë¬¸ ìƒë‹´ì‚¬ ë°°ì •, ì²´í—˜ ê¸°íšŒ í™•ëŒ€",
                "priority": "ë†’ìŒ"
            })
        
        return assessments
    
    def _create_user_friendly_summary(self, messages: List[Dict], intent_analysis: Dict, 
                                    insights: List[Dict]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½ ìƒì„±"""
        
        # í•µì‹¬ í•œ ì¤„ ìš”ì•½
        main_message = self._generate_one_line_summary(intent_analysis, messages)
        
        # ì£¼ìš” í¬ì¸íŠ¸ (3-5ê°œ)
        key_points = self._extract_key_points(messages, insights)
        
        # ì¶”ì²œ ì•¡ì…˜ (ì‹¤í–‰ ê°€ëŠ¥í•œ ê²ƒë“¤)
        recommended_actions = self._extract_recommended_actions(insights)
        
        # ê³ ê° ìƒíƒœ ìš”ì•½
        customer_status = self._summarize_customer_status(intent_analysis, messages)
        
        return {
            "one_line_summary": main_message,
            "key_points": key_points,
            "customer_status": customer_status,
            "recommended_actions": recommended_actions,
            "urgency_indicator": intent_analysis["urgency_level"],
            "confidence_score": intent_analysis["confidence"]
        }
    
    def _generate_one_line_summary(self, intent_analysis: Dict, messages: List[Dict]) -> str:
        """í•µì‹¬ í•œ ì¤„ ìš”ì•½ ìƒì„±"""
        
        intent = intent_analysis["primary_intent"]
        
        if intent == "êµ¬ë§¤_ì˜í–¥":
            return "ğŸ”¥ ê³ ê°ì´ êµ¬ë§¤ ì˜ì‚¬ë¥¼ ëª…í™•íˆ í‘œí˜„í–ˆìŠµë‹ˆë‹¤ - ì¦‰ì‹œ ìƒë‹´ ì§„í–‰ í•„ìš”"
        elif intent == "ì •ë³´_ë¬¸ì˜":
            products = [msg["keyword"] for msg in messages if msg.get("type", "").startswith("ì œí’ˆ_")]
            if products:
                return f"ğŸ“‹ ê³ ê°ì´ {', '.join(products[:2])}ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í•˜ê³  ìˆìŠµë‹ˆë‹¤"
            else:
                return "ğŸ“‹ ê³ ê°ì´ ì œí’ˆ ì •ë³´ë¥¼ ë¬¸ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤"
        elif intent == "ê³ ë¯¼_ìƒë‹´":
            return "ğŸ¤” ê³ ê°ì´ êµ¬ë§¤ ê²°ì •ì— ë„ì›€ì„ í•„ìš”ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤ - ìƒë‹´ ì§€ì› í•„ìš”"
        elif intent == "ë¹„êµ_ê²€í† ":
            return "âš–ï¸ ê³ ê°ì´ ì—¬ëŸ¬ ì˜µì…˜ì„ ë¹„êµ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤ - ì°¨ë³„í™” í¬ì¸íŠ¸ ì–´í•„ í•„ìš”"
        else:
            return "ğŸ’¬ ê³ ê°ê³¼ì˜ ì¼ë°˜ì ì¸ ìƒë‹´ì´ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤"
    
    def _extract_key_points(self, messages: List[Dict], insights: List[Dict]) -> List[str]:
        """ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ"""
        points = []
        
        # ë©”ì‹œì§€ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸
        for msg in messages[:3]:  # ìƒìœ„ 3ê°œ
            if msg.get("insight"):
                points.append(msg["insight"])
            elif msg.get("context"):
                points.append(f"{msg['type'].replace('_', ' ')}: {msg['context'][:50]}...")
        
        # ì¸ì‚¬ì´íŠ¸ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸
        for insight in insights[:2]:  # ìƒìœ„ 2ê°œ
            if insight.get("description"):
                points.append(insight["description"])
        
        return points[:5]  # ìµœëŒ€ 5ê°œ
    
    def _extract_recommended_actions(self, insights: List[Dict]) -> List[str]:
        """ì¶”ì²œ ì•¡ì…˜ ì¶”ì¶œ"""
        actions = []
        
        for insight in insights:
            if insight.get("action"):
                actions.append(f"â€¢ {insight['action']}")
        
        return actions[:3]  # ìµœëŒ€ 3ê°œ
    
    def _summarize_customer_status(self, intent_analysis: Dict, messages: List[Dict]) -> str:
        """ê³ ê° ìƒíƒœ ìš”ì•½"""
        
        intent = intent_analysis["primary_intent"]
        confidence = intent_analysis["confidence"]
        
        status_map = {
            "êµ¬ë§¤_ì˜í–¥": f"ğŸŸ¢ êµ¬ë§¤ ì¤€ë¹„ ìƒíƒœ (í™•ì‹ ë„: {confidence*100:.0f}%)",
            "ì •ë³´_ë¬¸ì˜": f"ğŸŸ¡ ì •ë³´ ìˆ˜ì§‘ ë‹¨ê³„ (ê´€ì‹¬ë„: {confidence*100:.0f}%)",
            "ê³ ë¯¼_ìƒë‹´": f"ğŸŸ  ì˜ì‚¬ê²°ì • ê³ ë¯¼ ì¤‘ (ì§€ì› í•„ìš”ë„: {confidence*100:.0f}%)",
            "ë¹„êµ_ê²€í† ": f"ğŸ”µ ì˜µì…˜ ë¹„êµ ê²€í†  ì¤‘ (ê²€í†  ê¹Šì´: {confidence*100:.0f}%)",
            "ì¼ë°˜_ëŒ€í™”": f"âšª ì¼ë°˜ ìƒë‹´ ì§„í–‰ ì¤‘"
        }
        
        return status_map.get(intent, "âšª ìƒíƒœ íŒŒì•… ì¤‘")
    
    def _get_speaker_distribution(self, speakers: List[Dict]) -> Dict[str, int]:
        """í™”ìë³„ ë°œì–¸ ë¹„ìœ¨"""
        distribution = {}
        for speaker_info in speakers:
            speaker = speaker_info["speaker"]
            distribution[speaker] = distribution.get(speaker, 0) + 1
        return distribution
    
    def _get_dominant_speaker(self, speakers: List[Dict]) -> str:
        """ì£¼ìš” í™”ì ì‹ë³„"""
        distribution = self._get_speaker_distribution(speakers)
        if not distribution:
            return "unknown"
        return max(distribution, key=distribution.get)
    
    def _create_empty_result(self) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ìƒì„±"""
        return {
            "status": "no_content",
            "main_summary": {
                "one_line_summary": "ë¶„ì„í•  ì¶©ë¶„í•œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤",
                "key_points": [],
                "customer_status": "âšª ë‚´ìš© ë¶€ì¡±",
                "recommended_actions": ["ë” ë§ì€ ëŒ€í™” ë‚´ìš© í•„ìš”"],
                "urgency_indicator": "ë‚®ìŒ",
                "confidence_score": 0.0
            },
            "key_messages": [],
            "conversation_analysis": {},
            "analysis_timestamp": datetime.now().isoformat()
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
global_message_extractor = ComprehensiveMessageExtractor()

def extract_comprehensive_messages(text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """ê°„í¸ ë©”ì‹œì§€ ì¶”ì¶œ í•¨ìˆ˜"""
    return global_message_extractor.extract_key_messages(text, context)

def extract_speaker_message(multimodal_data: Dict[str, Any], context: Dict[str, Any] = None) -> Dict[str, Any]:
    """ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ë¡œë¶€í„° í™”ì ë©”ì‹œì§€ ì¶”ì¶œ"""
    try:
        # ëª¨ë“  í…ìŠ¤íŠ¸ ì½˜í…ì¸  í†µí•©
        combined_text = ""
        
        if multimodal_data.get('audio_analysis'):
            audio_text = multimodal_data['audio_analysis'].get('full_text', '')
            combined_text += f"[ìŒì„±] {audio_text}\n"
        
        if multimodal_data.get('image_analysis'):
            for img_result in multimodal_data['image_analysis']:
                if img_result.get('extracted_text'):
                    combined_text += f"[ì´ë¯¸ì§€] {img_result['extracted_text']}\n"
        
        if multimodal_data.get('video_analysis'):
            video_text = multimodal_data['video_analysis'].get('full_text', '')
            combined_text += f"[ì˜ìƒ] {video_text}\n"
        
        if not combined_text.strip():
            return {
                "status": "error",
                "error": "ì¶”ì¶œí•  í…ìŠ¤íŠ¸ ì½˜í…ì¸ ê°€ ì—†ìŒ",
                "comprehensive_analysis": {}
            }
        
        # ì¢…í•© ë¶„ì„ ìˆ˜í–‰
        comprehensive_analysis = global_message_extractor.extract_key_messages(combined_text, context)
        
        return {
            "status": "success",
            "comprehensive_analysis": comprehensive_analysis,
            "source_data_types": list(multimodal_data.keys()),
            "combined_text_length": len(combined_text)
        }
        
    except Exception as e:
        return {
            "status": "error", 
            "error": f"í™”ì ë©”ì‹œì§€ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}",
            "comprehensive_analysis": {}
        }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_text = """
    ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ì´ì•„ëª¬ë“œ ë°˜ì§€ ê°€ê²©ì´ ê¶ê¸ˆí•´ì„œìš”. 
    1ìºëŸ¿ ì •ë„ë¡œ ìƒê°í•˜ê³  ìˆëŠ”ë° ì–¼ë§ˆ ì •ë„ í• ê¹Œìš”?
    ê²°í˜¼ ì˜ˆì •ì´ë¼ì„œ ì˜ˆìœ ê±¸ë¡œ ì°¾ê³  ìˆì–´ìš”.
    ì˜ˆì‚°ì€ 500ë§Œì› ì •ë„ ìƒê°í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    """
    
    extractor = ComprehensiveMessageExtractor()
    result = extractor.extract_key_messages(test_text)
    
    print("=== ë©”ì‹œì§€ ì¶”ì¶œ ê²°ê³¼ ===")
    summary = result["main_summary"]
    print(f"í•µì‹¬ ìš”ì•½: {summary['one_line_summary']}")
    print(f"ê³ ê° ìƒíƒœ: {summary['customer_status']}")
    print("ì£¼ìš” í¬ì¸íŠ¸:")
    for point in summary['key_points']:
        print(f"  - {point}")
    print("ì¶”ì²œ ì•¡ì…˜:")
    for action in summary['recommended_actions']:
        print(f"  {action}")