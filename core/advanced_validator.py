# Phase 2 Week 3 Day 3: ê³ ê¸‰ í¬ë¡œìŠ¤ ê²€ì¦ ì‹œìŠ¤í…œ
# AI ê¸°ë°˜ ì§€ëŠ¥í˜• ê²€ì¦ + ì´ìƒì¹˜ ê°ì§€ + í’ˆì§ˆ ì ìˆ˜ ì •êµí™”

import asyncio
import numpy as np
import json
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import re
import math
from collections import Counter, defaultdict
import time
from pathlib import Path
import logging

# í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¶„ì„ì„ ìœ„í•œ ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” transformers ì‚¬ìš© ê¶Œì¥)
from difflib import SequenceMatcher
import hashlib

class ValidationLevel(Enum):
    """ê²€ì¦ ë ˆë²¨"""
    BASIC = "basic"           # ê¸°ë³¸ ê²€ì¦
    ADVANCED = "advanced"     # ê³ ê¸‰ ê²€ì¦  
    AI_POWERED = "ai_powered" # AI ê¸°ë°˜ ê²€ì¦
    COMPREHENSIVE = "comprehensive"  # ì¢…í•© ê²€ì¦

class AnomalyType(Enum):
    """ì´ìƒì¹˜ ìœ í˜•"""
    CONTENT_MISMATCH = "content_mismatch"      # ë‚´ìš© ë¶ˆì¼ì¹˜
    QUALITY_DEGRADATION = "quality_degradation" # í’ˆì§ˆ ì €í•˜
    PROCESSING_ERROR = "processing_error"       # ì²˜ë¦¬ ì˜¤ë¥˜
    STATISTICAL_OUTLIER = "statistical_outlier" # í†µê³„ì  ì´ìƒì¹˜
    SEMANTIC_INCONSISTENCY = "semantic_inconsistency" # ì˜ë¯¸ì  ë¹„ì¼ê´€ì„±

@dataclass
class ValidationMetrics:
    """ê²€ì¦ ì§€í‘œ"""
    content_similarity: float = 0.0      # ë‚´ìš© ìœ ì‚¬ë„ (0-1)
    semantic_coherence: float = 0.0      # ì˜ë¯¸ì  ì¼ê´€ì„± (0-1)
    statistical_consistency: float = 0.0  # í†µê³„ì  ì¼ê´€ì„± (0-1)
    quality_score: float = 0.0           # í’ˆì§ˆ ì ìˆ˜ (0-1)
    confidence_level: float = 0.0        # ì‹ ë¢°ë„ (0-1)
    anomaly_score: float = 0.0           # ì´ìƒì¹˜ ì ìˆ˜ (0-1, ë‚®ì„ìˆ˜ë¡ ì •ìƒ)

@dataclass
class CrossValidationItem:
    """í¬ë¡œìŠ¤ ê²€ì¦ í•­ëª©"""
    item_id: str
    content: str
    metadata: Dict[str, Any]
    processing_quality: float
    source_reliability: float
    extracted_features: Dict[str, Any] = field(default_factory=dict)
    validation_metrics: ValidationMetrics = field(default_factory=ValidationMetrics)

@dataclass
class AnomalyDetection:
    """ì´ìƒì¹˜ íƒì§€ ê²°ê³¼"""
    anomaly_type: AnomalyType
    severity: float  # 0-1
    description: str
    affected_items: List[str]
    suggested_action: str
    confidence: float

@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    overall_score: float
    individual_scores: Dict[str, float]
    anomalies: List[AnomalyDetection]
    recommendations: List[str]
    validation_level: ValidationLevel
    processing_time: float

class JewelrySemanticAnalyzer:
    """ì£¼ì–¼ë¦¬ íŠ¹í™” ì˜ë¯¸ ë¶„ì„ê¸°"""
    
    def __init__(self):
        # ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ê°€ì¤‘ì¹˜
        self.jewelry_terms_weights = {
            # í•µì‹¬ ìš©ì–´ (ë†’ì€ ê°€ì¤‘ì¹˜)
            "ë‹¤ì´ì•„ëª¬ë“œ": 3.0, "diamond": 3.0,
            "ë£¨ë¹„": 2.5, "ruby": 2.5,
            "ì‚¬íŒŒì´ì–´": 2.5, "sapphire": 2.5,
            "ì—ë©”ë„ë“œ": 2.5, "emerald": 2.5,
            
            # í’ˆì§ˆ ìš©ì–´
            "4C": 2.8, "ìºëŸ¿": 2.5, "carat": 2.5,
            "ì»¬ëŸ¬": 2.3, "color": 2.3,
            "í´ë˜ë¦¬í‹°": 2.3, "clarity": 2.3,
            "ì»·": 2.3, "cut": 2.3,
            
            # ì¸ì¦ ìš©ì–´
            "GIA": 2.8, "AGS": 2.0, "SSEF": 2.0,
            "ê°ì •ì„œ": 2.5, "certificate": 2.5,
            "ì¸ì¦": 2.0, "certification": 2.0,
            
            # ê°€ê²© ìš©ì–´
            "ë„ë§¤ê°€": 2.2, "wholesale": 2.2,
            "ì†Œë§¤ê°€": 2.0, "retail": 2.0,
            "ì‹œì¤‘ê°€": 1.8, "market": 1.8,
            
            # ê¸°ìˆ  ìš©ì–´
            "ë¸Œë¦´ë¦¬ì–¸íŠ¸": 1.8, "brilliant": 1.8,
            "í”„ë¦°ì„¸ìŠ¤": 1.8, "princess": 1.8,
            "ì„¸íŒ…": 1.5, "setting": 1.5
        }
        
        # ì˜ë¯¸ ê·¸ë£¹ (ìœ ì‚¬í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ìš©ì–´ë“¤)
        self.semantic_groups = {
            "precious_stones": ["ë‹¤ì´ì•„ëª¬ë“œ", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", "ì—ë©”ë„ë“œ", "diamond", "ruby", "sapphire", "emerald"],
            "quality_grades": ["4C", "ìºëŸ¿", "ì»¬ëŸ¬", "í´ë˜ë¦¬í‹°", "ì»·", "carat", "color", "clarity", "cut"],
            "certifications": ["GIA", "AGS", "SSEF", "ê°ì •ì„œ", "ì¸ì¦", "certificate", "certification"],
            "pricing": ["ë„ë§¤ê°€", "ì†Œë§¤ê°€", "ì‹œì¤‘ê°€", "wholesale", "retail", "market"],
            "cuts": ["ë¸Œë¦´ë¦¬ì–¸íŠ¸", "í”„ë¦°ì„¸ìŠ¤", "ë¼ìš´ë“œ", "brilliant", "princess", "round"]
        }
        
        # íŒ¨í„´ ì¸ì‹ìš© ì •ê·œí‘œí˜„ì‹
        self.price_patterns = [
            r'\$[\d,]+',           # $1,000
            r'[\d,]+ë‹¬ëŸ¬',          # 1000ë‹¬ëŸ¬
            r'[\d,]+ì›',           # 1000ì›
            r'ìºëŸ¿ë‹¹\s*[\d,]+',      # ìºëŸ¿ë‹¹ 1000
        ]
        
        self.grade_patterns = [
            r'[A-Z]\s*ë“±ê¸‰',       # Dë“±ê¸‰
            r'[DEFGHIJK][12]?',    # D, E, F1, VS1 ë“±
            r'FL|IF|VVS[12]|VS[12]|SI[12]|I[123]',  # í´ë˜ë¦¬í‹° ë“±ê¸‰
        ]
    
    def extract_semantic_features(self, text: str) -> Dict[str, Any]:
        """ì˜ë¯¸ì  íŠ¹ì§• ì¶”ì¶œ"""
        features = {
            "jewelry_terms": [],
            "prices": [],
            "grades": [],
            "semantic_density": 0.0,
            "domain_relevance": 0.0,
            "technical_depth": 0.0
        }
        
        text_lower = text.lower()
        words = text.split()
        
        # ì£¼ì–¼ë¦¬ ìš©ì–´ ì¶”ì¶œ
        total_weight = 0.0
        for term, weight in self.jewelry_terms_weights.items():
            if term.lower() in text_lower:
                features["jewelry_terms"].append({
                    "term": term,
                    "weight": weight,
                    "occurrences": text_lower.count(term.lower())
                })
                total_weight += weight
        
        # ê°€ê²© ì •ë³´ ì¶”ì¶œ
        for pattern in self.price_patterns:
            matches = re.findall(pattern, text)
            features["prices"].extend(matches)
        
        # ë“±ê¸‰ ì •ë³´ ì¶”ì¶œ
        for pattern in self.grade_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            features["grades"].extend(matches)
        
        # ì˜ë¯¸ ë°€ë„ ê³„ì‚° (ì£¼ì–¼ë¦¬ ìš©ì–´ ë°€ë„)
        if len(words) > 0:
            features["semantic_density"] = len(features["jewelry_terms"]) / len(words)
            features["domain_relevance"] = min(1.0, total_weight / 10.0)  # ì •ê·œí™”
        
        # ê¸°ìˆ ì  ê¹Šì´ (ì „ë¬¸ ìš©ì–´ ë³µì¡ë„)
        tech_terms = ["4C", "GIA", "í´ë˜ë¦¬í‹°", "ë¸Œë¦´ë¦¬ì–¸íŠ¸", "ì„¸íŒ…"]
        tech_count = sum(1 for term in tech_terms if term.lower() in text_lower)
        features["technical_depth"] = min(1.0, tech_count / 5.0)
        
        return features
    
    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        features1 = self.extract_semantic_features(text1)
        features2 = self.extract_semantic_features(text2)
        
        # ìš©ì–´ ê¸°ë°˜ ìœ ì‚¬ë„
        terms1 = set(item["term"] for item in features1["jewelry_terms"])
        terms2 = set(item["term"] for item in features2["jewelry_terms"])
        
        if not terms1 and not terms2:
            term_similarity = 1.0
        elif not terms1 or not terms2:
            term_similarity = 0.0
        else:
            intersection = len(terms1.intersection(terms2))
            union = len(terms1.union(terms2))
            term_similarity = intersection / union if union > 0 else 0.0
        
        # ì˜ë¯¸ ê·¸ë£¹ ê¸°ë°˜ ìœ ì‚¬ë„
        group_similarity = self._calculate_group_similarity(features1, features2)
        
        # ê°€ê²©/ë“±ê¸‰ ì •ë³´ ìœ ì‚¬ë„
        price_similarity = self._calculate_info_similarity(
            features1["prices"], features2["prices"]
        )
        grade_similarity = self._calculate_info_similarity(
            features1["grades"], features2["grades"]
        )
        
        # ê°€ì¤‘ í‰ê· 
        weights = [0.4, 0.3, 0.15, 0.15]  # ìš©ì–´, ê·¸ë£¹, ê°€ê²©, ë“±ê¸‰
        similarities = [term_similarity, group_similarity, price_similarity, grade_similarity]
        
        return sum(w * s for w, s in zip(weights, similarities))
    
    def _calculate_group_similarity(self, features1: Dict, features2: Dict) -> float:
        """ì˜ë¯¸ ê·¸ë£¹ ê¸°ë°˜ ìœ ì‚¬ë„"""
        group_scores = []
        
        for group_name, group_terms in self.semantic_groups.items():
            # ê° ê·¸ë£¹ì—ì„œ ë°œê²¬ëœ ìš©ì–´ ìˆ˜
            count1 = sum(1 for item in features1["jewelry_terms"] 
                        if item["term"] in group_terms)
            count2 = sum(1 for item in features2["jewelry_terms"] 
                        if item["term"] in group_terms)
            
            # ê·¸ë£¹ë³„ ìœ ì‚¬ë„ (ë‘˜ ë‹¤ ìš©ì–´ê°€ ìˆê±°ë‚˜ ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ìœ ì‚¬)
            if count1 > 0 and count2 > 0:
                group_score = 1.0
            elif count1 == 0 and count2 == 0:
                group_score = 0.5  # ì¤‘ë¦½
            else:
                group_score = 0.0
            
            group_scores.append(group_score)
        
        return np.mean(group_scores) if group_scores else 0.0
    
    def _calculate_info_similarity(self, info1: List, info2: List) -> float:
        """ì •ë³´ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not info1 and not info2:
            return 1.0
        if not info1 or not info2:
            return 0.0
        
        # ì§‘í•© ê¸°ë°˜ ìœ ì‚¬ë„
        set1, set2 = set(info1), set(info2)
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        
        return intersection / union if union > 0 else 0.0

class AnomalyDetector:
    """ì´ìƒì¹˜ íƒì§€ê¸°"""
    
    def __init__(self, sensitivity: float = 0.7):
        self.sensitivity = sensitivity  # ë¯¼ê°ë„ (0-1, ë†’ì„ìˆ˜ë¡ ë¯¼ê°)
        self.statistical_thresholds = {
            "content_length_ratio": 3.0,      # ë‚´ìš© ê¸¸ì´ ë¹„ìœ¨ ì„ê³„ê°’
            "quality_deviation": 0.3,         # í’ˆì§ˆ í¸ì°¨ ì„ê³„ê°’
            "similarity_threshold": 0.3,      # ìœ ì‚¬ë„ ì„ê³„ê°’
            "consistency_threshold": 0.5      # ì¼ê´€ì„± ì„ê³„ê°’
        }
    
    def detect_anomalies(self, validation_items: List[CrossValidationItem]) -> List[AnomalyDetection]:
        """ì´ìƒì¹˜ íƒì§€"""
        anomalies = []
        
        if len(validation_items) < 2:
            return anomalies
        
        # 1. ë‚´ìš© ë¶ˆì¼ì¹˜ íƒì§€
        content_anomalies = self._detect_content_mismatches(validation_items)
        anomalies.extend(content_anomalies)
        
        # 2. í’ˆì§ˆ ì €í•˜ íƒì§€
        quality_anomalies = self._detect_quality_degradation(validation_items)
        anomalies.extend(quality_anomalies)
        
        # 3. í†µê³„ì  ì´ìƒì¹˜ íƒì§€
        statistical_anomalies = self._detect_statistical_outliers(validation_items)
        anomalies.extend(statistical_anomalies)
        
        # 4. ì˜ë¯¸ì  ë¹„ì¼ê´€ì„± íƒì§€
        semantic_anomalies = self._detect_semantic_inconsistencies(validation_items)
        anomalies.extend(semantic_anomalies)
        
        # ì‹¬ê°ë„ë³„ ì •ë ¬
        anomalies.sort(key=lambda x: x.severity, reverse=True)
        
        return anomalies
    
    def _detect_content_mismatches(self, items: List[CrossValidationItem]) -> List[AnomalyDetection]:
        """ë‚´ìš© ë¶ˆì¼ì¹˜ íƒì§€"""
        anomalies = []
        
        # ë‚´ìš© ê¸¸ì´ ë¹„êµ
        lengths = [len(item.content) for item in items]
        mean_length = np.mean(lengths)
        std_length = np.std(lengths)
        
        for i, item in enumerate(items):
            if std_length > 0:
                z_score = abs(lengths[i] - mean_length) / std_length
                if z_score > self.statistical_thresholds["content_length_ratio"]:
                    severity = min(1.0, z_score / 5.0)
                    
                    anomalies.append(AnomalyDetection(
                        anomaly_type=AnomalyType.CONTENT_MISMATCH,
                        severity=severity,
                        description=f"ë‚´ìš© ê¸¸ì´ ì´ìƒ: í‰ê·  ëŒ€ë¹„ {z_score:.1f} í‘œì¤€í¸ì°¨",
                        affected_items=[item.item_id],
                        suggested_action="ë‚´ìš© ì™„ì „ì„± ì¬ê²€í†  í•„ìš”",
                        confidence=0.8
                    ))
        
        return anomalies
    
    def _detect_quality_degradation(self, items: List[CrossValidationItem]) -> List[AnomalyDetection]:
        """í’ˆì§ˆ ì €í•˜ íƒì§€"""
        anomalies = []
        
        qualities = [item.processing_quality for item in items]
        mean_quality = np.mean(qualities)
        
        low_quality_items = []
        for item in items:
            if item.processing_quality < mean_quality - self.statistical_thresholds["quality_deviation"]:
                low_quality_items.append(item.item_id)
        
        if low_quality_items:
            severity = len(low_quality_items) / len(items)
            
            anomalies.append(AnomalyDetection(
                anomaly_type=AnomalyType.QUALITY_DEGRADATION,
                severity=severity,
                description=f"{len(low_quality_items)}ê°œ í•­ëª©ì—ì„œ í’ˆì§ˆ ì €í•˜ ê°ì§€",
                affected_items=low_quality_items,
                suggested_action="í’ˆì§ˆì´ ë‚®ì€ í•­ëª© ì¬ì²˜ë¦¬ ê²€í† ",
                confidence=0.9
            ))
        
        return anomalies
    
    def _detect_statistical_outliers(self, items: List[CrossValidationItem]) -> List[AnomalyDetection]:
        """í†µê³„ì  ì´ìƒì¹˜ íƒì§€"""
        anomalies = []
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì´ìƒì¹˜
        reliabilities = [item.source_reliability for item in items]
        
        if len(reliabilities) > 2:
            q1 = np.percentile(reliabilities, 25)
            q3 = np.percentile(reliabilities, 75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            outlier_items = []
            for item in items:
                if item.source_reliability < lower_bound or item.source_reliability > upper_bound:
                    outlier_items.append(item.item_id)
            
            if outlier_items:
                severity = len(outlier_items) / len(items)
                
                anomalies.append(AnomalyDetection(
                    anomaly_type=AnomalyType.STATISTICAL_OUTLIER,
                    severity=severity,
                    description=f"ì‹ ë¢°ë„ í†µê³„ì  ì´ìƒì¹˜: {len(outlier_items)}ê°œ í•­ëª©",
                    affected_items=outlier_items,
                    suggested_action="ì´ìƒì¹˜ í•­ëª©ì˜ ì²˜ë¦¬ ê³¼ì • ì¬ê²€í† ",
                    confidence=0.7
                ))
        
        return anomalies
    
    def _detect_semantic_inconsistencies(self, items: List[CrossValidationItem]) -> List[AnomalyDetection]:
        """ì˜ë¯¸ì  ë¹„ì¼ê´€ì„± íƒì§€"""
        anomalies = []
        
        semantic_analyzer = JewelrySemanticAnalyzer()
        
        # í•­ëª© ê°„ ì˜ë¯¸ì  ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        n_items = len(items)
        similarity_matrix = np.zeros((n_items, n_items))
        
        for i in range(n_items):
            for j in range(i + 1, n_items):
                similarity = semantic_analyzer.calculate_semantic_similarity(
                    items[i].content, items[j].content
                )
                similarity_matrix[i][j] = similarity
                similarity_matrix[j][i] = similarity
        
        # í‰ê·  ìœ ì‚¬ë„ê°€ ë‚®ì€ í•­ëª© íƒì§€
        avg_similarities = np.mean(similarity_matrix, axis=1)
        threshold = self.statistical_thresholds["similarity_threshold"]
        
        inconsistent_items = []
        for i, avg_sim in enumerate(avg_similarities):
            if avg_sim < threshold:
                inconsistent_items.append(items[i].item_id)
        
        if inconsistent_items:
            severity = len(inconsistent_items) / len(items)
            
            anomalies.append(AnomalyDetection(
                anomaly_type=AnomalyType.SEMANTIC_INCONSISTENCY,
                severity=severity,
                description=f"ì˜ë¯¸ì  ë¹„ì¼ê´€ì„±: {len(inconsistent_items)}ê°œ í•­ëª©",
                affected_items=inconsistent_items,
                suggested_action="ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ì—†ëŠ” í•­ëª© ê²€í† ",
                confidence=0.6
            ))
        
        return anomalies

class AdvancedCrossValidator:
    """ê³ ê¸‰ í¬ë¡œìŠ¤ ê²€ì¦ê¸°"""
    
    def __init__(self, validation_level: ValidationLevel = ValidationLevel.COMPREHENSIVE):
        self.validation_level = validation_level
        self.semantic_analyzer = JewelrySemanticAnalyzer()
        self.anomaly_detector = AnomalyDetector()
        self.logger = logging.getLogger(__name__)
        
        # ê²€ì¦ ê°€ì¤‘ì¹˜ (ê²€ì¦ ë ˆë²¨ì— ë”°ë¼ ì¡°ì •)
        self.validation_weights = self._get_validation_weights()
    
    def _get_validation_weights(self) -> Dict[str, float]:
        """ê²€ì¦ ë ˆë²¨ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        if self.validation_level == ValidationLevel.BASIC:
            return {
                "content_similarity": 0.6,
                "statistical_consistency": 0.4,
                "semantic_coherence": 0.0,
                "anomaly_penalty": 0.1
            }
        elif self.validation_level == ValidationLevel.ADVANCED:
            return {
                "content_similarity": 0.4,
                "statistical_consistency": 0.3,
                "semantic_coherence": 0.3,
                "anomaly_penalty": 0.2
            }
        else:  # AI_POWERED, COMPREHENSIVE
            return {
                "content_similarity": 0.3,
                "statistical_consistency": 0.25,
                "semantic_coherence": 0.35,
                "anomaly_penalty": 0.3
            }
    
    async def validate_cross_consistency(
        self, 
        items: List[Dict[str, Any]], 
        context: Dict[str, Any] = None
    ) -> ValidationResult:
        """í¬ë¡œìŠ¤ ì¼ê´€ì„± ê²€ì¦"""
        
        start_time = time.time()
        
        # ê²€ì¦ í•­ëª© ì¤€ë¹„
        validation_items = self._prepare_validation_items(items)
        
        # ê° í•­ëª©ë³„ ì§€í‘œ ê³„ì‚°
        await self._calculate_individual_metrics(validation_items)
        
        # í¬ë¡œìŠ¤ ê²€ì¦ ìˆ˜í–‰
        cross_validation_score = await self._perform_cross_validation(validation_items)
        
        # ì´ìƒì¹˜ íƒì§€
        anomalies = self.anomaly_detector.detect_anomalies(validation_items)
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_score(validation_items, anomalies)
        
        # ê°œë³„ ì ìˆ˜ ì¶”ì¶œ
        individual_scores = {
            item.item_id: item.validation_metrics.quality_score 
            for item in validation_items
        }
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        recommendations = self._generate_recommendations(validation_items, anomalies)
        
        processing_time = time.time() - start_time
        
        return ValidationResult(
            overall_score=overall_score,
            individual_scores=individual_scores,
            anomalies=anomalies,
            recommendations=recommendations,
            validation_level=self.validation_level,
            processing_time=processing_time
        )
    
    def _prepare_validation_items(self, items: List[Dict[str, Any]]) -> List[CrossValidationItem]:
        """ê²€ì¦ í•­ëª© ì¤€ë¹„"""
        validation_items = []
        
        for i, item in enumerate(items):
            validation_item = CrossValidationItem(
                item_id=item.get("id", f"item_{i}"),
                content=item.get("content", ""),
                metadata=item.get("metadata", {}),
                processing_quality=item.get("quality", 0.8),
                source_reliability=item.get("reliability", 0.8)
            )
            
            # ì˜ë¯¸ì  íŠ¹ì§• ì¶”ì¶œ
            validation_item.extracted_features = self.semantic_analyzer.extract_semantic_features(
                validation_item.content
            )
            
            validation_items.append(validation_item)
        
        return validation_items
    
    async def _calculate_individual_metrics(self, items: List[CrossValidationItem]):
        """ê°œë³„ í•­ëª© ì§€í‘œ ê³„ì‚°"""
        
        for item in items:
            metrics = ValidationMetrics()
            
            # ë„ë©”ì¸ ê´€ë ¨ì„± ì ìˆ˜
            domain_relevance = item.extracted_features.get("domain_relevance", 0.0)
            
            # ê¸°ìˆ ì  ê¹Šì´ ì ìˆ˜
            technical_depth = item.extracted_features.get("technical_depth", 0.0)
            
            # ì˜ë¯¸ ë°€ë„ ì ìˆ˜
            semantic_density = item.extracted_features.get("semantic_density", 0.0)
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì—¬ëŸ¬ ìš”ì†Œ ê²°í•©)
            quality_components = [
                item.processing_quality,
                item.source_reliability,
                domain_relevance,
                technical_depth * 0.5,  # ê¸°ìˆ  ê¹Šì´ëŠ” ë‚®ì€ ê°€ì¤‘ì¹˜
                semantic_density * 0.3   # ì˜ë¯¸ ë°€ë„ë„ ë‚®ì€ ê°€ì¤‘ì¹˜
            ]
            
            weights = [0.4, 0.3, 0.2, 0.05, 0.05]
            metrics.quality_score = sum(w * c for w, c in zip(weights, quality_components))
            
            # ê¸°ë³¸ ì‹ ë¢°ë„ ì„¤ì •
            metrics.confidence_level = item.source_reliability
            
            item.validation_metrics = metrics
    
    async def _perform_cross_validation(self, items: List[CrossValidationItem]) -> float:
        """í¬ë¡œìŠ¤ ê²€ì¦ ìˆ˜í–‰"""
        
        if len(items) < 2:
            return 1.0
        
        n_items = len(items)
        similarity_scores = []
        consistency_scores = []
        
        # ëª¨ë“  ìŒì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        for i in range(n_items):
            for j in range(i + 1, n_items):
                # ë‚´ìš© ìœ ì‚¬ë„
                content_sim = self.semantic_analyzer.calculate_semantic_similarity(
                    items[i].content, items[j].content
                )
                
                # í†µê³„ì  ì¼ê´€ì„± (í’ˆì§ˆ, ì‹ ë¢°ë„)
                quality_diff = abs(items[i].processing_quality - items[j].processing_quality)
                reliability_diff = abs(items[i].source_reliability - items[j].source_reliability)
                
                stat_consistency = 1.0 - (quality_diff + reliability_diff) / 2.0
                
                similarity_scores.append(content_sim)
                consistency_scores.append(stat_consistency)
                
                # ê°œë³„ í•­ëª©ì— ì§€í‘œ ì—…ë°ì´íŠ¸
                items[i].validation_metrics.content_similarity = max(
                    items[i].validation_metrics.content_similarity, content_sim
                )
                items[j].validation_metrics.content_similarity = max(
                    items[j].validation_metrics.content_similarity, content_sim
                )
                
                items[i].validation_metrics.statistical_consistency = max(
                    items[i].validation_metrics.statistical_consistency, stat_consistency
                )
                items[j].validation_metrics.statistical_consistency = max(
                    items[j].validation_metrics.statistical_consistency, stat_consistency
                )
        
        # ì „ì²´ í¬ë¡œìŠ¤ ê²€ì¦ ì ìˆ˜
        avg_similarity = np.mean(similarity_scores) if similarity_scores else 0.0
        avg_consistency = np.mean(consistency_scores) if consistency_scores else 0.0
        
        cross_score = (avg_similarity + avg_consistency) / 2.0
        
        # ì˜ë¯¸ì  ì¼ê´€ì„± ì—…ë°ì´íŠ¸
        for item in items:
            item.validation_metrics.semantic_coherence = avg_similarity
        
        return cross_score
    
    def _calculate_overall_score(
        self, 
        items: List[CrossValidationItem], 
        anomalies: List[AnomalyDetection]
    ) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        
        # ê°œë³„ ì ìˆ˜ë“¤ì˜ í‰ê· 
        individual_avg = np.mean([item.validation_metrics.quality_score for item in items])
        
        # í¬ë¡œìŠ¤ ê²€ì¦ ì ìˆ˜
        similarity_avg = np.mean([item.validation_metrics.content_similarity for item in items])
        consistency_avg = np.mean([item.validation_metrics.statistical_consistency for item in items])
        coherence_avg = np.mean([item.validation_metrics.semantic_coherence for item in items])
        
        # ì´ìƒì¹˜ í˜ë„í‹° ê³„ì‚°
        anomaly_penalty = 0.0
        if anomalies:
            total_severity = sum(anomaly.severity for anomaly in anomalies)
            anomaly_penalty = min(0.5, total_severity / len(items))  # ìµœëŒ€ 50% í˜ë„í‹°
        
        # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
        weights = self.validation_weights
        
        weighted_score = (
            weights["content_similarity"] * similarity_avg +
            weights["statistical_consistency"] * consistency_avg +
            weights["semantic_coherence"] * coherence_avg
        )
        
        # ì´ìƒì¹˜ í˜ë„í‹° ì ìš©
        final_score = weighted_score * (1.0 - weights["anomaly_penalty"] * anomaly_penalty)
        
        return max(0.0, min(1.0, final_score))
    
    def _generate_recommendations(
        self, 
        items: List[CrossValidationItem], 
        anomalies: List[AnomalyDetection]
    ) -> List[str]:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # í’ˆì§ˆ ê¸°ë°˜ ì¶”ì²œ
        low_quality_count = sum(1 for item in items if item.validation_metrics.quality_score < 0.7)
        if low_quality_count > 0:
            recommendations.append(
                f"{low_quality_count}ê°œ í•­ëª©ì˜ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì¬ì²˜ë¦¬ë¥¼ ê²€í† í•˜ì„¸ìš”."
            )
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ
        low_similarity_count = sum(1 for item in items if item.validation_metrics.content_similarity < 0.5)
        if low_similarity_count > 0:
            recommendations.append(
                f"{low_similarity_count}ê°œ í•­ëª©ì˜ ë‚´ìš© ì¼ì¹˜ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )
        
        # ì´ìƒì¹˜ ê¸°ë°˜ ì¶”ì²œ
        critical_anomalies = [a for a in anomalies if a.severity > 0.7]
        if critical_anomalies:
            recommendations.append(
                f"{len(critical_anomalies)}ê°œì˜ ì‹¬ê°í•œ ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        # ì£¼ì–¼ë¦¬ íŠ¹í™” ì¶”ì²œ
        jewelry_terms_avg = np.mean([
            len(item.extracted_features.get("jewelry_terms", [])) 
            for item in items
        ])
        
        if jewelry_terms_avg < 2:
            recommendations.append(
                "ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‚´ìš©ì˜ ê´€ë ¨ì„±ì„ í™•ì¸í•˜ì„¸ìš”."
            )
        
        # ê¸°ë³¸ ì¶”ì²œì‚¬í•­
        if not recommendations:
            if len(items) >= 3:
                recommendations.append("ëª¨ë“  í•­ëª©ì´ ì–‘í˜¸í•œ í’ˆì§ˆì„ ë³´ì…ë‹ˆë‹¤.")
            else:
                recommendations.append("ì¶”ê°€ ê²€ì¦ì„ ìœ„í•´ ë” ë§ì€ ë°ì´í„°ë¥¼ í™•ë³´í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        return recommendations

# ì‚¬ìš© ì˜ˆì‹œ
async def demo_advanced_validation():
    """ê³ ê¸‰ í¬ë¡œìŠ¤ ê²€ì¦ ë°ëª¨"""
    
    print("ğŸ” ê³ ê¸‰ í¬ë¡œìŠ¤ ê²€ì¦ ì‹œìŠ¤í…œ ë°ëª¨")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì£¼ì–¼ë¦¬ ê´€ë ¨ ë‚´ìš©)
    test_items = [
        {
            "id": "item_1",
            "content": "ì´ ë‹¤ì´ì•„ëª¬ë“œëŠ” 1.5ìºëŸ¿ Dì»¬ëŸ¬ FL ë“±ê¸‰ìœ¼ë¡œ GIA ê°ì •ì„œê°€ ìˆìŠµë‹ˆë‹¤. ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸ ì»·ìœ¼ë¡œ ì™„ë²½í•œ ëŒ€ì¹­ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
            "quality": 0.95,
            "reliability": 0.9,
            "metadata": {"source": "main_recording", "duration": 120}
        },
        {
            "id": "item_2", 
            "content": "1.5ct Dì»¬ëŸ¬ Flawless ë‹¤ì´ì•„ëª¬ë“œì…ë‹ˆë‹¤. GIA ì¸ì¦ì„ ë°›ì•˜ìœ¼ë©° ë¼ìš´ë“œ ì»·ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë§¤ìš° ë†’ì€ í’ˆì§ˆì˜ ë³´ì„ì…ë‹ˆë‹¤.",
            "quality": 0.92,
            "reliability": 0.88,
            "metadata": {"source": "backup_recording", "duration": 115}
        },
        {
            "id": "item_3",
            "content": "ì´ ë£¨ë¹„ëŠ” 2ìºëŸ¿ í¬ê¸°ë¡œ ë¯¸ì–€ë§ˆì‚°ì…ë‹ˆë‹¤. ë¹„ë‘˜ê¸°í”¼ ìƒ‰ìƒì´ ë§¤ìš° ì¸ìƒì ì´ë©° íˆíŠ¸ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "quality": 0.85,
            "reliability": 0.85,
            "metadata": {"source": "document", "pages": 2}
        },
        {
            "id": "item_4",
            "content": "ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”. ì˜¤ëŠ˜ ì ì‹¬ì€ ë­˜ ë¨¹ì„ê¹Œìš”? íšŒì˜ê°€ ëŠ¦ê²Œ ëë‚  ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
            "quality": 0.6,
            "reliability": 0.7,
            "metadata": {"source": "noise_data", "duration": 30}
        }
    ]
    
    # ë‹¤ì–‘í•œ ê²€ì¦ ë ˆë²¨ í…ŒìŠ¤íŠ¸
    validation_levels = [
        ValidationLevel.BASIC,
        ValidationLevel.ADVANCED, 
        ValidationLevel.COMPREHENSIVE
    ]
    
    for level in validation_levels:
        print(f"\nğŸ” ê²€ì¦ ë ˆë²¨: {level.value.upper()}")
        print("-" * 40)
        
        validator = AdvancedCrossValidator(validation_level=level)
        
        # ê²€ì¦ ì‹¤í–‰
        result = await validator.validate_cross_consistency(test_items)
        
        print(f"ğŸ“Š ì „ì²´ ì ìˆ˜: {result.overall_score:.3f}")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
        
        # ê°œë³„ ì ìˆ˜
        print(f"\nğŸ“‹ ê°œë³„ ì ìˆ˜:")
        for item_id, score in result.individual_scores.items():
            print(f"   {item_id}: {score:.3f}")
        
        # ì´ìƒì¹˜ íƒì§€ ê²°ê³¼
        if result.anomalies:
            print(f"\nâš ï¸ ì´ìƒì¹˜ íƒì§€ ({len(result.anomalies)}ê°œ):")
            for anomaly in result.anomalies[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                print(f"   - {anomaly.description} (ì‹¬ê°ë„: {anomaly.severity:.2f})")
        
        # ì¶”ì²œì‚¬í•­
        print(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
        for i, rec in enumerate(result.recommendations[:3], 1):
            print(f"   {i}. {rec}")
    
    print("\n" + "=" * 60)
    print("âœ… ê³ ê¸‰ í¬ë¡œìŠ¤ ê²€ì¦ ì‹œìŠ¤í…œ ë°ëª¨ ì™„ë£Œ!")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # ë°ëª¨ ì‹¤í–‰
    asyncio.run(demo_advanced_validation())
