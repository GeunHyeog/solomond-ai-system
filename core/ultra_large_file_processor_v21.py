"""
Ultra Large File Processor v2.1
1ì‹œê°„ ì˜ìƒ + 30ê°œ ì´ë¯¸ì§€ ë™ì‹œ ë¶„ì„ì„ ìœ„í•œ ì´ˆëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì—”ì§„

ì£¼ìš” ê¸°ëŠ¥:
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²­í‚¹ ì²˜ë¦¬ (ìµœëŒ€ 100MB ë©”ëª¨ë¦¬ ì‚¬ìš©)
- ë³‘ë ¬ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ (CPU ì½”ì–´ í™œìš©)
- ì§„í–‰ë¥  ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ì—ëŸ¬ ë³µêµ¬ ë° ì¬ì‹œì‘ ì§€ì›
- í’ˆì§ˆ ê¸°ë°˜ ì ì‘í˜• ì²˜ë¦¬
"""

import os
import sys
import asyncio
import time
import logging
import traceback
import multiprocessing
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import tempfile
import shutil
import hashlib
import mmap
from queue import Queue
import threading
import psutil

# ë¹„ë™ê¸° ì²˜ë¦¬
import aiofiles
import aiohttp

# ë¯¸ë””ì–´ ì²˜ë¦¬
try:
    import cv2
    import librosa
    import soundfile as sf
    from moviepy.editor import VideoFileClip
    import whisper
except ImportError as e:
    print(f"âš ï¸ ì„ íƒì  ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")

# ë©”ëª¨ë¦¬ ìµœì í™”
import gc
import resource
from functools import wraps
import weakref

@dataclass
class FileChunk:
    """íŒŒì¼ ì²­í¬ ì •ë³´"""
    chunk_id: str
    file_path: str
    start_time: float
    end_time: float
    chunk_type: str  # 'video', 'audio', 'image'
    size_bytes: int
    processing_priority: int = 1
    quality_score: float = 1.0
    metadata: Dict[str, Any] = None

@dataclass
class ProcessingProgress:
    """ì²˜ë¦¬ ì§„í–‰ë¥  ì •ë³´"""
    total_chunks: int
    completed_chunks: int
    failed_chunks: int
    current_chunk: Optional[str]
    estimated_time_remaining: float
    memory_usage_mb: float
    cpu_usage_percent: float
    throughput_mb_per_sec: float

class MemoryManager:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”"""
    
    def __init__(self, max_memory_mb: int = 1000):
        self.max_memory_mb = max_memory_mb
        self.process = psutil.Process()
        self.memory_threshold = max_memory_mb * 0.8  # 80% ì„ê³„ê°’
        
    def get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        memory_info = self.process.memory_info()
        return memory_info.rss / (1024 * 1024)
    
    def is_memory_critical(self) -> bool:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆëŠ”ì§€ í™•ì¸"""
        return self.get_memory_usage() > self.memory_threshold
    
    def force_garbage_collection(self):
        """ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜"""
        gc.collect()
        
    def optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        if self.is_memory_critical():
            self.force_garbage_collection()
            time.sleep(0.1)  # ì‹œìŠ¤í…œ ì•ˆì •í™”

class ChunkManager:
    """íŒŒì¼ ì²­í‚¹ ë° ë¶„í•  ê´€ë¦¬"""
    
    def __init__(self, temp_dir: str = None):
        self.temp_dir = temp_dir or tempfile.mkdtemp(prefix="ultra_processing_")
        self.chunk_size_mb = 50  # ì²­í¬ í¬ê¸° (MB)
        self.video_segment_seconds = 300  # 5ë¶„ ì„¸ê·¸ë¨¼íŠ¸
        
    async def create_video_chunks(self, video_path: str) -> List[FileChunk]:
        """ë¹„ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        
        try:
            # ë¹„ë””ì˜¤ ì •ë³´ ë¶„ì„
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps
            cap.release()
            
            # ì„¸ê·¸ë¨¼íŠ¸ ê³„ì‚°
            num_segments = max(1, int(duration / self.video_segment_seconds))
            segment_duration = duration / num_segments
            
            for i in range(num_segments):
                start_time = i * segment_duration
                end_time = min((i + 1) * segment_duration, duration)
                
                chunk = FileChunk(
                    chunk_id=f"video_{i:03d}",
                    file_path=video_path,
                    start_time=start_time,
                    end_time=end_time,
                    chunk_type="video",
                    size_bytes=os.path.getsize(video_path) // num_segments,
                    processing_priority=1,
                    metadata={
                        "fps": fps,
                        "duration": end_time - start_time,
                        "segment_index": i
                    }
                )
                chunks.append(chunk)
                
        except Exception as e:
            logging.error(f"ë¹„ë””ì˜¤ ì²­í‚¹ ì‹¤íŒ¨: {e}")
            
        return chunks
    
    async def create_image_chunks(self, image_paths: List[str]) -> List[FileChunk]:
        """ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì²­í¬ë¡œ ê·¸ë£¹í™”"""
        chunks = []
        
        # ì´ë¯¸ì§€ë¥¼ í¬ê¸°ë³„ë¡œ ê·¸ë£¹í™”
        batch_size = 5  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜
        
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i + batch_size]
            total_size = sum(os.path.getsize(path) for path in batch_paths)
            
            chunk = FileChunk(
                chunk_id=f"images_{i//batch_size:03d}",
                file_path=batch_paths[0],  # ëŒ€í‘œ íŒŒì¼
                start_time=0,
                end_time=0,
                chunk_type="image_batch",
                size_bytes=total_size,
                processing_priority=2,
                metadata={
                    "image_paths": batch_paths,
                    "batch_index": i // batch_size,
                    "image_count": len(batch_paths)
                }
            )
            chunks.append(chunk)
            
        return chunks

class QualityAnalyzer:
    """íŒŒì¼ í’ˆì§ˆ ë¶„ì„ ë° ì ì‘í˜• ì²˜ë¦¬"""
    
    def __init__(self):
        self.quality_cache = {}
        
    async def analyze_video_quality(self, video_path: str, start_time: float, duration: float) -> float:
        """ë¹„ë””ì˜¤ í’ˆì§ˆ ë¶„ì„"""
        try:
            cap = cv2.VideoCapture(video_path)
            cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)
            
            frame_count = 0
            quality_scores = []
            
            for _ in range(10):  # ìƒ˜í”Œ í”„ë ˆì„ ë¶„ì„
                ret, frame = cap.read()
                if not ret:
                    break
                    
                # í”„ë ˆì„ í’ˆì§ˆ ë¶„ì„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°ìœ¼ë¡œ ì„ ëª…ë„ ì¸¡ì •)
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
                quality_scores.append(laplacian_var)
                frame_count += 1
                
            cap.release()
            
            if quality_scores:
                avg_quality = sum(quality_scores) / len(quality_scores)
                normalized_quality = min(1.0, avg_quality / 1000)  # ì •ê·œí™”
                return normalized_quality
            else:
                return 0.5  # ê¸°ë³¸ê°’
                
        except Exception as e:
            logging.error(f"ë¹„ë””ì˜¤ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def analyze_audio_quality(self, audio_data: any) -> float:
        """ì˜¤ë””ì˜¤ í’ˆì§ˆ ë¶„ì„"""
        try:
            # ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ ê³„ì‚°
            signal_power = np.mean(audio_data ** 2)
            noise_power = np.var(audio_data - np.mean(audio_data))
            
            if noise_power > 0:
                snr = 10 * np.log10(signal_power / noise_power)
                normalized_snr = min(1.0, max(0.0, (snr + 10) / 40))  # -10~30dB ë²”ìœ„
                return normalized_snr
            else:
                return 1.0
                
        except Exception as e:
            logging.error(f"ì˜¤ë””ì˜¤ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5

class StreamingProcessor:
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì˜ íŒŒì¼ ì²˜ë¦¬"""
    
    def __init__(self, memory_manager: MemoryManager):
        self.memory_manager = memory_manager
        self.whisper_model = None
        self.processing_queue = asyncio.Queue()
        
    async def initialize_models(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        try:
            if self.whisper_model is None:
                self.whisper_model = whisper.load_model("base")
                logging.info("Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logging.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def process_video_chunk(self, chunk: FileChunk) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ ì²­í¬ ì²˜ë¦¬"""
        result = {
            "chunk_id": chunk.chunk_id,
            "type": "video",
            "transcript": "",
            "quality_score": chunk.quality_score,
            "processing_time": 0,
            "error": None
        }
        
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ í™•ì¸
            self.memory_manager.optimize_memory()
            
            # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ì¶œ
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
                temp_audio_path = temp_audio.name
                
            # FFmpegë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            import subprocess
            cmd = [
                "ffmpeg", "-i", chunk.file_path,
                "-ss", str(chunk.start_time),
                "-t", str(chunk.end_time - chunk.start_time),
                "-vn", "-acodec", "pcm_s16le",
                "-ar", "16000", "-ac", "1",
                temp_audio_path, "-y"
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            await process.wait()
            
            # STT ì²˜ë¦¬
            if self.whisper_model and os.path.exists(temp_audio_path):
                await self.initialize_models()
                
                # ë©”ëª¨ë¦¬ ì²´í¬
                if self.memory_manager.is_memory_critical():
                    logging.warning(f"ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì²­í¬ {chunk.chunk_id} ì§€ì—° ì²˜ë¦¬")
                    await asyncio.sleep(1)
                    self.memory_manager.optimize_memory()
                
                # Whisper ì²˜ë¦¬
                loop = asyncio.get_event_loop()
                transcript_result = await loop.run_in_executor(
                    None, 
                    self.whisper_model.transcribe, 
                    temp_audio_path
                )
                
                result["transcript"] = transcript_result.get("text", "")
                
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
                
        except Exception as e:
            result["error"] = str(e)
            logging.error(f"ë¹„ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨ {chunk.chunk_id}: {e}")
            
        finally:
            result["processing_time"] = time.time() - start_time
            
        return result
    
    async def process_image_batch(self, chunk: FileChunk) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬"""
        result = {
            "chunk_id": chunk.chunk_id,
            "type": "image_batch",
            "ocr_results": [],
            "image_analysis": [],
            "processing_time": 0,
            "error": None
        }
        
        start_time = time.time()
        
        try:
            image_paths = chunk.metadata.get("image_paths", [])
            
            for img_path in image_paths:
                try:
                    # ë©”ëª¨ë¦¬ ìµœì í™”
                    self.memory_manager.optimize_memory()
                    
                    # ì´ë¯¸ì§€ ë¡œë“œ ë° OCR
                    import cv2
                    import pytesseract
                    
                    img = cv2.imread(img_path)
                    if img is not None:
                        # OCR ì²˜ë¦¬
                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                        ocr_text = pytesseract.image_to_string(gray, lang='kor+eng')
                        
                        # ì´ë¯¸ì§€ ê¸°ë³¸ ë¶„ì„
                        height, width = img.shape[:2]
                        file_size = os.path.getsize(img_path)
                        
                        result["ocr_results"].append({
                            "file_path": img_path,
                            "text": ocr_text.strip(),
                            "confidence": 0.8  # ì„ì‹œê°’
                        })
                        
                        result["image_analysis"].append({
                            "file_path": img_path,
                            "dimensions": f"{width}x{height}",
                            "file_size": file_size,
                            "has_text": len(ocr_text.strip()) > 0
                        })
                        
                        # ë©”ëª¨ë¦¬ í•´ì œ
                        del img, gray
                        
                except Exception as e:
                    logging.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ {img_path}: {e}")
                    
        except Exception as e:
            result["error"] = str(e)
            logging.error(f"ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ {chunk.chunk_id}: {e}")
            
        finally:
            result["processing_time"] = time.time() - start_time
            
        return result

class UltraLargeFileProcessor:
    """ì´ˆëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ë©”ì¸ ì—”ì§„"""
    
    def __init__(self, max_memory_mb: int = 1000, max_workers: int = None):
        self.max_memory_mb = max_memory_mb
        self.max_workers = max_workers or min(4, multiprocessing.cpu_count())
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.memory_manager = MemoryManager(max_memory_mb)
        self.chunk_manager = ChunkManager()
        self.quality_analyzer = QualityAnalyzer()
        self.streaming_processor = StreamingProcessor(self.memory_manager)
        
        # ì²˜ë¦¬ ìƒíƒœ
        self.processing_stats = {
            "start_time": None,
            "total_chunks": 0,
            "completed_chunks": 0,
            "failed_chunks": 0,
            "total_files_processed": 0,
            "total_bytes_processed": 0
        }
        
        # ì§„í–‰ë¥  ì½œë°±
        self.progress_callback = None
        
    def set_progress_callback(self, callback):
        """ì§„í–‰ë¥  ì½œë°± ì„¤ì •"""
        self.progress_callback = callback
        
    async def process_ultra_large_files(
        self,
        video_files: List[str],
        image_files: List[str],
        output_dir: str = None
    ) -> Dict[str, Any]:
        """ì´ˆëŒ€ìš©ëŸ‰ íŒŒì¼ í†µí•© ì²˜ë¦¬"""
        
        self.processing_stats["start_time"] = time.time()
        output_dir = output_dir or tempfile.mkdtemp(prefix="ultra_results_")
        
        try:
            # 1. íŒŒì¼ ì²­í‚¹
            logging.info("íŒŒì¼ ì²­í‚¹ ì‹œì‘...")
            all_chunks = []
            
            # ë¹„ë””ì˜¤ ì²­í‚¹
            for video_file in video_files:
                if os.path.exists(video_file):
                    video_chunks = await self.chunk_manager.create_video_chunks(video_file)
                    all_chunks.extend(video_chunks)
                    
            # ì´ë¯¸ì§€ ì²­í‚¹
            if image_files:
                image_chunks = await self.chunk_manager.create_image_chunks(image_files)
                all_chunks.extend(image_chunks)
            
            self.processing_stats["total_chunks"] = len(all_chunks)
            logging.info(f"ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
            
            # 2. í’ˆì§ˆ ë¶„ì„ ë° ìš°ì„ ìˆœìœ„ ì„¤ì •
            logging.info("í’ˆì§ˆ ë¶„ì„ ì‹œì‘...")
            await self._analyze_chunk_quality(all_chunks)
            
            # 3. ìš°ì„ ìˆœìœ„ë³„ ì²­í¬ ì •ë ¬
            all_chunks.sort(key=lambda x: (x.processing_priority, -x.quality_score))
            
            # 4. ë³‘ë ¬ ì²˜ë¦¬
            logging.info("ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘...")
            results = await self._process_chunks_parallel(all_chunks)
            
            # 5. ê²°ê³¼ í†µí•©
            logging.info("ê²°ê³¼ í†µí•© ì¤‘...")
            final_result = await self._integrate_results(results, output_dir)
            
            return final_result
            
        except Exception as e:
            logging.error(f"ì´ˆëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
        
    async def _analyze_chunk_quality(self, chunks: List[FileChunk]):
        """ì²­í¬ í’ˆì§ˆ ë¶„ì„"""
        for chunk in chunks:
            try:
                if chunk.chunk_type == "video":
                    quality = await self.quality_analyzer.analyze_video_quality(
                        chunk.file_path, chunk.start_time, 
                        chunk.end_time - chunk.start_time
                    )
                    chunk.quality_score = quality
                    
                elif chunk.chunk_type == "image_batch":
                    # ì´ë¯¸ì§€ëŠ” ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜ ì‚¬ìš©
                    chunk.quality_score = 0.8
                    
            except Exception as e:
                logging.error(f"ì²­í¬ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨ {chunk.chunk_id}: {e}")
                chunk.quality_score = 0.5
    
    async def _process_chunks_parallel(self, chunks: List[FileChunk]) -> List[Dict[str, Any]]:
        """ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬"""
        results = []
        semaphore = asyncio.Semaphore(self.max_workers)
        
        async def process_single_chunk(chunk: FileChunk) -> Dict[str, Any]:
            async with semaphore:
                try:
                    # ë©”ëª¨ë¦¬ ì²´í¬
                    if self.memory_manager.is_memory_critical():
                        await asyncio.sleep(0.5)
                        self.memory_manager.optimize_memory()
                    
                    # ì²­í¬ íƒ€ì…ë³„ ì²˜ë¦¬
                    if chunk.chunk_type == "video":
                        result = await self.streaming_processor.process_video_chunk(chunk)
                    elif chunk.chunk_type == "image_batch":
                        result = await self.streaming_processor.process_image_batch(chunk)
                    else:
                        result = {"chunk_id": chunk.chunk_id, "error": "Unknown chunk type"}
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    self.processing_stats["completed_chunks"] += 1
                    if result.get("error"):
                        self.processing_stats["failed_chunks"] += 1
                    
                    await self._update_progress()
                    
                    return result
                    
                except Exception as e:
                    self.processing_stats["failed_chunks"] += 1
                    await self._update_progress()
                    return {"chunk_id": chunk.chunk_id, "error": str(e)}
        
        # ëª¨ë“  ì²­í¬ ì²˜ë¦¬
        tasks = [process_single_chunk(chunk) for chunk in chunks]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
    
    async def _update_progress(self):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        if self.progress_callback:
            progress = ProcessingProgress(
                total_chunks=self.processing_stats["total_chunks"],
                completed_chunks=self.processing_stats["completed_chunks"],
                failed_chunks=self.processing_stats["failed_chunks"],
                current_chunk=None,
                estimated_time_remaining=self._calculate_eta(),
                memory_usage_mb=self.memory_manager.get_memory_usage(),
                cpu_usage_percent=psutil.cpu_percent(),
                throughput_mb_per_sec=self._calculate_throughput()
            )
            
            await self.progress_callback(progress)
    
    def _calculate_eta(self) -> float:
        """ë‚¨ì€ ì‹œê°„ ê³„ì‚°"""
        if self.processing_stats["completed_chunks"] == 0:
            return 0.0
            
        elapsed = time.time() - self.processing_stats["start_time"]
        remaining_chunks = (
            self.processing_stats["total_chunks"] - 
            self.processing_stats["completed_chunks"]
        )
        
        chunks_per_second = self.processing_stats["completed_chunks"] / elapsed
        if chunks_per_second > 0:
            return remaining_chunks / chunks_per_second
        else:
            return 0.0
    
    def _calculate_throughput(self) -> float:
        """ì²˜ë¦¬ëŸ‰ ê³„ì‚° (MB/ì´ˆ)"""
        if self.processing_stats["completed_chunks"] == 0:
            return 0.0
            
        elapsed = time.time() - self.processing_stats["start_time"]
        return self.processing_stats["total_bytes_processed"] / (1024 * 1024) / elapsed
    
    async def _integrate_results(self, results: List[Dict[str, Any]], output_dir: str) -> Dict[str, Any]:
        """ê²°ê³¼ í†µí•©"""
        integrated_result = {
            "processing_summary": {
                "total_chunks": len(results),
                "successful_chunks": len([r for r in results if not r.get("error")]),
                "failed_chunks": len([r for r in results if r.get("error")]),
                "total_processing_time": time.time() - self.processing_stats["start_time"]
            },
            "video_transcripts": [],
            "image_ocr_results": [],
            "combined_transcript": "",
            "output_files": [],
            "quality_metrics": {
                "average_video_quality": 0.0,
                "total_text_extracted": 0,
                "processing_efficiency": 0.0
            }
        }
        
        try:
            # ê²°ê³¼ ë¶„ë¥˜ ë° í†µí•©
            video_texts = []
            image_texts = []
            
            for result in results:
                if isinstance(result, dict) and not result.get("error"):
                    if result.get("type") == "video":
                        transcript = result.get("transcript", "")
                        if transcript:
                            video_texts.append({
                                "chunk_id": result["chunk_id"],
                                "transcript": transcript,
                                "quality_score": result.get("quality_score", 0.5)
                            })
                            
                    elif result.get("type") == "image_batch":
                        ocr_results = result.get("ocr_results", [])
                        for ocr in ocr_results:
                            if ocr.get("text"):
                                image_texts.append(ocr)
            
            integrated_result["video_transcripts"] = video_texts
            integrated_result["image_ocr_results"] = image_texts
            
            # í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
            all_texts = []
            all_texts.extend([vt["transcript"] for vt in video_texts])
            all_texts.extend([it["text"] for it in image_texts])
            
            integrated_result["combined_transcript"] = "\n\n".join(all_texts)
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            if video_texts:
                avg_quality = sum(vt["quality_score"] for vt in video_texts) / len(video_texts)
                integrated_result["quality_metrics"]["average_video_quality"] = avg_quality
            
            integrated_result["quality_metrics"]["total_text_extracted"] = len(all_texts)
            
            # ê²°ê³¼ íŒŒì¼ ì €ì¥
            output_file = os.path.join(output_dir, "ultra_processing_results.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                import json
                json.dump(integrated_result, f, ensure_ascii=False, indent=2)
            
            integrated_result["output_files"].append(output_file)
            
        except Exception as e:
            logging.error(f"ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            integrated_result["integration_error"] = str(e)
        
        return integrated_result

# ì‚¬ìš© ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def demo_ultra_processing():
    """ë°ëª¨ ì‹¤í–‰"""
    print("ğŸš€ Ultra Large File Processor v2.1 ë°ëª¨")
    
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = UltraLargeFileProcessor(max_memory_mb=800, max_workers=3)
    
    # ì§„í–‰ë¥  ì½œë°± ì„¤ì •
    async def progress_callback(progress: ProcessingProgress):
        print(f"ì§„í–‰ë¥ : {progress.completed_chunks}/{progress.total_chunks} "
              f"({progress.completed_chunks/progress.total_chunks*100:.1f}%) "
              f"ë©”ëª¨ë¦¬: {progress.memory_usage_mb:.1f}MB "
              f"CPU: {progress.cpu_usage_percent:.1f}%")
    
    processor.set_progress_callback(progress_callback)
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì¡´ì¬í•˜ëŠ” íŒŒì¼ ê²½ë¡œ ì‚¬ìš©)
    video_files = [
        # "path/to/large_video.mp4"  # 1ì‹œê°„ ì˜ìƒ
    ]
    
    image_files = [
        # "path/to/image1.jpg", "path/to/image2.png", ...  # 30ê°œ ì´ë¯¸ì§€
    ]
    
    try:
        result = await processor.process_ultra_large_files(
            video_files=video_files,
            image_files=image_files
        )
        
        print("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š ì²˜ë¦¬ ìš”ì•½:")
        print(f"  - ì´ ì²­í¬: {result['processing_summary']['total_chunks']}")
        print(f"  - ì„±ê³µ: {result['processing_summary']['successful_chunks']}")
        print(f"  - ì‹¤íŒ¨: {result['processing_summary']['failed_chunks']}")
        print(f"  - ì²˜ë¦¬ ì‹œê°„: {result['processing_summary']['total_processing_time']:.1f}ì´ˆ")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # ë°ëª¨ ì‹¤í–‰
    asyncio.run(demo_ultra_processing())
