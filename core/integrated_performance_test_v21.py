"""
ğŸš€ ì†”ë¡œëª¬ë“œ AI v2.1.2 - í†µí•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ë° ìµœì í™” ì§€ì  ë¶„ì„

ì£¼ìš” ê¸°ëŠ¥:
- ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- ëª¨ë“ˆë³„ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ë¶„ì„
- ì—ëŸ¬ ë³µêµ¬ ì‹œìŠ¤í…œ ê²€ì¦
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import time
import json
import asyncio
import threading
import tempfile
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
import logging
from pathlib import Path

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤ import
try:
    from .performance_profiler_v21 import PerformanceProfiler, get_system_health
    from .memory_optimizer_v21 import MemoryManager, global_memory_manager
    from .error_recovery_system_v21 import ErrorRecoverySystem, global_recovery_system
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ ì‹œ fallback
    import sys
    sys.path.append('.')
    try:
        from performance_profiler_v21 import PerformanceProfiler, get_system_health
        from memory_optimizer_v21 import MemoryManager, global_memory_manager
        from error_recovery_system_v21 import ErrorRecoverySystem, global_recovery_system
    except ImportError:
        print("âš ï¸ ëª¨ë“ˆ import ì‹¤íŒ¨ - ë‹¨ë… í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰")
        PerformanceProfiler = None
        MemoryManager = None
        ErrorRecoverySystem = None

@dataclass
class BenchmarkResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼"""
    test_name: str
    duration_seconds: float
    memory_used_mb: float
    cpu_usage_percent: float
    throughput_ops_per_sec: float
    success_rate_percent: float
    errors_count: int
    metadata: Dict[str, Any]

@dataclass
class SystemPerformanceReport:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸"""
    timestamp: str
    overall_score: float
    benchmark_results: List[BenchmarkResult]
    system_health: Dict[str, Any]
    memory_stats: Dict[str, Any]
    error_analysis: Dict[str, Any]
    optimization_recommendations: List[str]

class PerformanceTestSuite:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.test_results = []
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        self.test_data_dir = Path(tempfile.mkdtemp(prefix="solomond_perf_test_"))
        self._prepare_test_data()
    
    def _prepare_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        try:
            # ì‘ì€ í…ìŠ¤íŠ¸ íŒŒì¼ (1MB)
            small_file = self.test_data_dir / "small_test.txt"
            with open(small_file, 'w', encoding='utf-8') as f:
                for i in range(10000):
                    f.write(f"ì£¼ì–¼ë¦¬ í…ŒìŠ¤íŠ¸ ë¼ì¸ {i:06d} - ë‹¤ì´ì•„ëª¬ë“œ, ë°˜ì§€, ëª©ê±¸ì´, ê·€ê±¸ì´\n")
            
            # ì¤‘ê°„ í…ìŠ¤íŠ¸ íŒŒì¼ (10MB)
            medium_file = self.test_data_dir / "medium_test.txt"
            with open(medium_file, 'w', encoding='utf-8') as f:
                for i in range(100000):
                    f.write(f"ì¤‘í˜• í…ŒìŠ¤íŠ¸ ë°ì´í„° {i:06d} - ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n")
            
            # JSON ë°ì´í„° íŒŒì¼
            json_file = self.test_data_dir / "test_data.json"
            test_json = {
                "jewelry_items": [
                    {"id": i, "type": "diamond", "carat": round(i * 0.1, 2), 
                     "price": i * 1000, "quality": f"Grade_{i%5}"}
                    for i in range(1000)
                ]
            }
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(test_json, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {self.test_data_dir}")
            
        except Exception as e:
            self.logger.error(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    
    def benchmark_file_processing(self) -> BenchmarkResult:
        """íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        start_time = time.time()
        start_memory = global_memory_manager.get_memory_usage().used_mb if global_memory_manager else 0
        
        operations_count = 0
        errors_count = 0
        
        try:
            # ì‘ì€ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            small_file = self.test_data_dir / "small_test.txt"
            if small_file.exists():
                with open(small_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if "ë‹¤ì´ì•„ëª¬ë“œ" in line:
                            operations_count += 1
            
            # JSON íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            json_file = self.test_data_dir / "test_data.json"
            if json_file.exists():
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for item in data.get("jewelry_items", []):
                        if item.get("carat", 0) > 1.0:
                            operations_count += 1
            
        except Exception as e:
            errors_count += 1
            self.logger.error(f"íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        end_time = time.time()
        end_memory = global_memory_manager.get_memory_usage().used_mb if global_memory_manager else 0
        
        duration = end_time - start_time
        throughput = operations_count / duration if duration > 0 else 0
        success_rate = ((operations_count) / (operations_count + errors_count) * 100) if (operations_count + errors_count) > 0 else 0
        
        return BenchmarkResult(
            test_name="íŒŒì¼ ì²˜ë¦¬",
            duration_seconds=duration,
            memory_used_mb=end_memory - start_memory,
            cpu_usage_percent=0,  # ë³„ë„ ì¸¡ì • í•„ìš”
            throughput_ops_per_sec=throughput,
            success_rate_percent=success_rate,
            errors_count=errors_count,
            metadata={"operations": operations_count, "files_processed": 2}
        )
    
    def benchmark_memory_operations(self) -> BenchmarkResult:
        """ë©”ëª¨ë¦¬ ì‘ì—… ë²¤ì¹˜ë§ˆí¬"""
        if not global_memory_manager:
            return BenchmarkResult(
                test_name="ë©”ëª¨ë¦¬ ì‘ì—…",
                duration_seconds=0,
                memory_used_mb=0,
                cpu_usage_percent=0,
                throughput_ops_per_sec=0,
                success_rate_percent=0,
                errors_count=1,
                metadata={"error": "ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì—†ìŒ"}
            )
        
        start_time = time.time()
        start_memory = global_memory_manager.get_memory_usage().used_mb
        
        operations_count = 0
        errors_count = 0
        
        try:
            # ìºì‹œ í…ŒìŠ¤íŠ¸
            for i in range(100):
                key = f"test_key_{i}"
                value = f"í…ŒìŠ¤íŠ¸ ê°’ {i}" * 100  # í° ê°’
                success = global_memory_manager.cache.put(key, value)
                if success:
                    operations_count += 1
            
            # ìºì‹œ ì½ê¸° í…ŒìŠ¤íŠ¸
            for i in range(50):
                key = f"test_key_{i}"
                value = global_memory_manager.cache.get(key)
                if value:
                    operations_count += 1
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸
            cleanup_result = global_memory_manager.routine_cleanup()
            if cleanup_result:
                operations_count += 1
            
        except Exception as e:
            errors_count += 1
            self.logger.error(f"ë©”ëª¨ë¦¬ ì‘ì—… í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        end_time = time.time()
        end_memory = global_memory_manager.get_memory_usage().used_mb
        
        duration = end_time - start_time
        throughput = operations_count / duration if duration > 0 else 0
        success_rate = ((operations_count) / (operations_count + errors_count) * 100) if (operations_count + errors_count) > 0 else 0
        
        return BenchmarkResult(
            test_name="ë©”ëª¨ë¦¬ ì‘ì—…",
            duration_seconds=duration,
            memory_used_mb=end_memory - start_memory,
            cpu_usage_percent=0,
            throughput_ops_per_sec=throughput,
            success_rate_percent=success_rate,
            errors_count=errors_count,
            metadata={"cache_operations": operations_count}
        )
    
    def benchmark_error_recovery(self) -> BenchmarkResult:
        """ì—ëŸ¬ ë³µêµ¬ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬"""
        if not global_recovery_system:
            return BenchmarkResult(
                test_name="ì—ëŸ¬ ë³µêµ¬",
                duration_seconds=0,
                memory_used_mb=0,
                cpu_usage_percent=0,
                throughput_ops_per_sec=0,
                success_rate_percent=0,
                errors_count=1,
                metadata={"error": "ë³µêµ¬ ì‹œìŠ¤í…œ ì—†ìŒ"}
            )
        
        start_time = time.time()
        start_memory = global_memory_manager.get_memory_usage().used_mb if global_memory_manager else 0
        
        operations_count = 0
        errors_count = 0
        recovered_count = 0
        
        # í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ë“¤
        @global_recovery_system.resilient_execution("test_operation")
        def test_function_success():
            return "ì„±ê³µ"
        
        @global_recovery_system.resilient_execution("test_operation_fail")
        def test_function_fail():
            raise ValueError("í…ŒìŠ¤íŠ¸ ì—ëŸ¬")
        
        try:
            # ì„±ê³µ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
            for i in range(20):
                try:
                    result = test_function_success()
                    if result == "ì„±ê³µ":
                        operations_count += 1
                except Exception:
                    errors_count += 1
            
            # ì‹¤íŒ¨ ë³µêµ¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
            for i in range(10):
                try:
                    result = test_function_fail()
                    recovered_count += 1  # ë³µêµ¬ëœ ê²½ìš°
                except Exception:
                    errors_count += 1  # ë³µêµ¬ ì‹¤íŒ¨
            
            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            status = global_recovery_system.get_system_status()
            if status.get("health_status") in ["HEALTHY", "WARNING"]:
                operations_count += 1
            
        except Exception as e:
            errors_count += 1
            self.logger.error(f"ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        end_time = time.time()
        end_memory = global_memory_manager.get_memory_usage().used_mb if global_memory_manager else 0
        
        duration = end_time - start_time
        total_operations = operations_count + recovered_count
        throughput = total_operations / duration if duration > 0 else 0
        success_rate = (total_operations / (total_operations + errors_count) * 100) if (total_operations + errors_count) > 0 else 0
        
        return BenchmarkResult(
            test_name="ì—ëŸ¬ ë³µêµ¬",
            duration_seconds=duration,
            memory_used_mb=end_memory - start_memory,
            cpu_usage_percent=0,
            throughput_ops_per_sec=throughput,
            success_rate_percent=success_rate,
            errors_count=errors_count,
            metadata={
                "successful_operations": operations_count,
                "recovered_operations": recovered_count
            }
        )
    
    def benchmark_concurrent_operations(self) -> BenchmarkResult:
        """ë™ì‹œ ì‘ì—… ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬"""
        start_time = time.time()
        start_memory = global_memory_manager.get_memory_usage().used_mb if global_memory_manager else 0
        
        operations_count = 0
        errors_count = 0
        
        def worker_task(task_id: int):
            nonlocal operations_count, errors_count
            try:
                # ê°„ë‹¨í•œ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
                data = [i**2 for i in range(1000)]
                result = sum(data)
                
                # ë©”ëª¨ë¦¬ ìºì‹± (ê°€ëŠ¥í•œ ê²½ìš°)
                if global_memory_manager:
                    global_memory_manager.cache.put(f"result_{task_id}", result)
                
                operations_count += 1
                
            except Exception as e:
                errors_count += 1
                self.logger.debug(f"ì›Œì»¤ íƒœìŠ¤í¬ {task_id} ì˜¤ë¥˜: {e}")
        
        try:
            # ìŠ¤ë ˆë“œ í’€ë¡œ ë™ì‹œ ì‘ì—… ì‹¤í–‰
            threads = []
            for i in range(10):
                thread = threading.Thread(target=worker_task, args=(i,))
                threads.append(thread)
                thread.start()
            
            # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
            for thread in threads:
                thread.join(timeout=5.0)
            
        except Exception as e:
            errors_count += 1
            self.logger.error(f"ë™ì‹œ ì‘ì—… í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        end_time = time.time()
        end_memory = global_memory_manager.get_memory_usage().used_mb if global_memory_manager else 0
        
        duration = end_time - start_time
        throughput = operations_count / duration if duration > 0 else 0
        success_rate = (operations_count / (operations_count + errors_count) * 100) if (operations_count + errors_count) > 0 else 0
        
        return BenchmarkResult(
            test_name="ë™ì‹œ ì‘ì—…",
            duration_seconds=duration,
            memory_used_mb=end_memory - start_memory,
            cpu_usage_percent=0,
            throughput_ops_per_sec=throughput,
            success_rate_percent=success_rate,
            errors_count=errors_count,
            metadata={"threads_used": 10, "tasks_per_thread": 1}
        )
    
    def run_full_benchmark(self) -> List[BenchmarkResult]:
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        self.logger.info("ğŸš€ ì „ì²´ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        
        benchmarks = [
            ("íŒŒì¼ ì²˜ë¦¬", self.benchmark_file_processing),
            ("ë©”ëª¨ë¦¬ ì‘ì—…", self.benchmark_memory_operations),
            ("ì—ëŸ¬ ë³µêµ¬", self.benchmark_error_recovery),
            ("ë™ì‹œ ì‘ì—…", self.benchmark_concurrent_operations)
        ]
        
        results = []
        
        for name, benchmark_func in benchmarks:
            self.logger.info(f"  ğŸ“Š {name} ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰...")
            try:
                result = benchmark_func()
                results.append(result)
                self.logger.info(f"    âœ… {name} ì™„ë£Œ: {result.duration_seconds:.2f}ì´ˆ, "
                               f"{result.success_rate_percent:.1f}% ì„±ê³µë¥ ")
            except Exception as e:
                self.logger.error(f"    âŒ {name} ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ê²°ê³¼ ì¶”ê°€
                results.append(BenchmarkResult(
                    test_name=name,
                    duration_seconds=0,
                    memory_used_mb=0,
                    cpu_usage_percent=0,
                    throughput_ops_per_sec=0,
                    success_rate_percent=0,
                    errors_count=1,
                    metadata={"error": str(e)}
                ))
        
        self.test_results = results
        return results
    
    def cleanup(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬"""
        try:
            import shutil
            shutil.rmtree(self.test_data_dir)
            self.logger.info("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.debug(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")

class SystemPerformanceAnalyzer:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.test_suite = PerformanceTestSuite()
    
    def analyze_system_performance(self) -> SystemPerformanceReport:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¢…í•© ë¶„ì„"""
        self.logger.info("ğŸ” ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
        
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        benchmark_results = self.test_suite.run_full_benchmark()
        
        # ì‹œìŠ¤í…œ ê±´ê°•ë„ ì²´í¬
        system_health = get_system_health() if 'get_system_health' in globals() else {
            "health_score": 0,
            "status": "Unknown",
            "metrics": {}
        }
        
        # ë©”ëª¨ë¦¬ í†µê³„
        memory_stats = {}
        if global_memory_manager:
            memory_usage = global_memory_manager.get_memory_usage()
            optimization_report = global_memory_manager.get_optimization_report()
            memory_stats = {
                "current_usage": {
                    "percent": memory_usage.percent,
                    "used_mb": memory_usage.used_mb,
                    "available_mb": memory_usage.available_mb
                },
                "cache_stats": optimization_report.get("cache", {}),
                "cleanup_stats": optimization_report.get("cleanup_stats", {})
            }
        
        # ì—ëŸ¬ ë¶„ì„
        error_analysis = {}
        if global_recovery_system:
            status = global_recovery_system.get_system_status()
            error_analysis = {
                "health_status": status.get("health_status", "Unknown"),
                "error_rate_1h": status.get("error_rate_1h", 0),
                "total_errors": status.get("total_errors", 0),
                "top_error_types": status.get("top_error_types", {})
            }
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_score(
            benchmark_results, system_health, memory_stats, error_analysis
        )
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = self._generate_optimization_recommendations(
            benchmark_results, system_health, memory_stats, error_analysis
        )
        
        report = SystemPerformanceReport(
            timestamp=datetime.now().isoformat(),
            overall_score=overall_score,
            benchmark_results=benchmark_results,
            system_health=system_health,
            memory_stats=memory_stats,
            error_analysis=error_analysis,
            optimization_recommendations=recommendations
        )
        
        self.logger.info(f"ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ - ì „ì²´ ì ìˆ˜: {overall_score:.1f}/100")
        return report
    
    def _calculate_overall_score(self, benchmark_results: List[BenchmarkResult],
                                system_health: Dict, memory_stats: Dict,
                                error_analysis: Dict) -> float:
        """ì „ì²´ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        scores = []
        
        # ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ (40%)
        if benchmark_results:
            avg_success_rate = sum(r.success_rate_percent for r in benchmark_results) / len(benchmark_results)
            avg_throughput = sum(r.throughput_ops_per_sec for r in benchmark_results) / len(benchmark_results)
            
            benchmark_score = (avg_success_rate + min(avg_throughput * 10, 100)) / 2
            scores.append(("benchmark", benchmark_score, 0.4))
        
        # ì‹œìŠ¤í…œ ê±´ê°•ë„ (25%)
        health_score = system_health.get("health_score", 50)
        scores.append(("health", health_score, 0.25))
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (20%)
        memory_score = 100
        if memory_stats and "current_usage" in memory_stats:
            usage_percent = memory_stats["current_usage"].get("percent", 50)
            memory_score = max(0, 100 - usage_percent)  # ì‚¬ìš©ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        scores.append(("memory", memory_score, 0.2))
        
        # ì—ëŸ¬ ì²˜ë¦¬ (15%)
        error_score = 100
        if error_analysis:
            error_rate = error_analysis.get("error_rate_1h", 0)
            error_score = max(0, 100 - error_rate * 2)  # ì—ëŸ¬ìœ¨ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        scores.append(("error", error_score, 0.15))
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        total_score = sum(score * weight for name, score, weight in scores)
        return min(100, max(0, total_score))
    
    def _generate_optimization_recommendations(self, benchmark_results: List[BenchmarkResult],
                                             system_health: Dict, memory_stats: Dict,
                                             error_analysis: Dict) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        for result in benchmark_results:
            if result.success_rate_percent < 80:
                recommendations.append(f"âš ï¸ {result.test_name} ì„±ê³µë¥  ê°œì„  í•„ìš” ({result.success_rate_percent:.1f}%)")
            
            if result.throughput_ops_per_sec < 1:
                recommendations.append(f"ğŸŒ {result.test_name} ì²˜ë¦¬ ì†ë„ ìµœì í™” í•„ìš”")
            
            if result.memory_used_mb > 100:
                recommendations.append(f"ğŸ’¾ {result.test_name} ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í•„ìš”")
        
        # ì‹œìŠ¤í…œ ê±´ê°•ë„ ê¸°ë°˜
        health_score = system_health.get("health_score", 100)
        if health_score < 70:
            recommendations.append("ğŸš¨ ì‹œìŠ¤í…œ ê±´ê°•ë„ ìœ„í—˜ - í•˜ë“œì›¨ì–´ ì ê²€ í•„ìš”")
        elif health_score < 85:
            recommendations.append("âš ï¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì£¼ì˜ - ë¦¬ì†ŒìŠ¤ ìµœì í™” ê¶Œì¥")
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜
        if memory_stats and "current_usage" in memory_stats:
            usage_percent = memory_stats["current_usage"].get("percent", 0)
            if usage_percent > 85:
                recommendations.append("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ - ì •ë¦¬ ë° ìµœì í™” í•„ìš”")
            
            cache_stats = memory_stats.get("cache_stats", {})
            hit_rate = cache_stats.get("hit_rate", 100)
            if hit_rate < 50:
                recommendations.append("ğŸ“Š ìºì‹œ íš¨ìœ¨ì„± ë‚®ìŒ - ìºì‹œ ì „ëµ ì¬ê²€í†  í•„ìš”")
        
        # ì—ëŸ¬ ë¶„ì„ ê¸°ë°˜
        if error_analysis:
            error_rate = error_analysis.get("error_rate_1h", 0)
            if error_rate > 10:
                recommendations.append("ğŸ”§ ë†’ì€ ì—ëŸ¬ìœ¨ - ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ ê°•í™” í•„ìš”")
            
            health_status = error_analysis.get("health_status", "HEALTHY")
            if health_status in ["CRITICAL", "WARNING"]:
                recommendations.append(f"ğŸ›¡ï¸ ì‹œìŠ¤í…œ ìƒíƒœ {health_status} - ì¦‰ì‹œ ì ê²€ í•„ìš”")
        
        # ì„±ëŠ¥ í–¥ìƒ íŒ
        if not recommendations:
            recommendations.extend([
                "âœ… ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœì…ë‹ˆë‹¤",
                "ğŸš€ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•´ ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "ğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì •ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì„±ëŠ¥ ì¶”ì´ë¥¼ í™•ì¸í•˜ì„¸ìš”"
            ])
        
        return recommendations
    
    def save_report(self, report: SystemPerformanceReport, filepath: str):
        """ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(asdict(report), f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ“„ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥: {filepath}")
            
        except Exception as e:
            self.logger.error(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.test_suite.cleanup()

def run_performance_analysis(save_report: bool = True) -> SystemPerformanceReport:
    """ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰ (í¸ì˜ í•¨ìˆ˜)"""
    analyzer = SystemPerformanceAnalyzer()
    
    try:
        report = analyzer.analyze_system_performance()
        
        if save_report:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_path = f"solomond_performance_report_{timestamp}.json"
            analyzer.save_report(report, report_path)
        
        return report
        
    finally:
        analyzer.cleanup()

if __name__ == "__main__":
    # ë©”ì¸ ì‹¤í–‰ë¶€
    print("ğŸš€ ì†”ë¡œëª¬ë“œ AI í†µí•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ v2.1.2")
    print("=" * 60)
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        # ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
        print("\nğŸ” ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘...")
        report = run_performance_analysis(save_report=True)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ì „ì²´ ì„±ëŠ¥ ì ìˆ˜: {report.overall_score:.1f}/100")
        
        print("\nğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        for result in report.benchmark_results:
            print(f"  {result.test_name}:")
            print(f"    â±ï¸  ì‹¤í–‰ ì‹œê°„: {result.duration_seconds:.3f}ì´ˆ")
            print(f"    ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©: {result.memory_used_mb:.2f}MB")
            print(f"    ğŸ¯ ì²˜ë¦¬ëŸ‰: {result.throughput_ops_per_sec:.2f} ops/sec")
            print(f"    âœ… ì„±ê³µë¥ : {result.success_rate_percent:.1f}%")
            if result.errors_count > 0:
                print(f"    âŒ ì—ëŸ¬ ìˆ˜: {result.errors_count}")
        
        print(f"\nğŸ’Š ì‹œìŠ¤í…œ ê±´ê°•ë„: {report.system_health.get('health_score', 0)}/100")
        
        if report.memory_stats and "current_usage" in report.memory_stats:
            memory = report.memory_stats["current_usage"]
            print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory.get('percent', 0):.1f}%")
            print(f"ğŸ†“ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {memory.get('available_mb', 0):.1f}MB")
        
        if report.error_analysis:
            error = report.error_analysis
            print(f"ğŸ”§ ì—ëŸ¬ìœ¨ (1ì‹œê°„): {error.get('error_rate_1h', 0):.2f}%")
            print(f"ğŸ›¡ï¸ ì‹œìŠ¤í…œ ìƒíƒœ: {error.get('health_status', 'Unknown')}")
        
        print("\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(report.optimization_recommendations, 1):
            print(f"  {i}. {rec}")
        
        # ì ìˆ˜ë³„ ë“±ê¸‰ íŒì •
        score = report.overall_score
        if score >= 90:
            grade = "ğŸ† ìš°ìˆ˜ (Excellent)"
        elif score >= 80:
            grade = "ğŸ¥ˆ ì¢‹ìŒ (Good)"
        elif score >= 70:
            grade = "ğŸ¥‰ ë³´í†µ (Fair)"
        elif score >= 60:
            grade = "âš ï¸ ì£¼ì˜ (Poor)"
        else:
            grade = "ğŸš¨ ìœ„í—˜ (Critical)"
        
        print(f"\nğŸ–ï¸ ì‹œìŠ¤í…œ ë“±ê¸‰: {grade}")
        
        # ì„±ëŠ¥ íŠ¸ë Œë“œ (ê°„ë‹¨í•œ í˜•íƒœ)
        print(f"\nğŸ“… ë¶„ì„ ì‹œê°: {report.timestamp}")
        print("ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì •ê¸°ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        print(traceback.format_exc())
    
    print("\nâœ… í†µí•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ’ ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œì´ ë”ìš± ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
