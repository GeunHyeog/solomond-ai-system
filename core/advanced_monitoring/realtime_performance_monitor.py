#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v2.5
2025 ìµœì‹  AI ì‹œìŠ¤í…œ ìµœì í™” ì „ëµ ë°˜ì˜
"""

import asyncio
import time
import psutil
import threading
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
import json
import logging
from dataclasses import dataclass, asdict
from collections import deque
import numpy as np

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: float
    cpu_usage: float
    memory_usage: float
    memory_available: float
    disk_io_read: float
    disk_io_write: float
    network_sent: float
    network_recv: float
    ollama_models_active: int
    processing_queue_size: int
    response_time_ms: float
    error_count: int
    user_sessions: int

@dataclass
class SystemAlert:
    """ì‹œìŠ¤í…œ ì•Œë¦¼ ë°ì´í„° í´ë˜ìŠ¤"""
    level: str  # 'info', 'warning', 'critical'
    message: str
    metric: str
    value: float
    threshold: float
    timestamp: float
    suggested_action: str

class RealtimePerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 alert_callback: Optional[Callable] = None,
                 metrics_retention_hours: int = 24):
        self.alert_callback = alert_callback
        self.metrics_retention_hours = metrics_retention_hours
        
        # ë©”íŠ¸ë¦­ ì €ì¥ì†Œ (ì‹œê°„ ê¸°ë°˜ ìˆœí™˜ í)
        self.metrics_history = deque(maxlen=metrics_retention_hours * 3600)  # 1ì´ˆë‹¹ 1ê°œ ë©”íŠ¸ë¦­
        self.alerts_history = deque(maxlen=1000)
        
        # ì„±ëŠ¥ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'cpu_usage': {'warning': 70.0, 'critical': 85.0},
            'memory_usage': {'warning': 75.0, 'critical': 90.0},
            'response_time_ms': {'warning': 2000.0, 'critical': 5000.0},
            'error_count': {'warning': 5, 'critical': 10},
            'disk_io_read': {'warning': 100.0, 'critical': 200.0},  # MB/s
            'disk_io_write': {'warning': 100.0, 'critical': 200.0},
        }
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.is_monitoring = False
        self.monitoring_thread = None
        self.ollama_stats = {'active_models': 0, 'total_requests': 0}
        self.processing_stats = {'queue_size': 0, 'completed_tasks': 0}
        self.user_stats = {'active_sessions': 0, 'total_requests': 0}
        
        # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹œ
        self._last_system_stats = None
        self._stats_cache_time = 0
        self._cache_duration = 1.0  # 1ì´ˆ ìºì‹œ
        
        self.logger = self._setup_logging()
        
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(f'{__name__}.RealtimePerformanceMonitor')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | %(name)s | %(levelname)s | %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def start_monitoring(self, interval: float = 1.0) -> None:
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_monitoring:
            self.logger.warning("âš ï¸ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
            
        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            args=(interval,),
            daemon=True
        )
        self.monitoring_thread.start()
        self.logger.info("ğŸš€ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5.0)
        self.logger.info("â¹ï¸ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitoring_loop(self, interval: float) -> None:
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_monitoring:
            try:
                metrics = self._collect_metrics()
                self.metrics_history.append(metrics)
                
                # ì•Œë¦¼ ê²€ì‚¬
                alerts = self._check_alerts(metrics)
                for alert in alerts:
                    self.alerts_history.append(alert)
                    if self.alert_callback:
                        self.alert_callback(alert)
                
                time.sleep(interval)
                
            except Exception as e:
                self.logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(interval)
    
    def _collect_metrics(self) -> PerformanceMetrics:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        current_time = time.time()
        
        # ìºì‹œëœ ì‹œìŠ¤í…œ í†µê³„ ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
        if (current_time - self._stats_cache_time) > self._cache_duration:
            self._last_system_stats = self._get_system_stats()
            self._stats_cache_time = current_time
        
        stats = self._last_system_stats
        
        return PerformanceMetrics(
            timestamp=current_time,
            cpu_usage=stats['cpu_percent'],
            memory_usage=stats['memory_percent'],
            memory_available=stats['memory_available'] / (1024**3),  # GB
            disk_io_read=stats['disk_read_mb'],
            disk_io_write=stats['disk_write_mb'],
            network_sent=stats['network_sent_mb'],
            network_recv=stats['network_recv_mb'],
            ollama_models_active=self.ollama_stats['active_models'],
            processing_queue_size=self.processing_stats['queue_size'],
            response_time_ms=self._calculate_avg_response_time(),
            error_count=self._get_recent_error_count(),
            user_sessions=self.user_stats['active_sessions']
        )
    
    def _get_system_stats(self) -> Dict[str, float]:
        """ì‹œìŠ¤í…œ í†µê³„ ìˆ˜ì§‘"""
        # CPU ì‚¬ìš©ë¥ 
        cpu_percent = psutil.cpu_percent(interval=0.1)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_available = memory.available
        
        # ë””ìŠ¤í¬ I/O (MB/s)
        disk_io = psutil.disk_io_counters()
        disk_read_mb = getattr(disk_io, 'read_bytes', 0) / (1024**2)
        disk_write_mb = getattr(disk_io, 'write_bytes', 0) / (1024**2)
        
        # ë„¤íŠ¸ì›Œí¬ I/O (MB/s)
        network_io = psutil.net_io_counters()
        network_sent_mb = getattr(network_io, 'bytes_sent', 0) / (1024**2)
        network_recv_mb = getattr(network_io, 'bytes_recv', 0) / (1024**2)
        
        return {
            'cpu_percent': cpu_percent,
            'memory_percent': memory_percent,
            'memory_available': memory_available,
            'disk_read_mb': disk_read_mb,
            'disk_write_mb': disk_write_mb,
            'network_sent_mb': network_sent_mb,
            'network_recv_mb': network_recv_mb,
        }
    
    def _calculate_avg_response_time(self) -> float:
        """í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°"""
        # ìµœê·¼ 10ê°œ ë©”íŠ¸ë¦­ì˜ í‰ê·  ê³„ì‚°
        if len(self.metrics_history) < 2:
            return 0.0
        
        recent_metrics = list(self.metrics_history)[-10:]
        response_times = [m.response_time_ms for m in recent_metrics if m.response_time_ms > 0]
        
        return np.mean(response_times) if response_times else 0.0
    
    def _get_recent_error_count(self) -> int:
        """ìµœê·¼ ì—ëŸ¬ ì¹´ìš´íŠ¸"""
        # ìµœê·¼ 1ë¶„ê°„ì˜ ì—ëŸ¬ ì¹´ìš´íŠ¸
        cutoff_time = time.time() - 60
        recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
        
        return sum(m.error_count for m in recent_metrics)
    
    def _check_alerts(self, metrics: PerformanceMetrics) -> List[SystemAlert]:
        """ì•Œë¦¼ ê²€ì‚¬"""
        alerts = []
        
        # CPU ì‚¬ìš©ë¥  ê²€ì‚¬
        alerts.extend(self._check_threshold_alerts(
            'cpu_usage', metrics.cpu_usage, '%',
            "CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤",
            "ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ê±°ë‚˜ ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ì„¸ìš”"
        ))
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê²€ì‚¬
        alerts.extend(self._check_threshold_alerts(
            'memory_usage', metrics.memory_usage, '%',
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤",
            "ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”"
        ))
        
        # ì‘ë‹µ ì‹œê°„ ê²€ì‚¬
        alerts.extend(self._check_threshold_alerts(
            'response_time_ms', metrics.response_time_ms, 'ms',
            "ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤",
            "ì‹œìŠ¤í…œ ë¶€í•˜ë¥¼ í™•ì¸í•˜ê³  ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”"
        ))
        
        # ë””ìŠ¤í¬ I/O ê²€ì‚¬
        alerts.extend(self._check_threshold_alerts(
            'disk_io_read', metrics.disk_io_read, 'MB/s',
            "ë””ìŠ¤í¬ ì½ê¸° ë¶€í•˜ê°€ ë†’ìŠµë‹ˆë‹¤",
            "ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”"
        ))
        
        return alerts
    
    def _check_threshold_alerts(self, 
                              metric_name: str, 
                              value: float, 
                              unit: str,
                              message: str,
                              action: str) -> List[SystemAlert]:
        """ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ ê²€ì‚¬"""
        alerts = []
        thresholds = self.thresholds.get(metric_name, {})
        
        if value >= thresholds.get('critical', float('inf')):
            alerts.append(SystemAlert(
                level='critical',
                message=f"ğŸš¨ CRITICAL: {message}",
                metric=metric_name,
                value=value,
                threshold=thresholds['critical'],
                timestamp=time.time(),
                suggested_action=action
            ))
        elif value >= thresholds.get('warning', float('inf')):
            alerts.append(SystemAlert(
                level='warning',
                message=f"âš ï¸ WARNING: {message}",
                metric=metric_name,
                value=value,
                threshold=thresholds['warning'],
                timestamp=time.time(),
                suggested_action=action
            ))
        
        return alerts
    
    def get_current_metrics(self) -> Optional[PerformanceMetrics]:
        """í˜„ì¬ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        return self.metrics_history[-1] if self.metrics_history else None
    
    def get_metrics_history(self, hours: int = 1) -> List[PerformanceMetrics]:
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        cutoff_time = time.time() - (hours * 3600)
        return [m for m in self.metrics_history if m.timestamp > cutoff_time]
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        if not self.metrics_history:
            return {"status": "no_data"}
        
        recent_metrics = self.get_metrics_history(1)  # ìµœê·¼ 1ì‹œê°„
        
        if not recent_metrics:
            return {"status": "insufficient_data"}
        
        # í‰ê·  ê³„ì‚°
        avg_cpu = np.mean([m.cpu_usage for m in recent_metrics])
        avg_memory = np.mean([m.memory_usage for m in recent_metrics])
        avg_response_time = np.mean([m.response_time_ms for m in recent_metrics])
        total_errors = sum([m.error_count for m in recent_metrics])
        
        # ìµœëŒ€ê°’
        max_cpu = max([m.cpu_usage for m in recent_metrics])
        max_memory = max([m.memory_usage for m in recent_metrics])
        max_response_time = max([m.response_time_ms for m in recent_metrics])
        
        # í˜„ì¬ í™œì„± ì•Œë¦¼
        active_alerts = [a for a in self.alerts_history 
                        if time.time() - a.timestamp < 300]  # 5ë¶„ ì´ë‚´
        
        return {
            "status": "active",
            "monitoring_duration_hours": len(recent_metrics) / 3600,
            "averages": {
                "cpu_usage": round(avg_cpu, 2),
                "memory_usage": round(avg_memory, 2),
                "response_time_ms": round(avg_response_time, 2)
            },
            "peaks": {
                "cpu_usage": round(max_cpu, 2),
                "memory_usage": round(max_memory, 2),
                "response_time_ms": round(max_response_time, 2)
            },
            "total_errors": total_errors,
            "active_alerts": len(active_alerts),
            "critical_alerts": len([a for a in active_alerts if a.level == 'critical']),
            "ollama_models_active": self.ollama_stats['active_models'],
            "user_sessions": self.user_stats['active_sessions']
        }
    
    def update_ollama_stats(self, active_models: int, total_requests: int = None) -> None:
        """Ollama í†µê³„ ì—…ë°ì´íŠ¸"""
        self.ollama_stats['active_models'] = active_models
        if total_requests is not None:
            self.ollama_stats['total_requests'] = total_requests
    
    def update_processing_stats(self, queue_size: int, completed_tasks: int = None) -> None:
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.processing_stats['queue_size'] = queue_size
        if completed_tasks is not None:
            self.processing_stats['completed_tasks'] = completed_tasks
    
    def update_user_stats(self, active_sessions: int, total_requests: int = None) -> None:
        """ì‚¬ìš©ì í†µê³„ ì—…ë°ì´íŠ¸"""
        self.user_stats['active_sessions'] = active_sessions
        if total_requests is not None:
            self.user_stats['total_requests'] = total_requests
    
    def export_metrics(self, hours: int = 24) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        metrics = self.get_metrics_history(hours)
        alerts = [a for a in self.alerts_history 
                 if time.time() - a.timestamp < (hours * 3600)]
        
        return {
            "export_timestamp": datetime.now().isoformat(),
            "duration_hours": hours,
            "metrics_count": len(metrics),
            "alerts_count": len(alerts),
            "metrics": [asdict(m) for m in metrics],
            "alerts": [asdict(a) for a in alerts],
            "summary": self.get_performance_summary()
        }

# ì „ì—­ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
_global_monitor = None

def get_global_monitor() -> RealtimePerformanceMonitor:
    """ì „ì—­ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_monitor
    if _global_monitor is None:
        _global_monitor = RealtimePerformanceMonitor()
        _global_monitor.start_monitoring()
    return _global_monitor

def setup_monitoring_with_alerts(alert_callback: Callable[[SystemAlert], None]) -> RealtimePerformanceMonitor:
    """ì•Œë¦¼ ì½œë°±ê³¼ í•¨ê»˜ ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    monitor = RealtimePerformanceMonitor(alert_callback=alert_callback)
    monitor.start_monitoring()
    return monitor

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    def alert_handler(alert: SystemAlert):
        print(f"ğŸš¨ ALERT: {alert.message} (ê°’: {alert.value}, ì„ê³„ê°’: {alert.threshold})")
        print(f"   ê¶Œì¥ ì¡°ì¹˜: {alert.suggested_action}")
    
    # ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = setup_monitoring_with_alerts(alert_handler)
    
    try:
        print("ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨. Ctrl+Cë¡œ ì¢…ë£Œ...")
        while True:
            time.sleep(10)
            summary = monitor.get_performance_summary()
            print(f"ğŸ“Š CPU: {summary.get('averages', {}).get('cpu_usage', 0):.1f}% | "
                  f"ë©”ëª¨ë¦¬: {summary.get('averages', {}).get('memory_usage', 0):.1f}% | "
                  f"ì•Œë¦¼: {summary.get('active_alerts', 0)}ê°œ")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì¤‘...")
        monitor.stop_monitoring()
        print("âœ… ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")