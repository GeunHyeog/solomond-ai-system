#!/usr/bin/env python3
"""
ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ v2.6
ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìë™ ìµœì í™” ì‹œìŠ¤í…œ
83% ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì„ 70% ì´í•˜ë¡œ ê°œì„ 
"""

import gc
import os
import sys
import time
import psutil
import threading
import weakref
from typing import Dict, List, Any, Optional, Callable, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from collections import defaultdict, deque
import logging
import json
from pathlib import Path
import numpy as np

@dataclass
class MemorySnapshot:
    """ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: float
    total_memory_mb: float
    available_memory_mb: float
    used_memory_mb: float
    usage_percent: float
    process_memory_mb: float
    cache_size_mb: float
    gc_stats: Dict[str, int]
    large_objects_count: int
    memory_pressure_level: str  # 'low', 'medium', 'high', 'critical'

@dataclass
class MemoryLeak:
    """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ ê²°ê³¼"""
    object_type: str
    instance_count: int
    growth_rate: float  # objects per minute
    memory_size_mb: float
    first_detected: str
    severity: str  # 'minor', 'major', 'critical'
    suggested_action: str

@dataclass
class OptimizationAction:
    """ìµœì í™” ì•¡ì…˜ ê²°ê³¼"""
    action_type: str
    memory_freed_mb: float
    execution_time_ms: float
    success: bool
    details: str
    timestamp: str

class MemoryOptimizationEngine:
    """ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„"""
    
    def __init__(self, 
                 target_usage_percent: float = 70.0,
                 monitoring_interval: float = 10.0,
                 optimization_threshold: float = 80.0):
        
        self.target_usage_percent = target_usage_percent
        self.monitoring_interval = monitoring_interval
        self.optimization_threshold = optimization_threshold
        
        self.logger = self._setup_logging()
        
        # ë©”ëª¨ë¦¬ ì¶”ì 
        self.memory_history = deque(maxlen=1000)
        self.optimization_history = deque(maxlen=500)
        
        # ëˆ„ìˆ˜ ê°ì§€
        self.object_tracking = defaultdict(list)
        self.baseline_objects = {}
        self.leak_detection_window = 300  # 5ë¶„
        
        # ìµœì í™” í†µê³„
        self.optimization_stats = {
            'total_optimizations': 0,
            'memory_freed_total_mb': 0.0,
            'average_optimization_time_ms': 0.0,
            'success_rate': 0.0,
            'last_optimization': None
        }
        
        # ìºì‹œ ë° ì„ì‹œ ê°ì²´ ì¶”ì 
        self.managed_caches = weakref.WeakSet()
        self.temporary_objects = weakref.WeakSet()
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.is_monitoring = False
        self.monitoring_thread = None
        self.optimization_callbacks = []
        
        # ì„¤ì •
        self.auto_optimization_enabled = True
        self.aggressive_mode = False
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self.lock = threading.RLock()
        
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(f'{__name__}.MemoryOptimizationEngine')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | %(name)s | %(levelname)s | %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def start_monitoring(self) -> None:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_monitoring:
            self.logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            daemon=True
        )
        self.monitoring_thread.start()
        self.logger.info("ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ ì‹œì‘")
    
    def stop_monitoring(self) -> None:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5.0)
        self.logger.info("â¹ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ ì¤‘ì§€")
    
    def _monitoring_loop(self) -> None:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_monitoring:
            try:
                # ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘
                snapshot = self._collect_memory_snapshot()
                
                with self.lock:
                    self.memory_history.append(snapshot)
                
                # ìµœì í™” í•„ìš”ì„± í™•ì¸
                if (self.auto_optimization_enabled and 
                    snapshot.usage_percent > self.optimization_threshold):
                    
                    self.logger.warning(
                        f"ğŸ”´ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {snapshot.usage_percent:.1f}% "
                        f"(ì„ê³„ê°’: {self.optimization_threshold:.1f}%)"
                    )
                    
                    # ìë™ ìµœì í™” ì‹¤í–‰
                    self._execute_auto_optimization(snapshot)
                
                # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
                if len(self.memory_history) >= 10:
                    self._detect_memory_leaks()
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(self.monitoring_interval)
    
    def _collect_memory_snapshot(self) -> MemorySnapshot:
        """ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘"""
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
        memory = psutil.virtual_memory()
        process = psutil.Process()
        process_memory = process.memory_info()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í†µê³„
        gc_stats = {
            'generation_0': len(gc.get_objects(0)) if hasattr(gc, 'get_objects') else 0,
            'generation_1': len(gc.get_objects(1)) if hasattr(gc, 'get_objects') else 0,
            'generation_2': len(gc.get_objects(2)) if hasattr(gc, 'get_objects') else 0,
            'uncollectable': len(gc.garbage)
        }
        
        # í° ê°ì²´ ì¹´ìš´íŠ¸ (1MB ì´ìƒ)
        large_objects_count = self._count_large_objects()
        
        # ìºì‹œ í¬ê¸° ê³„ì‚°
        cache_size_mb = self._calculate_cache_size()
        
        # ë©”ëª¨ë¦¬ ì••ë°• ìˆ˜ì¤€ ê³„ì‚°
        pressure_level = self._calculate_memory_pressure(memory.percent)
        
        return MemorySnapshot(
            timestamp=time.time(),
            total_memory_mb=memory.total / (1024**2),
            available_memory_mb=memory.available / (1024**2),
            used_memory_mb=memory.used / (1024**2),
            usage_percent=memory.percent,
            process_memory_mb=process_memory.rss / (1024**2),
            cache_size_mb=cache_size_mb,
            gc_stats=gc_stats,
            large_objects_count=large_objects_count,
            memory_pressure_level=pressure_level
        )
    
    def _count_large_objects(self) -> int:
        """í° ê°ì²´ ìˆ˜ ê³„ì‚° (ëŒ€ëµì )"""
        try:
            large_count = 0
            # í° ë¦¬ìŠ¤íŠ¸, ë”•íŠ¸, ë°”ì´íŠ¸ ê°ì²´ ë“±ì„ ì¹´ìš´íŠ¸
            for obj in gc.get_objects():
                if isinstance(obj, (list, dict, bytes, bytearray)):
                    if sys.getsizeof(obj) > 1024 * 1024:  # 1MB ì´ìƒ
                        large_count += 1
                if large_count > 100:  # ì„±ëŠ¥ì„ ìœ„í•´ ì œí•œ
                    break
            return large_count
        except Exception:
            return 0
    
    def _calculate_cache_size(self) -> float:
        """ê´€ë¦¬ë˜ëŠ” ìºì‹œ í¬ê¸° ê³„ì‚°"""
        total_cache_size = 0.0
        try:
            for cache in self.managed_caches:
                if hasattr(cache, 'get_size'):
                    total_cache_size += cache.get_size()
        except Exception:
            pass
        return total_cache_size / (1024**2)  # MB ë‹¨ìœ„
    
    def _calculate_memory_pressure(self, usage_percent: float) -> str:
        """ë©”ëª¨ë¦¬ ì••ë°• ìˆ˜ì¤€ ê³„ì‚°"""
        if usage_percent >= 95:
            return 'critical'
        elif usage_percent >= 85:
            return 'high'
        elif usage_percent >= 75:
            return 'medium'
        else:
            return 'low'
    
    def _execute_auto_optimization(self, snapshot: MemorySnapshot) -> None:
        """ìë™ ìµœì í™” ì‹¤í–‰"""
        self.logger.info("ğŸ”§ ìë™ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘")
        
        optimization_actions = []
        
        # 1. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        action = self._force_garbage_collection()
        optimization_actions.append(action)
        
        # 2. ìºì‹œ ì •ë¦¬
        if snapshot.cache_size_mb > 100:  # 100MB ì´ìƒì´ë©´ ì •ë¦¬
            action = self._clear_managed_caches(aggressive=snapshot.memory_pressure_level == 'critical')
            optimization_actions.append(action)
        
        # 3. ì„ì‹œ ê°ì²´ ì •ë¦¬
        action = self._clear_temporary_objects()
        optimization_actions.append(action)
        
        # 4. í° ê°ì²´ ì •ë¦¬ (aggressive modeì—ì„œë§Œ)
        if self.aggressive_mode or snapshot.memory_pressure_level == 'critical':
            action = self._optimize_large_objects()
            optimization_actions.append(action)
        
        # ê²°ê³¼ ê¸°ë¡
        with self.lock:
            self.optimization_history.extend(optimization_actions)
            self._update_optimization_stats(optimization_actions)
        
        # ì½œë°± ì‹¤í–‰
        for callback in self.optimization_callbacks:
            try:
                callback(snapshot, optimization_actions)
            except Exception as e:
                self.logger.error(f"âŒ ìµœì í™” ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        total_freed = sum(a.memory_freed_mb for a in optimization_actions)
        self.logger.info(f"âœ… ìë™ ìµœì í™” ì™„ë£Œ: {total_freed:.1f}MB í•´ì œ")
    
    def _force_garbage_collection(self) -> OptimizationAction:
        """ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜"""
        start_time = time.time()
        
        try:
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
            before_memory = psutil.Process().memory_info().rss / (1024**2)
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
            collected = gc.collect()
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            after_memory = psutil.Process().memory_info().rss / (1024**2)
            memory_freed = max(0, before_memory - after_memory)
            
            execution_time = (time.time() - start_time) * 1000
            
            return OptimizationAction(
                action_type='garbage_collection',
                memory_freed_mb=memory_freed,
                execution_time_ms=execution_time,
                success=True,
                details=f"ìˆ˜ì§‘ëœ ê°ì²´: {collected}ê°œ",
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return OptimizationAction(
                action_type='garbage_collection',
                memory_freed_mb=0.0,
                execution_time_ms=execution_time,
                success=False,
                details=f"ì‹¤íŒ¨: {str(e)}",
                timestamp=datetime.now().isoformat()
            )
    
    def _clear_managed_caches(self, aggressive: bool = False) -> OptimizationAction:
        """ê´€ë¦¬ë˜ëŠ” ìºì‹œ ì •ë¦¬"""
        start_time = time.time()
        
        try:
            before_memory = psutil.Process().memory_info().rss / (1024**2)
            cleared_caches = 0
            
            # WeakSetì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë°˜ë³µ
            caches_to_clear = list(self.managed_caches)
            
            for cache in caches_to_clear:
                try:
                    if hasattr(cache, 'clear'):
                        if aggressive:
                            cache.clear()
                            cleared_caches += 1
                        elif hasattr(cache, 'partial_clear'):
                            cache.partial_clear(0.5)  # 50% ì •ë¦¬
                            cleared_caches += 1
                        elif hasattr(cache, 'clear'):
                            cache.clear()
                            cleared_caches += 1
                except Exception:
                    continue
            
            after_memory = psutil.Process().memory_info().rss / (1024**2)
            memory_freed = max(0, before_memory - after_memory)
            execution_time = (time.time() - start_time) * 1000
            
            return OptimizationAction(
                action_type='cache_clearing',
                memory_freed_mb=memory_freed,
                execution_time_ms=execution_time,
                success=True,
                details=f"ì •ë¦¬ëœ ìºì‹œ: {cleared_caches}ê°œ (aggressive: {aggressive})",
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return OptimizationAction(
                action_type='cache_clearing',
                memory_freed_mb=0.0,
                execution_time_ms=execution_time,
                success=False,
                details=f"ì‹¤íŒ¨: {str(e)}",
                timestamp=datetime.now().isoformat()
            )
    
    def _clear_temporary_objects(self) -> OptimizationAction:
        """ì„ì‹œ ê°ì²´ ì •ë¦¬"""
        start_time = time.time()
        
        try:
            before_memory = psutil.Process().memory_info().rss / (1024**2)
            cleared_objects = 0
            
            # WeakSetì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë°˜ë³µ
            temp_objects = list(self.temporary_objects)
            
            for obj in temp_objects:
                try:
                    if hasattr(obj, 'cleanup'):
                        obj.cleanup()
                        cleared_objects += 1
                    elif hasattr(obj, 'close'):
                        obj.close()
                        cleared_objects += 1
                except Exception:
                    continue
            
            # WeakSet ìì²´ ì •ë¦¬
            self.temporary_objects.clear()
            
            after_memory = psutil.Process().memory_info().rss / (1024**2)
            memory_freed = max(0, before_memory - after_memory)
            execution_time = (time.time() - start_time) * 1000
            
            return OptimizationAction(
                action_type='temporary_objects_cleanup',
                memory_freed_mb=memory_freed,
                execution_time_ms=execution_time,
                success=True,
                details=f"ì •ë¦¬ëœ ì„ì‹œ ê°ì²´: {cleared_objects}ê°œ",
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return OptimizationAction(
                action_type='temporary_objects_cleanup',
                memory_freed_mb=0.0,
                execution_time_ms=execution_time,
                success=False,
                details=f"ì‹¤íŒ¨: {str(e)}",
                timestamp=datetime.now().isoformat()
            )
    
    def _optimize_large_objects(self) -> OptimizationAction:
        """í° ê°ì²´ ìµœì í™”"""
        start_time = time.time()
        
        try:
            before_memory = psutil.Process().memory_info().rss / (1024**2)
            optimized_objects = 0
            
            # NumPy ë°°ì—´ ë©”ëª¨ë¦¬ ì •ë¦¬
            try:
                import numpy as np
                # NumPyì˜ ë©”ëª¨ë¦¬ ì •ë¦¬
                for obj in gc.get_objects():
                    if isinstance(obj, np.ndarray) and obj.size > 1000000:  # 1M ìš”ì†Œ ì´ìƒ
                        if hasattr(obj, 'base') and obj.base is not None:
                            # ë·°ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì •ë¦¬ ì‹œë„
                            continue
                        optimized_objects += 1
                        if optimized_objects > 10:  # ì„±ëŠ¥ì„ ìœ„í•´ ì œí•œ
                            break
            except ImportError:
                pass
            
            # í° ë¦¬ìŠ¤íŠ¸/ë”•íŠ¸ ì••ì¶•
            large_objects_found = 0
            for obj in gc.get_objects():
                if isinstance(obj, list) and len(obj) > 100000 and not obj:
                    # ë¹ˆ í° ë¦¬ìŠ¤íŠ¸ëŠ” ì •ë¦¬
                    obj.clear()
                    large_objects_found += 1
                elif isinstance(obj, dict) and len(obj) > 10000:
                    # í° ë”•íŠ¸ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ë°ì´í„° ì†ì‹¤ ìœ„í—˜)
                    large_objects_found += 1
                
                if large_objects_found > 20:  # ì„±ëŠ¥ì„ ìœ„í•´ ì œí•œ
                    break
            
            after_memory = psutil.Process().memory_info().rss / (1024**2)
            memory_freed = max(0, before_memory - after_memory)
            execution_time = (time.time() - start_time) * 1000
            
            return OptimizationAction(
                action_type='large_objects_optimization',
                memory_freed_mb=memory_freed,
                execution_time_ms=execution_time,
                success=True,
                details=f"ìµœì í™”ëœ ê°ì²´: {optimized_objects}ê°œ, ë°œê²¬ëœ í° ê°ì²´: {large_objects_found}ê°œ",
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return OptimizationAction(
                action_type='large_objects_optimization',
                memory_freed_mb=0.0,
                execution_time_ms=execution_time,
                success=False,
                details=f"ì‹¤íŒ¨: {str(e)}",
                timestamp=datetime.now().isoformat()
            )
    
    def _detect_memory_leaks(self) -> List[MemoryLeak]:
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€"""
        leaks = []
        
        try:
            # ìµœê·¼ 10ê°œ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ì¶”ì„¸ ë¶„ì„
            recent_snapshots = list(self.memory_history)[-10:]
            
            if len(recent_snapshots) < 5:
                return leaks
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì¶”ì„¸ í™•ì¸
            memory_usage = [s.usage_percent for s in recent_snapshots]
            time_points = [s.timestamp for s in recent_snapshots]
            
            # ì„ í˜• íšŒê·€ë¡œ ì¦ê°€ ì¶”ì„¸ ê³„ì‚°
            if len(memory_usage) >= 5:
                x = np.array(time_points)
                y = np.array(memory_usage)
                
                # ë‹¨ìˆœ ì„ í˜• íšŒê·€
                x_mean = np.mean(x)
                y_mean = np.mean(y)
                
                numerator = np.sum((x - x_mean) * (y - y_mean))
                denominator = np.sum((x - x_mean) ** 2)
                
                if denominator != 0:
                    slope = numerator / denominator
                    
                    # ë¶„ë‹¹ ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ ê³„ì‚° (slopeëŠ” ì´ˆë‹¹ì´ë¯€ë¡œ 60ì„ ê³±í•¨)
                    growth_rate_per_minute = slope * 60
                    
                    # ëˆ„ìˆ˜ ì˜ì‹¬ ê¸°ì¤€: ë¶„ë‹¹ 0.5% ì´ìƒ ì¦ê°€
                    if growth_rate_per_minute > 0.5:
                        leak = MemoryLeak(
                            object_type='system_memory',
                            instance_count=0,
                            growth_rate=growth_rate_per_minute,
                            memory_size_mb=recent_snapshots[-1].used_memory_mb,
                            first_detected=recent_snapshots[0].timestamp,
                            severity='major' if growth_rate_per_minute > 1.0 else 'minor',
                            suggested_action=f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë¶„ë‹¹ {growth_rate_per_minute:.2f}% ì¦ê°€ ì¤‘. ì›ì¸ ì¡°ì‚¬ í•„ìš”"
                        )
                        leaks.append(leak)
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°ì²´ ìˆ˜ ì¦ê°€ í™•ì¸
            gc_growth = self._check_gc_object_growth(recent_snapshots)
            if gc_growth:
                leaks.append(gc_growth)
        
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ ì‹¤íŒ¨: {e}")
        
        return leaks
    
    def _check_gc_object_growth(self, snapshots: List[MemorySnapshot]) -> Optional[MemoryLeak]:
        """ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°ì²´ ì¦ê°€ í™•ì¸"""
        if len(snapshots) < 5:
            return None
        
        try:
            # ì„¸ëŒ€ë³„ ê°ì²´ ìˆ˜ ì¦ê°€ í™•ì¸
            for generation in ['generation_0', 'generation_1', 'generation_2']:
                counts = [s.gc_stats.get(generation, 0) for s in snapshots]
                
                if len(counts) >= 5:
                    # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ë¹„êµ
                    first_count = counts[0]
                    last_count = counts[-1]
                    
                    if first_count > 0:
                        growth_ratio = (last_count - first_count) / first_count
                        
                        # 50% ì´ìƒ ì¦ê°€í–ˆë‹¤ë©´ ëˆ„ìˆ˜ ì˜ì‹¬
                        if growth_ratio > 0.5:
                            return MemoryLeak(
                                object_type=f'gc_{generation}',
                                instance_count=last_count,
                                growth_rate=growth_ratio,
                                memory_size_mb=0.0,  # ì •í™•í•œ í¬ê¸° ê³„ì‚° ì–´ë ¤ì›€
                                first_detected=datetime.fromtimestamp(snapshots[0].timestamp).isoformat(),
                                severity='minor',
                                suggested_action=f"GC {generation} ê°ì²´ê°€ {growth_ratio:.1%} ì¦ê°€. ì°¸ì¡° í•´ì œ í™•ì¸ í•„ìš”"
                            )
        
        except Exception:
            pass
        
        return None
    
    def _update_optimization_stats(self, actions: List[OptimizationAction]) -> None:
        """ìµœì í™” í†µê³„ ì—…ë°ì´íŠ¸"""
        successful_actions = [a for a in actions if a.success]
        
        if successful_actions:
            self.optimization_stats['total_optimizations'] += len(successful_actions)
            
            total_freed = sum(a.memory_freed_mb for a in successful_actions)
            self.optimization_stats['memory_freed_total_mb'] += total_freed
            
            avg_time = np.mean([a.execution_time_ms for a in successful_actions])
            current_avg = self.optimization_stats['average_optimization_time_ms']
            total_count = self.optimization_stats['total_optimizations']
            
            # ì´ë™ í‰ê·  ê³„ì‚°
            self.optimization_stats['average_optimization_time_ms'] = (
                (current_avg * (total_count - len(successful_actions)) + 
                 avg_time * len(successful_actions)) / total_count
            )
            
            # ì„±ê³µë¥  ê³„ì‚°
            total_attempts = len(self.optimization_history)
            successful_attempts = len([a for a in self.optimization_history if a.success])
            self.optimization_stats['success_rate'] = (
                successful_attempts / total_attempts if total_attempts > 0 else 0.0
            )
            
            self.optimization_stats['last_optimization'] = datetime.now().isoformat()
    
    # ê³µê°œ API ë©”ì„œë“œë“¤
    
    def register_cache(self, cache_object: Any) -> None:
        """ìºì‹œ ê°ì²´ ë“±ë¡ (WeakReferenceë¡œ ê´€ë¦¬)"""
        if hasattr(cache_object, 'clear') or hasattr(cache_object, 'partial_clear'):
            self.managed_caches.add(cache_object)
            self.logger.debug(f"ğŸ“¦ ìºì‹œ ê°ì²´ ë“±ë¡: {type(cache_object).__name__}")
    
    def register_temporary_object(self, temp_object: Any) -> None:
        """ì„ì‹œ ê°ì²´ ë“±ë¡ (WeakReferenceë¡œ ê´€ë¦¬)"""
        self.temporary_objects.add(temp_object)
        self.logger.debug(f"ğŸ—‚ï¸ ì„ì‹œ ê°ì²´ ë“±ë¡: {type(temp_object).__name__}")
    
    def add_optimization_callback(self, callback: Callable) -> None:
        """ìµœì í™” ì½œë°± ë“±ë¡"""
        self.optimization_callbacks.append(callback)
    
    def force_optimization(self, aggressive: bool = False) -> List[OptimizationAction]:
        """ìˆ˜ë™ ìµœì í™” ì‹¤í–‰"""
        self.logger.info(f"ğŸ”§ ìˆ˜ë™ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘ (aggressive: {aggressive})")
        
        old_aggressive = self.aggressive_mode
        self.aggressive_mode = aggressive
        
        try:
            snapshot = self._collect_memory_snapshot()
            
            actions = []
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            actions.append(self._force_garbage_collection())
            
            # ìºì‹œ ì •ë¦¬
            actions.append(self._clear_managed_caches(aggressive=aggressive))
            
            # ì„ì‹œ ê°ì²´ ì •ë¦¬
            actions.append(self._clear_temporary_objects())
            
            # í° ê°ì²´ ìµœì í™” (aggressive ëª¨ë“œì—ì„œë§Œ)
            if aggressive:
                actions.append(self._optimize_large_objects())
            
            with self.lock:
                self.optimization_history.extend(actions)
                self._update_optimization_stats(actions)
            
            total_freed = sum(a.memory_freed_mb for a in actions if a.success)
            self.logger.info(f"âœ… ìˆ˜ë™ ìµœì í™” ì™„ë£Œ: {total_freed:.1f}MB í•´ì œ")
            
            return actions
            
        finally:
            self.aggressive_mode = old_aggressive
    
    def get_current_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            latest_snapshot = self.memory_history[-1] if self.memory_history else None
            
            if not latest_snapshot:
                return {"status": "no_data"}
            
            return {
                "timestamp": datetime.now().isoformat(),
                "memory_usage_percent": latest_snapshot.usage_percent,
                "memory_pressure_level": latest_snapshot.memory_pressure_level,
                "target_usage_percent": self.target_usage_percent,
                "is_within_target": latest_snapshot.usage_percent <= self.target_usage_percent,
                "process_memory_mb": latest_snapshot.process_memory_mb,
                "cache_size_mb": latest_snapshot.cache_size_mb,
                "large_objects_count": latest_snapshot.large_objects_count,
                "optimization_stats": self.optimization_stats.copy(),
                "monitoring_enabled": self.is_monitoring,
                "auto_optimization_enabled": self.auto_optimization_enabled
            }
    
    def get_memory_trend(self, hours: int = 1) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš© ì¶”ì„¸ ë¶„ì„"""
        with self.lock:
            cutoff_time = time.time() - (hours * 3600)
            recent_snapshots = [
                s for s in self.memory_history 
                if s.timestamp > cutoff_time
            ]
            
            if len(recent_snapshots) < 2:
                return {"status": "insufficient_data"}
            
            # ì¶”ì„¸ ê³„ì‚°
            usage_values = [s.usage_percent for s in recent_snapshots]
            
            return {
                "period_hours": hours,
                "snapshots_count": len(recent_snapshots),
                "current_usage": usage_values[-1],
                "min_usage": min(usage_values),
                "max_usage": max(usage_values),
                "avg_usage": np.mean(usage_values),
                "usage_trend": "increasing" if usage_values[-1] > usage_values[0] else "decreasing",
                "volatility": np.std(usage_values),
                "memory_leaks_detected": len(self._detect_memory_leaks())
            }
    
    def export_diagnostics(self, output_path: str) -> None:
        """ì§„ë‹¨ ì •ë³´ ë‚´ë³´ë‚´ê¸°"""
        with self.lock:
            diagnostics = {
                "export_timestamp": datetime.now().isoformat(),
                "engine_config": {
                    "target_usage_percent": self.target_usage_percent,
                    "optimization_threshold": self.optimization_threshold,
                    "monitoring_interval": self.monitoring_interval,
                    "auto_optimization_enabled": self.auto_optimization_enabled,
                    "aggressive_mode": self.aggressive_mode
                },
                "current_status": self.get_current_status(),
                "memory_trend": self.get_memory_trend(24),  # 24ì‹œê°„
                "optimization_history": [asdict(a) for a in list(self.optimization_history)[-50:]],
                "memory_snapshots": [asdict(s) for s in list(self.memory_history)[-100:]],
                "detected_leaks": [asdict(leak) for leak in self._detect_memory_leaks()]
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(diagnostics, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ğŸ“Š ë©”ëª¨ë¦¬ ì§„ë‹¨ ì •ë³´ ì €ì¥ë¨: {output_path}")

# ì „ì—­ ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
_global_memory_optimizer = None

def get_global_memory_optimizer() -> MemoryOptimizationEngine:
    """ì „ì—­ ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_memory_optimizer
    if _global_memory_optimizer is None:
        _global_memory_optimizer = MemoryOptimizationEngine()
        _global_memory_optimizer.start_monitoring()
    return _global_memory_optimizer

# í¸ì˜ í•¨ìˆ˜ë“¤
def optimize_memory(aggressive: bool = False) -> List[OptimizationAction]:
    """ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰"""
    return get_global_memory_optimizer().force_optimization(aggressive=aggressive)

def register_cache(cache_object: Any) -> None:
    """ìºì‹œ ê°ì²´ ë“±ë¡"""
    get_global_memory_optimizer().register_cache(cache_object)

def register_temp_object(temp_object: Any) -> None:
    """ì„ì‹œ ê°ì²´ ë“±ë¡"""
    get_global_memory_optimizer().register_temporary_object(temp_object)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    optimizer = MemoryOptimizationEngine(target_usage_percent=70.0)
    optimizer.start_monitoring()
    
    print("ğŸ§  ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í˜„ì¬ ìƒíƒœ í™•ì¸
    status = optimizer.get_current_status()
    print(f"í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {status.get('memory_usage_percent', 0):.1f}%")
    
    # ìˆ˜ë™ ìµœì í™” ì‹¤í–‰
    actions = optimizer.force_optimization()
    total_freed = sum(a.memory_freed_mb for a in actions if a.success)
    print(f"ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {total_freed:.1f}MB í•´ì œ")
    
    # ì§„ë‹¨ ì •ë³´ ì €ì¥
    optimizer.export_diagnostics("memory_diagnostics.json")
    
    try:
        time.sleep(30)  # 30ì´ˆ ë™ì•ˆ ëª¨ë‹ˆí„°ë§
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
    finally:
        optimizer.stop_monitoring()
        print("âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")