"""
ğŸ§  ì†”ë¡œëª¬ë“œ AI v2.1.2 - ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„
ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”

ì£¼ìš” ê¸°ëŠ¥:
- ì ì‘í˜• ë©”ëª¨ë¦¬ ê´€ë¦¬
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
- ì§€ëŠ¥í˜• ìºì‹œ ì‹œìŠ¤í…œ
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ë° ì •ë¦¬
- ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
"""

import gc
import os
import sys
import mmap
import tempfile
import weakref
import threading
import time
import psutil
from typing import Dict, List, Any, Optional, Iterator, Union, Callable
from collections import OrderedDict, defaultdict
from contextlib import contextmanager
from dataclasses import dataclass
import logging
from pathlib import Path
import pickle
import json
import hashlib
from io import BytesIO
import functools

@dataclass
class MemoryStats:
    """ë©”ëª¨ë¦¬ í†µê³„ ì •ë³´"""
    total_mb: float
    used_mb: float
    available_mb: float
    percent: float
    cached_mb: float
    gc_collections: int
    objects_tracked: int

@dataclass
class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬"""
    key: str
    value: Any
    size_mb: float
    access_count: int
    last_accessed: float
    created_at: float

class LRUCache:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ LRU ìºì‹œ"""
    
    def __init__(self, max_size_mb: float = 100.0, max_items: int = 1000):
        self.max_size_mb = max_size_mb
        self.max_items = max_items
        self.cache = OrderedDict()
        self.current_size_mb = 0.0
        self.hits = 0
        self.misses = 0
        self.lock = threading.RLock()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°"""
        with self.lock:
            if key in self.cache:
                entry = self.cache[key]
                entry.access_count += 1
                entry.last_accessed = time.time()
                # LRU: ìµœê·¼ ì ‘ê·¼í•œ í•­ëª©ì„ ë§¨ ë’¤ë¡œ ì´ë™
                self.cache.move_to_end(key)
                self.hits += 1
                return entry.value
            else:
                self.misses += 1
                return None
    
    def put(self, key: str, value: Any, size_mb: float = None) -> bool:
        """ìºì‹œì— ê°’ ì €ì¥"""
        if size_mb is None:
            size_mb = self._estimate_size(value)
        
        # ë„ˆë¬´ í° ê°ì²´ëŠ” ìºì‹œí•˜ì§€ ì•ŠìŒ
        if size_mb > self.max_size_mb * 0.5:
            return False
        
        with self.lock:
            current_time = time.time()
            
            # ê¸°ì¡´ í‚¤ê°€ ìˆìœ¼ë©´ ì œê±°
            if key in self.cache:
                old_entry = self.cache[key]
                self.current_size_mb -= old_entry.size_mb
                del self.cache[key]
            
            # ê³µê°„ í™•ë³´
            while (len(self.cache) >= self.max_items or 
                   self.current_size_mb + size_mb > self.max_size_mb):
                if not self.cache:
                    break
                self._evict_lru()
            
            # ìƒˆ ì—”íŠ¸ë¦¬ ì¶”ê°€
            entry = CacheEntry(
                key=key,
                value=value,
                size_mb=size_mb,
                access_count=1,
                last_accessed=current_time,
                created_at=current_time
            )
            
            self.cache[key] = entry
            self.current_size_mb += size_mb
            return True
    
    def _evict_lru(self):
        """ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°"""
        if self.cache:
            key, entry = self.cache.popitem(last=False)
            self.current_size_mb -= entry.size_mb
    
    def _estimate_size(self, obj: Any) -> float:
        """ê°ì²´ í¬ê¸° ì¶”ì • (MB)"""
        try:
            if hasattr(obj, '__len__'):
                # ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬ ë“±
                return sys.getsizeof(obj) / (1024 * 1024)
            elif isinstance(obj, (str, bytes)):
                return len(obj) / (1024 * 1024)
            else:
                return sys.getsizeof(obj) / (1024 * 1024)
        except:
            return 1.0  # ê¸°ë³¸ê°’
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        with self.lock:
            self.cache.clear()
            self.current_size_mb = 0.0
    
    def stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        total_requests = self.hits + self.misses
        hit_rate = (self.hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "items": len(self.cache),
            "size_mb": round(self.current_size_mb, 2),
            "max_size_mb": self.max_size_mb,
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": round(hit_rate, 2),
            "utilization": round(self.current_size_mb / self.max_size_mb * 100, 2)
        }

class StreamingFileProcessor:
    """ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ê¸°"""
    
    def __init__(self, chunk_size_mb: float = 10.0):
        self.chunk_size = int(chunk_size_mb * 1024 * 1024)
        self.logger = logging.getLogger(__name__)
    
    @contextmanager
    def open_large_file(self, filepath: str, mode: str = 'rb'):
        """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì•ˆì „ ì—´ê¸°"""
        file_size = os.path.getsize(filepath)
        
        if file_size > 100 * 1024 * 1024:  # 100MB ì´ìƒ
            self.logger.info(f"ğŸ“ ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€: {file_size / (1024*1024):.1f}MB")
            
            # ë©”ëª¨ë¦¬ ë§¤í•‘ ì‚¬ìš©
            with open(filepath, mode) as f:
                with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                    yield mm
        else:
            # ì¼ë°˜ íŒŒì¼ ì—´ê¸°
            with open(filepath, mode) as f:
                yield f
    
    def process_file_chunks(self, filepath: str, processor_func: Callable) -> Iterator[Any]:
        """íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬"""
        with self.open_large_file(filepath, 'rb') as f:
            while True:
                chunk = f.read(self.chunk_size)
                if not chunk:
                    break
                
                yield processor_func(chunk)
                
                # ì¤‘ê°„ì— ë©”ëª¨ë¦¬ ì •ë¦¬
                if gc.get_count()[0] > 1000:
                    gc.collect()
    
    def stream_text_file(self, filepath: str, encoding: str = 'utf-8') -> Iterator[str]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ë¼ì¸ë³„ ìŠ¤íŠ¸ë¦¬ë°"""
        try:
            with open(filepath, 'r', encoding=encoding, buffering=8192) as f:
                for line in f:
                    yield line.strip()
        except UnicodeDecodeError:
            # ì¸ì½”ë”© ì˜¤ë¥˜ ì‹œ ë°”ì´íŠ¸ë¡œ ì²˜ë¦¬
            with open(filepath, 'rb') as f:
                for line in f:
                    try:
                        yield line.decode('utf-8', errors='ignore').strip()
                    except:
                        continue
    
    def batch_process_lines(self, lines: Iterator[str], batch_size: int = 1000) -> Iterator[List[str]]:
        """ë¼ì¸ë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”"""
        batch = []
        for line in lines:
            batch.append(line)
            if len(batch) >= batch_size:
                yield batch
                batch = []
        
        if batch:  # ë§ˆì§€ë§‰ ë°°ì¹˜
            yield batch

class MemoryManager:
    """í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self, 
                 cache_size_mb: float = 200.0,
                 gc_threshold: float = 80.0,
                 emergency_threshold: float = 95.0):
        self.cache = LRUCache(max_size_mb=cache_size_mb)
        self.streaming_processor = StreamingFileProcessor()
        self.gc_threshold = gc_threshold
        self.emergency_threshold = emergency_threshold
        
        # ë©”ëª¨ë¦¬ ì¶”ì 
        self.memory_snapshots = []
        self.object_refs = weakref.WeakSet()
        self.temp_files = []
        
        # í†µê³„
        self.total_cleanups = 0
        self.bytes_freed = 0
        
        self.logger = logging.getLogger(__name__)
        
        # ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ìŠ¤ë ˆë“œ
        self.cleanup_thread = None
        self.should_stop = False
        self.start_background_cleanup()
    
    def start_background_cleanup(self):
        """ë°±ê·¸ë¼ìš´ë“œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘"""
        if self.cleanup_thread and self.cleanup_thread.is_alive():
            return
        
        self.should_stop = False
        self.cleanup_thread = threading.Thread(
            target=self._background_cleanup_loop,
            daemon=True
        )
        self.cleanup_thread.start()
        self.logger.info("ğŸ§¹ ë°±ê·¸ë¼ìš´ë“œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
    
    def stop_background_cleanup(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì¤‘ì§€"""
        self.should_stop = True
        if self.cleanup_thread:
            self.cleanup_thread.join(timeout=5.0)
    
    def _background_cleanup_loop(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ë£¨í”„"""
        while not self.should_stop:
            try:
                memory_percent = self.get_memory_usage().percent
                
                if memory_percent > self.emergency_threshold:
                    self.emergency_cleanup()
                elif memory_percent > self.gc_threshold:
                    self.routine_cleanup()
                
                time.sleep(30)  # 30ì´ˆë§ˆë‹¤ í™•ì¸
                
            except Exception as e:
                self.logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
                time.sleep(60)
    
    def get_memory_usage(self) -> MemoryStats:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"""
        memory = psutil.virtual_memory()
        process = psutil.Process()
        process_memory = process.memory_info()
        
        return MemoryStats(
            total_mb=memory.total / (1024 * 1024),
            used_mb=memory.used / (1024 * 1024),
            available_mb=memory.available / (1024 * 1024),
            percent=memory.percent,
            cached_mb=self.cache.current_size_mb,
            gc_collections=sum(gc.get_stats()[i]['collections'] for i in range(3)),
            objects_tracked=len(gc.get_objects())
        )
    
    def routine_cleanup(self) -> Dict[str, Any]:
        """ì¼ë°˜ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        before_stats = self.get_memory_usage()
        
        # 1. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        collected_objects = gc.collect()
        
        # 2. ìºì‹œ ì •ë¦¬ (50% ë¹„ìš°ê¸°)
        cache_items_before = len(self.cache.cache)
        items_to_remove = cache_items_before // 2
        for _ in range(items_to_remove):
            if self.cache.cache:
                self.cache._evict_lru()
        
        # 3. ì„ì‹œ íŒŒì¼ ì •ë¦¬
        self._cleanup_temp_files()
        
        after_stats = self.get_memory_usage()
        freed_mb = before_stats.used_mb - after_stats.used_mb
        
        self.total_cleanups += 1
        self.bytes_freed += max(0, freed_mb)
        
        result = {
            "type": "routine",
            "freed_mb": round(freed_mb, 2),
            "objects_collected": collected_objects,
            "cache_items_removed": cache_items_before - len(self.cache.cache),
            "memory_before": round(before_stats.percent, 1),
            "memory_after": round(after_stats.percent, 1)
        }
        
        self.logger.info(f"ğŸ§½ ì¼ë°˜ ì •ë¦¬ ì™„ë£Œ: {freed_mb:.1f}MB í•´ì œ")
        return result
    
    def emergency_cleanup(self) -> Dict[str, Any]:
        """ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        self.logger.warning("ğŸš¨ ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
        before_stats = self.get_memory_usage()
        
        # 1. ìºì‹œ ì „ì²´ ì‚­ì œ
        cache_size_before = self.cache.current_size_mb
        self.cache.clear()
        
        # 2. ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰)
        total_collected = 0
        for _ in range(3):
            total_collected += gc.collect()
            time.sleep(0.1)
        
        # 3. ì„ì‹œ íŒŒì¼ ëª¨ë‘ ì‚­ì œ
        temp_files_removed = self._cleanup_temp_files(force=True)
        
        # 4. ì•½í•œ ì°¸ì¡° ì •ë¦¬
        weak_refs_before = len(self.object_refs)
        self.object_refs.clear()
        
        after_stats = self.get_memory_usage()
        freed_mb = before_stats.used_mb - after_stats.used_mb
        
        result = {
            "type": "emergency",
            "freed_mb": round(freed_mb, 2),
            "objects_collected": total_collected,
            "cache_cleared_mb": round(cache_size_before, 2),
            "temp_files_removed": temp_files_removed,
            "weak_refs_cleared": weak_refs_before,
            "memory_before": round(before_stats.percent, 1),
            "memory_after": round(after_stats.percent, 1)
        }
        
        self.logger.warning(f"ğŸš¨ ê¸´ê¸‰ ì •ë¦¬ ì™„ë£Œ: {freed_mb:.1f}MB í•´ì œ")
        return result
    
    def _cleanup_temp_files(self, force: bool = False) -> int:
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        removed_count = 0
        files_to_remove = []
        
        for temp_file in self.temp_files[:]:
            try:
                if os.path.exists(temp_file):
                    # íŒŒì¼ì´ ë„ˆë¬´ ì˜¤ë˜ë˜ì—ˆê±°ë‚˜ force ëª¨ë“œ
                    if force or (time.time() - os.path.getctime(temp_file)) > 3600:  # 1ì‹œê°„
                        os.remove(temp_file)
                        files_to_remove.append(temp_file)
                        removed_count += 1
            except Exception as e:
                self.logger.debug(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {temp_file} - {e}")
        
        # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°
        for temp_file in files_to_remove:
            self.temp_files.remove(temp_file)
        
        return removed_count
    
    @contextmanager
    def temporary_file(self, suffix: str = '.tmp', prefix: str = 'solomond_'):
        """ì„ì‹œ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        temp_file = None
        try:
            with tempfile.NamedTemporaryFile(
                delete=False, 
                suffix=suffix, 
                prefix=prefix
            ) as f:
                temp_file = f.name
                self.temp_files.append(temp_file)
                yield temp_file
        finally:
            if temp_file and os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                    if temp_file in self.temp_files:
                        self.temp_files.remove(temp_file)
                except:
                    pass
    
    def track_object(self, obj: Any) -> Any:
        """ê°ì²´ ì¶”ì  (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)"""
        self.object_refs.add(obj)
        return obj
    
    def smart_cache(self, key: str, factory_func: Callable, 
                   size_hint_mb: float = None, ttl_seconds: float = 3600) -> Any:
        """ìŠ¤ë§ˆíŠ¸ ìºì‹±"""
        # ìºì‹œì—ì„œ í™•ì¸
        cached_value = self.cache.get(key)
        if cached_value is not None:
            return cached_value
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        memory_stats = self.get_memory_usage()
        if memory_stats.percent > self.gc_threshold:
            # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìºì‹± ì œí•œ
            self.logger.warning("ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ìºì‹± ì œí•œ")
            return factory_func()
        
        # ìƒˆ ê°’ ìƒì„± ë° ìºì‹±
        value = factory_func()
        
        if size_hint_mb is None:
            size_hint_mb = self._estimate_object_size(value)
        
        # TTL ê³ ë ¤í•˜ì—¬ ìºì‹±
        success = self.cache.put(key, value, size_hint_mb)
        if not success:
            self.logger.debug(f"ìºì‹± ì‹¤íŒ¨: {key}")
        
        return value
    
    def _estimate_object_size(self, obj: Any) -> float:
        """ê°ì²´ í¬ê¸° ì¶”ì •"""
        try:
            # ì§ë ¬í™”í•˜ì—¬ ì •í™•í•œ í¬ê¸° ì¸¡ì •
            pickled = pickle.dumps(obj)
            return len(pickled) / (1024 * 1024)
        except:
            # ì§ë ¬í™” ì‹¤íŒ¨ ì‹œ sys.getsizeof ì‚¬ìš©
            return sys.getsizeof(obj) / (1024 * 1024)
    
    def optimize_for_large_file(self, filepath: str) -> Dict[str, Any]:
        """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”"""
        file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
        memory_stats = self.get_memory_usage()
        
        recommendations = []
        
        # íŒŒì¼ í¬ê¸°ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­
        if file_size_mb > memory_stats.available_mb * 0.5:
            recommendations.append("ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í•„ìˆ˜")
            chunk_size_mb = max(1.0, memory_stats.available_mb * 0.1)
        elif file_size_mb > 100:
            recommendations.append("ì²­í¬ ê¸°ë°˜ ì²˜ë¦¬ ê¶Œì¥")
            chunk_size_mb = 10.0
        else:
            recommendations.append("ì¼ë°˜ ì²˜ë¦¬ ê°€ëŠ¥")
            chunk_size_mb = file_size_mb
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìš”ì„±
        if memory_stats.percent > 70:
            recommendations.append("ì²˜ë¦¬ ì „ ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìš”")
            self.routine_cleanup()
        
        return {
            "file_size_mb": round(file_size_mb, 2),
            "available_memory_mb": round(memory_stats.available_mb, 2),
            "recommended_chunk_size_mb": chunk_size_mb,
            "recommendations": recommendations,
            "use_streaming": file_size_mb > memory_stats.available_mb * 0.3
        }
    
    def get_optimization_report(self) -> Dict[str, Any]:
        """ìµœì í™” ë¦¬í¬íŠ¸"""
        memory_stats = self.get_memory_usage()
        cache_stats = self.cache.stats()
        
        return {
            "memory": {
                "current_usage_percent": round(memory_stats.percent, 1),
                "available_mb": round(memory_stats.available_mb, 1),
                "cached_mb": round(memory_stats.cached_mb, 1)
            },
            "cache": cache_stats,
            "cleanup_stats": {
                "total_cleanups": self.total_cleanups,
                "bytes_freed_mb": round(self.bytes_freed, 1),
                "temp_files_active": len(self.temp_files),
                "objects_tracked": len(self.object_refs)
            },
            "performance_tips": self._generate_performance_tips(memory_stats, cache_stats)
        }
    
    def _generate_performance_tips(self, memory_stats: MemoryStats, cache_stats: Dict) -> List[str]:
        """ì„±ëŠ¥ íŒ ìƒì„±"""
        tips = []
        
        if memory_stats.percent > 85:
            tips.append("ğŸš¨ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ - ê¸´ê¸‰ ì •ë¦¬ ê¶Œì¥")
        elif memory_stats.percent > 70:
            tips.append("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì£¼ì˜ - ì •ë¦¬ ê¶Œì¥")
        
        if cache_stats["hit_rate"] < 50:
            tips.append("ğŸ“Š ìºì‹œ íš¨ìœ¨ì„± ë‚®ìŒ - ìºì‹œ í¬ê¸° ì¡°ì • ê³ ë ¤")
        
        if cache_stats["utilization"] > 90:
            tips.append("ğŸ’¾ ìºì‹œ ê±°ì˜ ê°€ë“ì°¸ - ìºì‹œ í¬ê¸° ì¦ê°€ ê³ ë ¤")
        
        if memory_stats.objects_tracked > 10000:
            tips.append("ğŸ§¹ ì¶”ì  ê°ì²´ ë§ìŒ - ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê¶Œì¥")
        
        if not tips:
            tips.append("âœ… ë©”ëª¨ë¦¬ ìƒíƒœ ì–‘í˜¸")
        
        return tips

# ì „ì—­ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì €
global_memory_manager = MemoryManager()

def memory_optimized(cache_key: str = None, ttl: float = 3600):
    """ë©”ëª¨ë¦¬ ìµœì í™” ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            if cache_key:
                key = cache_key
            else:
                key = f"{func.__module__}.{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            return global_memory_manager.smart_cache(
                key=key,
                factory_func=lambda: func(*args, **kwargs),
                ttl_seconds=ttl
            )
        return wrapper
    return decorator

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§  ì†”ë¡œëª¬ë“œ AI ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ v2.1.2")
    print("=" * 50)
    
    manager = MemoryManager(cache_size_mb=50.0)
    
    # í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ
    stats = manager.get_memory_usage()
    print(f"ğŸ’¾ í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {stats.percent:.1f}%")
    print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {stats.available_mb:.1f}MB")
    
    # ìºì‹œ í…ŒìŠ¤íŠ¸
    @memory_optimized(cache_key="test_function")
    def expensive_computation(n):
        return sum(i**2 for i in range(n))
    
    print("\nğŸ”„ ìºì‹œ í…ŒìŠ¤íŠ¸...")
    start_time = time.time()
    result1 = expensive_computation(100000)
    first_time = time.time() - start_time
    
    start_time = time.time()
    result2 = expensive_computation(100000)  # ìºì‹œëœ ê²°ê³¼
    second_time = time.time() - start_time
    
    print(f"ì²« ë²ˆì§¸ ì‹¤í–‰: {first_time:.4f}ì´ˆ")
    print(f"ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ): {second_time:.4f}ì´ˆ")
    print(f"ì†ë„ í–¥ìƒ: {first_time/second_time:.1f}ë°°")
    
    # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì‹œë®¬ë ˆì´ì…˜
    print("\nğŸ“ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜...")
    with manager.temporary_file(suffix='.txt') as temp_file:
        # 10MB í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        with open(temp_file, 'w', encoding='utf-8') as f:
            for i in range(100000):
                f.write(f"ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë¼ì¸ {i:06d} ì…ë‹ˆë‹¤. " * 10 + "\n")
        
        # ìµœì í™” ë¶„ì„
        optimization = manager.optimize_for_large_file(temp_file)
        print(f"íŒŒì¼ í¬ê¸°: {optimization['file_size_mb']:.1f}MB")
        print(f"ê¶Œì¥ ì²­í¬ í¬ê¸°: {optimization['recommended_chunk_size_mb']:.1f}MB")
        print("ê¶Œì¥ì‚¬í•­:")
        for rec in optimization['recommendations']:
            print(f"  - {rec}")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        if optimization['use_streaming']:
            print("\nğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")
            line_count = 0
            for batch in manager.streaming_processor.batch_process_lines(
                manager.streaming_processor.stream_text_file(temp_file),
                batch_size=1000
            ):
                line_count += len(batch)
            print(f"ì´ {line_count:,}ê°œ ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸
    print("\nğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸...")
    cleanup_result = manager.routine_cleanup()
    print(f"í•´ì œëœ ë©”ëª¨ë¦¬: {cleanup_result['freed_mb']:.2f}MB")
    print(f"ìˆ˜ì§‘ëœ ê°ì²´: {cleanup_result['objects_collected']}ê°œ")
    
    # ìµœì í™” ë¦¬í¬íŠ¸
    print("\nğŸ“Š ìµœì í™” ë¦¬í¬íŠ¸:")
    report = manager.get_optimization_report()
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {report['memory']['current_usage_percent']}%")
    print(f"ìºì‹œ ì ì¤‘ë¥ : {report['cache']['hit_rate']}%")
    print("ì„±ëŠ¥ íŒ:")
    for tip in report['performance_tips']:
        print(f"  {tip}")
    
    # ì •ë¦¬
    manager.stop_background_cleanup()
    print("\nâœ… ë©”ëª¨ë¦¬ ìµœì í™” ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
