#!/usr/bin/env python3
"""
ë©”ëª¨ë¦¬ ì¸ì‹ íŒŒì¼ í”„ë¡œì„¸ì„œ v2.6
ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
"""

import gc
import time
import threading
import psutil
from typing import Dict, List, Any, Optional, Union, Callable, Iterator, Tuple
from dataclasses import dataclass, field
from pathlib import Path
import logging
from datetime import datetime
from contextlib import contextmanager

from .large_file_streaming_optimizer import (
    LargeFileStreamingOptimizer, 
    StreamingConfig, 
    FileChunk,
    get_global_streaming_optimizer
)

@dataclass
class ProcessingConfig:
    """íŒŒì¼ ì²˜ë¦¬ ì„¤ì •"""
    max_memory_usage_mb: float = 512.0  # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    memory_warning_threshold: float = 0.8  # ë©”ëª¨ë¦¬ ê²½ê³  ì„ê³„ê°’ (80%)
    memory_critical_threshold: float = 0.9  # ë©”ëª¨ë¦¬ ìœ„í—˜ ì„ê³„ê°’ (90%)
    auto_gc_enabled: bool = True  # ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    gc_frequency: int = 10  # GC ì£¼ê¸° (ì²˜ë¦¬ëœ ì²­í¬ ìˆ˜)
    batch_size: int = 5  # ë°°ì¹˜ í¬ê¸°
    enable_progress_tracking: bool = True  # ì§„í–‰ë¥  ì¶”ì 
    memory_optimization_level: str = "balanced"  # conservative, balanced, aggressive

@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„"""
    files_processed: int = 0
    total_size_processed_mb: float = 0.0
    total_processing_time_seconds: float = 0.0
    peak_memory_usage_mb: float = 0.0
    average_processing_speed_mbps: float = 0.0
    gc_collections: int = 0
    memory_warnings: int = 0
    memory_pressure_events: int = 0
    successful_files: int = 0
    failed_files: int = 0
    optimization_actions: List[str] = field(default_factory=list)

class MemoryAwareFileProcessor:
    """ë©”ëª¨ë¦¬ ì¸ì‹ íŒŒì¼ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, config: Optional[ProcessingConfig] = None):
        self.config = config or ProcessingConfig()
        self.stats = ProcessingStats()
        self.is_processing = False
        self.cancel_requested = False
        self.lock = threading.RLock()
        self.logger = self._setup_logging()
        
        # ìŠ¤íŠ¸ë¦¬ë° ìµœì í™” ì‹œìŠ¤í…œ
        streaming_config = StreamingConfig(
            max_memory_usage_mb=self.config.max_memory_usage_mb * 0.7,  # 70%ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ì— í• ë‹¹
            enable_memory_mapping=True,
            enable_async=True
        )
        self.streaming_optimizer = LargeFileStreamingOptimizer(streaming_config)
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        self.memory_monitor = MemoryMonitor(self.config)
        
        # ì²˜ë¦¬ ê²°ê³¼ ì„ì‹œ ì €ì¥ì†Œ
        self.temp_results = []
        self.temp_results_size_mb = 0.0
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(f'{__name__}.{self.__class__.__name__}')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | %(name)s | %(levelname)s | %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    @contextmanager
    def _memory_management_context(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì»¨í…ìŠ¤íŠ¸"""
        # ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ìƒíƒœ ì²´í¬
        initial_memory = self.memory_monitor.get_current_usage_mb()
        
        try:
            yield
        finally:
            # ì¢…ë£Œ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.config.auto_gc_enabled:
                gc.collect()
                self.stats.gc_collections += 1
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            final_memory = self.memory_monitor.get_current_usage_mb()
            memory_increase = final_memory - initial_memory
            
            if memory_increase > 50:  # 50MB ì´ìƒ ì¦ê°€
                self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€: {memory_increase:.1f}MB")
                self.stats.memory_warnings += 1
    
    def _should_trigger_gc(self, processed_chunks: int) -> bool:
        """ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¸"""
        if not self.config.auto_gc_enabled:
            return False
        
        # ì£¼ê¸°ì  GC
        if processed_chunks % self.config.gc_frequency == 0:
            return True
        
        # ë©”ëª¨ë¦¬ ì••ë°• ì‹œ ê°•ì œ GC
        current_usage = self.memory_monitor.get_current_usage_mb()
        usage_ratio = current_usage / self.config.max_memory_usage_mb
        
        if usage_ratio > self.config.memory_critical_threshold:
            self.stats.memory_pressure_events += 1
            return True
        
        return False
    
    def _optimize_memory_settings(self, file_size_mb: float) -> None:
        """íŒŒì¼ í¬ê¸°ì— ë”°ë¥¸ ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”"""
        optimization_level = self.config.memory_optimization_level
        
        if optimization_level == "conservative":
            # ë³´ìˆ˜ì : ì•ˆì „í•˜ê²Œ ì‘ì€ ì²­í¬ ì‚¬ìš©
            chunk_size_mb = min(4.0, file_size_mb / 50)
            max_memory = self.config.max_memory_usage_mb * 0.5
            
        elif optimization_level == "aggressive":
            # ê³µê²©ì : í° ì²­í¬ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
            chunk_size_mb = min(32.0, file_size_mb / 5)
            max_memory = self.config.max_memory_usage_mb * 0.9
            
        else:  # balanced
            # ê· í˜•: ì ì ˆí•œ ì²­í¬ í¬ê¸°
            chunk_size_mb = min(16.0, file_size_mb / 20)
            max_memory = self.config.max_memory_usage_mb * 0.7
        
        # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ì—…ë°ì´íŠ¸
        self.streaming_optimizer.config.chunk_size_mb = chunk_size_mb
        self.streaming_optimizer.config.max_memory_usage_mb = max_memory
        self.streaming_optimizer.chunk_size_bytes = int(chunk_size_mb * 1024 * 1024)
        
        self.stats.optimization_actions.append(
            f"ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”: ì²­í¬ {chunk_size_mb}MB, ìµœëŒ€ ë©”ëª¨ë¦¬ {max_memory}MB"
        )
        
        self.logger.info(f"ğŸ¯ ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™” ({optimization_level}): ì²­í¬ {chunk_size_mb}MB")
    
    def process_file(self, 
                    file_path: Union[str, Path],
                    processor_func: Callable[[FileChunk], Any],
                    progress_callback: Optional[Callable[[float, Dict], None]] = None) -> List[Any]:
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        self.logger.info(f"ğŸš€ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name} ({file_size_mb:.1f}MB)")
        
        # ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”
        self._optimize_memory_settings(file_size_mb)
        
        # ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”
        self.streaming_optimizer.optimize_for_file_type(file_path)
        
        results = []
        start_time = time.time()
        processed_chunks = 0
        
        try:
            with self._memory_management_context():
                # ì§„í–‰ë¥  ì½œë°± ì„¤ì •
                def streaming_progress_callback(progress: float, chunk: FileChunk):
                    if progress_callback and self.config.enable_progress_tracking:
                        progress_info = {
                            'file_name': file_path.name,
                            'progress_percent': progress,
                            'chunk_id': chunk.chunk_id,
                            'memory_usage_mb': self.memory_monitor.get_current_usage_mb(),
                            'processing_speed_mbps': self._calculate_current_speed()
                        }
                        progress_callback(progress, progress_info)
                
                self.streaming_optimizer.config.progress_callback = streaming_progress_callback
                
                # ì²­í¬ë³„ ì²˜ë¦¬
                for chunk in self.streaming_optimizer.stream_file_chunks(file_path):
                    if self.cancel_requested:
                        break
                    
                    try:
                        # ë©”ëª¨ë¦¬ ì••ë°• ì²´í¬
                        if self.memory_monitor.is_memory_pressure():
                            self.logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ì••ë°• ê°ì§€, ì²˜ë¦¬ ì¼ì‹œ ì¤‘ë‹¨")
                            time.sleep(0.1)  # ì§§ì€ ëŒ€ê¸°
                            
                            # ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                            gc.collect()
                            self.stats.gc_collections += 1
                        
                        # ì²­í¬ ì²˜ë¦¬
                        chunk_start_time = time.time()
                        result = processor_func(chunk)
                        
                        if result is not None:
                            results.append(result)
                            
                            # ê²°ê³¼ í¬ê¸° ì¶”ì  (ë©”ëª¨ë¦¬ ê´€ë¦¬ìš©)
                            try:
                                import sys
                                result_size = sys.getsizeof(result) / (1024 * 1024)  # MB
                                self.temp_results_size_mb += result_size
                            except:
                                pass
                        
                        processed_chunks += 1
                        
                        # ì£¼ê¸°ì  ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                        if self._should_trigger_gc(processed_chunks):
                            gc.collect()
                            self.stats.gc_collections += 1
                        
                        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¤‘ê°„ ê²°ê³¼ ì •ë¦¬
                        if processed_chunks % self.config.batch_size == 0:
                            self._cleanup_intermediate_results()
                    
                    except Exception as e:
                        self.logger.error(f"âŒ ì²­í¬ {chunk.chunk_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        continue
                
                # ìµœì¢… í†µê³„ ì—…ë°ì´íŠ¸
                processing_time = time.time() - start_time
                self.stats.files_processed += 1
                self.stats.total_size_processed_mb += file_size_mb
                self.stats.total_processing_time_seconds += processing_time
                
                if processing_time > 0:
                    speed_mbps = file_size_mb / processing_time
                    self.stats.average_processing_speed_mbps = (
                        (self.stats.average_processing_speed_mbps * (self.stats.files_processed - 1) + speed_mbps) / 
                        self.stats.files_processed
                    )
                
                # ë©”ëª¨ë¦¬ í”¼í¬ ì—…ë°ì´íŠ¸
                current_memory = self.memory_monitor.get_current_usage_mb()
                if current_memory > self.stats.peak_memory_usage_mb:
                    self.stats.peak_memory_usage_mb = current_memory
                
                self.stats.successful_files += 1
                self.logger.info(f"âœ… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼, {speed_mbps:.1f}MB/s")
        
        except Exception as e:
            self.stats.failed_files += 1
            self.logger.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
        
        return results
    
    def process_files_batch(self,
                           file_paths: List[Union[str, Path]],
                           processor_func: Callable[[FileChunk], Any],
                           progress_callback: Optional[Callable[[float, Dict], None]] = None) -> Dict[str, List[Any]]:
        """ì—¬ëŸ¬ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        self.is_processing = True
        self.cancel_requested = False
        
        total_files = len(file_paths)
        results = {}
        
        try:
            for i, file_path in enumerate(file_paths):
                if self.cancel_requested:
                    break
                
                file_path = Path(file_path)
                
                # ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
                overall_progress = (i / total_files) * 100
                
                def batch_progress_callback(file_progress: float, progress_info: Dict):
                    # íŒŒì¼ë³„ ì§„í–‰ë¥ ì„ ì „ì²´ ì§„í–‰ë¥ ì— ë°˜ì˜
                    adjusted_progress = overall_progress + (file_progress / total_files)
                    progress_info['overall_progress'] = adjusted_progress
                    progress_info['file_index'] = i + 1
                    progress_info['total_files'] = total_files
                    
                    if progress_callback:
                        progress_callback(adjusted_progress, progress_info)
                
                try:
                    self.logger.info(f"ğŸ“ íŒŒì¼ {i+1}/{total_files} ì²˜ë¦¬ ì¤‘: {file_path.name}")
                    file_results = self.process_file(file_path, processor_func, batch_progress_callback)
                    results[str(file_path)] = file_results
                    
                except Exception as e:
                    self.logger.error(f"âŒ íŒŒì¼ {file_path.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    results[str(file_path)] = []
                    continue
                
                # ë°°ì¹˜ ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
                if (i + 1) % 3 == 0:  # 3ê°œ íŒŒì¼ë§ˆë‹¤
                    self._cleanup_batch_memory()
        
        finally:
            self.is_processing = False
            
            # ìµœì¢… ì •ë¦¬
            self._cleanup_intermediate_results()
            gc.collect()
            self.stats.gc_collections += 1
        
        self.logger.info(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ íŒŒì¼")
        return results
    
    def _cleanup_intermediate_results(self) -> None:
        """ì¤‘ê°„ ê²°ê³¼ ì •ë¦¬"""
        if hasattr(self, 'temp_results'):
            self.temp_results.clear()
            self.temp_results_size_mb = 0.0
    
    def _cleanup_batch_memory(self) -> None:
        """ë°°ì¹˜ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        self._cleanup_intermediate_results()
        gc.collect()
        self.stats.gc_collections += 1
        
        self.logger.debug("ğŸ§¹ ë°°ì¹˜ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
    
    def _calculate_current_speed(self) -> float:
        """í˜„ì¬ ì²˜ë¦¬ ì†ë„ ê³„ì‚°"""
        if self.stats.total_processing_time_seconds > 0:
            return self.stats.total_size_processed_mb / self.stats.total_processing_time_seconds
        return 0.0
    
    def cancel_processing(self) -> None:
        """ì²˜ë¦¬ ì·¨ì†Œ"""
        self.cancel_requested = True
        self.streaming_optimizer.cancel_streaming()
        self.logger.info("ğŸ›‘ íŒŒì¼ ì²˜ë¦¬ ì·¨ì†Œ ìš”ì²­")
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return {
            'is_processing': self.is_processing,
            'files_processed': self.stats.files_processed,
            'successful_files': self.stats.successful_files,
            'failed_files': self.stats.failed_files,
            'total_size_processed_mb': self.stats.total_size_processed_mb,
            'total_processing_time_seconds': self.stats.total_processing_time_seconds,
            'average_processing_speed_mbps': self.stats.average_processing_speed_mbps,
            'peak_memory_usage_mb': self.stats.peak_memory_usage_mb,
            'current_memory_usage_mb': self.memory_monitor.get_current_usage_mb(),
            'memory_usage_percent': self.memory_monitor.get_usage_percent(),
            'gc_collections': self.stats.gc_collections,
            'memory_warnings': self.stats.memory_warnings,
            'memory_pressure_events': self.stats.memory_pressure_events,
            'optimization_actions': self.stats.optimization_actions,
            'memory_trend': self.memory_monitor.get_memory_trend(),
            'estimated_memory_efficiency': self._calculate_memory_efficiency()
        }
    
    def _calculate_memory_efficiency(self) -> float:
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê³„ì‚°"""
        if self.stats.total_size_processed_mb > 0 and self.stats.peak_memory_usage_mb > 0:
            return self.stats.peak_memory_usage_mb / self.stats.total_size_processed_mb
        return 1.0
    
    def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.cancel_processing()
        self._cleanup_intermediate_results()
        self.streaming_optimizer.cleanup()
        
        gc.collect()
        self.logger.info("ğŸ§¹ ë©”ëª¨ë¦¬ ì¸ì‹ íŒŒì¼ í”„ë¡œì„¸ì„œ ì •ë¦¬ ì™„ë£Œ")

class MemoryMonitor:
    """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.logger = logging.getLogger(f'{__name__}.MemoryMonitor')
        self.memory_history = []
        self.lock = threading.Lock()
    
    def get_current_usage_mb(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        try:
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / (1024 * 1024)
            
            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            with self.lock:
                self.memory_history.append((time.time(), memory_mb))
                # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
                if len(self.memory_history) > 100:
                    self.memory_history = self.memory_history[-100:]
            
            return memory_mb
        except Exception:
            return 0.0
    
    def get_usage_percent(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)"""
        current_usage = self.get_current_usage_mb()
        return (current_usage / self.config.max_memory_usage_mb) * 100
    
    def is_memory_pressure(self) -> bool:
        """ë©”ëª¨ë¦¬ ì••ë°• ìƒíƒœ í™•ì¸"""
        usage_ratio = self.get_usage_percent() / 100
        return usage_ratio > self.config.memory_critical_threshold
    
    def get_memory_trend(self) -> str:
        """ë©”ëª¨ë¦¬ ì‚¬ìš© ì¶”ì„¸"""
        with self.lock:
            if len(self.memory_history) < 10:
                return "insufficient_data"
            
            recent_values = [mem for _, mem in self.memory_history[-10:]]
            trend_sum = sum(recent_values[i] - recent_values[i-1] for i in range(1, len(recent_values)))
            
            if trend_sum > 5:  # 5MB ì´ìƒ ì¦ê°€
                return "increasing"
            elif trend_sum < -5:  # 5MB ì´ìƒ ê°ì†Œ
                return "decreasing"
            else:
                return "stable"

# ì „ì—­ íŒŒì¼ í”„ë¡œì„¸ì„œ
_global_file_processor = None
_global_processor_lock = threading.Lock()

def get_global_file_processor(config: Optional[ProcessingConfig] = None) -> MemoryAwareFileProcessor:
    """ì „ì—­ íŒŒì¼ í”„ë¡œì„¸ì„œ ê°€ì ¸ì˜¤ê¸°"""
    global _global_file_processor
    
    with _global_processor_lock:
        if _global_file_processor is None:
            _global_file_processor = MemoryAwareFileProcessor(config)
        return _global_file_processor

# í¸ì˜ í•¨ìˆ˜ë“¤
def process_large_file_memory_safe(file_path: Union[str, Path],
                                  processor_func: Callable[[FileChunk], Any],
                                  max_memory_mb: float = 512.0,
                                  optimization_level: str = "balanced",
                                  progress_callback: Optional[Callable] = None) -> List[Any]:
    """ë©”ëª¨ë¦¬ ì•ˆì „ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ (í¸ì˜ í•¨ìˆ˜)"""
    config = ProcessingConfig(
        max_memory_usage_mb=max_memory_mb,
        memory_optimization_level=optimization_level,
        auto_gc_enabled=True
    )
    
    processor = MemoryAwareFileProcessor(config)
    return processor.process_file(file_path, processor_func, progress_callback)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© í”„ë¡œì„¸ì„œ í•¨ìˆ˜
    def test_processor(chunk: FileChunk) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ì²­í¬ í”„ë¡œì„¸ì„œ"""
        # ì²­í¬ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
        time.sleep(0.01)  # 10ms ì²˜ë¦¬ ì‹œê°„
        
        return {
            'chunk_id': chunk.chunk_id,
            'size_mb': chunk.size_bytes / (1024 * 1024),
            'checksum': chunk.checksum,
            'is_compressed': chunk.is_compressed,
            'processing_time': datetime.now().isoformat()
        }
    
    # ì§„í–‰ë¥  ì½œë°±
    def progress_callback(progress: float, info: Dict):
        print(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% - {info.get('file_name', 'Unknown')} - ë©”ëª¨ë¦¬: {info.get('memory_usage_mb', 0):.1f}MB")
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •)
    test_file = Path("test_large_file.bin")
    
    if test_file.exists():
        print(f"ğŸ§ª ë©”ëª¨ë¦¬ ì¸ì‹ íŒŒì¼ í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸: {test_file.name}")
        
        config = ProcessingConfig(
            max_memory_usage_mb=256.0,
            memory_optimization_level="balanced",
            auto_gc_enabled=True,
            enable_progress_tracking=True
        )
        
        processor = MemoryAwareFileProcessor(config)
        
        try:
            results = processor.process_file(test_file, test_processor, progress_callback)
            
            # í†µê³„ ì¶œë ¥
            stats = processor.get_processing_stats()
            print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
            print(f"  ì²˜ë¦¬ëœ ê²°ê³¼: {len(results)}ê°œ")
            print(f"  ì²˜ë¦¬ ì†ë„: {stats['average_processing_speed_mbps']:.1f}MB/s")
            print(f"  í”¼í¬ ë©”ëª¨ë¦¬: {stats['peak_memory_usage_mb']:.1f}MB")
            print(f"  ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {stats['estimated_memory_efficiency']:.2f}")
            print(f"  GC íšŸìˆ˜: {stats['gc_collections']}íšŒ")
            
        finally:
            processor.cleanup()
    
    else:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì§€ì •í•˜ì„¸ìš”.")
    
    print("âœ… ë©”ëª¨ë¦¬ ì¸ì‹ íŒŒì¼ í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")