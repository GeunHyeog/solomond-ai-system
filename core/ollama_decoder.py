#!/usr/bin/env python3
"""
ğŸ§  Ollama ê¸°ë°˜ ì§€ëŠ¥í˜• ë””ì½”ë” - SOLOMOND AI ì§„ì •í•œ ë©€í‹°ëª¨ë‹¬ë¦¬í‹° êµ¬í˜„
Intelligent Ollama Decoder: Strategic Model Chaining for Insight Generation

ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
1. 5ê°œ ëª¨ë¸ ì „ëµì  ì²´ì´ë‹ - ê° ëª¨ë¸ì˜ íŠ¹ì„±ì„ ìµœì í™” í™œìš©
2. ìœµí•© ì„ë² ë”© â†’ ì¸ì‚¬ì´íŠ¸ ë³€í™˜ - 768ì°¨ì› ë²¡í„°ë¥¼ ì˜ë¯¸ìˆëŠ” ë¶„ì„ìœ¼ë¡œ
3. ê³„ì¸µì  ë¶„ì„ í”„ë¡œì„¸ìŠ¤ - ê¸°ë³¸â†’ì‹¬í™”â†’ì „ë¬¸â†’í†µí•©â†’ê²€ì¦ ë‹¨ê³„
4. ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ë””ì½”ë”© - ë„ë©”ì¸ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì ìš©
5. í’ˆì§ˆ ë³´ì¦ ì‹œìŠ¤í…œ - ë‹¤ì¤‘ ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°ì„± í™•ë³´
"""

import numpy as np
import json
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import asyncio
from concurrent.futures import ThreadPoolExecutor

# ë¡œì»¬ ì„í¬íŠ¸
from .multimodal_encoder import EncodedResult
from .crossmodal_fusion import FusionResult
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'shared'))

try:
    from ollama_interface import OllamaInterface, get_ollama_status
except ImportError:
    logging.error("Ollama ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    OllamaInterface = None

# ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DecodingResult:
    """ë””ì½”ë”© ê²°ê³¼ êµ¬ì¡°"""
    insights: List[Dict[str, Any]]  # ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸ë“¤
    confidence_scores: Dict[str, float]  # ëª¨ë¸ë³„ ì‹ ë¢°ë„
    processing_chain: List[str]  # ì‚¬ìš©ëœ ëª¨ë¸ ì²´ì¸
    final_confidence: float  # ìµœì¢… ì‹ ë¢°ë„
    processing_time: float  # ì²˜ë¦¬ ì‹œê°„
    metadata: Dict[str, Any]  # ë©”íƒ€ë°ì´í„°
    quality_assessment: str  # í’ˆì§ˆ í‰ê°€

class OllamaIntelligentDecoder:
    """Ollama ê¸°ë°˜ ì§€ëŠ¥í˜• ë””ì½”ë”"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        
        # Ollama ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
        if OllamaInterface:
            self.ollama = OllamaInterface()
        else:
            self.ollama = None
            logger.error("Ollama ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        # 5ê°œ ëª¨ë¸ ì²´ì¸ ì„¤ì •
        self.model_chain = self._setup_model_chain()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.stats = {
            'decodings_performed': 0,
            'average_processing_time': 0.0,
            'model_usage_count': {},
            'quality_scores': [],
            'failed_decodings': 0
        }
        
    def _get_default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            'model_chain': [
                'qwen2.5:7b',    # 1ë‹¨ê³„: ê¸°ë³¸ ë¶„ì„ (ë¹ ë¥´ê³  ì•ˆì •ì )
                'gemma2:9b',     # 2ë‹¨ê³„: ì‹¬í™” ë¶„ì„ (ê· í˜•ì¡íŒ ì„±ëŠ¥)
                'llama3.1:8b',   # 3ë‹¨ê³„: ì „ë¬¸ ë¶„ì„ (ê³ í’ˆì§ˆ ì¶”ë¡ )
                'qwen2:7b',      # 4ë‹¨ê³„: í†µí•© ë¶„ì„ (ë‹¤ê°ë„ ê´€ì )
                'gemma:7b'       # 5ë‹¨ê³„: ê²€ì¦ ë¶„ì„ (í’ˆì§ˆ ë³´ì¦)
            ],
            'fallback_models': ['qwen2.5:7b', 'llama3.2:3b'],
            'max_retries': 3,
            'timeout_per_model': 300,  # 5ë¶„
            'min_confidence_threshold': 0.3,
            'enable_parallel_processing': True,
            'context_window': 4000,
            'temperature': 0.7
        }
    
    def _setup_model_chain(self) -> List[Dict]:
        """ëª¨ë¸ ì²´ì¸ ì„¤ì •"""
        return [
            {
                'model': self.config['model_chain'][0],
                'role': 'basic_analyzer',
                'description': 'ê¸°ë³¸ ë¶„ì„: í•µì‹¬ ìš”ì†Œ ì¶”ì¶œ ë° ì´ˆê¸° í•´ì„',
                'temperature': 0.3,
                'max_tokens': 500,
                'prompt_style': 'concise'
            },
            {
                'model': self.config['model_chain'][1],
                'role': 'deep_analyzer',
                'description': 'ì‹¬í™” ë¶„ì„: íŒ¨í„´ íƒì§€ ë° ê´€ê³„ ë¶„ì„',
                'temperature': 0.5,
                'max_tokens': 800,
                'prompt_style': 'analytical'
            },
            {
                'model': self.config['model_chain'][2],
                'role': 'expert_analyzer',
                'description': 'ì „ë¬¸ ë¶„ì„: ë„ë©”ì¸ íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±',
                'temperature': 0.7,
                'max_tokens': 1000,
                'prompt_style': 'expert'
            },
            {
                'model': self.config['model_chain'][3],
                'role': 'synthesizer',
                'description': 'í†µí•© ë¶„ì„: ë‹¤ê°ë„ ê´€ì  í†µí•© ë° ì¢…í•©',
                'temperature': 0.6,
                'max_tokens': 1200,
                'prompt_style': 'comprehensive'
            },
            {
                'model': self.config['model_chain'][4],
                'role': 'validator',
                'description': 'ê²€ì¦ ë¶„ì„: ê²°ê³¼ ê²€í†  ë° í’ˆì§ˆ ë³´ì¦',
                'temperature': 0.2,
                'max_tokens': 600,
                'prompt_style': 'critical'
            }
        ]
    
    def decode_fusion_result(self, fusion_result: FusionResult, context: Optional[Dict] = None) -> DecodingResult:
        """ìœµí•© ê²°ê³¼ë¥¼ ì¸ì‚¬ì´íŠ¸ë¡œ ë””ì½”ë”©"""
        if not self.ollama:
            return self._create_fallback_result("Ollama ì¸í„°í˜ì´ìŠ¤ ì—†ìŒ")
            
        logger.info("ğŸ§  ì§€ëŠ¥í˜• ë””ì½”ë”© í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
        start_time = time.time()
        
        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        analysis_context = self._prepare_context(fusion_result, context)
        
        # 5ë‹¨ê³„ ì²´ì´ë‹ ë¶„ì„ ì‹¤í–‰
        insights = []
        confidence_scores = {}
        processing_chain = []
        
        previous_output = ""
        
        for step_idx, model_config in enumerate(self.model_chain):
            try:
                logger.info(f"ğŸ”„ {step_idx + 1}ë‹¨ê³„: {model_config['description']}")
                
                # ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self._generate_stage_prompt(
                    step_idx, model_config, fusion_result, 
                    analysis_context, previous_output
                )
                
                # ëª¨ë¸ ì‹¤í–‰
                response = self._execute_model(model_config, prompt)
                
                if response and len(response.strip()) > 10:
                    # ì‘ë‹µ íŒŒì‹± ë° ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
                    stage_insights = self._parse_model_response(
                        response, model_config['role'], step_idx
                    )
                    
                    insights.extend(stage_insights)
                    confidence_scores[model_config['role']] = self._calculate_response_confidence(response)
                    processing_chain.append(f"{model_config['role']}({model_config['model']})")
                    previous_output = response
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    model_name = model_config['model']
                    self.stats['model_usage_count'][model_name] = self.stats['model_usage_count'].get(model_name, 0) + 1
                    
                else:
                    logger.warning(f"âš ï¸ {step_idx + 1}ë‹¨ê³„ ëª¨ë¸ ì‘ë‹µ ë¶€ì¡±, ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰")
                    
            except Exception as e:
                logger.error(f"âŒ {step_idx + 1}ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰
                continue
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        processing_time = time.time() - start_time
        final_confidence = self._calculate_final_confidence(confidence_scores, insights)
        quality_assessment = self._assess_quality(insights, confidence_scores)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_stats(processing_time, final_confidence, len(insights))
        
        result = DecodingResult(
            insights=insights,
            confidence_scores=confidence_scores,
            processing_chain=processing_chain,
            final_confidence=final_confidence,
            processing_time=processing_time,
            quality_assessment=quality_assessment,
            metadata={
                'total_stages': len(self.model_chain),
                'successful_stages': len(confidence_scores),
                'context_provided': context is not None,
                'fusion_confidence': fusion_result.fusion_confidence,
                'dominant_modality': fusion_result.dominant_modality
            }
        )
        
        logger.info(f"âœ… ì§€ëŠ¥í˜• ë””ì½”ë”© ì™„ë£Œ: {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸, ì‹ ë¢°ë„ {final_confidence:.3f}")
        return result
    
    def _prepare_context(self, fusion_result: FusionResult, additional_context: Optional[Dict]) -> Dict:
        """ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        context = {
            'modality_weights': fusion_result.modal_weights,
            'dominant_modality': fusion_result.dominant_modality,
            'semantic_coherence': fusion_result.semantic_coherence,
            'fusion_confidence': fusion_result.fusion_confidence,
            'cross_modal_correlations': fusion_result.cross_modal_correlations[:3],  # ìƒìœ„ 3ê°œë§Œ
            'analysis_domain': 'conference_analysis'  # ê¸°ë³¸ê°’
        }
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ë³‘í•©
        if additional_context:
            context.update(additional_context)
            
        return context
    
    def _generate_stage_prompt(self, stage: int, model_config: Dict, fusion_result: FusionResult, 
                              context: Dict, previous_output: str) -> str:
        """ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        base_info = f"""
ë‹¤ìŒì€ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:
- ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹°: {fusion_result.dominant_modality}
- ìœµí•© ì‹ ë¢°ë„: {fusion_result.fusion_confidence:.3f}
- ì˜ë¯¸ì  ì¼ê´€ì„±: {fusion_result.semantic_coherence:.3f}
- ëª¨ë‹¬ êµ¬ì„±: {', '.join(fusion_result.modal_weights.keys())}
"""
        
        # ë‹¨ê³„ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        if stage == 0:  # ê¸°ë³¸ ë¶„ì„
            return f"""
{base_info}

ğŸ¯ **1ë‹¨ê³„ - ê¸°ë³¸ ë¶„ì„ ìš”ì²­**
ë‹¹ì‹ ì€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì˜ í•µì‹¬ ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **í•µì‹¬ ì£¼ì œ**: ë¬´ì—‡ì— ê´€í•œ ë‚´ìš©ì¸ê°€?
2. **ì£¼ìš” íŠ¹ì§•**: ì–´ë–¤ íŠ¹ì§•ë“¤ì´ ë‘ë“œëŸ¬ì§€ëŠ”ê°€?
3. **ì´ˆê¸° ê´€ì°°**: ì²« ë²ˆì§¸ ì¸ìƒì€ ì–´ë– í•œê°€?

ğŸ“‹ **ì‘ë‹µ í˜•ì‹**: ê° í•­ëª©ì„ 3-4ì¤„ë¡œ ê°„ë‹¨íˆ ì •ë¦¬
"""
            
        elif stage == 1:  # ì‹¬í™” ë¶„ì„
            return f"""
{base_info}

ì´ì „ ë‹¨ê³„ ê²°ê³¼:
{previous_output[:500]}

ğŸ” **2ë‹¨ê³„ - ì‹¬í™” ë¶„ì„ ìš”ì²­**
ë‹¹ì‹ ì€ íŒ¨í„´ê³¼ ê´€ê³„ë¥¼ íƒì§€í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ìœ„ ê¸°ë³¸ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

1. **íŒ¨í„´ íƒì§€**: ì–´ë–¤ ê·œì¹™ì„±ì´ë‚˜ íŒ¨í„´ì´ ë³´ì´ëŠ”ê°€?
2. **ê´€ê³„ ë¶„ì„**: ìš”ì†Œë“¤ ê°„ì˜ ì—°ê´€ì„±ì€ ì–´ë– í•œê°€?
3. **ìˆ¨ê²¨ì§„ ì˜ë¯¸**: í‘œë©´ì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ì§€ ì•Šì€ ì˜ë¯¸ëŠ”?

ğŸ“‹ **ì‘ë‹µ í˜•ì‹**: ê° í•­ëª©ì„ 5-6ì¤„ë¡œ ë¶„ì„ì ìœ¼ë¡œ ì„¤ëª…
"""
            
        elif stage == 2:  # ì „ë¬¸ ë¶„ì„
            domain = context.get('analysis_domain', 'general')
            return f"""
{base_info}

ì´ì „ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼:
{previous_output[:800]}

ğŸ‘¨â€ğŸ« **3ë‹¨ê³„ - ì „ë¬¸ ë¶„ì„ ìš”ì²­**
ë‹¹ì‹ ì€ {domain} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•ì„  ë¶„ì„ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ì  ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì „ë¬¸ì  í•´ì„**: í•´ë‹¹ ë¶„ì•¼ ê´€ì ì—ì„œì˜ ì˜ë¯¸ëŠ”?
2. **ì¤‘ìš”í•œ ì‹œì‚¬ì **: ì „ë¬¸ê°€ê°€ ì£¼ëª©í•  í¬ì¸íŠ¸ë“¤ì€?
3. **ì‹¤ë¬´ì  ê°€ì¹˜**: ì‹¤ì œ í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ëŠ”?

ğŸ“‹ **ì‘ë‹µ í˜•ì‹**: ì „ë¬¸ ìš©ì–´ë¥¼ í¬í•¨í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
"""
            
        elif stage == 3:  # í†µí•© ë¶„ì„
            return f"""
{base_info}

ì§€ê¸ˆê¹Œì§€ì˜ ëª¨ë“  ë¶„ì„ ê²°ê³¼:
{previous_output[:1000]}

ğŸ”— **4ë‹¨ê³„ - í†µí•© ë¶„ì„ ìš”ì²­**
ë‹¹ì‹ ì€ ë‹¤ê°ë„ ê´€ì ì„ í†µí•©í•˜ëŠ” í†µí•©ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ëª¨ë“  ì´ì „ ë¶„ì„ë“¤ì„ ì¢…í•©í•˜ì—¬ í†µí•©ì  ê´€ì ì„ ì œì‹œí•´ì£¼ì„¸ìš”:

1. **ì¢…í•© ì¸ì‚¬ì´íŠ¸**: ëª¨ë“  ë¶„ì„ì„ í†µí•©í•œ í•µì‹¬ ë©”ì‹œì§€ëŠ”?
2. **ë‹¤ê°ë„ ê´€ì **: ì—¬ëŸ¬ ê´€ì ì—ì„œ ë³¸ ì™„ì „í•œ ê·¸ë¦¼ì€?
3. **ì „ëµì  í•¨ì˜**: ì´ ë¶„ì„ì´ ê°€ì ¸ë‹¤ì£¼ëŠ” ì „ëµì  ê°€ì¹˜ëŠ”?

ğŸ“‹ **ì‘ë‹µ í˜•ì‹**: í¬ê´„ì ì´ê³  ê· í˜•ì¡íŒ ì¢…í•© ë¶„ì„
"""
            
        else:  # ê²€ì¦ ë¶„ì„
            return f"""
{base_info}

ìµœì¢… í†µí•© ë¶„ì„ ê²°ê³¼:
{previous_output}

âœ… **5ë‹¨ê³„ - ê²€ì¦ ë¶„ì„ ìš”ì²­**
ë‹¹ì‹ ì€ í’ˆì§ˆê³¼ ì •í™•ì„±ì„ ê²€ì¦í•˜ëŠ” ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ìœ„ í†µí•© ë¶„ì„ì„ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ê³  ìµœì¢… ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:

1. **ë¶„ì„ í’ˆì§ˆ**: ìœ„ ë¶„ì„ì˜ íƒ€ë‹¹ì„±ê³¼ ì‹ ë¢°ë„ëŠ”?
2. **ê°œì„  í¬ì¸íŠ¸**: ë³´ì™„í•˜ê±°ë‚˜ ìˆ˜ì •í•´ì•¼ í•  ë¶€ë¶„ì€?
3. **ìµœì¢… ê¶Œê³ **: ì´ ë¶„ì„ì„ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì„ê¹Œ?

ğŸ“‹ **ì‘ë‹µ í˜•ì‹**: ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ ê²€ì¦ ì˜ê²¬
"""
    
    def _execute_model(self, model_config: Dict, prompt: str) -> Optional[str]:
        """ê°œë³„ ëª¨ë¸ ì‹¤í–‰"""
        try:
            model_name = model_config['model']
            
            # ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
            available_models = self.ollama.available_models
            if model_name not in available_models:
                # í´ë°± ëª¨ë¸ ì‚¬ìš©
                for fallback in self.config['fallback_models']:
                    if fallback in available_models:
                        model_name = fallback
                        logger.info(f"í´ë°± ëª¨ë¸ ì‚¬ìš©: {model_name}")
                        break
                else:
                    logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return None
            
            # Ollama í˜¸ì¶œ
            response = self.ollama.generate_response(
                prompt=prompt,
                model=model_name,
                temperature=model_config.get('temperature', 0.7),
                max_tokens=model_config.get('max_tokens', 800)
            )
            
            return response.strip() if response else None
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨ {model_config['model']}: {e}")
            return None
    
    def _parse_model_response(self, response: str, role: str, stage: int) -> List[Dict[str, Any]]:
        """ëª¨ë¸ ì‘ë‹µ íŒŒì‹±í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        try:
            # ì‘ë‹µì„ ì„¹ì…˜ë³„ë¡œ ë¶„í• 
            sections = []
            current_section = ""
            
            lines = response.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith(('1.', '2.', '3.', '**', '#', '-')):
                    if current_section:
                        sections.append(current_section.strip())
                    current_section = line
                else:
                    current_section += f" {line}"
                    
            if current_section:
                sections.append(current_section.strip())
            
            # ê° ì„¹ì…˜ì„ ì¸ì‚¬ì´íŠ¸ë¡œ ë³€í™˜
            for i, section in enumerate(sections):
                if len(section) > 20:  # ë„ˆë¬´ ì§§ì€ ì„¹ì…˜ ì œì™¸
                    insight = {
                        'content': section,
                        'type': self._classify_insight_type(section, role),
                        'stage': stage + 1,
                        'role': role,
                        'confidence': self._calculate_section_confidence(section),
                        'priority': self._calculate_priority(section, role, i)
                    }
                    insights.append(insight)
                    
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±: ì „ì²´ ì‘ë‹µì„ í•˜ë‚˜ì˜ ì¸ì‚¬ì´íŠ¸ë¡œ ì²˜ë¦¬
            if response and len(response) > 50:
                insights.append({
                    'content': response,
                    'type': 'general',
                    'stage': stage + 1,
                    'role': role,
                    'confidence': 0.5,
                    'priority': 'medium'
                })
        
        return insights
    
    def _classify_insight_type(self, content: str, role: str) -> str:
        """ì¸ì‚¬ì´íŠ¸ íƒ€ì… ë¶„ë¥˜"""
        content_lower = content.lower()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        if any(keyword in content_lower for keyword in ['íŒ¨í„´', 'pattern', 'ê·œì¹™', 'ê²½í–¥']):
            return 'pattern'
        elif any(keyword in content_lower for keyword in ['ê´€ê³„', 'ì—°ê´€', 'ìƒê´€', 'ê´€ë ¨']):
            return 'relationship'
        elif any(keyword in content_lower for keyword in ['ì¸ì‚¬ì´íŠ¸', 'í•¨ì˜', 'ì˜ë¯¸', 'ì‹œì‚¬ì ']):
            return 'insight'
        elif any(keyword in content_lower for keyword in ['ì¶”ì²œ', 'ì œì•ˆ', 'ê¶Œê³ ', 'ê°œì„ ']):
            return 'recommendation'
        elif any(keyword in content_lower for keyword in ['ë¬¸ì œ', 'ì´ìŠˆ', 'ìœ„í—˜', 'ì£¼ì˜']):
            return 'issue'
        else:
            return 'general'
    
    def _calculate_section_confidence(self, section: str) -> float:
        """ì„¹ì…˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ê¸¸ì´, êµ¬ì¡°, êµ¬ì²´ì„± ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        length_score = min(1.0, len(section) / 200.0)  # 200ì ê¸°ì¤€
        
        # êµ¬ì²´ì  í‘œí˜„ ì ìˆ˜
        concrete_words = ['êµ¬ì²´ì ìœ¼ë¡œ', 'ì˜ˆë¥¼ ë“¤ì–´', 'ì‹¤ì œë¡œ', 'íŠ¹íˆ', 'ëª…í™•íˆ']
        concrete_score = sum(1 for word in concrete_words if word in section) * 0.1
        
        # ì „ë¬¸ ìš©ì–´ ì ìˆ˜
        expert_words = ['ë¶„ì„', 'ê´€ì ', 'ì¸¡ë©´', 'ìš”ì†Œ', 'íŠ¹ì§•', 'íŒ¨í„´', 'íŠ¸ë Œë“œ']
        expert_score = min(0.3, sum(1 for word in expert_words if word in section) * 0.05)
        
        base_confidence = 0.4
        return min(1.0, base_confidence + length_score * 0.3 + concrete_score + expert_score)
    
    def _calculate_priority(self, section: str, role: str, position: int) -> str:
        """ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        # ì—­í• ë³„ ê¸°ë³¸ ìš°ì„ ìˆœìœ„
        role_priority = {
            'basic_analyzer': 'medium',
            'deep_analyzer': 'medium', 
            'expert_analyzer': 'high',
            'synthesizer': 'high',
            'validator': 'medium'
        }
        
        # ë‚´ìš© ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì¡°ì •
        content_lower = section.lower()
        high_priority_keywords = ['ì¤‘ìš”', 'í•µì‹¬', 'ì£¼ìš”', 'ê²°ì •ì ', 'í•„ìˆ˜', 'urgent', 'critical']
        low_priority_keywords = ['ì°¸ê³ ', 'ë¶€ê°€', 'ì¶”ê°€', 'ë³´ì™„', 'ê¸°íƒ€']
        
        if any(keyword in content_lower for keyword in high_priority_keywords):
            return 'high'
        elif any(keyword in content_lower for keyword in low_priority_keywords):
            return 'low'
        else:
            return role_priority.get(role, 'medium')
    
    def _calculate_response_confidence(self, response: str) -> float:
        """ì „ì²´ ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not response:
            return 0.0
            
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.5
        
        # ê¸¸ì´ ì ìˆ˜ (ì ì ˆí•œ ê¸¸ì´)
        length = len(response)
        if 100 <= length <= 2000:
            length_score = 0.3
        elif length > 50:
            length_score = 0.1
        else:
            length_score = 0.0
            
        # êµ¬ì¡°í™” ì ìˆ˜ (ë²ˆí˜¸, ë¶ˆë¦¿ í¬ì¸íŠ¸ ë“±)
        structure_indicators = ['1.', '2.', '3.', '**', '##', '-', 'â€¢']
        structure_score = min(0.2, sum(0.05 for indicator in structure_indicators if indicator in response))
        
        return min(1.0, base_score + length_score + structure_score)
    
    def _calculate_final_confidence(self, confidence_scores: Dict[str, float], insights: List[Dict]) -> float:
        """ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°"""
        if not confidence_scores:
            return 0.0
            
        # ë‹¨ê³„ë³„ ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        stage_weights = {
            'basic_analyzer': 0.15,
            'deep_analyzer': 0.20,
            'expert_analyzer': 0.25,
            'synthesizer': 0.25,
            'validator': 0.15
        }
        
        weighted_confidence = 0.0
        total_weight = 0.0
        
        for role, confidence in confidence_scores.items():
            weight = stage_weights.get(role, 0.2)
            weighted_confidence += confidence * weight
            total_weight += weight
            
        stage_confidence = weighted_confidence / total_weight if total_weight > 0 else 0.0
        
        # ì¸ì‚¬ì´íŠ¸ í’ˆì§ˆ ë³´ë„ˆìŠ¤
        if insights:
            avg_insight_confidence = np.mean([insight.get('confidence', 0.5) for insight in insights])
            insight_bonus = (avg_insight_confidence - 0.5) * 0.1
        else:
            insight_bonus = 0.0
            
        return min(1.0, stage_confidence + insight_bonus)
    
    def _assess_quality(self, insights: List[Dict], confidence_scores: Dict[str, float]) -> str:
        """í’ˆì§ˆ í‰ê°€"""
        if not insights:
            return 'poor'
            
        avg_confidence = np.mean(list(confidence_scores.values())) if confidence_scores else 0.0
        insight_count = len(insights)
        
        if avg_confidence >= 0.8 and insight_count >= 8:
            return 'excellent'
        elif avg_confidence >= 0.6 and insight_count >= 5:
            return 'good'
        elif avg_confidence >= 0.4 and insight_count >= 3:
            return 'fair'
        else:
            return 'poor'
    
    def _create_fallback_result(self, reason: str) -> DecodingResult:
        """í´ë°± ê²°ê³¼ ìƒì„±"""
        return DecodingResult(
            insights=[{
                'content': f'ë””ì½”ë”© ì‹¤íŒ¨: {reason}',
                'type': 'error',
                'stage': 0,
                'role': 'system',
                'confidence': 0.0,
                'priority': 'high'
            }],
            confidence_scores={},
            processing_chain=[],
            final_confidence=0.0,
            processing_time=0.0,
            quality_assessment='poor',
            metadata={'fallback': True, 'reason': reason}
        )
    
    def _update_stats(self, processing_time: float, confidence: float, insight_count: int):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['decodings_performed'] += 1
        
        # ì´ë™ í‰ê· ìœ¼ë¡œ ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        alpha = 0.1
        self.stats['average_processing_time'] = (
            (1 - alpha) * self.stats['average_processing_time'] + 
            alpha * processing_time
        )
        
        self.stats['quality_scores'].append(confidence)
        
        if confidence < self.config['min_confidence_threshold']:
            self.stats['failed_decodings'] += 1
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        success_rate = (
            (self.stats['decodings_performed'] - self.stats['failed_decodings']) / 
            max(1, self.stats['decodings_performed']) * 100
        )
        
        avg_quality = (
            np.mean(self.stats['quality_scores']) if self.stats['quality_scores'] else 0.0
        )
        
        return {
            'total_decodings': self.stats['decodings_performed'],
            'success_rate': f"{success_rate:.1f}%",
            'average_processing_time': f"{self.stats['average_processing_time']:.2f}ì´ˆ",
            'average_quality_score': f"{avg_quality:.3f}",
            'model_usage_distribution': self.stats['model_usage_count'].copy(),
            'failed_decodings': self.stats['failed_decodings']
        }

# ì‚¬ìš© ì˜ˆì œ
def main():
    """ì‚¬ìš© ì˜ˆì œ"""
    decoder = OllamaIntelligentDecoder()
    
    # Ollama ìƒíƒœ í™•ì¸
    if decoder.ollama:
        status = decoder.ollama.health_check()
        print(f"ğŸ¤– Ollama ì—°ê²° ìƒíƒœ: {'âœ… ì—°ê²°ë¨' if status else 'âŒ ì—°ê²° ì‹¤íŒ¨'}")
        
        if status:
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {decoder.ollama.available_models}")
            
            # ì˜ˆì œ ìœµí•© ê²°ê³¼ ìƒì„± (ì‹¤ì œë¡œëŠ” crossmodal_fusion.pyì—ì„œ ë°›ì•„ì˜´)
            from .crossmodal_fusion import FusionResult
            
            sample_fusion_result = FusionResult(
                fused_embedding=np.random.rand(768).astype(np.float32),
                modal_weights={'image': 0.4, 'audio': 0.6},
                cross_modal_correlations=[],
                dominant_modality='audio',
                fusion_confidence=0.85,
                semantic_coherence=0.78,
                metadata={'test': True}
            )
            
            print("\nğŸ§  ì§€ëŠ¥í˜• ë””ì½”ë” í…ŒìŠ¤íŠ¸ ì‹œì‘...")
            result = decoder.decode_fusion_result(sample_fusion_result)
            
            print(f"\nğŸ¯ ë””ì½”ë”© ê²°ê³¼:")
            print(f"   ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸: {len(result.insights)}ê°œ")
            print(f"   ìµœì¢… ì‹ ë¢°ë„: {result.final_confidence:.3f}")
            print(f"   í’ˆì§ˆ í‰ê°€: {result.quality_assessment}")
            print(f"   ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
            print(f"   ì‚¬ìš©ëœ ëª¨ë¸ ì²´ì¸: {' â†’ '.join(result.processing_chain)}")
            
            print(f"\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ë“¤:")
            for i, insight in enumerate(result.insights[:3], 1):
                print(f"   {i}. [{insight['type']}] {insight['content'][:100]}...")
                
        else:
            print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ Ollamaë¥¼ ì‹œì‘í•˜ì„¸ìš”: ollama serve")
    else:
        print("âŒ Ollama ì¸í„°í˜ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()