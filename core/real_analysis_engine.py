#!/usr/bin/env python3
"""
ì‹¤ì œ ë¶„ì„ ì—”ì§„ - ê°€ì§œ ë¶„ì„ì„ ì‹¤ì œ ë¶„ì„ìœ¼ë¡œ êµì²´
Whisper STT + EasyOCR + ë¬´ë£Œ AI ëª¨ë¸ í†µí•©
"""

import os
import time
import logging
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
import json
from datetime import datetime

# CPU ëª¨ë“œ ìµœì í™” ì„¤ì • (GPU ì—†ëŠ” í™˜ê²½)
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # GPU ë¹„í™œì„±í™”
# PyTorch ì„¤ì • ìµœì í™”
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
os.environ['TORCH_HOME'] = os.path.expanduser('~/.cache/torch')

# Unicode ì¸ì½”ë”© ë¬¸ì œ í•´ê²° (Windows)
os.environ['PYTHONIOENCODING'] = 'utf-8'
import sys
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='torch')
warnings.filterwarnings('ignore', message='.*pin_memory.*')

# ì‹¤ì œ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import whisper
import easyocr
import subprocess
import tempfile

try:
    import librosa
    import numpy as np
    librosa_available = True
except ImportError:
    librosa_available = False

try:
    from transformers import pipeline
    transformers_available = True
except ImportError:
    transformers_available = False

try:
    import google.generativeai as genai
    gemini_available = True
except ImportError:
    gemini_available = False

try:
    from .document_processor import document_processor
    document_processor_available = True
except ImportError:
    document_processor_available = False

try:
    from .youtube_processor import youtube_processor
    youtube_processor_available = True
except ImportError:
    youtube_processor_available = False

try:
    from .large_video_processor import large_video_processor
    large_video_processor_available = True
except ImportError:
    large_video_processor_available = False

try:
    from .error_recovery_analyzer import error_recovery_analyzer
    error_recovery_available = True
except ImportError:
    error_recovery_available = False

try:
    from .analysis_quality_enhancer import global_quality_enhancer, enhance_analysis_quality
    quality_enhancer_available = True
except ImportError:
    quality_enhancer_available = False

try:
    from .comprehensive_message_extractor import global_message_extractor, extract_speaker_message
    message_extractor_available = True
except ImportError:
    message_extractor_available = False

try:
    from .ppt_intelligence_engine import global_ppt_engine, analyze_ppt_slide
    ppt_intelligence_available = True
except ImportError:
    ppt_intelligence_available = False

try:
    from .jewelry_domain_enhancer import global_jewelry_enhancer, enhance_with_jewelry_domain
    jewelry_enhancer_available = True
except ImportError:
    jewelry_enhancer_available = False

try:
    from .audio_converter import global_audio_converter, convert_audio_to_wav, get_audio_info
    audio_converter_available = True
except ImportError:
    audio_converter_available = False

try:
    from .performance_monitor import global_performance_monitor, record_analysis_result
    performance_monitor_available = True
except ImportError:
    performance_monitor_available = False

class RealAnalysisEngine:
    """ì‹¤ì œ íŒŒì¼ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
        # ë¶„ì„ ëª¨ë¸ë“¤ ì´ˆê¸°í™”
        self.whisper_model = None
        self.ocr_reader = None
        self.nlp_pipeline = None
        
        # ì„±ëŠ¥ ì¶”ì 
        self.analysis_stats = {
            "total_files": 0,
            "successful_analyses": 0,
            "partial_successes": 0,
            "failed_analyses": 0,
            "total_processing_time": 0,
            "last_analysis_time": None
        }
        
        self.logger.info("[INFO] ì‹¤ì œ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"[INFO] ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ê¸°: {'í™œì„±í™”' if error_recovery_available else 'ë¹„í™œì„±í™”'}")
    
    def _enhance_with_context(self, extracted_text: str, context: Dict[str, Any] = None) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í™œìš©í•œ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬"""
        if not context or not extracted_text:
            return extracted_text
        
        enhanced_text = extracted_text
        
        # ì£¼ì œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê´€ë ¨ ìš©ì–´ ë³´ì •
        if context.get('topic_keywords'):
            keywords = [k.strip() for k in context['topic_keywords'].split(',')]
            for keyword in keywords:
                if keyword and len(keyword) > 2:
                    # ìœ ì‚¬í•œ ë‹¨ì–´ ì°¾ì•„ì„œ ë³´ì • (ê°„ë‹¨í•œ ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê¸°ë°˜)
                    import difflib
                    words = enhanced_text.split()
                    for i, word in enumerate(words):
                        if difflib.SequenceMatcher(None, word.lower(), keyword.lower()).ratio() > 0.7:
                            words[i] = keyword  # ì •í™•í•œ í‚¤ì›Œë“œë¡œ êµì²´
                    enhanced_text = ' '.join(words)
        
        # ì°¸ì„ì/ë°œí‘œì ì •ë³´ë¡œ ì¸ëª… ë³´ì •
        if context.get('speakers') or context.get('participants'):
            names = []
            if context.get('speakers'):
                names.extend([n.strip() for n in context['speakers'].split(',')])
            if context.get('participants'):
                # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°í•˜ê³  ì´ë¦„ë§Œ ì¶”ì¶œ
                import re
                participant_text = context['participants']
                participant_names = re.findall(r'([ê°€-í£a-zA-Z\s]+?)(?:\s*\([^)]*\))?(?:,|$)', participant_text)
                names.extend([n.strip() for n in participant_names if n.strip()])
            
            # ì¸ëª… ë³´ì •
            for name in names:
                if name and len(name) > 1:
                    import difflib
                    words = enhanced_text.split()
                    for i, word in enumerate(words):
                        if difflib.SequenceMatcher(None, word, name).ratio() > 0.6:
                            words[i] = name
                    enhanced_text = ' '.join(words)
        
        return enhanced_text
    
    def _generate_context_aware_summary(self, text: str, context: Dict[str, Any] = None) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìš”ì•½ ìƒì„±"""
        if not context:
            return self._generate_summary(text)
        
        # ê¸°ë³¸ ìš”ì•½ ìƒì„±
        base_summary = self._generate_summary(text)
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if context.get('event_context'):
            context_prefix = f"[{context['event_context']}] "
        else:
            context_prefix = ""
        
        if context.get('objective'):
            objective_suffix = f" (ëª©ì : {context['objective']})"
        else:
            objective_suffix = ""
        
        return f"{context_prefix}{base_summary}{objective_suffix}"
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì • (Unicode ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            # UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì •
            if hasattr(handler.stream, 'reconfigure'):
                handler.stream.reconfigure(encoding='utf-8')
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _lazy_load_whisper(self, model_size: str = "base") -> whisper.Whisper:
        """Whisper ëª¨ë¸ ì§€ì—° ë¡œë”©"""
        if self.whisper_model is None:
            self.logger.info(f"ğŸ¤ Whisper {model_size} ëª¨ë¸ ë¡œë”©...")
            start_time = time.time()
            self.whisper_model = whisper.load_model(model_size)
            load_time = time.time() - start_time
            self.logger.info(f"âœ… Whisper ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
        return self.whisper_model
    
    def _lazy_load_ocr(self) -> easyocr.Reader:
        """EasyOCR ëª¨ë¸ ì§€ì—° ë¡œë”© (ì„±ëŠ¥ ìµœì í™”)"""
        if self.ocr_reader is None:
            self.logger.info("ğŸ–¼ï¸ EasyOCR í•œ/ì˜ ëª¨ë¸ ë¡œë”©... (CPU ìµœì í™”)")
            start_time = time.time()
            
            # CPU ëª¨ë“œì™€ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            import torch
            # PyTorch DataLoader pin_memory ê²½ê³  ë°©ì§€
            if not torch.cuda.is_available():
                torch.backends.cudnn.enabled = False
                # CPU ëª¨ë“œì—ì„œ ìŠ¤ë ˆë“œ ìˆ˜ ìµœì í™”
                torch.set_num_threads(2)  # CPU ì½”ì–´ì— ë§ê²Œ ì¡°ì •
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ê¸°ì¡´ ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if hasattr(self, 'ocr_reader') and self.ocr_reader is not None:
                del self.ocr_reader
                import gc
                gc.collect()
            
            self.ocr_reader = easyocr.Reader(
                ['ko', 'en'],
                gpu=False,  # CPU ê°•ì œ ì‚¬ìš©
                model_storage_directory=None,  # ê¸°ë³¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì‚¬ìš©
                user_network_directory=None,
                recog_network='CRNN',  # ê¸°ë³¸ recognition network
                detector=True,
                recognizer=True,
                verbose=False,  # ë¡œê·¸ ìµœì†Œí™”
                download_enabled=True
            )
            
            load_time = time.time() - start_time
            self.logger.info(f"âœ… EasyOCR ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
        return self.ocr_reader
    
    def _lazy_load_nlp(self) -> Optional[any]:
        """NLP íŒŒì´í”„ë¼ì¸ ì§€ì—° ë¡œë”©"""
        if not transformers_available:
            return None
            
        if self.nlp_pipeline is None:
            try:
                self.logger.info("ğŸ§  NLP ëª¨ë¸ ë¡œë”©...")
                start_time = time.time()
                self.nlp_pipeline = pipeline("summarization", 
                                           model="facebook/bart-large-cnn")
                load_time = time.time() - start_time
                self.logger.info(f"âœ… NLP ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
            except Exception as e:
                self.logger.warning(f"NLP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
        return self.nlp_pipeline
    
    def _validate_whisper_language(self, language: str) -> Optional[str]:
        """Whisper ì–¸ì–´ ì„¤ì • ê²€ì¦ ë° ë³€í™˜"""
        if language == "auto":
            return None  # Whisper ìë™ ê°ì§€
        
        # Whisperì—ì„œ ì§€ì›í•˜ëŠ” ì£¼ìš” ì–¸ì–´ ì½”ë“œ
        whisper_languages = {
            "ko": "ko",  # í•œêµ­ì–´
            "en": "en",  # ì˜ì–´
            "ja": "ja",  # ì¼ë³¸ì–´
            "zh": "zh",  # ì¤‘êµ­ì–´
            "es": "es",  # ìŠ¤í˜ì¸ì–´
            "fr": "fr",  # í”„ë‘ìŠ¤ì–´
            "de": "de",  # ë…ì¼ì–´
            "it": "it",  # ì´íƒˆë¦¬ì•„ì–´
            "pt": "pt",  # í¬ë¥´íˆ¬ê°ˆì–´
            "ru": "ru",  # ëŸ¬ì‹œì•„ì–´
            "ar": "ar",  # ì•„ëì–´
            "hi": "hi",  # íŒë””ì–´
        }
        
        # ì–¸ì–´ ì½”ë“œ ì •ê·œí™”
        lang_code = language.lower().strip()
        
        if lang_code in whisper_languages:
            return whisper_languages[lang_code]
        else:
            self.logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ ì½”ë“œ: {language}, ìë™ ê°ì§€ë¡œ ëŒ€ì²´")
            return None  # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ëŠ” ìë™ ê°ì§€ë¡œ ëŒ€ì²´
    
    def _validate_audio_data(self, file_path: str) -> bool:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë°ì´í„° ê²€ì¦"""
        try:
            if librosa_available:
                # librosaë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ì˜¤ë””ì˜¤ ë°ì´í„° ê²€ì¦
                audio_data, sample_rate = librosa.load(file_path, sr=None)
                
                # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if len(audio_data) == 0:
                    self.logger.error("âŒ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    return False
                
                # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ (ìµœì†Œ 0.1ì´ˆ)
                duration = len(audio_data) / sample_rate
                if duration < 0.1:
                    self.logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {duration:.2f}ì´ˆ")
                    return False
                
                # NaN ë˜ëŠ” ë¬´í•œëŒ€ ê°’ í™•ì¸
                if np.any(np.isnan(audio_data)) or np.any(np.isinf(audio_data)):
                    self.logger.error("âŒ ì˜¤ë””ì˜¤ ë°ì´í„°ì— ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
                    return False
                
                self.logger.info(f"âœ… ì˜¤ë””ì˜¤ ê²€ì¦ ì„±ê³µ: {duration:.2f}ì´ˆ, {sample_rate}Hz")
                return True
            else:
                # librosaê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ íŒŒì¼ ê²€ì¦
                self.logger.info("ğŸ”§ librosa ì—†ìŒ, ê¸°ë³¸ íŒŒì¼ ê²€ì¦ ì‚¬ìš©")
                
                # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
                if not os.path.exists(file_path):
                    self.logger.error("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                    return False
                
                file_size = os.path.getsize(file_path)
                if file_size < 1024:  # 1KB ë¯¸ë§Œ
                    self.logger.error(f"âŒ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {file_size} bytes")
                    return False
                
                # FFmpeg/ffprobeë¥¼ ì‚¬ìš©í•œ íŒŒì¼ ì •ë³´ í™•ì¸
                try:
                    # ffprobeê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
                    cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', file_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    
                    if result.returncode == 0:
                        import json
                        info = json.loads(result.stdout)
                        duration = float(info.get('format', {}).get('duration', 0))
                        
                        if duration < 0.1:
                            self.logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {duration:.2f}ì´ˆ")
                            return False
                        
                        self.logger.info(f"âœ… ê¸°ë³¸ ì˜¤ë””ì˜¤ ê²€ì¦ ì„±ê³µ: {duration:.2f}ì´ˆ")
                        return True
                    else:
                        raise Exception("ffprobe failed")
                        
                except Exception:
                    # ffprobe ì‹¤íŒ¨ì‹œ ffmpegìœ¼ë¡œ ëŒ€ì²´ ì‹œë„
                    try:
                        cmd = ['ffmpeg', '-i', file_path, '-f', 'null', '-', '-v', 'quiet']
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                        
                        # ffmpegê°€ ì„±ê³µì ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ìˆìœ¼ë©´ ìœ íš¨í•œ íŒŒì¼ë¡œ ê°„ì£¼
                        if result.returncode == 0:
                            self.logger.info("âœ… ffmpeg ê¸°ë³¸ ê²€ì¦ ì„±ê³µ")
                            return True
                        else:
                            self.logger.warning("âš ï¸ ffmpeg ê²€ì¦ ì‹¤íŒ¨, íŒŒì¼ í˜•ì‹ì„ ì‹ ë¢°í•˜ê³  ì§„í–‰")
                            return True
                            
                    except (subprocess.TimeoutExpired, Exception) as e:
                        self.logger.warning(f"âš ï¸ ê¸°ë³¸ ê²€ì¦ ì‹¤íŒ¨: {e}, íŒŒì¼ í˜•ì‹ì„ ì‹ ë¢°í•˜ê³  ì§„í–‰")
                        return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜¤ë””ì˜¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _convert_m4a_to_wav(self, m4a_path: str) -> str:
        """M4A íŒŒì¼ì„ WAVë¡œ ë³€í™˜ (FFmpeg ì‚¬ìš©)"""
        try:
            # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                temp_wav_path = temp_wav.name
            
            # FFmpeg ëª…ë ¹ì–´ë¡œ M4Aë¥¼ WAVë¡œ ë³€í™˜
            cmd = [
                'ffmpeg', '-i', m4a_path,
                '-acodec', 'pcm_s16le',  # PCM 16-bit
                '-ar', '16000',          # 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸
                '-ac', '1',              # ëª¨ë…¸ ì±„ë„
                '-y',                    # ë®ì–´ì“°ê¸° í—ˆìš©
                temp_wav_path
            ]
            
            self.logger.info("ğŸ”„ M4A â†’ WAV ë³€í™˜ ì¤‘...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                self.logger.info("âœ… M4A â†’ WAV ë³€í™˜ ì™„ë£Œ")
                return temp_wav_path
            else:
                self.logger.error(f"âŒ FFmpeg ë³€í™˜ ì‹¤íŒ¨: {result.stderr}")
                # ì‹¤íŒ¨ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if os.path.exists(temp_wav_path):
                    os.unlink(temp_wav_path)
                return None
                
        except subprocess.TimeoutExpired:
            self.logger.error("âŒ FFmpeg ë³€í™˜ ì‹œê°„ ì´ˆê³¼")
            return None
        except Exception as e:
            self.logger.error(f"âŒ M4A ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _preprocess_audio_file(self, file_path: str) -> str:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²˜ë¦¬ (M4A í¬í•¨ ëª¨ë“  í¬ë§· ì§€ì›)"""
        file_ext = Path(file_path).suffix.lower()
        self.logger.info(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²˜ë¦¬ ì‹œì‘: {file_ext}")
        
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ í™•ì¸
        if audio_converter_available:
            audio_info = get_audio_info(file_path)
            self.logger.info(f"ğŸ“Š ì˜¤ë””ì˜¤ ì •ë³´: {audio_info['duration_seconds']:.1f}ì´ˆ, "
                           f"{audio_info['file_size_mb']:.1f}MB, {audio_info['sample_rate']}Hz")
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ì˜¤ë””ì˜¤ íŒŒì¼ì´ê±°ë‚˜ M4Aì¸ ê²½ìš° ë³€í™˜
            if not audio_info['is_valid'] or file_ext in ['.m4a', '.aac']:
                self.logger.info("ğŸ”§ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹œë„...")
                converted_path = convert_audio_to_wav(file_path, target_sample_rate=16000)
                
                if converted_path and self._validate_audio_data(converted_path):
                    self.logger.info("âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì„±ê³µ")
                    return converted_path
                else:
                    self.logger.warning("âš ï¸ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ë¡œ ì‹œë„")
                    # ë³€í™˜ ì‹¤íŒ¨ì‹œ ì›ë³¸ìœ¼ë¡œ ì‹œë„
                    if self._validate_audio_data(file_path):
                        return file_path
                    return None
            else:
                # ìœ íš¨í•œ ì˜¤ë””ì˜¤ íŒŒì¼ì´ë©´ ê²€ì¦ í›„ ì‚¬ìš©
                if self._validate_audio_data(file_path):
                    return file_path
                else:
                    # ê²€ì¦ ì‹¤íŒ¨ì‹œ ë³€í™˜ ì‹œë„
                    converted_path = convert_audio_to_wav(file_path)
                    return converted_path if converted_path and self._validate_audio_data(converted_path) else None
        
        # ì˜¤ë””ì˜¤ ì»¨ë²„í„° ì—†ìœ¼ë©´ ê¸°ì¡´ M4A ë³€í™˜ ë¡œì§ ì‚¬ìš©
        else:
            if file_ext == ".m4a":
                if not self._validate_audio_data(file_path):
                    self.logger.info("ğŸ”§ FFmpeg ë³€í™˜ìœ¼ë¡œ ì¬ì‹œë„")
                    converted_path = self._convert_m4a_to_wav(file_path)
                    if converted_path and self._validate_audio_data(converted_path):
                        return converted_path
                    else:
                        if converted_path and os.path.exists(converted_path):
                            os.unlink(converted_path)
                        return None
            
            # ì›ë³¸ íŒŒì¼ì´ ì •ìƒì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return file_path if self._validate_audio_data(file_path) else None
    
    def analyze_audio_file(self, file_path: str, language: str = "ko", context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì‹¤ì œ ìŒì„± íŒŒì¼ ë¶„ì„"""
        self.logger.info(f"ğŸ¤ ì‹¤ì œ ìŒì„± ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)}")
        
        start_time = time.time()
        processed_file_path = None
        temp_file_created = False
        
        try:
            # Whisper ëª¨ë¸ ë¡œë“œ
            model = self._lazy_load_whisper()
            
            # ì–¸ì–´ ì„¤ì • ì²˜ë¦¬ - "auto"ì¸ ê²½ìš° Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìë™ ê°ì§€ í™œì„±í™”
            whisper_language = self._validate_whisper_language(language)
            self.logger.info(f"ğŸ”¤ ì–¸ì–´ ì„¤ì •: {language} -> Whisper: {whisper_language}")
            
            # íŒŒì¼ í˜•ì‹ í™•ì¸ ë° íŠ¹ë³„ ì²˜ë¦¬
            file_ext = Path(file_path).suffix.lower()
            self.logger.info(f"ğŸ“ íŒŒì¼ í˜•ì‹: {file_ext}")
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²˜ë¦¬ (ëª¨ë“  í¬ë§· ì§€ì›)
            processed_file_path = self._preprocess_audio_file(file_path)
            if processed_file_path is None:
                raise Exception("ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨: ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ë³€í™˜ëœ íŒŒì¼ì¸ì§€ í™•ì¸ (ì„ì‹œ íŒŒì¼ ì •ë¦¬ë¥¼ ìœ„í•´)
            temp_file_created = (processed_file_path != file_path)
            
            # ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
            self.logger.info("ğŸ”„ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            transcribe_options = {
                "language": whisper_language,
                "fp16": False,  # ì•ˆì •ì„±ì„ ìœ„í•´ fp16 ë¹„í™œì„±í™”
                "verbose": False
            }
            
            # M4A íŒŒì¼ì˜ ê²½ìš° ì¶”ê°€ ì˜µì…˜ ì„¤ì •
            if file_ext == ".m4a":
                self.logger.info("ğŸµ M4A íŒŒì¼ íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œ")
                transcribe_options.update({
                    "condition_on_previous_text": False,
                    "beam_size": 1,           # ì•ˆì •ì„±ì„ ìœ„í•´ ë¹” ì‚¬ì´ì¦ˆ ì¶•ì†Œ
                    "best_of": 1,            # ìµœìƒ í›„ë³´ë§Œ ì‚¬ìš©
                    "temperature": 0.0,      # ì˜¨ë„ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ì„± í–¥ìƒ
                    "compression_ratio_threshold": 2.4,  # ì••ì¶•ë¹„ ì„ê³„ê°’ ì„¤ì •
                    "logprob_threshold": -1.0,           # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’ ì„¤ì •
                    "no_speech_threshold": 0.6           # ë¬´ìŒ ê°ì§€ ì„ê³„ê°’ ì„¤ì •
                })
            
            # Whisperì— ì˜¤ë””ì˜¤ ì „ë‹¬í•˜ê¸° ì „ ë§ˆì§€ë§‰ ì•ˆì „ ì²´í¬
            if not os.path.exists(processed_file_path):
                raise Exception(f"ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {processed_file_path}")
            
            result = model.transcribe(processed_file_path, **transcribe_options)
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ë¶„ì„
            text = result["text"]
            segments = result["segments"]
            detected_language = result["language"]
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ í–¥ìƒ
            enhanced_text = self._enhance_with_context(text, context)
            
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìš”ì•½ ìƒì„±
            summary = self._generate_context_aware_summary(enhanced_text, context)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„ (í–¥ìƒëœ í…ìŠ¤íŠ¸ ê¸°ë°˜)
            jewelry_keywords = self._extract_jewelry_keywords(enhanced_text)
            
            analysis_result = {
                "status": "success",
                "file_name": os.path.basename(file_path),
                "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2)),
                "processing_time": float(round(processing_time, 1)),
                "detected_language": detected_language,
                "segments_count": int(len(segments)),
                "text_length": int(len(text)),
                "full_text": enhanced_text,
                "original_text": text,
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "segments": segments,
                "analysis_type": "real_whisper_stt",
                "timestamp": datetime.now().isoformat()
            }
            
            self._update_stats(processing_time, True)
            self.logger.info(f"âœ… ìŒì„± ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return analysis_result
            
        except Exception as e:
            # M4A ê´€ë ¨ íŠ¹ë³„ ì—ëŸ¬ ì²˜ë¦¬
            error_str = str(e)
            if file_ext == ".m4a" and ("reshape" in error_str or "tensor" in error_str or "0 elements" in error_str):
                error_msg = f"M4A íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤. FFmpegë‚˜ librosa ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì›ë³¸ ì˜¤ë¥˜: {error_str}"
                self.logger.error("âŒ M4A í…ì„œ ë¦¬ì…°ì´í”„ ì˜¤ë¥˜ ê°ì§€")
            else:
                error_msg = f"ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {error_str}"
            
            self.logger.error(error_msg)
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(file_path, "audio", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": os.path.basename(file_path),
                    "file_extension": file_ext,
                    "librosa_available": librosa_available,
                    "analysis_type": "real_whisper_stt_recovery",
                    "timestamp": datetime.now().isoformat(),
                    "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2))
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(time.time() - start_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(time.time() - start_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": os.path.basename(file_path),
                "file_extension": file_ext,
                "librosa_available": librosa_available,
                "analysis_type": "real_whisper_stt",
                "timestamp": datetime.now().isoformat()
            }
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_file_created and processed_file_path and os.path.exists(processed_file_path):
                try:
                    os.unlink(processed_file_path)
                    self.logger.info("ğŸ—‘ï¸ ì„ì‹œ ë³€í™˜ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def analyze_image_file(self, file_path: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ OCR ë¶„ì„"""
        self.logger.info(f"ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)}")
        
        start_time = time.time()
        
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸ ë° ì „ì²˜ë¦¬
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
            self.logger.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size_mb:.1f}MB")
            
            # í° íŒŒì¼ì˜ ê²½ìš° ì¶”ê°€ ìµœì í™”
            if file_size_mb > 5:  # 5MB ì´ìƒ
                canvas_size = 960
                mag_ratio = 0.8
                text_threshold = 0.6
                self.logger.info("ğŸ“ ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€ - ì¶”ê°€ ì†ë„ ìµœì í™” ì ìš©")
            else:
                canvas_size = 1280
                mag_ratio = 1.0
                text_threshold = 0.5
            
            # OCR ëª¨ë¸ ë¡œë“œ
            reader = self._lazy_load_ocr()
            
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì†ë„ ìµœì í™” ëª¨ë“œ)
            self.logger.info("ğŸ”„ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... (ì†ë„ ìµœì í™” ëª¨ë“œ)")
            results = reader.readtext(
                file_path,
                width_ths=0.7,     # í…ìŠ¤íŠ¸ í­ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                height_ths=0.7,    # í…ìŠ¤íŠ¸ ë†’ì´ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                paragraph=False,   # ë‹¨ë½ ëª¨ë“œ ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)
                detail=1,          # ìƒì„¸ ì •ë³´ í¬í•¨
                batch_size=1,      # CPU ëª¨ë“œì—ì„œ ë°°ì¹˜ í¬ê¸° ìµœì í™”
                workers=0,         # CPU ëª¨ë“œì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™”
                text_threshold=text_threshold,   # ë™ì  ì„ê³„ê°’
                low_text=0.4,      # ë‚®ì€ í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                link_threshold=0.4, # ë§í¬ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                canvas_size=canvas_size,  # ë™ì  ìº”ë²„ìŠ¤ í¬ê¸°
                mag_ratio=mag_ratio      # ë™ì  í™•ëŒ€ ë¹„ìœ¨
            )
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            processing_time = time.time() - start_time
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ë¡
            if performance_monitor_available:
                record_analysis_result(
                    file_name=os.path.basename(file_path),
                    file_type="image",
                    processing_time=processing_time,
                    status="success",
                    additional_info={
                        "file_size_mb": file_size_mb,
                        "canvas_size": canvas_size,
                        "detected_blocks": len(results)
                    }
                )
            
            # ê²°ê³¼ ì²˜ë¦¬
            detected_texts = []
            total_confidence = 0
            
            for bbox, text, confidence in results:
                detected_texts.append({
                    "text": text,
                    "confidence": float(round(confidence, 3)),  # NumPy floatë¥¼ Python floatë¡œ ë³€í™˜
                    "bbox": bbox
                })
                total_confidence += float(confidence)  # NumPy floatë¥¼ Python floatë¡œ ë³€í™˜
            
            avg_confidence = float(total_confidence / len(results)) if results else 0.0
            full_text = ' '.join([item["text"] for item in detected_texts])
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ í–¥ìƒ
            enhanced_text = self._enhance_with_context(full_text, context)
            
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìš”ì•½ ìƒì„±
            summary = self._generate_context_aware_summary(enhanced_text, context)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„ (í–¥ìƒëœ í…ìŠ¤íŠ¸ ê¸°ë°˜)
            jewelry_keywords = self._extract_jewelry_keywords(enhanced_text)
            
            analysis_result = {
                "status": "success",
                "file_name": os.path.basename(file_path),
                "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2)),
                "processing_time": float(round(processing_time, 1)),
                "blocks_detected": int(len(results)),
                "average_confidence": float(round(avg_confidence, 3)),
                "full_text": enhanced_text,
                "original_text": full_text,
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "detailed_results": detected_texts,
                "analysis_type": "real_easyocr",
                "timestamp": datetime.now().isoformat()
            }
            
            self._update_stats(processing_time, True)
            self.logger.info(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return analysis_result
            
        except Exception as e:
            error_msg = f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            self.logger.error(error_msg)
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ë¡ (ì‹¤íŒ¨)
            if performance_monitor_available:
                record_analysis_result(
                    file_name=os.path.basename(file_path),
                    file_type="image",
                    processing_time=time.time() - start_time,
                    status="failed",
                    error_msg=error_msg,
                    additional_info={
                        "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2)) if os.path.exists(file_path) else 0
                    }
                )
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(file_path, "image", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": os.path.basename(file_path),
                    "analysis_type": "real_easyocr_recovery",
                    "timestamp": datetime.now().isoformat(),
                    "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2))
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(time.time() - start_time, True, partial=True)
                
                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ë¡ (ë¶€ë¶„ ì„±ê³µ)
                if performance_monitor_available:
                    record_analysis_result(
                        file_name=os.path.basename(file_path),
                        file_type="image",
                        processing_time=time.time() - start_time,
                        status="partial",
                        error_msg=f"ë³µêµ¬ë¨: {error_msg}",
                        additional_info={"recovery_used": True}
                    )
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(time.time() - start_time, False)
            
            return {
                "status": "error", 
                "error": error_msg,
                "file_name": os.path.basename(file_path),
                "analysis_type": "real_easyocr",
                "timestamp": datetime.now().isoformat()
            }
    
    def _generate_summary(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        if not text or len(text.strip()) < 50:
            return "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # NLP ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì‹œ
        nlp = self._lazy_load_nlp()
        if nlp and len(text) > 100:
            try:
                # ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë¥´ê¸°
                if len(text) > 1024:
                    text = text[:1024]
                
                summary_result = nlp(text, max_length=100, min_length=30, do_sample=False)
                return summary_result[0]['summary_text']
            except Exception as e:
                self.logger.debug(f"NLP ìš”ì•½ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ìš”ì•½ (ì²« 100ì)
        return text[:100] + "..." if len(text) > 100 else text
    
    def _extract_jewelry_keywords(self, text: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return []
        
        jewelry_terms = [
            # ì˜ì–´ ì£¼ì–¼ë¦¬ ìš©ì–´
            "diamond", "gold", "silver", "platinum", "jewelry", "jewellery", 
            "ring", "necklace", "bracelet", "earring", "pendant", "gemstone",
            "ruby", "sapphire", "emerald", "pearl", "crystal", "luxury",
            "carat", "cut", "clarity", "color", "certificate", "GIA",
            
            # í•œêµ­ì–´ ì£¼ì–¼ë¦¬ ìš©ì–´  
            "ë‹¤ì´ì•„ëª¬ë“œ", "ê¸ˆ", "ì€", "ë°±ê¸ˆ", "ì£¼ì–¼ë¦¬", "ë°˜ì§€", "ëª©ê±¸ì´", 
            "íŒ”ì°Œ", "ê·€ê±¸ì´", "íœë˜íŠ¸", "ë³´ì„", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", 
            "ì—ë©”ë„ë“œ", "ì§„ì£¼", "í¬ë¦¬ìŠ¤íƒˆ", "ëŸ­ì…”ë¦¬", "ìºëŸ¿", "ì»¤íŒ…",
            "íˆ¬ëª…ë„", "ìƒ‰ìƒ", "ì¸ì¦ì„œ", "ì§€ì•„"
        ]
        
        text_lower = text.lower()
        found_keywords = []
        
        for term in jewelry_terms:
            if term.lower() in text_lower:
                found_keywords.append(term)
        
        return list(set(found_keywords))  # ì¤‘ë³µ ì œê±°
    
    def analyze_document_file(self, file_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ë¶„ì„ (PDF, DOCX, DOC)"""
        start_time = time.time()
        file_name = os.path.basename(file_path)
        
        try:
            self.logger.info(f"[INFO] ë¬¸ì„œ íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name}")
            
            if not document_processor_available:
                raise Exception("ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. document_processorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            doc_result = document_processor.process_document(file_path)
            
            if doc_result['status'] != 'success':
                if doc_result['status'] == 'partial_success':
                    self.logger.warning(f"[WARNING] ë¬¸ì„œ ë¶€ë¶„ ì²˜ë¦¬: {doc_result.get('warning', '')}")
                else:
                    raise Exception(doc_result.get('error', 'ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨'))
            
            extracted_text = doc_result['extracted_text']
            
            if not extracted_text or len(extracted_text.strip()) < 10:
                raise Exception("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # AI ìš”ì•½ ìƒì„±
            summary = self._generate_summary(extracted_text)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            jewelry_keywords = self._extract_jewelry_keywords(extracted_text)
            
            # í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
            quality_score = min(100, len(extracted_text) / 10)  # ê°„ë‹¨í•œ í’ˆì§ˆ ì ìˆ˜
            
            processing_time = time.time() - start_time
            
            result = {
                "status": "success",
                "file_name": file_name,
                "file_path": file_path,
                "file_type": doc_result.get('file_type', 'unknown'),
                "extracted_text": extracted_text,
                "text_length": len(extracted_text),
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "quality_score": round(quality_score, 1),
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat(),
                "document_metadata": doc_result.get('metadata', {}),
                "document_info": {
                    "total_characters": doc_result.get('total_characters', 0),
                    "page_count": doc_result.get('page_count'),
                    "paragraph_count": doc_result.get('paragraph_count')
                }
            }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, True)
            self.logger.info(f"[SUCCESS] ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ë¬¸ì„œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            self.logger.error(f"[ERROR] {error_msg}")
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(file_path, "document", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": file_name,
                    "file_path": file_path,
                    "processing_time": round(processing_time, 2),
                    "timestamp": datetime.now().isoformat(),
                    "analysis_type": "document_recovery"
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(processing_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(processing_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": file_name,
                "file_path": file_path,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
    
    def analyze_youtube_video(self, url: str, language: str = "ko") -> Dict[str, Any]:
        """YouTube ì˜ìƒ ë¶„ì„"""
        start_time = time.time()
        
        try:
            self.logger.info(f"[INFO] YouTube ì˜ìƒ ë¶„ì„ ì‹œì‘: {url}")
            
            if not youtube_processor_available:
                raise Exception("YouTube ì²˜ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. youtube_processorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            if not youtube_processor.is_youtube_url(url):
                raise Exception("ìœ íš¨í•˜ì§€ ì•Šì€ YouTube URLì…ë‹ˆë‹¤.")
            
            # 1. ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            video_info = youtube_processor.get_video_info(url)
            if video_info['status'] != 'success':
                raise Exception(f"ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {video_info.get('error', 'Unknown')}")
            
            # 2. ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            self.logger.info("[INFO] YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            download_result = youtube_processor.download_audio(url)
            
            if download_result['status'] != 'success':
                raise Exception(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result.get('error', 'Unknown')}")
            
            audio_file = download_result['audio_file']
            
            # 3. ì˜¤ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰
            self.logger.info("[INFO] ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...")
            audio_analysis = self.analyze_audio_file(audio_file, language=language)
            
            if audio_analysis['status'] != 'success':
                # ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ë°˜í™˜
                self.logger.warning(f"[WARNING] ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {audio_analysis.get('error', 'Unknown')}")
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ í†µí•©
            result = {
                "status": "success",
                "source_type": "youtube",
                "url": url,
                "video_info": video_info,
                "download_info": {
                    "audio_file": download_result['audio_file'],
                    "file_size_mb": download_result.get('file_size_mb', 0),
                    "download_time": download_result.get('processing_time', 0)
                },
                "audio_analysis": audio_analysis,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
            
            # STT ê²°ê³¼ê°€ ìˆìœ¼ë©´ YouTube íŠ¹í™” ë¶„ì„ ì¶”ê°€
            if audio_analysis.get('status') == 'success' and audio_analysis.get('transcription'):
                # YouTube ì˜ìƒ + STT ê²°ê³¼ í†µí•© ë¶„ì„
                combined_text = f"ì˜ìƒ ì œëª©: {video_info['title']}\n"
                combined_text += f"ì„¤ëª…: {video_info.get('description', '')[:500]}...\n"
                combined_text += f"ìŒì„± ë‚´ìš©: {audio_analysis['transcription']}"
                
                # í†µí•© ìš”ì•½ ìƒì„±
                combined_summary = self._generate_summary(combined_text)
                combined_keywords = self._extract_jewelry_keywords(combined_text)
                
                result["combined_analysis"] = {
                    "integrated_summary": combined_summary,
                    "jewelry_keywords": combined_keywords,
                    "content_type": self._analyze_content_type(video_info, audio_analysis),
                    "engagement_metrics": {
                        "view_count": video_info.get('view_count', 0),
                        "like_count": video_info.get('like_count', 0),
                        "duration": video_info.get('duration_formatted', 'N/A')
                    }
                }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, True)
            self.logger.info(f"[SUCCESS] YouTube ì˜ìƒ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì„ íƒì )
            try:
                if os.path.exists(audio_file):
                    os.unlink(audio_file)
                    self.logger.info("[INFO] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ë¨")
            except:
                pass  # ì •ë¦¬ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"YouTube ì˜ìƒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, False)
            self.logger.error(f"[ERROR] {error_msg}")
            
            return {
                "status": "error",
                "error": error_msg,
                "url": url,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
    
    def _analyze_content_type(self, video_info: Dict, audio_analysis: Dict) -> str:
        """ì½˜í…ì¸  íƒ€ì… ë¶„ì„"""
        title = video_info.get('title', '').lower()
        description = video_info.get('description', '').lower()
        transcription = audio_analysis.get('transcription', '').lower()
        
        # ì£¼ì–¼ë¦¬ ê´€ë ¨ ì½˜í…ì¸  íŒë³„
        jewelry_indicators = [
            'jewelry', 'diamond', 'gold', 'silver', 'ring', 'necklace',
            'ì£¼ì–¼ë¦¬', 'ë‹¤ì´ì•„ëª¬ë“œ', 'ê¸ˆ', 'ì€', 'ë°˜ì§€', 'ëª©ê±¸ì´', 'ë³´ì„'
        ]
        
        combined_text = f"{title} {description} {transcription}"
        
        jewelry_score = sum(1 for indicator in jewelry_indicators if indicator in combined_text)
        
        if jewelry_score >= 3:
            return "jewelry_focused"
        elif jewelry_score >= 1:
            return "jewelry_related"
        else:
            return "general"
    
    def analyze_video_file(self, video_path: str, language: str = "ko") -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ (MOV, MP4, AVI ë“±)"""
        start_time = time.time()
        file_name = os.path.basename(video_path)
        
        try:
            self.logger.info(f"[INFO] ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name}")
            
            if not large_video_processor_available:
                raise Exception("ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ ì²˜ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. large_video_processorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            # 1. í–¥ìƒëœ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ (MoviePy ê¸°ëŠ¥ í¬í•¨)
            video_info = large_video_processor.get_enhanced_video_info_moviepy(video_path)
            if video_info['status'] not in ['success', 'partial_success']:
                raise Exception(f"ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {video_info.get('error', 'Unknown')}")
            
            # 1.5. í‚¤í”„ë ˆì„ ì¶”ì¶œ ë° OCR ë¶„ì„ (MoviePy ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            keyframes_info = None
            visual_analysis = None
            if video_info.get('moviepy_duration') and video_info['file_size_mb'] <= 500:  # 500MB ì´í•˜ë§Œ
                try:
                    self.logger.info("[INFO] í‚¤í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
                    keyframes_result = large_video_processor.extract_keyframes_moviepy(video_path, num_frames=5)
                    if keyframes_result['status'] == 'success':
                        keyframes_info = keyframes_result
                        self.logger.info(f"[SUCCESS] {len(keyframes_result['keyframes'])}ê°œ í‚¤í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")
                        
                        # ğŸ†• í‚¤í”„ë ˆì„ë³„ OCR ë¶„ì„ ì¶”ê°€
                        self.logger.info("ğŸ” í‚¤í”„ë ˆì„ OCR ë¶„ì„ ì¤‘...")
                        visual_analysis = self._analyze_keyframes_ocr(keyframes_result['keyframes'], context)
                        
                except Exception as e:
                    self.logger.warning(f"[WARNING] í‚¤í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    keyframes_info = {"error": str(e)}
            
            # 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ (ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ìˆëŠ” ê²½ìš°)
            audio_analysis = None
            audio_file = None
            
            if video_info.get('has_audio', False):
                self.logger.info("[INFO] ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
                
                audio_extract_result = large_video_processor.extract_audio_from_video(video_path)
                
                if audio_extract_result['status'] == 'success':
                    audio_file = audio_extract_result['audio_file']
                    
                    # 3. ì¶”ì¶œëœ ì˜¤ë””ì˜¤ STT ë¶„ì„
                    self.logger.info("[INFO] ì¶”ì¶œëœ ì˜¤ë””ì˜¤ STT ë¶„ì„ ì¤‘...")
                    audio_analysis = self.analyze_audio_file(audio_file, language=language)
                    
                    # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
                    try:
                        if os.path.exists(audio_file):
                            os.unlink(audio_file)
                            self.logger.info("[INFO] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ë¨")
                    except:
                        pass
                
                else:
                    self.logger.warning(f"[WARNING] ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {audio_extract_result.get('error', 'Unknown')}")
                    audio_extract_result = None
            
            else:
                self.logger.info("[INFO] ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ìŒ - STT ë¶„ì„ ìƒëµ")
                audio_extract_result = None
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ í†µí•©
            result = {
                "status": "success",
                "file_name": file_name,
                "file_path": video_path,
                "file_type": "video",
                "video_info": video_info,
                "keyframes_info": keyframes_info,
                "visual_analysis": visual_analysis,  # ğŸ†• ì‹œê°ì  OCR ë¶„ì„ ê²°ê³¼
                "audio_extraction": audio_extract_result,
                "audio_analysis": audio_analysis,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat(),
                "enhanced_features": {
                    "moviepy_analysis": video_info.get('moviepy_duration') is not None,
                    "quality_analysis": video_info.get('video_quality_analysis') is not None,
                    "keyframe_extraction": keyframes_info is not None,
                    "visual_ocr_analysis": visual_analysis is not None,  # ğŸ†• ì‹œê° ë¶„ì„ ì—¬ë¶€
                    "frame_analysis": video_info.get('frame_analysis') is not None
                }
            }
            
            # ğŸš€ ì§„ì •í•œ ë‹¤ê°ë„ ë¶„ì„: ìŒì„± + ì‹œê° ì •ë³´ í†µí•©
            audio_available = audio_analysis and audio_analysis.get('status') == 'success'
            visual_available = visual_analysis and visual_analysis.get('status') == 'success'
            
            if audio_available or visual_available:
                # ë©€í‹°ëª¨ë‹¬ ì •ë³´ í†µí•©
                combined_content = {
                    "metadata": f"ë¹„ë””ì˜¤ íŒŒì¼: {file_name}",
                    "audio_content": "",
                    "visual_content": "",
                    "temporal_mapping": []
                }
                
                # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                if video_info.get('format_name'):
                    combined_content["metadata"] += f" | í˜•ì‹: {video_info['format_name']}"
                if video_info.get('duration_formatted'):
                    combined_content["metadata"] += f" | ê¸¸ì´: {video_info['duration_formatted']}"
                
                # ìŒì„± ì •ë³´ ì¶”ê°€
                if audio_available:
                    transcription = audio_analysis.get('transcription', '')
                    combined_content["audio_content"] = f"ìŒì„± ë‚´ìš©: {transcription}"
                    
                # ğŸ†• ì‹œê° ì •ë³´ ì¶”ê°€ (ìƒˆë¡œ êµ¬í˜„ëœ ê¸°ëŠ¥)
                if visual_available:
                    visual_text = visual_analysis.get('combined_visual_text', '')
                    combined_content["visual_content"] = f"í™”ë©´ í…ìŠ¤íŠ¸: {visual_text}"
                    
                    # ğŸ†• ì‹œê°„ëŒ€ë³„ ë§¤í•‘ (ìŒì„± + ì‹œê° ì •ë³´ ë™ê¸°í™”)
                    if visual_analysis.get('frame_details'):
                        for frame in visual_analysis['frame_details']:
                            if frame.get('enhanced_text', '').strip():
                                combined_content["temporal_mapping"].append({
                                    "timestamp": frame['timestamp_formatted'],
                                    "timestamp_seconds": frame['timestamp_seconds'], 
                                    "visual_info": frame['enhanced_text'],
                                    "confidence": frame.get('average_confidence', 0)
                                })
                
                # ğŸ¯ ë©€í‹°ëª¨ë‹¬ í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
                integrated_text = f"{combined_content['metadata']}\n"
                if combined_content["audio_content"]:
                    integrated_text += f"{combined_content['audio_content']}\n"
                if combined_content["visual_content"]:
                    integrated_text += f"{combined_content['visual_content']}\n"
                
                # ğŸ§  í†µí•© ë¶„ì„ ìˆ˜í–‰
                integrated_summary = self._generate_context_aware_summary(integrated_text, context)
                integrated_keywords = self._extract_jewelry_keywords(integrated_text)
                
                result["integrated_analysis"] = {
                    "summary": integrated_summary,
                    "jewelry_keywords": integrated_keywords,
                    "multimodal_insights": {
                        "has_audio": audio_available,
                        "has_visual_text": visual_available and len(combined_content["visual_content"]) > 20,
                        "temporal_mappings": len(combined_content["temporal_mapping"]),
                        "analysis_depth": "multimodal" if (audio_available and visual_available) else "single_modal"
                    },
                    "content_analysis": {
                        "has_speech": audio_available,
                        "has_visual_info": visual_available,
                        "speech_duration": video_info.get('duration', 0),
                        "video_quality": video_info.get('video_info', {}).get('quality', 'Unknown'),
                        "file_size_category": self._categorize_file_size(video_info.get('file_size_mb', 0))
                    },
                    "temporal_synchronization": combined_content["temporal_mapping"][:10]  # ìƒìœ„ 10ê°œ ì‹œê°„ëŒ€
                }
            
            else:
                # ì˜¤ë””ì˜¤ ì—†ê±°ë‚˜ STT ì‹¤íŒ¨ ì‹œ ë¹„ë””ì˜¤ ì •ë³´ë§Œìœ¼ë¡œ ë¶„ì„
                video_text = f"ë¹„ë””ì˜¤ íŒŒì¼: {file_name} ({video_info.get('format_name', 'Unknown')})"
                
                result["integrated_analysis"] = {
                    "summary": f"ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì™„ë£Œ. ê¸¸ì´: {video_info.get('duration_formatted', 'Unknown')}",
                    "jewelry_keywords": self._extract_jewelry_keywords(video_text),
                    "content_analysis": {
                        "has_speech": False,
                        "video_quality": video_info.get('video_info', {}).get('quality', 'Unknown'),
                        "file_size_category": self._categorize_file_size(video_info.get('file_size_mb', 0))
                    }
                }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, True)
            self.logger.info(f"[SUCCESS] ë¹„ë””ì˜¤ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ë¹„ë””ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì˜¤ë¥˜ ì‹œì—ë„)
            if 'audio_file' in locals() and audio_file and os.path.exists(audio_file):
                try:
                    os.unlink(audio_file)
                except:
                    pass
            
            self.logger.error(f"[ERROR] {error_msg}")
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(video_path, "video", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": file_name,
                    "file_path": video_path,
                    "processing_time": round(processing_time, 2),
                    "timestamp": datetime.now().isoformat(),
                    "analysis_type": "video_recovery"
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(processing_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(processing_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": file_name,
                "file_path": video_path,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
    
    def _analyze_keyframes_ocr(self, keyframes_list: List[Dict], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """í‚¤í”„ë ˆì„ë³„ OCR ë¶„ì„ - ì˜ìƒì˜ ì‹œê°ì  ì •ë³´ ì¶”ì¶œ"""
        start_time = time.time()
        
        try:
            # OCR ëª¨ë¸ ë¡œë“œ (ì´ë¯¸ì§€ ë¶„ì„ê³¼ ë™ì¼)
            reader = self._lazy_load_ocr()
            
            frame_analyses = []
            all_extracted_texts = []
            total_confidence = 0
            
            for i, frame_info in enumerate(keyframes_list):
                frame_path = frame_info.get('frame_path')
                timestamp_seconds = frame_info.get('timestamp', i * 10)  # ê¸°ë³¸ê°’ìœ¼ë¡œ 10ì´ˆ ê°„ê²©
                
                if not frame_path or not os.path.exists(frame_path):
                    continue
                    
                try:
                    self.logger.info(f"ğŸ–¼ï¸ í”„ë ˆì„ {i+1} OCR ë¶„ì„: {timestamp_seconds}ì´ˆ")
                    
                    # OCR ìˆ˜í–‰ (í”„ë ˆì„ë³„ ì†ë„ ìµœì í™”)
                    results = reader.readtext(
                        frame_path,
                        width_ths=0.8, height_ths=0.8, paragraph=False, detail=1,
                        batch_size=1, workers=0,  # í”„ë ˆì„ ë¶„ì„ ê³ ì†í™”
                        text_threshold=0.6, low_text=0.5, link_threshold=0.5,
                        canvas_size=960, mag_ratio=1.0  # ë” ì‘ì€ í¬ê¸°ë¡œ ì†ë„ í–¥ìƒ
                    )
                    
                    # ê²°ê³¼ ì²˜ë¦¬
                    detected_texts = []
                    frame_confidence = 0
                    
                    for bbox, text, confidence in results:
                        if confidence > 0.3:  # ìµœì†Œ ì‹ ë¢°ë„ í•„í„°ë§
                            detected_texts.append({
                                "text": text.strip(),
                                "confidence": float(round(confidence, 3)),
                                "bbox": bbox
                            })
                            frame_confidence += float(confidence)
                    
                    avg_frame_confidence = float(frame_confidence / len(results)) if results else 0.0
                    frame_text = ' '.join([item["text"] for item in detected_texts])
                    
                    # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ í–¥ìƒ (ì°¸ì„ì/í‚¤ì›Œë“œ ë³´ì •)
                    enhanced_frame_text = self._enhance_with_context(frame_text, context) if frame_text.strip() else ""
                    
                    frame_analysis = {
                        "frame_index": i + 1,
                        "timestamp_seconds": timestamp_seconds,
                        "timestamp_formatted": self._format_timestamp(timestamp_seconds),
                        "frame_path": frame_path,
                        "texts_detected": len(detected_texts),
                        "average_confidence": avg_frame_confidence,
                        "raw_text": frame_text,
                        "enhanced_text": enhanced_frame_text,
                        "detected_elements": detected_texts[:5]  # ìƒìœ„ 5ê°œë§Œ ì €ì¥
                    }
                    
                    frame_analyses.append(frame_analysis)
                    all_extracted_texts.append(enhanced_frame_text)
                    total_confidence += avg_frame_confidence
                    
                except Exception as frame_error:
                    self.logger.warning(f"âŒ í”„ë ˆì„ {i+1} OCR ì‹¤íŒ¨: {frame_error}")
                    continue
            
            processing_time = time.time() - start_time
            
            # ì „ì²´ í…ìŠ¤íŠ¸ í†µí•© ë° ë¶„ì„
            combined_visual_text = ' '.join(filter(None, all_extracted_texts))
            visual_summary = self._generate_context_aware_summary(combined_visual_text, context) if combined_visual_text.strip() else "ì‹œê°ì  í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ"
            visual_keywords = self._extract_jewelry_keywords(combined_visual_text) if combined_visual_text.strip() else []
            
            return {
                "status": "success",
                "processing_time": round(processing_time, 1),
                "frames_analyzed": len(frame_analyses),
                "total_texts_found": len(all_extracted_texts),
                "average_confidence": round(total_confidence / len(frame_analyses), 3) if frame_analyses else 0,
                "combined_visual_text": combined_visual_text,
                "visual_summary": visual_summary,
                "visual_keywords": visual_keywords,
                "frame_details": frame_analyses,
                "analysis_type": "keyframe_ocr"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í‚¤í”„ë ˆì„ OCR ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "processing_time": round(time.time() - start_time, 1)
            }
    
    def _format_timestamp(self, seconds: float) -> str:
        """ì´ˆë¥¼ mm:ss í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"

    def _categorize_file_size(self, size_mb: float) -> str:
        """íŒŒì¼ í¬ê¸° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        if size_mb < 10:
            return "small"
        elif size_mb < 100:
            return "medium"
        elif size_mb < 1000:
            return "large"
        else:
            return "very_large"
    
    def _update_stats(self, processing_time: float, success: bool, partial: bool = False):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.analysis_stats["total_files"] += 1
        self.analysis_stats["total_processing_time"] += processing_time
        if success:
            if partial:
                self.analysis_stats["partial_successes"] += 1
            else:
                self.analysis_stats["successful_analyses"] += 1
        else:
            self.analysis_stats["failed_analyses"] += 1
        self.analysis_stats["last_analysis_time"] = datetime.now().isoformat()
    
    def _try_recovery_analysis(self, file_path: str, file_type: str, original_error: str) -> Dict[str, Any]:
        """ì‹¤íŒ¨í•œ ë¶„ì„ì— ëŒ€í•œ ë³µêµ¬ ì‹œë„"""
        if not error_recovery_available:
            return None
        
        try:
            self.logger.info(f"[RECOVERY] ë³µêµ¬ ë¶„ì„ ì‹œë„: {os.path.basename(file_path)}")
            recovery_result = error_recovery_analyzer.recover_failed_analysis(file_path, file_type, original_error)
            
            if recovery_result.get("status") == "partial_success":
                self.logger.info(f"[RECOVERY] ë¶€ë¶„ ë³µêµ¬ ì„±ê³µ: {recovery_result.get('recovery_method', 'unknown')}")
                return recovery_result
            else:
                self.logger.warning(f"[RECOVERY] ë³µêµ¬ ì‹¤íŒ¨: {recovery_result.get('recovery_error', 'unknown')}")
                return None
                
        except Exception as e:
            self.logger.error(f"[RECOVERY] ë³µêµ¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """ë¶„ì„ í†µê³„ ë°˜í™˜"""
        total_files = self.analysis_stats["total_files"]
        if total_files == 0:
            return self.analysis_stats
        
        stats = self.analysis_stats.copy()
        
        # ì „ì²´ ì„±ê³µë¥  (ì™„ì „ ì„±ê³µ + ë¶€ë¶„ ì„±ê³µ)
        total_successes = stats["successful_analyses"] + stats["partial_successes"]
        stats["overall_success_rate"] = round((total_successes / total_files) * 100, 1)
        
        # ì™„ì „ ì„±ê³µë¥ ë§Œ
        stats["full_success_rate"] = round((stats["successful_analyses"] / total_files) * 100, 1)
        
        # ë¶€ë¶„ ì„±ê³µë¥ 
        stats["partial_success_rate"] = round((stats["partial_successes"] / total_files) * 100, 1)
        
        # ì‹¤íŒ¨ìœ¨
        stats["failure_rate"] = round((stats["failed_analyses"] / total_files) * 100, 1)
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„
        stats["average_processing_time"] = round(stats["total_processing_time"] / total_files, 1)
        
        # ë³µêµ¬ íš¨ê³¼ (ë¶€ë¶„ ì„±ê³µì´ ìˆìœ¼ë©´ ë³µêµ¬ ì‹œìŠ¤í…œì´ ì‘ë™í–ˆë‹¤ëŠ” ì˜ë¯¸)
        stats["recovery_effectiveness"] = stats["partial_successes"] > 0
        
        return stats

# ì „ì—­ ë¶„ì„ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
global_analysis_engine = RealAnalysisEngine()

def analyze_file_real(file_path: str, file_type: str, language: str = "auto", context: Dict[str, Any] = None) -> Dict[str, Any]:
    """íŒŒì¼ ì‹¤ì œ ë¶„ì„ (ê°„í¸ ì‚¬ìš©, ì»¨í…ìŠ¤íŠ¸ ì§€ì›, í’ˆì§ˆ í–¥ìƒ ì ìš©)"""
    # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
    if file_type == "audio":
        result = global_analysis_engine.analyze_audio_file(file_path, language=language, context=context)
    elif file_type == "image":
        result = global_analysis_engine.analyze_image_file(file_path, context=context)
    elif file_type == "document":
        result = global_analysis_engine.analyze_document_file(file_path)
    elif file_type == "youtube":
        result = global_analysis_engine.analyze_youtube_video(file_path, language=language)
    elif file_type == "video":
        result = global_analysis_engine.analyze_video_file(file_path, language=language)
    else:
        return {
            "status": "error",
            "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}",
            "file_name": os.path.basename(file_path) if os.path.exists(file_path) else file_path,
            "timestamp": datetime.now().isoformat()
        }
    
    # ğŸš€ ì¢…í•© ë¶„ì„ ì—”ì§„ ì ìš© (í´ë¡œë°” ë…¸íŠ¸ + ChatGPT ìˆ˜ì¤€)
    if result.get('status') == 'success':
        try:
            # 1. í’ˆì§ˆ í–¥ìƒ ì—”ì§„ ì ìš©
            if quality_enhancer_available:
                result = enhance_analysis_quality(result, context)
                result['quality_enhancement_applied'] = True
            
            # 2. PPT ì§€ëŠ¥í˜• ë¶„ì„ (ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°)
            if file_type == "image" and ppt_intelligence_available:
                ppt_analysis = analyze_ppt_slide(file_path, context)
                if ppt_analysis.get('status') == 'success':
                    result['ppt_intelligence'] = ppt_analysis['ppt_intelligence']
                    result['ppt_enhanced_understanding'] = ppt_analysis['enhanced_understanding']
            
            # 3. ì¢…í•© ë©”ì‹œì§€ ì¶”ì¶œ (ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if message_extractor_available:
                # ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„° ì¤€ë¹„
                multimodal_data = {}
                if file_type == "audio":
                    multimodal_data['audio_analysis'] = result
                elif file_type == "image":
                    multimodal_data['image_analysis'] = [result]
                elif file_type == "video":
                    multimodal_data['video_analysis'] = result
                
                # ì¢…í•© ë©”ì‹œì§€ ì¶”ì¶œ
                if multimodal_data:
                    message_analysis = extract_speaker_message(multimodal_data, context)
                    result['comprehensive_message'] = message_analysis['comprehensive_analysis']
                    result['clova_style_summary'] = message_analysis['comprehensive_analysis']['clova_style_summary']
            
            # 4. ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)
            if jewelry_enhancer_available and result.get('enhanced_text'):
                result = enhance_with_jewelry_domain(result, result['enhanced_text'])
            
            # ì¢…í•© ë¶„ì„ ì™„ë£Œ ë§ˆí‚¹
            result['comprehensive_analysis_applied'] = True
            result['analysis_engines_used'] = {
                'quality_enhancer': quality_enhancer_available,
                'message_extractor': message_extractor_available,
                'ppt_intelligence': ppt_intelligence_available and file_type == "image",
                'jewelry_domain': jewelry_enhancer_available
            }
            
        except Exception as e:
            # ì¢…í•© ë¶„ì„ ì‹¤íŒ¨ì‹œ ì›ë³¸ ê²°ê³¼ ë°˜í™˜ (ë¡œê·¸ ê¸°ë¡)
            logging.getLogger(__name__).warning(f"ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {e}")
            result['comprehensive_analysis_error'] = str(e)
            result['comprehensive_analysis_applied'] = False
    
    return result

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸš€ ì‹¤ì œ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    engine = RealAnalysisEngine()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        ("/mnt/c/Users/PC_58410/Desktop/ê·¼í˜/ì„¸ë¯¸ë‚˜/202506í™ì½©ì‡¼/D1/ìƒˆë¡œìš´ ë…¹ìŒ 2.m4a", "audio"),
        ("/mnt/c/Users/PC_58410/Desktop/ê·¼í˜/ì„¸ë¯¸ë‚˜/202506í™ì½©ì‡¼/D1/IMG_2160.JPG", "image")
    ]
    
    for file_path, file_type in test_files:
        if os.path.exists(file_path):
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸: {os.path.basename(file_path)}")
            result = analyze_file_real(file_path, file_type)
            print(f"ê²°ê³¼: {result.get('status', 'unknown')}")
            if result.get('status') == 'success':
                print(f"ì²˜ë¦¬ì‹œê°„: {result.get('processing_time', 0)}ì´ˆ")
                if 'full_text' in result:
                    text = result['full_text']
                    print(f"ì¶”ì¶œ í…ìŠ¤íŠ¸: {text[:100]}{'...' if len(text) > 100 else ''}")
        else:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
    
    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ë¶„ì„ í†µê³„:")
    stats = engine.get_analysis_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\nâœ… ì‹¤ì œ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")