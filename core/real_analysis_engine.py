#!/usr/bin/env python3
"""
ì‹¤ì œ ë¶„ì„ ì—”ì§„ - ê°€ì§œ ë¶„ì„ì„ ì‹¤ì œ ë¶„ì„ìœ¼ë¡œ êµì²´
Whisper STT + EasyOCR + ë¬´ë£Œ AI ëª¨ë¸ í†µí•©
"""

import os
import time
import logging
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
import json
from datetime import datetime

# ì‹¤ì œ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import whisper
import easyocr
try:
    from transformers import pipeline
    transformers_available = True
except ImportError:
    transformers_available = False

try:
    import google.generativeai as genai
    gemini_available = True
except ImportError:
    gemini_available = False

class RealAnalysisEngine:
    """ì‹¤ì œ íŒŒì¼ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
        # ë¶„ì„ ëª¨ë¸ë“¤ ì´ˆê¸°í™”
        self.whisper_model = None
        self.ocr_reader = None
        self.nlp_pipeline = None
        
        # ì„±ëŠ¥ ì¶”ì 
        self.analysis_stats = {
            "total_files": 0,
            "successful_analyses": 0,
            "total_processing_time": 0,
            "last_analysis_time": None
        }
        
        self.logger.info("ğŸš€ ì‹¤ì œ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _lazy_load_whisper(self, model_size: str = "base") -> whisper.Whisper:
        """Whisper ëª¨ë¸ ì§€ì—° ë¡œë”©"""
        if self.whisper_model is None:
            self.logger.info(f"ğŸ¤ Whisper {model_size} ëª¨ë¸ ë¡œë”©...")
            start_time = time.time()
            self.whisper_model = whisper.load_model(model_size)
            load_time = time.time() - start_time
            self.logger.info(f"âœ… Whisper ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
        return self.whisper_model
    
    def _lazy_load_ocr(self) -> easyocr.Reader:
        """EasyOCR ëª¨ë¸ ì§€ì—° ë¡œë”©"""
        if self.ocr_reader is None:
            self.logger.info("ğŸ–¼ï¸ EasyOCR í•œ/ì˜ ëª¨ë¸ ë¡œë”©...")
            start_time = time.time()
            self.ocr_reader = easyocr.Reader(['ko', 'en'])
            load_time = time.time() - start_time
            self.logger.info(f"âœ… EasyOCR ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
        return self.ocr_reader
    
    def _lazy_load_nlp(self) -> Optional[any]:
        """NLP íŒŒì´í”„ë¼ì¸ ì§€ì—° ë¡œë”©"""
        if not transformers_available:
            return None
            
        if self.nlp_pipeline is None:
            try:
                self.logger.info("ğŸ§  NLP ëª¨ë¸ ë¡œë”©...")
                start_time = time.time()
                self.nlp_pipeline = pipeline("summarization", 
                                           model="facebook/bart-large-cnn")
                load_time = time.time() - start_time
                self.logger.info(f"âœ… NLP ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
            except Exception as e:
                self.logger.warning(f"NLP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
        return self.nlp_pipeline
    
    def analyze_audio_file(self, file_path: str, language: str = "ko") -> Dict[str, Any]:
        """ì‹¤ì œ ìŒì„± íŒŒì¼ ë¶„ì„"""
        self.logger.info(f"ğŸ¤ ì‹¤ì œ ìŒì„± ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)}")
        
        start_time = time.time()
        
        try:
            # Whisper ëª¨ë¸ ë¡œë“œ
            model = self._lazy_load_whisper()
            
            # ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
            self.logger.info("ğŸ”„ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            result = model.transcribe(file_path, language=language)
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ë¶„ì„
            text = result["text"]
            segments = result["segments"]
            detected_language = result["language"]
            
            # í…ìŠ¤íŠ¸ ìš”ì•½ (NLP ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì‹œ)
            summary = self._generate_summary(text)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„
            jewelry_keywords = self._extract_jewelry_keywords(text)
            
            analysis_result = {
                "status": "success",
                "file_name": os.path.basename(file_path),
                "file_size_mb": round(os.path.getsize(file_path) / (1024 * 1024), 2),
                "processing_time": round(processing_time, 1),
                "detected_language": detected_language,
                "segments_count": len(segments),
                "text_length": len(text),
                "full_text": text,
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "segments": segments,
                "analysis_type": "real_whisper_stt",
                "timestamp": datetime.now().isoformat()
            }
            
            self._update_stats(processing_time, True)
            self.logger.info(f"âœ… ìŒì„± ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return analysis_result
            
        except Exception as e:
            error_msg = f"ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            self.logger.error(error_msg)
            self._update_stats(time.time() - start_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": os.path.basename(file_path),
                "analysis_type": "real_whisper_stt",
                "timestamp": datetime.now().isoformat()
            }
    
    def analyze_image_file(self, file_path: str) -> Dict[str, Any]:
        """ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ OCR ë¶„ì„"""
        self.logger.info(f"ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)}")
        
        start_time = time.time()
        
        try:
            # OCR ëª¨ë¸ ë¡œë“œ
            reader = self._lazy_load_ocr()
            
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
            self.logger.info("ğŸ”„ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            results = reader.readtext(file_path)
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ì²˜ë¦¬
            detected_texts = []
            total_confidence = 0
            
            for bbox, text, confidence in results:
                detected_texts.append({
                    "text": text,
                    "confidence": round(confidence, 3),
                    "bbox": bbox
                })
                total_confidence += confidence
            
            avg_confidence = total_confidence / len(results) if results else 0
            full_text = ' '.join([item["text"] for item in detected_texts])
            
            # í…ìŠ¤íŠ¸ ìš”ì•½
            summary = self._generate_summary(full_text)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„
            jewelry_keywords = self._extract_jewelry_keywords(full_text)
            
            analysis_result = {
                "status": "success",
                "file_name": os.path.basename(file_path),
                "file_size_mb": round(os.path.getsize(file_path) / (1024 * 1024), 2),
                "processing_time": round(processing_time, 1),
                "blocks_detected": len(results),
                "average_confidence": round(avg_confidence, 3),
                "full_text": full_text,
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "detailed_results": detected_texts,
                "analysis_type": "real_easyocr",
                "timestamp": datetime.now().isoformat()
            }
            
            self._update_stats(processing_time, True)
            self.logger.info(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return analysis_result
            
        except Exception as e:
            error_msg = f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            self.logger.error(error_msg)
            self._update_stats(time.time() - start_time, False)
            
            return {
                "status": "error", 
                "error": error_msg,
                "file_name": os.path.basename(file_path),
                "analysis_type": "real_easyocr",
                "timestamp": datetime.now().isoformat()
            }
    
    def _generate_summary(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        if not text or len(text.strip()) < 50:
            return "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # NLP ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì‹œ
        nlp = self._lazy_load_nlp()
        if nlp and len(text) > 100:
            try:
                # ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë¥´ê¸°
                if len(text) > 1024:
                    text = text[:1024]
                
                summary_result = nlp(text, max_length=100, min_length=30, do_sample=False)
                return summary_result[0]['summary_text']
            except Exception as e:
                self.logger.debug(f"NLP ìš”ì•½ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ìš”ì•½ (ì²« 100ì)
        return text[:100] + "..." if len(text) > 100 else text
    
    def _extract_jewelry_keywords(self, text: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return []
        
        jewelry_terms = [
            # ì˜ì–´ ì£¼ì–¼ë¦¬ ìš©ì–´
            "diamond", "gold", "silver", "platinum", "jewelry", "jewellery", 
            "ring", "necklace", "bracelet", "earring", "pendant", "gemstone",
            "ruby", "sapphire", "emerald", "pearl", "crystal", "luxury",
            "carat", "cut", "clarity", "color", "certificate", "GIA",
            
            # í•œêµ­ì–´ ì£¼ì–¼ë¦¬ ìš©ì–´  
            "ë‹¤ì´ì•„ëª¬ë“œ", "ê¸ˆ", "ì€", "ë°±ê¸ˆ", "ì£¼ì–¼ë¦¬", "ë°˜ì§€", "ëª©ê±¸ì´", 
            "íŒ”ì°Œ", "ê·€ê±¸ì´", "íœë˜íŠ¸", "ë³´ì„", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", 
            "ì—ë©”ë„ë“œ", "ì§„ì£¼", "í¬ë¦¬ìŠ¤íƒˆ", "ëŸ­ì…”ë¦¬", "ìºëŸ¿", "ì»¤íŒ…",
            "íˆ¬ëª…ë„", "ìƒ‰ìƒ", "ì¸ì¦ì„œ", "ì§€ì•„"
        ]
        
        text_lower = text.lower()
        found_keywords = []
        
        for term in jewelry_terms:
            if term.lower() in text_lower:
                found_keywords.append(term)
        
        return list(set(found_keywords))  # ì¤‘ë³µ ì œê±°
    
    def _update_stats(self, processing_time: float, success: bool):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.analysis_stats["total_files"] += 1
        self.analysis_stats["total_processing_time"] += processing_time
        if success:
            self.analysis_stats["successful_analyses"] += 1
        self.analysis_stats["last_analysis_time"] = datetime.now().isoformat()
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """ë¶„ì„ í†µê³„ ë°˜í™˜"""
        total_files = self.analysis_stats["total_files"]
        if total_files == 0:
            return self.analysis_stats
        
        stats = self.analysis_stats.copy()
        stats["success_rate"] = round(
            (stats["successful_analyses"] / total_files) * 100, 1
        )
        stats["average_processing_time"] = round(
            stats["total_processing_time"] / total_files, 1
        )
        
        return stats

# ì „ì—­ ë¶„ì„ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
global_analysis_engine = RealAnalysisEngine()

def analyze_file_real(file_path: str, file_type: str) -> Dict[str, Any]:
    """íŒŒì¼ ì‹¤ì œ ë¶„ì„ (ê°„í¸ ì‚¬ìš©)"""
    if file_type == "audio":
        return global_analysis_engine.analyze_audio_file(file_path)
    elif file_type == "image":
        return global_analysis_engine.analyze_image_file(file_path)
    else:
        return {
            "status": "error",
            "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}",
            "file_name": os.path.basename(file_path),
            "timestamp": datetime.now().isoformat()
        }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸš€ ì‹¤ì œ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    engine = RealAnalysisEngine()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        ("/mnt/c/Users/PC_58410/Desktop/ê·¼í˜/ì„¸ë¯¸ë‚˜/202506í™ì½©ì‡¼/D1/ìƒˆë¡œìš´ ë…¹ìŒ 2.m4a", "audio"),
        ("/mnt/c/Users/PC_58410/Desktop/ê·¼í˜/ì„¸ë¯¸ë‚˜/202506í™ì½©ì‡¼/D1/IMG_2160.JPG", "image")
    ]
    
    for file_path, file_type in test_files:
        if os.path.exists(file_path):
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸: {os.path.basename(file_path)}")
            result = analyze_file_real(file_path, file_type)
            print(f"ê²°ê³¼: {result.get('status', 'unknown')}")
            if result.get('status') == 'success':
                print(f"ì²˜ë¦¬ì‹œê°„: {result.get('processing_time', 0)}ì´ˆ")
                if 'full_text' in result:
                    text = result['full_text']
                    print(f"ì¶”ì¶œ í…ìŠ¤íŠ¸: {text[:100]}{'...' if len(text) > 100 else ''}")
        else:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
    
    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ë¶„ì„ í†µê³„:")
    stats = engine.get_analysis_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\nâœ… ì‹¤ì œ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")