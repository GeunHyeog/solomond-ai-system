#!/usr/bin/env python3
"""
ì‹¤ì œ ë¶„ì„ ì—”ì§„ - ê°€ì§œ ë¶„ì„ì„ ì‹¤ì œ ë¶„ì„ìœ¼ë¡œ êµì²´
Whisper STT + EasyOCR + ë¬´ë£Œ AI ëª¨ë¸ í†µí•©
"""

import os
import time
import logging
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
import json
from datetime import datetime

# GPU ë©”ëª¨ë¦¬ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ CPU ëª¨ë“œ ê°•ì œ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'

# ì‹¤ì œ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import whisper
import easyocr
import subprocess
import tempfile

try:
    import librosa
    import numpy as np
    librosa_available = True
except ImportError:
    librosa_available = False

try:
    from transformers import pipeline
    transformers_available = True
except ImportError:
    transformers_available = False

try:
    import google.generativeai as genai
    gemini_available = True
except ImportError:
    gemini_available = False

try:
    from .document_processor import document_processor
    document_processor_available = True
except ImportError:
    document_processor_available = False

try:
    from .youtube_processor import youtube_processor
    youtube_processor_available = True
except ImportError:
    youtube_processor_available = False

try:
    from .large_video_processor import large_video_processor
    large_video_processor_available = True
except ImportError:
    large_video_processor_available = False

try:
    from .error_recovery_analyzer import error_recovery_analyzer
    error_recovery_available = True
except ImportError:
    error_recovery_available = False

class RealAnalysisEngine:
    """ì‹¤ì œ íŒŒì¼ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        
        # ë¶„ì„ ëª¨ë¸ë“¤ ì´ˆê¸°í™”
        self.whisper_model = None
        self.ocr_reader = None
        self.nlp_pipeline = None
        
        # ì„±ëŠ¥ ì¶”ì 
        self.analysis_stats = {
            "total_files": 0,
            "successful_analyses": 0,
            "partial_successes": 0,
            "failed_analyses": 0,
            "total_processing_time": 0,
            "last_analysis_time": None
        }
        
        self.logger.info("[INFO] ì‹¤ì œ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"[INFO] ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ê¸°: {'í™œì„±í™”' if error_recovery_available else 'ë¹„í™œì„±í™”'}")
    
    def _enhance_with_context(self, extracted_text: str, context: Dict[str, Any] = None) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í™œìš©í•œ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬"""
        if not context or not extracted_text:
            return extracted_text
        
        enhanced_text = extracted_text
        
        # ì£¼ì œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê´€ë ¨ ìš©ì–´ ë³´ì •
        if context.get('topic_keywords'):
            keywords = [k.strip() for k in context['topic_keywords'].split(',')]
            for keyword in keywords:
                if keyword and len(keyword) > 2:
                    # ìœ ì‚¬í•œ ë‹¨ì–´ ì°¾ì•„ì„œ ë³´ì • (ê°„ë‹¨í•œ ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê¸°ë°˜)
                    import difflib
                    words = enhanced_text.split()
                    for i, word in enumerate(words):
                        if difflib.SequenceMatcher(None, word.lower(), keyword.lower()).ratio() > 0.7:
                            words[i] = keyword  # ì •í™•í•œ í‚¤ì›Œë“œë¡œ êµì²´
                    enhanced_text = ' '.join(words)
        
        # ì°¸ì„ì/ë°œí‘œì ì •ë³´ë¡œ ì¸ëª… ë³´ì •
        if context.get('speakers') or context.get('participants'):
            names = []
            if context.get('speakers'):
                names.extend([n.strip() for n in context['speakers'].split(',')])
            if context.get('participants'):
                # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°í•˜ê³  ì´ë¦„ë§Œ ì¶”ì¶œ
                import re
                participant_text = context['participants']
                participant_names = re.findall(r'([ê°€-í£a-zA-Z\s]+?)(?:\s*\([^)]*\))?(?:,|$)', participant_text)
                names.extend([n.strip() for n in participant_names if n.strip()])
            
            # ì¸ëª… ë³´ì •
            for name in names:
                if name and len(name) > 1:
                    import difflib
                    words = enhanced_text.split()
                    for i, word in enumerate(words):
                        if difflib.SequenceMatcher(None, word, name).ratio() > 0.6:
                            words[i] = name
                    enhanced_text = ' '.join(words)
        
        return enhanced_text
    
    def _generate_context_aware_summary(self, text: str, context: Dict[str, Any] = None) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìš”ì•½ ìƒì„±"""
        if not context:
            return self._generate_summary(text)
        
        # ê¸°ë³¸ ìš”ì•½ ìƒì„±
        base_summary = self._generate_summary(text)
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if context.get('event_context'):
            context_prefix = f"[{context['event_context']}] "
        else:
            context_prefix = ""
        
        if context.get('objective'):
            objective_suffix = f" (ëª©ì : {context['objective']})"
        else:
            objective_suffix = ""
        
        return f"{context_prefix}{base_summary}{objective_suffix}"
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _lazy_load_whisper(self, model_size: str = "base") -> whisper.Whisper:
        """Whisper ëª¨ë¸ ì§€ì—° ë¡œë”©"""
        if self.whisper_model is None:
            self.logger.info(f"ğŸ¤ Whisper {model_size} ëª¨ë¸ ë¡œë”©...")
            start_time = time.time()
            self.whisper_model = whisper.load_model(model_size)
            load_time = time.time() - start_time
            self.logger.info(f"âœ… Whisper ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
        return self.whisper_model
    
    def _lazy_load_ocr(self) -> easyocr.Reader:
        """EasyOCR ëª¨ë¸ ì§€ì—° ë¡œë”© (ì„±ëŠ¥ ìµœì í™”)"""
        if self.ocr_reader is None:
            self.logger.info("ğŸ–¼ï¸ EasyOCR í•œ/ì˜ ëª¨ë¸ ë¡œë”©... (CPU ìµœì í™”)")
            start_time = time.time()
            
            # CPU ëª¨ë“œì™€ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            self.ocr_reader = easyocr.Reader(
                ['ko', 'en'],
                gpu=False,  # CPU ê°•ì œ ì‚¬ìš©
                model_storage_directory=None,  # ê¸°ë³¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì‚¬ìš©
                user_network_directory=None,
                recog_network='CRNN',  # ê¸°ë³¸ recognition network
                detector=True,
                recognizer=True,
                verbose=False  # ë¡œê·¸ ìµœì†Œí™”
            )
            
            load_time = time.time() - start_time
            self.logger.info(f"âœ… EasyOCR ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
        return self.ocr_reader
    
    def _lazy_load_nlp(self) -> Optional[any]:
        """NLP íŒŒì´í”„ë¼ì¸ ì§€ì—° ë¡œë”©"""
        if not transformers_available:
            return None
            
        if self.nlp_pipeline is None:
            try:
                self.logger.info("ğŸ§  NLP ëª¨ë¸ ë¡œë”©...")
                start_time = time.time()
                self.nlp_pipeline = pipeline("summarization", 
                                           model="facebook/bart-large-cnn")
                load_time = time.time() - start_time
                self.logger.info(f"âœ… NLP ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
            except Exception as e:
                self.logger.warning(f"NLP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
        return self.nlp_pipeline
    
    def _validate_whisper_language(self, language: str) -> Optional[str]:
        """Whisper ì–¸ì–´ ì„¤ì • ê²€ì¦ ë° ë³€í™˜"""
        if language == "auto":
            return None  # Whisper ìë™ ê°ì§€
        
        # Whisperì—ì„œ ì§€ì›í•˜ëŠ” ì£¼ìš” ì–¸ì–´ ì½”ë“œ
        whisper_languages = {
            "ko": "ko",  # í•œêµ­ì–´
            "en": "en",  # ì˜ì–´
            "ja": "ja",  # ì¼ë³¸ì–´
            "zh": "zh",  # ì¤‘êµ­ì–´
            "es": "es",  # ìŠ¤í˜ì¸ì–´
            "fr": "fr",  # í”„ë‘ìŠ¤ì–´
            "de": "de",  # ë…ì¼ì–´
            "it": "it",  # ì´íƒˆë¦¬ì•„ì–´
            "pt": "pt",  # í¬ë¥´íˆ¬ê°ˆì–´
            "ru": "ru",  # ëŸ¬ì‹œì•„ì–´
            "ar": "ar",  # ì•„ëì–´
            "hi": "hi",  # íŒë””ì–´
        }
        
        # ì–¸ì–´ ì½”ë“œ ì •ê·œí™”
        lang_code = language.lower().strip()
        
        if lang_code in whisper_languages:
            return whisper_languages[lang_code]
        else:
            self.logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ ì½”ë“œ: {language}, ìë™ ê°ì§€ë¡œ ëŒ€ì²´")
            return None  # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ëŠ” ìë™ ê°ì§€ë¡œ ëŒ€ì²´
    
    def _validate_audio_data(self, file_path: str) -> bool:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë°ì´í„° ê²€ì¦"""
        try:
            if librosa_available:
                # librosaë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ì˜¤ë””ì˜¤ ë°ì´í„° ê²€ì¦
                audio_data, sample_rate = librosa.load(file_path, sr=None)
                
                # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if len(audio_data) == 0:
                    self.logger.error("âŒ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    return False
                
                # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ (ìµœì†Œ 0.1ì´ˆ)
                duration = len(audio_data) / sample_rate
                if duration < 0.1:
                    self.logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {duration:.2f}ì´ˆ")
                    return False
                
                # NaN ë˜ëŠ” ë¬´í•œëŒ€ ê°’ í™•ì¸
                if np.any(np.isnan(audio_data)) or np.any(np.isinf(audio_data)):
                    self.logger.error("âŒ ì˜¤ë””ì˜¤ ë°ì´í„°ì— ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
                    return False
                
                self.logger.info(f"âœ… ì˜¤ë””ì˜¤ ê²€ì¦ ì„±ê³µ: {duration:.2f}ì´ˆ, {sample_rate}Hz")
                return True
            else:
                # librosaê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ íŒŒì¼ ê²€ì¦
                self.logger.info("ğŸ”§ librosa ì—†ìŒ, ê¸°ë³¸ íŒŒì¼ ê²€ì¦ ì‚¬ìš©")
                
                # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
                if not os.path.exists(file_path):
                    self.logger.error("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                    return False
                
                file_size = os.path.getsize(file_path)
                if file_size < 1024:  # 1KB ë¯¸ë§Œ
                    self.logger.error(f"âŒ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {file_size} bytes")
                    return False
                
                # FFmpeg/ffprobeë¥¼ ì‚¬ìš©í•œ íŒŒì¼ ì •ë³´ í™•ì¸
                try:
                    # ffprobeê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
                    cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', file_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    
                    if result.returncode == 0:
                        import json
                        info = json.loads(result.stdout)
                        duration = float(info.get('format', {}).get('duration', 0))
                        
                        if duration < 0.1:
                            self.logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {duration:.2f}ì´ˆ")
                            return False
                        
                        self.logger.info(f"âœ… ê¸°ë³¸ ì˜¤ë””ì˜¤ ê²€ì¦ ì„±ê³µ: {duration:.2f}ì´ˆ")
                        return True
                    else:
                        raise Exception("ffprobe failed")
                        
                except Exception:
                    # ffprobe ì‹¤íŒ¨ì‹œ ffmpegìœ¼ë¡œ ëŒ€ì²´ ì‹œë„
                    try:
                        cmd = ['ffmpeg', '-i', file_path, '-f', 'null', '-', '-v', 'quiet']
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                        
                        # ffmpegê°€ ì„±ê³µì ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ìˆìœ¼ë©´ ìœ íš¨í•œ íŒŒì¼ë¡œ ê°„ì£¼
                        if result.returncode == 0:
                            self.logger.info("âœ… ffmpeg ê¸°ë³¸ ê²€ì¦ ì„±ê³µ")
                            return True
                        else:
                            self.logger.warning("âš ï¸ ffmpeg ê²€ì¦ ì‹¤íŒ¨, íŒŒì¼ í˜•ì‹ì„ ì‹ ë¢°í•˜ê³  ì§„í–‰")
                            return True
                            
                    except (subprocess.TimeoutExpired, Exception) as e:
                        self.logger.warning(f"âš ï¸ ê¸°ë³¸ ê²€ì¦ ì‹¤íŒ¨: {e}, íŒŒì¼ í˜•ì‹ì„ ì‹ ë¢°í•˜ê³  ì§„í–‰")
                        return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜¤ë””ì˜¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _convert_m4a_to_wav(self, m4a_path: str) -> str:
        """M4A íŒŒì¼ì„ WAVë¡œ ë³€í™˜ (FFmpeg ì‚¬ìš©)"""
        try:
            # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                temp_wav_path = temp_wav.name
            
            # FFmpeg ëª…ë ¹ì–´ë¡œ M4Aë¥¼ WAVë¡œ ë³€í™˜
            cmd = [
                'ffmpeg', '-i', m4a_path,
                '-acodec', 'pcm_s16le',  # PCM 16-bit
                '-ar', '16000',          # 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸
                '-ac', '1',              # ëª¨ë…¸ ì±„ë„
                '-y',                    # ë®ì–´ì“°ê¸° í—ˆìš©
                temp_wav_path
            ]
            
            self.logger.info("ğŸ”„ M4A â†’ WAV ë³€í™˜ ì¤‘...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                self.logger.info("âœ… M4A â†’ WAV ë³€í™˜ ì™„ë£Œ")
                return temp_wav_path
            else:
                self.logger.error(f"âŒ FFmpeg ë³€í™˜ ì‹¤íŒ¨: {result.stderr}")
                # ì‹¤íŒ¨ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if os.path.exists(temp_wav_path):
                    os.unlink(temp_wav_path)
                return None
                
        except subprocess.TimeoutExpired:
            self.logger.error("âŒ FFmpeg ë³€í™˜ ì‹œê°„ ì´ˆê³¼")
            return None
        except Exception as e:
            self.logger.error(f"âŒ M4A ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _preprocess_m4a_file(self, file_path: str) -> str:
        """M4A íŒŒì¼ ì „ì²˜ë¦¬"""
        self.logger.info("ğŸµ M4A íŒŒì¼ ì „ì²˜ë¦¬ ì‹œì‘")
        
        # 1. ì›ë³¸ íŒŒì¼ ê²€ì¦
        if not self._validate_audio_data(file_path):
            # ê²€ì¦ ì‹¤íŒ¨ì‹œ FFmpeg ë³€í™˜ ì‹œë„
            self.logger.info("ğŸ”§ FFmpeg ë³€í™˜ìœ¼ë¡œ ì¬ì‹œë„")
            converted_path = self._convert_m4a_to_wav(file_path)
            if converted_path and self._validate_audio_data(converted_path):
                return converted_path
            else:
                # ë³€í™˜ë„ ì‹¤íŒ¨ì‹œ ì •ë¦¬í•˜ê³  None ë°˜í™˜
                if converted_path and os.path.exists(converted_path):
                    os.unlink(converted_path)
                return None
        
        # ì›ë³¸ íŒŒì¼ì´ ì •ìƒì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return file_path
    
    def analyze_audio_file(self, file_path: str, language: str = "ko", context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì‹¤ì œ ìŒì„± íŒŒì¼ ë¶„ì„"""
        self.logger.info(f"ğŸ¤ ì‹¤ì œ ìŒì„± ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)}")
        
        start_time = time.time()
        processed_file_path = None
        temp_file_created = False
        
        try:
            # Whisper ëª¨ë¸ ë¡œë“œ
            model = self._lazy_load_whisper()
            
            # ì–¸ì–´ ì„¤ì • ì²˜ë¦¬ - "auto"ì¸ ê²½ìš° Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìë™ ê°ì§€ í™œì„±í™”
            whisper_language = self._validate_whisper_language(language)
            self.logger.info(f"ğŸ”¤ ì–¸ì–´ ì„¤ì •: {language} -> Whisper: {whisper_language}")
            
            # íŒŒì¼ í˜•ì‹ í™•ì¸ ë° íŠ¹ë³„ ì²˜ë¦¬
            file_ext = Path(file_path).suffix.lower()
            self.logger.info(f"ğŸ“ íŒŒì¼ í˜•ì‹: {file_ext}")
            
            # M4A íŒŒì¼ ì „ì²˜ë¦¬
            if file_ext == ".m4a":
                processed_file_path = self._preprocess_m4a_file(file_path)
                if processed_file_path is None:
                    raise Exception("M4A íŒŒì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨: ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
                # ë³€í™˜ëœ íŒŒì¼ì¸ì§€ í™•ì¸ (ì„ì‹œ íŒŒì¼ ì •ë¦¬ë¥¼ ìœ„í•´)
                temp_file_created = (processed_file_path != file_path)
            else:
                processed_file_path = file_path
            
            # ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
            self.logger.info("ğŸ”„ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            transcribe_options = {
                "language": whisper_language,
                "fp16": False,  # ì•ˆì •ì„±ì„ ìœ„í•´ fp16 ë¹„í™œì„±í™”
                "verbose": False
            }
            
            # M4A íŒŒì¼ì˜ ê²½ìš° ì¶”ê°€ ì˜µì…˜ ì„¤ì •
            if file_ext == ".m4a":
                self.logger.info("ğŸµ M4A íŒŒì¼ íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œ")
                transcribe_options.update({
                    "condition_on_previous_text": False,
                    "beam_size": 1,           # ì•ˆì •ì„±ì„ ìœ„í•´ ë¹” ì‚¬ì´ì¦ˆ ì¶•ì†Œ
                    "best_of": 1,            # ìµœìƒ í›„ë³´ë§Œ ì‚¬ìš©
                    "temperature": 0.0,      # ì˜¨ë„ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ì„± í–¥ìƒ
                    "compression_ratio_threshold": 2.4,  # ì••ì¶•ë¹„ ì„ê³„ê°’ ì„¤ì •
                    "logprob_threshold": -1.0,           # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’ ì„¤ì •
                    "no_speech_threshold": 0.6           # ë¬´ìŒ ê°ì§€ ì„ê³„ê°’ ì„¤ì •
                })
            
            # Whisperì— ì˜¤ë””ì˜¤ ì „ë‹¬í•˜ê¸° ì „ ë§ˆì§€ë§‰ ì•ˆì „ ì²´í¬
            if not os.path.exists(processed_file_path):
                raise Exception(f"ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {processed_file_path}")
            
            result = model.transcribe(processed_file_path, **transcribe_options)
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ë¶„ì„
            text = result["text"]
            segments = result["segments"]
            detected_language = result["language"]
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ í–¥ìƒ
            enhanced_text = self._enhance_with_context(text, context)
            
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìš”ì•½ ìƒì„±
            summary = self._generate_context_aware_summary(enhanced_text, context)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„ (í–¥ìƒëœ í…ìŠ¤íŠ¸ ê¸°ë°˜)
            jewelry_keywords = self._extract_jewelry_keywords(enhanced_text)
            
            analysis_result = {
                "status": "success",
                "file_name": os.path.basename(file_path),
                "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2)),
                "processing_time": float(round(processing_time, 1)),
                "detected_language": detected_language,
                "segments_count": int(len(segments)),
                "text_length": int(len(text)),
                "full_text": enhanced_text,
                "original_text": text,
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "segments": segments,
                "analysis_type": "real_whisper_stt",
                "timestamp": datetime.now().isoformat()
            }
            
            self._update_stats(processing_time, True)
            self.logger.info(f"âœ… ìŒì„± ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return analysis_result
            
        except Exception as e:
            # M4A ê´€ë ¨ íŠ¹ë³„ ì—ëŸ¬ ì²˜ë¦¬
            error_str = str(e)
            if file_ext == ".m4a" and ("reshape" in error_str or "tensor" in error_str or "0 elements" in error_str):
                error_msg = f"M4A íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤. FFmpegë‚˜ librosa ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì›ë³¸ ì˜¤ë¥˜: {error_str}"
                self.logger.error("âŒ M4A í…ì„œ ë¦¬ì…°ì´í”„ ì˜¤ë¥˜ ê°ì§€")
            else:
                error_msg = f"ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {error_str}"
            
            self.logger.error(error_msg)
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(file_path, "audio", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": os.path.basename(file_path),
                    "file_extension": file_ext,
                    "librosa_available": librosa_available,
                    "analysis_type": "real_whisper_stt_recovery",
                    "timestamp": datetime.now().isoformat(),
                    "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2))
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(time.time() - start_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(time.time() - start_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": os.path.basename(file_path),
                "file_extension": file_ext,
                "librosa_available": librosa_available,
                "analysis_type": "real_whisper_stt",
                "timestamp": datetime.now().isoformat()
            }
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_file_created and processed_file_path and os.path.exists(processed_file_path):
                try:
                    os.unlink(processed_file_path)
                    self.logger.info("ğŸ—‘ï¸ ì„ì‹œ ë³€í™˜ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def analyze_image_file(self, file_path: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ OCR ë¶„ì„"""
        self.logger.info(f"ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)}")
        
        start_time = time.time()
        
        try:
            # OCR ëª¨ë¸ ë¡œë“œ
            reader = self._lazy_load_ocr()
            
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (í’ˆì§ˆê³¼ ì„±ëŠ¥ ê· í˜•)
            self.logger.info("ğŸ”„ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... (í’ˆì§ˆ ìš°ì„  ëª¨ë“œ)")
            results = reader.readtext(
                file_path,
                width_ths=0.5,     # í…ìŠ¤íŠ¸ í­ ì„ê³„ê°’ (ë” ë¯¼ê°í•˜ê²Œ)
                height_ths=0.5,    # í…ìŠ¤íŠ¸ ë†’ì´ ì„ê³„ê°’ (ë” ë¯¼ê°í•˜ê²Œ)
                paragraph=False,   # ë‹¨ë½ ëª¨ë“œ ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)
                detail=1,          # ìƒì„¸ ì •ë³´ í¬í•¨ (bbox, text, confidence)
                batch_size=1,      # ë°°ì¹˜ í¬ê¸° ìµœì†Œí™”
                workers=1,         # ì›Œì»¤ ìˆ˜ ìµœì†Œí™”
                text_threshold=0.4,   # í…ìŠ¤íŠ¸ ê°ì§€ ì„ê³„ê°’ ë‚®ì¶¤ (ë” ë§ì€ í…ìŠ¤íŠ¸ ê°ì§€)
                low_text=0.3,      # ë‚®ì€ í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ì„ê³„ê°’ ë‚®ì¶¤
                link_threshold=0.3, # ë§í¬ ì„ê³„ê°’ ë‚®ì¶¤
                canvas_size=4096,  # ìº”ë²„ìŠ¤ í¬ê¸° ì¦ê°€ (ê³ í•´ìƒë„ ì§€ì›)
                mag_ratio=2.0      # í™•ëŒ€ ë¹„ìœ¨ ì¦ê°€ (ì‘ì€ í…ìŠ¤íŠ¸ ê°ì§€)
            )
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ì²˜ë¦¬
            detected_texts = []
            total_confidence = 0
            
            for bbox, text, confidence in results:
                detected_texts.append({
                    "text": text,
                    "confidence": float(round(confidence, 3)),  # NumPy floatë¥¼ Python floatë¡œ ë³€í™˜
                    "bbox": bbox
                })
                total_confidence += float(confidence)  # NumPy floatë¥¼ Python floatë¡œ ë³€í™˜
            
            avg_confidence = float(total_confidence / len(results)) if results else 0.0
            full_text = ' '.join([item["text"] for item in detected_texts])
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ í–¥ìƒ
            enhanced_text = self._enhance_with_context(full_text, context)
            
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìš”ì•½ ìƒì„±
            summary = self._generate_context_aware_summary(enhanced_text, context)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„ (í–¥ìƒëœ í…ìŠ¤íŠ¸ ê¸°ë°˜)
            jewelry_keywords = self._extract_jewelry_keywords(enhanced_text)
            
            analysis_result = {
                "status": "success",
                "file_name": os.path.basename(file_path),
                "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2)),
                "processing_time": float(round(processing_time, 1)),
                "blocks_detected": int(len(results)),
                "average_confidence": float(round(avg_confidence, 3)),
                "full_text": enhanced_text,
                "original_text": full_text,
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "detailed_results": detected_texts,
                "analysis_type": "real_easyocr",
                "timestamp": datetime.now().isoformat()
            }
            
            self._update_stats(processing_time, True)
            self.logger.info(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return analysis_result
            
        except Exception as e:
            error_msg = f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            self.logger.error(error_msg)
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(file_path, "image", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": os.path.basename(file_path),
                    "analysis_type": "real_easyocr_recovery",
                    "timestamp": datetime.now().isoformat(),
                    "file_size_mb": float(round(os.path.getsize(file_path) / (1024 * 1024), 2))
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(time.time() - start_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(time.time() - start_time, False)
            
            return {
                "status": "error", 
                "error": error_msg,
                "file_name": os.path.basename(file_path),
                "analysis_type": "real_easyocr",
                "timestamp": datetime.now().isoformat()
            }
    
    def _generate_summary(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        if not text or len(text.strip()) < 50:
            return "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # NLP ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì‹œ
        nlp = self._lazy_load_nlp()
        if nlp and len(text) > 100:
            try:
                # ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë¥´ê¸°
                if len(text) > 1024:
                    text = text[:1024]
                
                summary_result = nlp(text, max_length=100, min_length=30, do_sample=False)
                return summary_result[0]['summary_text']
            except Exception as e:
                self.logger.debug(f"NLP ìš”ì•½ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ìš”ì•½ (ì²« 100ì)
        return text[:100] + "..." if len(text) > 100 else text
    
    def _extract_jewelry_keywords(self, text: str) -> List[str]:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return []
        
        jewelry_terms = [
            # ì˜ì–´ ì£¼ì–¼ë¦¬ ìš©ì–´
            "diamond", "gold", "silver", "platinum", "jewelry", "jewellery", 
            "ring", "necklace", "bracelet", "earring", "pendant", "gemstone",
            "ruby", "sapphire", "emerald", "pearl", "crystal", "luxury",
            "carat", "cut", "clarity", "color", "certificate", "GIA",
            
            # í•œêµ­ì–´ ì£¼ì–¼ë¦¬ ìš©ì–´  
            "ë‹¤ì´ì•„ëª¬ë“œ", "ê¸ˆ", "ì€", "ë°±ê¸ˆ", "ì£¼ì–¼ë¦¬", "ë°˜ì§€", "ëª©ê±¸ì´", 
            "íŒ”ì°Œ", "ê·€ê±¸ì´", "íœë˜íŠ¸", "ë³´ì„", "ë£¨ë¹„", "ì‚¬íŒŒì´ì–´", 
            "ì—ë©”ë„ë“œ", "ì§„ì£¼", "í¬ë¦¬ìŠ¤íƒˆ", "ëŸ­ì…”ë¦¬", "ìºëŸ¿", "ì»¤íŒ…",
            "íˆ¬ëª…ë„", "ìƒ‰ìƒ", "ì¸ì¦ì„œ", "ì§€ì•„"
        ]
        
        text_lower = text.lower()
        found_keywords = []
        
        for term in jewelry_terms:
            if term.lower() in text_lower:
                found_keywords.append(term)
        
        return list(set(found_keywords))  # ì¤‘ë³µ ì œê±°
    
    def analyze_document_file(self, file_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ íŒŒì¼ ë¶„ì„ (PDF, DOCX, DOC)"""
        start_time = time.time()
        file_name = os.path.basename(file_path)
        
        try:
            self.logger.info(f"[INFO] ë¬¸ì„œ íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name}")
            
            if not document_processor_available:
                raise Exception("ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. document_processorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            doc_result = document_processor.process_document(file_path)
            
            if doc_result['status'] != 'success':
                if doc_result['status'] == 'partial_success':
                    self.logger.warning(f"[WARNING] ë¬¸ì„œ ë¶€ë¶„ ì²˜ë¦¬: {doc_result.get('warning', '')}")
                else:
                    raise Exception(doc_result.get('error', 'ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨'))
            
            extracted_text = doc_result['extracted_text']
            
            if not extracted_text or len(extracted_text.strip()) < 10:
                raise Exception("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # AI ìš”ì•½ ìƒì„±
            summary = self._generate_summary(extracted_text)
            
            # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            jewelry_keywords = self._extract_jewelry_keywords(extracted_text)
            
            # í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
            quality_score = min(100, len(extracted_text) / 10)  # ê°„ë‹¨í•œ í’ˆì§ˆ ì ìˆ˜
            
            processing_time = time.time() - start_time
            
            result = {
                "status": "success",
                "file_name": file_name,
                "file_path": file_path,
                "file_type": doc_result.get('file_type', 'unknown'),
                "extracted_text": extracted_text,
                "text_length": len(extracted_text),
                "summary": summary,
                "jewelry_keywords": jewelry_keywords,
                "quality_score": round(quality_score, 1),
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat(),
                "document_metadata": doc_result.get('metadata', {}),
                "document_info": {
                    "total_characters": doc_result.get('total_characters', 0),
                    "page_count": doc_result.get('page_count'),
                    "paragraph_count": doc_result.get('paragraph_count')
                }
            }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, True)
            self.logger.info(f"[SUCCESS] ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ë¬¸ì„œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            self.logger.error(f"[ERROR] {error_msg}")
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(file_path, "document", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": file_name,
                    "file_path": file_path,
                    "processing_time": round(processing_time, 2),
                    "timestamp": datetime.now().isoformat(),
                    "analysis_type": "document_recovery"
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(processing_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(processing_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": file_name,
                "file_path": file_path,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
    
    def analyze_youtube_video(self, url: str, language: str = "ko") -> Dict[str, Any]:
        """YouTube ì˜ìƒ ë¶„ì„"""
        start_time = time.time()
        
        try:
            self.logger.info(f"[INFO] YouTube ì˜ìƒ ë¶„ì„ ì‹œì‘: {url}")
            
            if not youtube_processor_available:
                raise Exception("YouTube ì²˜ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. youtube_processorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            if not youtube_processor.is_youtube_url(url):
                raise Exception("ìœ íš¨í•˜ì§€ ì•Šì€ YouTube URLì…ë‹ˆë‹¤.")
            
            # 1. ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            video_info = youtube_processor.get_video_info(url)
            if video_info['status'] != 'success':
                raise Exception(f"ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {video_info.get('error', 'Unknown')}")
            
            # 2. ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            self.logger.info("[INFO] YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            download_result = youtube_processor.download_audio(url)
            
            if download_result['status'] != 'success':
                raise Exception(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result.get('error', 'Unknown')}")
            
            audio_file = download_result['audio_file']
            
            # 3. ì˜¤ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰
            self.logger.info("[INFO] ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...")
            audio_analysis = self.analyze_audio_file(audio_file, language=language)
            
            if audio_analysis['status'] != 'success':
                # ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ë°˜í™˜
                self.logger.warning(f"[WARNING] ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {audio_analysis.get('error', 'Unknown')}")
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ í†µí•©
            result = {
                "status": "success",
                "source_type": "youtube",
                "url": url,
                "video_info": video_info,
                "download_info": {
                    "audio_file": download_result['audio_file'],
                    "file_size_mb": download_result.get('file_size_mb', 0),
                    "download_time": download_result.get('processing_time', 0)
                },
                "audio_analysis": audio_analysis,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
            
            # STT ê²°ê³¼ê°€ ìˆìœ¼ë©´ YouTube íŠ¹í™” ë¶„ì„ ì¶”ê°€
            if audio_analysis.get('status') == 'success' and audio_analysis.get('transcription'):
                # YouTube ì˜ìƒ + STT ê²°ê³¼ í†µí•© ë¶„ì„
                combined_text = f"ì˜ìƒ ì œëª©: {video_info['title']}\n"
                combined_text += f"ì„¤ëª…: {video_info.get('description', '')[:500]}...\n"
                combined_text += f"ìŒì„± ë‚´ìš©: {audio_analysis['transcription']}"
                
                # í†µí•© ìš”ì•½ ìƒì„±
                combined_summary = self._generate_summary(combined_text)
                combined_keywords = self._extract_jewelry_keywords(combined_text)
                
                result["combined_analysis"] = {
                    "integrated_summary": combined_summary,
                    "jewelry_keywords": combined_keywords,
                    "content_type": self._analyze_content_type(video_info, audio_analysis),
                    "engagement_metrics": {
                        "view_count": video_info.get('view_count', 0),
                        "like_count": video_info.get('like_count', 0),
                        "duration": video_info.get('duration_formatted', 'N/A')
                    }
                }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, True)
            self.logger.info(f"[SUCCESS] YouTube ì˜ìƒ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì„ íƒì )
            try:
                if os.path.exists(audio_file):
                    os.unlink(audio_file)
                    self.logger.info("[INFO] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ë¨")
            except:
                pass  # ì •ë¦¬ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"YouTube ì˜ìƒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, False)
            self.logger.error(f"[ERROR] {error_msg}")
            
            return {
                "status": "error",
                "error": error_msg,
                "url": url,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
    
    def _analyze_content_type(self, video_info: Dict, audio_analysis: Dict) -> str:
        """ì½˜í…ì¸  íƒ€ì… ë¶„ì„"""
        title = video_info.get('title', '').lower()
        description = video_info.get('description', '').lower()
        transcription = audio_analysis.get('transcription', '').lower()
        
        # ì£¼ì–¼ë¦¬ ê´€ë ¨ ì½˜í…ì¸  íŒë³„
        jewelry_indicators = [
            'jewelry', 'diamond', 'gold', 'silver', 'ring', 'necklace',
            'ì£¼ì–¼ë¦¬', 'ë‹¤ì´ì•„ëª¬ë“œ', 'ê¸ˆ', 'ì€', 'ë°˜ì§€', 'ëª©ê±¸ì´', 'ë³´ì„'
        ]
        
        combined_text = f"{title} {description} {transcription}"
        
        jewelry_score = sum(1 for indicator in jewelry_indicators if indicator in combined_text)
        
        if jewelry_score >= 3:
            return "jewelry_focused"
        elif jewelry_score >= 1:
            return "jewelry_related"
        else:
            return "general"
    
    def analyze_video_file(self, video_path: str, language: str = "ko") -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ (MOV, MP4, AVI ë“±)"""
        start_time = time.time()
        file_name = os.path.basename(video_path)
        
        try:
            self.logger.info(f"[INFO] ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_name}")
            
            if not large_video_processor_available:
                raise Exception("ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ ì²˜ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. large_video_processorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            # 1. í–¥ìƒëœ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ (MoviePy ê¸°ëŠ¥ í¬í•¨)
            video_info = large_video_processor.get_enhanced_video_info_moviepy(video_path)
            if video_info['status'] not in ['success', 'partial_success']:
                raise Exception(f"ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {video_info.get('error', 'Unknown')}")
            
            # 1.5. í‚¤í”„ë ˆì„ ì¶”ì¶œ (MoviePy ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            keyframes_info = None
            if video_info.get('moviepy_duration') and video_info['file_size_mb'] <= 500:  # 500MB ì´í•˜ë§Œ
                try:
                    self.logger.info("[INFO] í‚¤í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
                    keyframes_result = large_video_processor.extract_keyframes_moviepy(video_path, num_frames=3)
                    if keyframes_result['status'] == 'success':
                        keyframes_info = keyframes_result
                        self.logger.info(f"[SUCCESS] {len(keyframes_result['keyframes'])}ê°œ í‚¤í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"[WARNING] í‚¤í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    keyframes_info = {"error": str(e)}
            
            # 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ (ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ìˆëŠ” ê²½ìš°)
            audio_analysis = None
            audio_file = None
            
            if video_info.get('has_audio', False):
                self.logger.info("[INFO] ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
                
                audio_extract_result = large_video_processor.extract_audio_from_video(video_path)
                
                if audio_extract_result['status'] == 'success':
                    audio_file = audio_extract_result['audio_file']
                    
                    # 3. ì¶”ì¶œëœ ì˜¤ë””ì˜¤ STT ë¶„ì„
                    self.logger.info("[INFO] ì¶”ì¶œëœ ì˜¤ë””ì˜¤ STT ë¶„ì„ ì¤‘...")
                    audio_analysis = self.analyze_audio_file(audio_file, language=language)
                    
                    # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
                    try:
                        if os.path.exists(audio_file):
                            os.unlink(audio_file)
                            self.logger.info("[INFO] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ë¨")
                    except:
                        pass
                
                else:
                    self.logger.warning(f"[WARNING] ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {audio_extract_result.get('error', 'Unknown')}")
                    audio_extract_result = None
            
            else:
                self.logger.info("[INFO] ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ìŒ - STT ë¶„ì„ ìƒëµ")
                audio_extract_result = None
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ í†µí•©
            result = {
                "status": "success",
                "file_name": file_name,
                "file_path": video_path,
                "file_type": "video",
                "video_info": video_info,
                "keyframes_info": keyframes_info,
                "audio_extraction": audio_extract_result,
                "audio_analysis": audio_analysis,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat(),
                "enhanced_features": {
                    "moviepy_analysis": video_info.get('moviepy_duration') is not None,
                    "quality_analysis": video_info.get('video_quality_analysis') is not None,
                    "keyframe_extraction": keyframes_info is not None,
                    "frame_analysis": video_info.get('frame_analysis') is not None
                }
            }
            
            # ë¹„ë””ì˜¤ + ì˜¤ë””ì˜¤ í†µí•© ë¶„ì„
            if audio_analysis and audio_analysis.get('status') == 'success':
                transcription = audio_analysis.get('transcription', '')
                
                if transcription:
                    # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° + STT ê²°ê³¼ í†µí•©
                    combined_text = f"ë¹„ë””ì˜¤ íŒŒì¼: {file_name}\n"
                    
                    if video_info.get('format_name'):
                        combined_text += f"í˜•ì‹: {video_info['format_name']}\n"
                    
                    if video_info.get('duration_formatted'):
                        combined_text += f"ê¸¸ì´: {video_info['duration_formatted']}\n"
                    
                    if video_info.get('video_info', {}).get('quality'):
                        combined_text += f"í™”ì§ˆ: {video_info['video_info']['quality']}\n"
                    
                    combined_text += f"ìŒì„± ë‚´ìš©: {transcription}"
                    
                    # í†µí•© ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
                    summary = self._generate_summary(combined_text)
                    keywords = self._extract_jewelry_keywords(combined_text)
                    
                    result["integrated_analysis"] = {
                        "summary": summary,
                        "jewelry_keywords": keywords,
                        "content_analysis": {
                            "has_speech": True,
                            "speech_duration": video_info.get('duration', 0),
                            "video_quality": video_info.get('video_info', {}).get('quality', 'Unknown'),
                            "file_size_category": self._categorize_file_size(video_info.get('file_size_mb', 0))
                        }
                    }
            
            else:
                # ì˜¤ë””ì˜¤ ì—†ê±°ë‚˜ STT ì‹¤íŒ¨ ì‹œ ë¹„ë””ì˜¤ ì •ë³´ë§Œìœ¼ë¡œ ë¶„ì„
                video_text = f"ë¹„ë””ì˜¤ íŒŒì¼: {file_name} ({video_info.get('format_name', 'Unknown')})"
                
                result["integrated_analysis"] = {
                    "summary": f"ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì™„ë£Œ. ê¸¸ì´: {video_info.get('duration_formatted', 'Unknown')}",
                    "jewelry_keywords": self._extract_jewelry_keywords(video_text),
                    "content_analysis": {
                        "has_speech": False,
                        "video_quality": video_info.get('video_info', {}).get('quality', 'Unknown'),
                        "file_size_category": self._categorize_file_size(video_info.get('file_size_mb', 0))
                    }
                }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, True)
            self.logger.info(f"[SUCCESS] ë¹„ë””ì˜¤ ë¶„ì„ ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ë¹„ë””ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì˜¤ë¥˜ ì‹œì—ë„)
            if 'audio_file' in locals() and audio_file and os.path.exists(audio_file):
                try:
                    os.unlink(audio_file)
                except:
                    pass
            
            self.logger.error(f"[ERROR] {error_msg}")
            
            # ì—ëŸ¬ ë³µêµ¬ ë¶„ì„ ì‹œë„
            recovery_result = self._try_recovery_analysis(video_path, "video", error_msg)
            if recovery_result:
                # ë³µêµ¬ ì„±ê³µì‹œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                recovery_result.update({
                    "file_name": file_name,
                    "file_path": video_path,
                    "processing_time": round(processing_time, 2),
                    "timestamp": datetime.now().isoformat(),
                    "analysis_type": "video_recovery"
                })
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_stats(processing_time, True, partial=True)
                return recovery_result
            
            # ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë˜ ì—ëŸ¬ ë°˜í™˜
            self._update_stats(processing_time, False)
            
            return {
                "status": "error",
                "error": error_msg,
                "file_name": file_name,
                "file_path": video_path,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat()
            }
    
    def _categorize_file_size(self, size_mb: float) -> str:
        """íŒŒì¼ í¬ê¸° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        if size_mb < 10:
            return "small"
        elif size_mb < 100:
            return "medium"
        elif size_mb < 1000:
            return "large"
        else:
            return "very_large"
    
    def _update_stats(self, processing_time: float, success: bool, partial: bool = False):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.analysis_stats["total_files"] += 1
        self.analysis_stats["total_processing_time"] += processing_time
        if success:
            if partial:
                self.analysis_stats["partial_successes"] += 1
            else:
                self.analysis_stats["successful_analyses"] += 1
        else:
            self.analysis_stats["failed_analyses"] += 1
        self.analysis_stats["last_analysis_time"] = datetime.now().isoformat()
    
    def _try_recovery_analysis(self, file_path: str, file_type: str, original_error: str) -> Dict[str, Any]:
        """ì‹¤íŒ¨í•œ ë¶„ì„ì— ëŒ€í•œ ë³µêµ¬ ì‹œë„"""
        if not error_recovery_available:
            return None
        
        try:
            self.logger.info(f"[RECOVERY] ë³µêµ¬ ë¶„ì„ ì‹œë„: {os.path.basename(file_path)}")
            recovery_result = error_recovery_analyzer.recover_failed_analysis(file_path, file_type, original_error)
            
            if recovery_result.get("status") == "partial_success":
                self.logger.info(f"[RECOVERY] ë¶€ë¶„ ë³µêµ¬ ì„±ê³µ: {recovery_result.get('recovery_method', 'unknown')}")
                return recovery_result
            else:
                self.logger.warning(f"[RECOVERY] ë³µêµ¬ ì‹¤íŒ¨: {recovery_result.get('recovery_error', 'unknown')}")
                return None
                
        except Exception as e:
            self.logger.error(f"[RECOVERY] ë³µêµ¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """ë¶„ì„ í†µê³„ ë°˜í™˜"""
        total_files = self.analysis_stats["total_files"]
        if total_files == 0:
            return self.analysis_stats
        
        stats = self.analysis_stats.copy()
        
        # ì „ì²´ ì„±ê³µë¥  (ì™„ì „ ì„±ê³µ + ë¶€ë¶„ ì„±ê³µ)
        total_successes = stats["successful_analyses"] + stats["partial_successes"]
        stats["overall_success_rate"] = round((total_successes / total_files) * 100, 1)
        
        # ì™„ì „ ì„±ê³µë¥ ë§Œ
        stats["full_success_rate"] = round((stats["successful_analyses"] / total_files) * 100, 1)
        
        # ë¶€ë¶„ ì„±ê³µë¥ 
        stats["partial_success_rate"] = round((stats["partial_successes"] / total_files) * 100, 1)
        
        # ì‹¤íŒ¨ìœ¨
        stats["failure_rate"] = round((stats["failed_analyses"] / total_files) * 100, 1)
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„
        stats["average_processing_time"] = round(stats["total_processing_time"] / total_files, 1)
        
        # ë³µêµ¬ íš¨ê³¼ (ë¶€ë¶„ ì„±ê³µì´ ìˆìœ¼ë©´ ë³µêµ¬ ì‹œìŠ¤í…œì´ ì‘ë™í–ˆë‹¤ëŠ” ì˜ë¯¸)
        stats["recovery_effectiveness"] = stats["partial_successes"] > 0
        
        return stats

# ì „ì—­ ë¶„ì„ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
global_analysis_engine = RealAnalysisEngine()

def analyze_file_real(file_path: str, file_type: str, language: str = "auto", context: Dict[str, Any] = None) -> Dict[str, Any]:
    """íŒŒì¼ ì‹¤ì œ ë¶„ì„ (ê°„í¸ ì‚¬ìš©, ì»¨í…ìŠ¤íŠ¸ ì§€ì›)"""
    if file_type == "audio":
        return global_analysis_engine.analyze_audio_file(file_path, language=language, context=context)
    elif file_type == "image":
        return global_analysis_engine.analyze_image_file(file_path, context=context)
    elif file_type == "document":
        return global_analysis_engine.analyze_document_file(file_path)
    elif file_type == "youtube":
        return global_analysis_engine.analyze_youtube_video(file_path, language=language)
    elif file_type == "video":
        return global_analysis_engine.analyze_video_file(file_path, language=language)
    else:
        return {
            "status": "error",
            "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}",
            "file_name": os.path.basename(file_path) if os.path.exists(file_path) else file_path,
            "timestamp": datetime.now().isoformat()
        }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸš€ ì‹¤ì œ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    engine = RealAnalysisEngine()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        ("/mnt/c/Users/PC_58410/Desktop/ê·¼í˜/ì„¸ë¯¸ë‚˜/202506í™ì½©ì‡¼/D1/ìƒˆë¡œìš´ ë…¹ìŒ 2.m4a", "audio"),
        ("/mnt/c/Users/PC_58410/Desktop/ê·¼í˜/ì„¸ë¯¸ë‚˜/202506í™ì½©ì‡¼/D1/IMG_2160.JPG", "image")
    ]
    
    for file_path, file_type in test_files:
        if os.path.exists(file_path):
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸: {os.path.basename(file_path)}")
            result = analyze_file_real(file_path, file_type)
            print(f"ê²°ê³¼: {result.get('status', 'unknown')}")
            if result.get('status') == 'success':
                print(f"ì²˜ë¦¬ì‹œê°„: {result.get('processing_time', 0)}ì´ˆ")
                if 'full_text' in result:
                    text = result['full_text']
                    print(f"ì¶”ì¶œ í…ìŠ¤íŠ¸: {text[:100]}{'...' if len(text) > 100 else ''}")
        else:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
    
    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ë¶„ì„ í†µê³„:")
    stats = engine.get_analysis_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\nâœ… ì‹¤ì œ ë¶„ì„ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")