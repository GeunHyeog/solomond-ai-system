"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ì£¼ì–¼ë¦¬ íŠ¹í™” STT í›„ì²˜ë¦¬ ëª¨ë“ˆ
Jewelry Industry Specialized Speech-to-Text Enhancement Engine
"""

import json
import re
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from difflib import SequenceMatcher

class JewelrySTTEnhancer:
    """ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” STT í›„ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self, terms_db_path: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            terms_db_path: ì£¼ì–¼ë¦¬ ìš©ì–´ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        self.terms_db = None
        self.correction_cache = {}
        
        # ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if terms_db_path is None:
            current_dir = Path(__file__).parent.parent
            terms_db_path = current_dir / "data" / "jewelry_terms.json"
        
        self.load_terms_database(terms_db_path)
        
        # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë¹ ë¥¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶•
        self._build_search_indices()
        
    def load_terms_database(self, file_path: str) -> bool:
        """ì£¼ì–¼ë¦¬ ìš©ì–´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        try:
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    self.terms_db = json.load(f)
                print(f"âœ… ì£¼ì–¼ë¦¬ ìš©ì–´ DB ë¡œë“œ ì„±ê³µ: {file_path}")
                return True
            else:
                print(f"âš ï¸ ìš©ì–´ DB íŒŒì¼ ì—†ìŒ: {file_path}")
                # ê¸°ë³¸ ìš©ì–´ ì‚¬ì „ ìƒì„±
                self.terms_db = self._create_minimal_terms_db()
                return False
        except Exception as e:
            print(f"âŒ ìš©ì–´ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.terms_db = self._create_minimal_terms_db()
            return False
    
    def _create_minimal_terms_db(self) -> Dict:
        """ìµœì†Œí•œì˜ ìš©ì–´ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
        return {
            "jewelry_terms_db": {
                "version": "1.0-minimal",
                "common_corrections": {
                    "pronunciation_fixes": {
                        "ë‹¤ì´ëª¬ë“œ": "ë‹¤ì´ì•„ëª¬ë“œ",
                        "ë””ì•„ëª¬ë“œ": "ë‹¤ì´ì•„ëª¬ë“œ",
                        "ìƒˆíŒŒì´ì–´": "ì‚¬íŒŒì´ì–´",
                        "ì—ë¨¸ë„ë“œ": "ì—ë©”ë„ë“œ",
                        "ìºëŸ¿": "ìºëŸ¿",
                        "ì§€ì•„ì´ì—ì´": "GIA",
                        "í¬ì”¨": "4C"
                    }
                }
            }
        }
    
    def _build_search_indices(self):
        """ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.all_terms = []
        self.correction_map = {}
        
        if not self.terms_db or "jewelry_terms_db" not in self.terms_db:
            return
        
        db = self.terms_db["jewelry_terms_db"]
        
        # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ìš©ì–´ ìˆ˜ì§‘
        categories = ["precious_stones", "grading_4c", "grading_institutes", 
                     "business_terms", "technical_terms", "market_analysis", "education_terms"]
        
        for category in categories:
            if category in db:
                self._extract_terms_from_category(db[category])
        
        # ì¼ë°˜ì ì¸ ìˆ˜ì •ì‚¬í•­ ì¶”ê°€
        if "common_corrections" in db:
            corrections = db["common_corrections"]
            if "pronunciation_fixes" in corrections:
                self.correction_map.update(corrections["pronunciation_fixes"])
            if "common_mistakes" in corrections:
                self.correction_map.update(corrections["common_mistakes"])
        
        print(f"ğŸ“š ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.all_terms)}ê°œ ìš©ì–´, {len(self.correction_map)}ê°œ ìˆ˜ì •ì‚¬í•­")
    
    def _extract_terms_from_category(self, category_data: Dict):
        """ì¹´í…Œê³ ë¦¬ì—ì„œ ëª¨ë“  ìš©ì–´ ì¶”ì¶œ"""
        if isinstance(category_data, dict):
            for key, value in category_data.items():
                if isinstance(value, dict):
                    # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
                    for lang in ["korean", "english", "chinese"]:
                        if lang in value and isinstance(value[lang], list):
                            self.all_terms.extend(value[lang])
                    
                    # ì˜ëª»ëœ ë°œìŒ ìˆ˜ì •
                    if "common_mistakes" in value and isinstance(value["common_mistakes"], list):
                        correct_term = value.get("korean", [])
                        if correct_term and isinstance(correct_term, list):
                            for mistake in value["common_mistakes"]:
                                self.correction_map[mistake] = correct_term[0]
                    
                    # ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ ë°ì´í„° ì²˜ë¦¬
                    self._extract_terms_from_category(value)
                elif isinstance(value, list):
                    self.all_terms.extend(value)
    
    def enhance_transcription(self, transcribed_text: str, 
                            detected_language: str = "ko",
                            confidence_threshold: float = 0.7) -> Dict:
        """
        STT ê²°ê³¼ë¥¼ ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™”ë¡œ ê°œì„ 
        
        Args:
            transcribed_text: ì›ë³¸ STT ê²°ê³¼
            detected_language: ê°ì§€ëœ ì–¸ì–´
            confidence_threshold: ìˆ˜ì • ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            ê°œì„ ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not transcribed_text.strip():
            return {
                "original_text": transcribed_text,
                "enhanced_text": transcribed_text,
                "corrections": [],
                "detected_terms": [],
                "confidence": 1.0
            }
        
        enhanced_text = transcribed_text
        corrections = []
        detected_terms = []
        
        # 1. ì§ì ‘ì ì¸ ìš©ì–´ ìˆ˜ì •
        enhanced_text, direct_corrections = self._apply_direct_corrections(enhanced_text)
        corrections.extend(direct_corrections)
        
        # 2. í¼ì§€ ë§¤ì¹­ì„ í†µí•œ ìœ ì‚¬ ìš©ì–´ ìˆ˜ì •
        enhanced_text, fuzzy_corrections = self._apply_fuzzy_corrections(
            enhanced_text, confidence_threshold
        )
        corrections.extend(fuzzy_corrections)
        
        # 3. ì£¼ì–¼ë¦¬ ìš©ì–´ ì‹ë³„
        detected_terms = self._detect_jewelry_terms(enhanced_text)
        
        # 4. ë¬¸ë§¥ ê¸°ë°˜ ê°œì„ 
        enhanced_text, context_corrections = self._apply_context_corrections(enhanced_text)
        corrections.extend(context_corrections)
        
        # 5. ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_enhancement_confidence(
            transcribed_text, enhanced_text, corrections
        )
        
        return {
            "original_text": transcribed_text,
            "enhanced_text": enhanced_text,
            "corrections": corrections,
            "detected_terms": detected_terms,
            "confidence": confidence,
            "language": detected_language,
            "terms_count": len(detected_terms),
            "corrections_count": len(corrections)
        }
    
    def _apply_direct_corrections(self, text: str) -> Tuple[str, List[Dict]]:
        """ì§ì ‘ì ì¸ ìš©ì–´ ìˆ˜ì • ì ìš©"""
        corrections = []
        enhanced_text = text
        
        for wrong_term, correct_term in self.correction_map.items():
            if wrong_term in enhanced_text:
                enhanced_text = enhanced_text.replace(wrong_term, correct_term)
                corrections.append({
                    "type": "direct_correction",
                    "original": wrong_term,
                    "corrected": correct_term,
                    "confidence": 0.95
                })
        
        return enhanced_text, corrections
    
    def _apply_fuzzy_corrections(self, text: str, threshold: float) -> Tuple[str, List[Dict]]:
        """í¼ì§€ ë§¤ì¹­ì„ í†µí•œ ìœ ì‚¬ ìš©ì–´ ìˆ˜ì •"""
        corrections = []
        words = text.split()
        enhanced_words = []
        
        for word in words:
            # ì •í™•í•œ ë§¤ì¹˜ í™•ì¸
            if word in self.all_terms:
                enhanced_words.append(word)
                continue
            
            # í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ ìœ ì‚¬í•œ ìš©ì–´ ì°¾ê¸°
            best_match, similarity = self._find_best_fuzzy_match(word, threshold)
            
            if best_match and similarity >= threshold:
                enhanced_words.append(best_match)
                corrections.append({
                    "type": "fuzzy_correction", 
                    "original": word,
                    "corrected": best_match,
                    "confidence": similarity
                })
            else:
                enhanced_words.append(word)
        
        return " ".join(enhanced_words), corrections
    
    def _find_best_fuzzy_match(self, word: str, threshold: float) -> Tuple[Optional[str], float]:
        """ê°€ì¥ ìœ ì‚¬í•œ ìš©ì–´ ì°¾ê¸°"""
        best_match = None
        best_similarity = 0.0
        
        for term in self.all_terms:
            if isinstance(term, str) and len(term) > 1:
                similarity = SequenceMatcher(None, word.lower(), term.lower()).ratio()
                
                # ê¸¸ì´ ì°¨ì´ê°€ ë„ˆë¬´ í¬ë©´ íŒ¨ìŠ¤
                if abs(len(word) - len(term)) > max(len(word), len(term)) * 0.5:
                    continue
                
                if similarity > best_similarity and similarity >= threshold:
                    best_similarity = similarity
                    best_match = term
        
        return best_match, best_similarity
    
    def _detect_jewelry_terms(self, text: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì–¼ë¦¬ ìš©ì–´ ì‹ë³„"""
        detected_terms = []
        text_lower = text.lower()
        
        for term in self.all_terms:
            if isinstance(term, str) and term.lower() in text_lower:
                # ìš©ì–´ ì¹´í…Œê³ ë¦¬ ì‹ë³„
                category = self._identify_term_category(term)
                detected_terms.append({
                    "term": term,
                    "category": category,
                    "position": text_lower.find(term.lower())
                })
        
        # ìœ„ì¹˜ìˆœìœ¼ë¡œ ì •ë ¬
        detected_terms.sort(key=lambda x: x["position"])
        return detected_terms
    
    def _identify_term_category(self, term: str) -> str:
        """ìš©ì–´ì˜ ì¹´í…Œê³ ë¦¬ ì‹ë³„"""
        if not self.terms_db or "jewelry_terms_db" not in self.terms_db:
            return "unknown"
        
        db = self.terms_db["jewelry_terms_db"]
        
        # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìš©ì–´ ê²€ìƒ‰
        category_map = {
            "precious_stones": "ë³´ì„",
            "grading_4c": "ë“±ê¸‰",
            "grading_institutes": "ê°ì •ê¸°ê´€",
            "business_terms": "ë¹„ì¦ˆë‹ˆìŠ¤",
            "technical_terms": "ê¸°ìˆ ",
            "market_analysis": "ì‹œì¥ë¶„ì„",
            "education_terms": "êµìœ¡"
        }
        
        for category_key, category_name in category_map.items():
            if self._term_in_category(term, db.get(category_key, {})):
                return category_name
        
        return "ê¸°íƒ€"
    
    def _term_in_category(self, term: str, category_data: Dict) -> bool:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì— ìš©ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        term_lower = term.lower()
        
        def search_recursive(data):
            if isinstance(data, dict):
                for key, value in data.items():
                    if key in ["korean", "english", "chinese"] and isinstance(value, list):
                        if any(term_lower == t.lower() for t in value if isinstance(t, str)):
                            return True
                    elif isinstance(value, (dict, list)):
                        if search_recursive(value):
                            return True
            elif isinstance(data, list):
                for item in data:
                    if isinstance(item, str) and term_lower == item.lower():
                        return True
                    elif isinstance(item, dict) and search_recursive(item):
                        return True
            return False
        
        return search_recursive(category_data)
    
    def _apply_context_corrections(self, text: str) -> Tuple[str, List[Dict]]:
        """ë¬¸ë§¥ ê¸°ë°˜ ìš©ì–´ ìˆ˜ì •"""
        corrections = []
        enhanced_text = text
        
        # ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” ë¬¸ë§¥ íŒ¨í„´
        context_patterns = [
            (r'(\d+)\s*c', r'\1ìºëŸ¿', "ë¬´ê²Œ ë‹¨ìœ„ ì •ê·œí™”"),
            (r'(\d+)\s*k(?!\w)', r'\1K', "ê¸ˆ ìˆœë„ ì •ê·œí™”"),
            (r'pt\s*(\d+)', r'PT\1', "í”Œë˜í‹°ë„˜ ìˆœë„ ì •ê·œí™”"),
            (r'vs\s*(\d+)', r'VS\1', "ë‹¤ì´ì•„ëª¬ë“œ ë“±ê¸‰ ì •ê·œí™”"),
            (r'vvs\s*(\d+)', r'VVS\1', "ë‹¤ì´ì•„ëª¬ë“œ ë“±ê¸‰ ì •ê·œí™”"),
            (r'ì§€ì•„ì´ì—ì´', r'GIA', "ê°ì •ê¸°ê´€ëª… ì •ê·œí™”"),
            (r'ì—ì´ì§€ì—ìŠ¤', r'AGS', "ê°ì •ê¸°ê´€ëª… ì •ê·œí™”")
        ]
        
        for pattern, replacement, description in context_patterns:
            original_text = enhanced_text
            enhanced_text = re.sub(pattern, replacement, enhanced_text, flags=re.IGNORECASE)
            
            if original_text != enhanced_text:
                corrections.append({
                    "type": "context_correction",
                    "description": description,
                    "pattern": pattern,
                    "confidence": 0.9
                })
        
        return enhanced_text, corrections
    
    def _calculate_enhancement_confidence(self, original: str, enhanced: str, corrections: List[Dict]) -> float:
        """ê°œì„  ì‹ ë¢°ë„ ê³„ì‚°"""
        if original == enhanced:
            return 1.0
        
        # ìˆ˜ì •ì‚¬í•­ì˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        if corrections:
            avg_confidence = sum(c.get("confidence", 0.7) for c in corrections) / len(corrections)
            return avg_confidence
        
        return 0.8  # ê¸°ë³¸ ì‹ ë¢°ë„
    
    def analyze_jewelry_content(self, enhanced_result: Dict) -> Dict:
        """ì£¼ì–¼ë¦¬ ì½˜í…ì¸  ì‹¬ì¸µ ë¶„ì„"""
        text = enhanced_result.get("enhanced_text", "")
        detected_terms = enhanced_result.get("detected_terms", [])
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìš©ì–´ ë¶„ì„
        category_analysis = {}
        for term_info in detected_terms:
            category = term_info["category"]
            if category not in category_analysis:
                category_analysis[category] = []
            category_analysis[category].append(term_info["term"])
        
        # ì£¼ì œ ì‹ë³„
        topics = self._identify_topics(text, detected_terms)
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        insights = self._extract_business_insights(text, detected_terms)
        
        return {
            "category_analysis": category_analysis,
            "identified_topics": topics,
            "business_insights": insights,
            "technical_level": self._assess_technical_level(detected_terms),
            "language_complexity": self._assess_language_complexity(text)
        }
    
    def _identify_topics(self, text: str, detected_terms: List[Dict]) -> List[str]:
        """ì£¼ìš” ì£¼ì œ ì‹ë³„"""
        topics = []
        
        # ì£¼ì œë³„ í‚¤ì›Œë“œ ë§¤í•‘
        topic_keywords = {
            "ë‹¤ì´ì•„ëª¬ë“œ ë“±ê¸‰í‰ê°€": ["4C", "ìºëŸ¿", "ì»·", "ì»¬ëŸ¬", "í´ë˜ë¦¬í‹°", "GIA"],
            "ë³´ì„ ê±°ë˜": ["ë„ë§¤ê°€", "ì†Œë§¤ê°€", "í• ì¸", "ì¬ê³ ", "ì£¼ë¬¸"],
            "ì œí’ˆ ê¸°ìˆ ": ["ì„¸íŒ…", "ê°€ê³µ", "ì—°ë§ˆ", "í‘œë©´ì²˜ë¦¬"],
            "ì‹œì¥ ë¶„ì„": ["íŠ¸ë Œë“œ", "ìœ í–‰", "ì¸ê¸°", "ì‹œì¥"],
            "ê³ ê° ìƒë‹´": ["ì¶”ì²œ", "ìƒë‹´", "ì„ íƒ", "êµ¬ë§¤"],
            "êµ­ì œ ë¬´ì—­": ["FOB", "ìˆ˜ì¶œ", "ìˆ˜ì…", "í†µê´€", "ê´€ì„¸"]
        }
        
        text_lower = text.lower()
        for topic, keywords in topic_keywords.items():
            keyword_count = sum(1 for keyword in keywords if keyword.lower() in text_lower)
            if keyword_count >= 2:  # 2ê°œ ì´ìƒì˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì£¼ì œë¡œ ì¸ì‹
                topics.append(topic)
        
        return topics
    
    def _extract_business_insights(self, text: str, detected_terms: List[Dict]) -> List[str]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # ê°€ê²© ê´€ë ¨ ì–¸ê¸‰
        if any(term["category"] == "ë¹„ì¦ˆë‹ˆìŠ¤" for term in detected_terms):
            if "í• ì¸" in text or "ì„¸ì¼" in text:
                insights.append("ê°€ê²© í• ì¸ ì´ë²¤íŠ¸ ê´€ë ¨ ë…¼ì˜")
            if "ì¬ê³ " in text:
                insights.append("ì¬ê³  ê´€ë¦¬ ê´€ë ¨ ë…¼ì˜")
        
        # í’ˆì§ˆ ê´€ë ¨ ì–¸ê¸‰
        if any(term["category"] == "ë“±ê¸‰" for term in detected_terms):
            insights.append("í’ˆì§ˆ ë“±ê¸‰ ë° í‰ê°€ ê¸°ì¤€ ë…¼ì˜")
        
        # ê¸°ìˆ  ê´€ë ¨ ì–¸ê¸‰
        if any(term["category"] == "ê¸°ìˆ " for term in detected_terms):
            insights.append("ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ë° ì œì¡° ê³¼ì • ë…¼ì˜")
        
        return insights
    
    def _assess_technical_level(self, detected_terms: List[Dict]) -> str:
        """ê¸°ìˆ ì  ë³µì¡ë„ í‰ê°€"""
        technical_terms = [t for t in detected_terms if t["category"] in ["ë“±ê¸‰", "ê¸°ìˆ ", "ê°ì •ê¸°ê´€"]]
        
        if len(technical_terms) >= 5:
            return "ê³ ê¸‰"
        elif len(technical_terms) >= 2:
            return "ì¤‘ê¸‰"
        else:
            return "ì´ˆê¸‰"
    
    def _assess_language_complexity(self, text: str) -> str:
        """ì–¸ì–´ ë³µì¡ë„ í‰ê°€"""
        sentences = text.split('.')
        avg_sentence_length = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)
        
        if avg_sentence_length > 15:
            return "ë³µì¡"
        elif avg_sentence_length > 8:
            return "ë³´í†µ"
        else:
            return "ë‹¨ìˆœ"
    
    def generate_jewelry_summary(self, enhanced_result: Dict, analysis: Dict) -> str:
        """ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” ìš”ì•½ ìƒì„±"""
        text = enhanced_result.get("enhanced_text", "")
        topics = analysis.get("identified_topics", [])
        category_analysis = analysis.get("category_analysis", {})
        
        summary_parts = []
        
        # ì£¼ìš” ì£¼ì œ
        if topics:
            summary_parts.append(f"ğŸ¯ ì£¼ìš” ì£¼ì œ: {', '.join(topics)}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìš©ì–´
        for category, terms in category_analysis.items():
            if terms:
                unique_terms = list(set(terms))
                summary_parts.append(f"ğŸ“š {category}: {', '.join(unique_terms[:3])}")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
        insights = analysis.get("business_insights", [])
        if insights:
            summary_parts.append(f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸: {insights[0]}")
        
        # ìš”ì•½ë¬¸ ìƒì„±
        if summary_parts:
            return "\\n".join(summary_parts)
        else:
            return "ì£¼ì–¼ë¦¬ ê´€ë ¨ ì¼ë°˜ì ì¸ ë…¼ì˜ê°€ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    def get_enhancement_stats(self) -> Dict:
        """ê°œì„  ì—”ì§„ í†µê³„ ì •ë³´"""
        return {
            "terms_database_version": self.terms_db.get("jewelry_terms_db", {}).get("version", "unknown"),
            "total_terms": len(self.all_terms),
            "correction_rules": len(self.correction_map),
            "categories": ["ë³´ì„", "ë“±ê¸‰", "ê°ì •ê¸°ê´€", "ë¹„ì¦ˆë‹ˆìŠ¤", "ê¸°ìˆ ", "ì‹œì¥ë¶„ì„", "êµìœ¡"],
            "supported_languages": ["í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´"],
            "features": [
                "ì§ì ‘ ìš©ì–´ ìˆ˜ì •",
                "í¼ì§€ ë§¤ì¹­ ìˆ˜ì •", 
                "ë¬¸ë§¥ ê¸°ë°˜ ì •ê·œí™”",
                "ì£¼ì–¼ë¦¬ ìš©ì–´ ì‹ë³„",
                "ì£¼ì œ ë¶„ì„",
                "ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ",
                "ì—…ê³„ íŠ¹í™” ìš”ì•½"
            ]
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_jewelry_enhancer_instance = None

def get_jewelry_enhancer() -> JewelrySTTEnhancer:
    """ì „ì—­ ì£¼ì–¼ë¦¬ STT ê°œì„  ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _jewelry_enhancer_instance
    if _jewelry_enhancer_instance is None:
        _jewelry_enhancer_instance = JewelrySTTEnhancer()
    return _jewelry_enhancer_instance

def enhance_jewelry_transcription(transcribed_text: str, 
                                detected_language: str = "ko",
                                include_analysis: bool = True) -> Dict:
    """ì£¼ì–¼ë¦¬ íŠ¹í™” STT ê²°ê³¼ ê°œì„  (í¸ì˜ í•¨ìˆ˜)"""
    enhancer = get_jewelry_enhancer()
    
    # ê¸°ë³¸ ê°œì„ 
    enhanced_result = enhancer.enhance_transcription(transcribed_text, detected_language)
    
    # ì‹¬ì¸µ ë¶„ì„ ì¶”ê°€
    if include_analysis:
        analysis = enhancer.analyze_jewelry_content(enhanced_result)
        enhanced_result["analysis"] = analysis
        enhanced_result["summary"] = enhancer.generate_jewelry_summary(enhanced_result, analysis)
    
    return enhanced_result
