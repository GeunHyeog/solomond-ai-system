"""
ğŸ™ï¸ Audio Quality Checker v2.1
ìŒì„± í’ˆì§ˆ ì‹¤ì‹œê°„ ë¶„ì„ ë° í˜„ì¥ ìµœì í™” ëª¨ë“ˆ

ì£¼ìš” ê¸°ëŠ¥:
- SNR (Signal-to-Noise Ratio) ì‹¤ì‹œê°„ ì¸¡ì • 
- ë°°ê²½ ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„
- ìŒì„± ëª…ë£Œë„ ì ìˆ˜ ê³„ì‚°
- í˜„ì¥ ë…¹ìŒ í’ˆì§ˆ ì¦‰ì‹œ ê²€ì¦
- ì¬ë…¹ìŒ ê¶Œì¥ ì•Œê³ ë¦¬ì¦˜
"""

import numpy as np
import librosa
import scipy.signal
from typing import Dict, List, Tuple, Optional
import logging
import warnings
warnings.filterwarnings("ignore")

class AudioQualityChecker:
    """ìŒì„± í’ˆì§ˆ ì‹¤ì‹œê°„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # í’ˆì§ˆ ê¸°ì¤€ê°’ (dB)
        self.quality_thresholds = {
            'snr_excellent': 25.0,    # SNR 25dB ì´ìƒ = ìš°ìˆ˜
            'snr_good': 20.0,         # SNR 20-25dB = ì–‘í˜¸  
            'snr_fair': 15.0,         # SNR 15-20dB = ë³´í†µ
            'snr_poor': 10.0,         # SNR 10dB ë¯¸ë§Œ = ë¶ˆëŸ‰
            
            'noise_low': -40.0,       # ë…¸ì´ì¦ˆ -40dB ì´í•˜ = ë‚®ìŒ
            'noise_medium': -30.0,    # ë…¸ì´ì¦ˆ -30~-40dB = ë³´í†µ
            'noise_high': -20.0,      # ë…¸ì´ì¦ˆ -20dB ì´ìƒ = ë†’ìŒ
            
            'clarity_excellent': 0.9, # ëª…ë£Œë„ 90% ì´ìƒ = ìš°ìˆ˜
            'clarity_good': 0.8,      # ëª…ë£Œë„ 80-90% = ì–‘í˜¸
            'clarity_fair': 0.7,      # ëª…ë£Œë„ 70-80% = ë³´í†µ
        }
        
        # ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” í‚¤ì›Œë“œ (ëª…ë£Œë„ ì¸¡ì •ìš©)
        self.jewelry_keywords = [
            'diamond', 'gold', 'silver', 'platinum', 'gemstone',
            'carat', 'cut', 'clarity', 'color', 'certificate',
            'ë‹¤ì´ì•„ëª¬ë“œ', 'ê¸ˆ', 'ì€', 'ë°±ê¸ˆ', 'ë³´ì„',
            'ìºëŸ¿', 'ì»·', 'íˆ¬ëª…ë„', 'ìƒ‰ìƒ', 'ê°ì •ì„œ'
        ]

    def analyze_audio_quality(self, 
                            audio_path: str = None, 
                            audio_data: np.ndarray = None, 
                            sr: int = 22050) -> Dict:
        """
        ìŒì„± í’ˆì§ˆ ì¢…í•© ë¶„ì„
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            Dict: í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        """
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            if audio_data is None:
                if audio_path is None:
                    raise ValueError("audio_path ë˜ëŠ” audio_data ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")
                audio_data, sr = librosa.load(audio_path, sr=sr)
            
            # ê¸°ë³¸ ë¶„ì„
            results = {
                'timestamp': self._get_timestamp(),
                'duration': len(audio_data) / sr,
                'sample_rate': sr,
                'file_path': audio_path or 'real_time_data'
            }
            
            # SNR ë¶„ì„
            snr_result = self.calculate_snr(audio_data, sr)
            results.update(snr_result)
            
            # ë…¸ì´ì¦ˆ ë¶„ì„  
            noise_result = self.analyze_background_noise(audio_data, sr)
            results.update(noise_result)
            
            # ëª…ë£Œë„ ë¶„ì„
            clarity_result = self.calculate_speech_clarity(audio_data, sr)
            results.update(clarity_result)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            overall_score = self.calculate_overall_quality_score(results)
            results['overall_quality'] = overall_score
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self.generate_recommendations(results)
            results['recommendations'] = recommendations
            
            return results
            
        except Exception as e:
            self.logger.error(f"ìŒì„± í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                'error': str(e),
                'overall_quality': {'score': 0, 'level': 'error'}
            }

    def calculate_snr(self, audio_data: np.ndarray, sr: int) -> Dict:
        """SNR (Signal-to-Noise Ratio) ê³„ì‚°"""
        try:
            # ìŒì„± êµ¬ê°„ê³¼ ë¬´ìŒ êµ¬ê°„ ë¶„ë¦¬
            voice_segments, silence_segments = self._detect_voice_silence(audio_data, sr)
            
            if len(voice_segments) == 0 or len(silence_segments) == 0:
                return {
                    'snr_db': 0.0,
                    'snr_level': 'unknown',
                    'signal_power': 0.0,
                    'noise_power': 0.0
                }
            
            # ì‹ í˜¸ íŒŒì›Œ ê³„ì‚° (ìŒì„± êµ¬ê°„)
            signal_power = np.mean([np.mean(segment**2) for segment in voice_segments])
            
            # ë…¸ì´ì¦ˆ íŒŒì›Œ ê³„ì‚° (ë¬´ìŒ êµ¬ê°„)
            noise_power = np.mean([np.mean(segment**2) for segment in silence_segments])
            
            # SNR ê³„ì‚° (dB)
            if noise_power > 0:
                snr_db = 10 * np.log10(signal_power / noise_power)
            else:
                snr_db = 60.0  # ë…¸ì´ì¦ˆê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš°
            
            # SNR ë“±ê¸‰ ë¶„ë¥˜
            snr_level = self._classify_snr_level(snr_db)
            
            return {
                'snr_db': round(snr_db, 1),
                'snr_level': snr_level,
                'signal_power': float(signal_power),
                'noise_power': float(noise_power)
            }
            
        except Exception as e:
            self.logger.error(f"SNR ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return {
                'snr_db': 0.0,
                'snr_level': 'error',
                'signal_power': 0.0,
                'noise_power': 0.0
            }

    def analyze_background_noise(self, audio_data: np.ndarray, sr: int) -> Dict:
        """ë°°ê²½ ë…¸ì´ì¦ˆ ë¶„ì„"""
        try:
            # ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
            stft = librosa.stft(audio_data)
            magnitude = np.abs(stft)
            
            # ë…¸ì´ì¦ˆ í”„ë¡œíŒŒì¼ ì¶”ì¶œ (ì €ì£¼íŒŒ + ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ)
            low_freq_noise = np.mean(magnitude[:10, :])    # ì €ì£¼íŒŒ (0-1kHz)
            mid_freq_noise = np.mean(magnitude[10:50, :])  # ì¤‘ì£¼íŒŒ (1-5kHz)
            high_freq_noise = np.mean(magnitude[50:, :])   # ê³ ì£¼íŒŒ (5kHz+)
            
            # ì „ì²´ ë…¸ì´ì¦ˆ ë ˆë²¨
            total_noise_db = 20 * np.log10(np.mean(magnitude) + 1e-10)
            
            # ë…¸ì´ì¦ˆ ìœ í˜• ë¶„ì„
            noise_types = self._analyze_noise_types(audio_data, sr)
            
            # ë…¸ì´ì¦ˆ ë“±ê¸‰ ë¶„ë¥˜
            noise_level = self._classify_noise_level(total_noise_db)
            
            return {
                'noise_db': round(total_noise_db, 1),
                'noise_level': noise_level,
                'low_freq_noise': float(low_freq_noise),
                'mid_freq_noise': float(mid_freq_noise),
                'high_freq_noise': float(high_freq_noise),
                'noise_types': noise_types
            }
            
        except Exception as e:
            self.logger.error(f"ë…¸ì´ì¦ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                'noise_db': 0.0,
                'noise_level': 'error',
                'noise_types': []
            }

    def calculate_speech_clarity(self, audio_data: np.ndarray, sr: int) -> Dict:
        """ìŒì„± ëª…ë£Œë„ ê³„ì‚°"""
        try:
            # ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            features = self._extract_speech_features(audio_data, sr)
            
            # ì£¼íŒŒìˆ˜ ë¶„í¬ ë¶„ì„ (ìŒì„± ëŒ€ì—­ ì§‘ì¤‘ë„)
            speech_band_energy = self._calculate_speech_band_energy(audio_data, sr)
            
            # ìŒì„± ì¼ê´€ì„± ë¶„ì„
            consistency_score = self._calculate_speech_consistency(audio_data, sr)
            
            # ì „ì²´ ëª…ë£Œë„ ì ìˆ˜ ê³„ì‚°
            clarity_score = (
                features['spectral_centroid_score'] * 0.3 +
                features['zero_crossing_score'] * 0.2 +
                speech_band_energy * 0.3 +
                consistency_score * 0.2
            )
            
            # ëª…ë£Œë„ ë“±ê¸‰ ë¶„ë¥˜
            clarity_level = self._classify_clarity_level(clarity_score)
            
            return {
                'clarity_score': round(clarity_score, 3),
                'clarity_level': clarity_level,
                'clarity_percentage': round(clarity_score * 100, 1),
                'speech_features': features,
                'speech_band_energy': round(speech_band_energy, 3),
                'consistency_score': round(consistency_score, 3)
            }
            
        except Exception as e:
            self.logger.error(f"ëª…ë£Œë„ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return {
                'clarity_score': 0.0,
                'clarity_level': 'error',
                'clarity_percentage': 0.0
            }

    def calculate_overall_quality_score(self, results: Dict) -> Dict:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°€ì¤‘ì¹˜ ì„¤ì •
            weights = {
                'snr': 0.4,        # SNR 40%
                'noise': 0.3,      # ë…¸ì´ì¦ˆ 30%
                'clarity': 0.3     # ëª…ë£Œë„ 30%
            }
            
            # ê°œë³„ ì ìˆ˜ ì •ê·œí™” (0-1)
            snr_normalized = self._normalize_snr_score(results.get('snr_db', 0))
            noise_normalized = self._normalize_noise_score(results.get('noise_db', 0))
            clarity_normalized = results.get('clarity_score', 0)
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            overall_score = (
                snr_normalized * weights['snr'] +
                noise_normalized * weights['noise'] +
                clarity_normalized * weights['clarity']
            )
            
            # ë“±ê¸‰ ë¶„ë¥˜
            if overall_score >= 0.9:
                level = 'excellent'
                status = 'ìš°ìˆ˜'
                color = 'ğŸŸ¢'
            elif overall_score >= 0.8:
                level = 'good'  
                status = 'ì–‘í˜¸'
                color = 'ğŸŸ¡'
            elif overall_score >= 0.7:
                level = 'fair'
                status = 'ë³´í†µ'
                color = 'ğŸŸ '
            else:
                level = 'poor'
                status = 'ë¶ˆëŸ‰'
                color = 'ğŸ”´'
            
            return {
                'score': round(overall_score, 3),
                'percentage': round(overall_score * 100, 1),
                'level': level,
                'status': status,
                'color': color,
                'components': {
                    'snr_score': round(snr_normalized, 3),
                    'noise_score': round(noise_normalized, 3),
                    'clarity_score': round(clarity_normalized, 3)
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return {
                'score': 0.0,
                'level': 'error',
                'status': 'ì˜¤ë¥˜'
            }

    def generate_recommendations(self, results: Dict) -> List[Dict]:
        """í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            overall_quality = results.get('overall_quality', {})
            snr_db = results.get('snr_db', 0)
            noise_db = results.get('noise_db', 0)
            clarity_score = results.get('clarity_score', 0)
            
            # SNR ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if snr_db < self.quality_thresholds['snr_poor']:
                recommendations.append({
                    'type': 'critical',
                    'icon': 'ğŸ”´',
                    'title': 'SNR ë§¤ìš° ë‚®ìŒ',
                    'message': 'ë§ˆì´í¬ë¥¼ ì…ì— ë” ê°€ê¹Œì´ í•˜ê±°ë‚˜ ì¡°ìš©í•œ ê³³ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”',
                    'action': 'move_closer_or_quiet_place'
                })
            elif snr_db < self.quality_thresholds['snr_fair']:
                recommendations.append({
                    'type': 'warning',
                    'icon': 'ğŸŸ¡',
                    'title': 'SNR ê°œì„  í•„ìš”',
                    'message': 'ë§í•˜ëŠ” ì†Œë¦¬ë¥¼ ì¡°ê¸ˆ ë” í¬ê²Œ í•˜ê±°ë‚˜ ë°°ê²½ìŒì„ ì¤„ì—¬ë³´ì„¸ìš”',
                    'action': 'speak_louder_or_reduce_background'
                })
            
            # ë…¸ì´ì¦ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­  
            if noise_db > self.quality_thresholds['noise_high']:
                recommendations.append({
                    'type': 'critical',
                    'icon': 'ğŸ”´',
                    'title': 'ë°°ê²½ ë…¸ì´ì¦ˆ ë†’ìŒ',
                    'message': 'ì—ì–´ì»¨, íŒ¬ ë“±ì„ ë„ê±°ë‚˜ ë” ì¡°ìš©í•œ ì¥ì†Œë¡œ ì´ë™í•˜ì„¸ìš”',
                    'action': 'reduce_background_noise'
                })
            elif noise_db > self.quality_thresholds['noise_medium']:
                recommendations.append({
                    'type': 'warning',
                    'icon': 'ğŸŸ ',
                    'title': 'ë°°ê²½ ë…¸ì´ì¦ˆ ë³´í†µ',
                    'message': 'ê°€ëŠ¥í•˜ë©´ ì¡°ìš©í•œ í™˜ê²½ì—ì„œ ë…¹ìŒí•´ë³´ì„¸ìš”',
                    'action': 'find_quieter_environment'
                })
            
            # ëª…ë£Œë„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if clarity_score < self.quality_thresholds['clarity_fair']:
                recommendations.append({
                    'type': 'warning',
                    'icon': 'ğŸŸ ',
                    'title': 'ìŒì„± ëª…ë£Œë„ ë‚®ìŒ',
                    'message': 'ë” ë˜ë ·í•˜ê²Œ ë°œìŒí•˜ê³  ì ë‹¹í•œ ì†ë„ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”',
                    'action': 'speak_more_clearly'
                })
            
            # ì „ì²´ í’ˆì§ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if overall_quality.get('level') == 'poor':
                recommendations.append({
                    'type': 'critical',
                    'icon': 'ğŸ”´',
                    'title': 'ì¬ë…¹ìŒ ê¶Œì¥',
                    'message': 'í˜„ì¬ ìŒì§ˆì´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ì„ ê°œì„ í•œ í›„ ë‹¤ì‹œ ë…¹ìŒí•´ë³´ì„¸ìš”',
                    'action': 'retry_recording'
                })
            elif overall_quality.get('level') == 'excellent':
                recommendations.append({
                    'type': 'success',
                    'icon': 'ğŸŸ¢',
                    'title': 'ìµœì  í’ˆì§ˆ',
                    'message': 'í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì—¬ ê³„ì† ë…¹ìŒí•˜ì„¸ìš”',
                    'action': 'maintain_current_settings'
                })
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"ê¶Œì¥ì‚¬í•­ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return [{
                'type': 'error',
                'icon': 'âŒ',
                'title': 'ë¶„ì„ ì˜¤ë¥˜',
                'message': 'í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
                'action': 'retry_analysis'
            }]

    # === ë‚´ë¶€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===
    
    def _detect_voice_silence(self, audio_data: np.ndarray, sr: int) -> Tuple[List, List]:
        """ìŒì„±/ë¬´ìŒ êµ¬ê°„ ê°ì§€"""
        # ì—ë„ˆì§€ ê¸°ë°˜ VAD (Voice Activity Detection)
        frame_length = int(0.025 * sr)  # 25ms í”„ë ˆì„
        hop_length = int(0.010 * sr)    # 10ms í™‰
        
        # ë‹¨êµ¬ê°„ ì—ë„ˆì§€ ê³„ì‚°
        energy = []
        for i in range(0, len(audio_data) - frame_length, hop_length):
            frame = audio_data[i:i + frame_length]
            energy.append(np.sum(frame**2))
        
        energy = np.array(energy)
        
        # ì„ê³„ê°’ ì„¤ì • (ì—ë„ˆì§€ì˜ ì¤‘ê°„ê°’ ê¸°ì¤€)
        threshold = np.median(energy) * 2
        
        # ìŒì„±/ë¬´ìŒ êµ¬ê°„ ë¶„ë¥˜
        voice_segments = []
        silence_segments = []
        
        for i, e in enumerate(energy):
            start_idx = i * hop_length
            end_idx = start_idx + frame_length
            
            if end_idx <= len(audio_data):
                segment = audio_data[start_idx:end_idx]
                
                if e > threshold:
                    voice_segments.append(segment)
                else:
                    silence_segments.append(segment)
        
        return voice_segments, silence_segments
    
    def _analyze_noise_types(self, audio_data: np.ndarray, sr: int) -> List[str]:
        """ë…¸ì´ì¦ˆ ìœ í˜• ë¶„ì„"""
        noise_types = []
        
        # ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
        stft = librosa.stft(audio_data)
        magnitude = np.abs(stft)
        
        # 50Hz/60Hz í—˜ ê°ì§€
        freqs = librosa.fft_frequencies(sr=sr)
        hum_indices = [
            np.argmin(np.abs(freqs - 50)),   # 50Hz
            np.argmin(np.abs(freqs - 60)),   # 60Hz
            np.argmin(np.abs(freqs - 100)),  # 100Hz
            np.argmin(np.abs(freqs - 120))   # 120Hz
        ]
        
        hum_energy = np.mean([np.mean(magnitude[idx, :]) for idx in hum_indices])
        total_energy = np.mean(magnitude)
        
        if hum_energy / total_energy > 0.1:
            noise_types.append('electrical_hum')
        
        # í™”ì´íŠ¸ ë…¸ì´ì¦ˆ ê°ì§€
        high_freq_energy = np.mean(magnitude[100:, :])
        if high_freq_energy / total_energy > 0.3:
            noise_types.append('white_noise')
        
        # í™˜ê²½ìŒ ê°ì§€ (ì €ì£¼íŒŒ ì—ë„ˆì§€)
        low_freq_energy = np.mean(magnitude[:20, :])
        if low_freq_energy / total_energy > 0.4:
            noise_types.append('environmental')
        
        return noise_types
    
    def _extract_speech_features(self, audio_data: np.ndarray, sr: int) -> Dict:
        """ìŒì„± íŠ¹ì§• ì¶”ì¶œ"""
        # ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬ (Spectral Centroid)
        spec_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)[0]
        centroid_mean = np.mean(spec_centroid)
        centroid_score = min(1.0, centroid_mean / 3000)  # 3kHz ê¸°ì¤€ ì •ê·œí™”
        
        # ì˜êµì°¨ìœ¨ (Zero Crossing Rate)
        zcr = librosa.feature.zero_crossing_rate(audio_data)[0]
        zcr_mean = np.mean(zcr)
        zcr_score = min(1.0, zcr_mean * 10)  # ì •ê·œí™”
        
        return {
            'spectral_centroid': round(centroid_mean, 1),
            'spectral_centroid_score': round(centroid_score, 3),
            'zero_crossing_rate': round(zcr_mean, 4),
            'zero_crossing_score': round(zcr_score, 3)
        }
    
    def _calculate_speech_band_energy(self, audio_data: np.ndarray, sr: int) -> float:
        """ìŒì„± ëŒ€ì—­ ì—ë„ˆì§€ ë¹„ìœ¨ ê³„ì‚°"""
        stft = librosa.stft(audio_data)
        magnitude = np.abs(stft)
        
        freqs = librosa.fft_frequencies(sr=sr)
        
        # ìŒì„± ì£¼ìš” ëŒ€ì—­ (300Hz - 3400Hz)
        speech_band_indices = np.where((freqs >= 300) & (freqs <= 3400))[0]
        speech_energy = np.mean(magnitude[speech_band_indices, :])
        
        # ì „ì²´ ì—ë„ˆì§€
        total_energy = np.mean(magnitude)
        
        if total_energy > 0:
            return speech_energy / total_energy
        else:
            return 0.0
    
    def _calculate_speech_consistency(self, audio_data: np.ndarray, sr: int) -> float:
        """ìŒì„± ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        # ì˜¤ë””ì˜¤ë¥¼ ì—¬ëŸ¬ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¼ê´€ì„± ì¸¡ì •
        segment_length = int(1.0 * sr)  # 1ì´ˆ êµ¬ê°„
        num_segments = len(audio_data) // segment_length
        
        if num_segments < 2:
            return 1.0
        
        segment_energies = []
        for i in range(num_segments):
            start = i * segment_length
            end = start + segment_length
            segment = audio_data[start:end]
            energy = np.mean(segment**2)
            segment_energies.append(energy)
        
        # ì—ë„ˆì§€ ë³€ë™ ê³„ìˆ˜ ê³„ì‚°
        if len(segment_energies) > 1:
            std_dev = np.std(segment_energies)
            mean_energy = np.mean(segment_energies)
            
            if mean_energy > 0:
                cv = std_dev / mean_energy  # ë³€ë™ê³„ìˆ˜
                consistency = max(0.0, 1.0 - cv)  # ë³€ë™ì´ ì ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ
            else:
                consistency = 0.0
        else:
            consistency = 1.0
        
        return consistency
    
    def _classify_snr_level(self, snr_db: float) -> str:
        """SNR ë“±ê¸‰ ë¶„ë¥˜"""
        if snr_db >= self.quality_thresholds['snr_excellent']:
            return 'excellent'
        elif snr_db >= self.quality_thresholds['snr_good']:
            return 'good'
        elif snr_db >= self.quality_thresholds['snr_fair']:
            return 'fair'
        else:
            return 'poor'
    
    def _classify_noise_level(self, noise_db: float) -> str:
        """ë…¸ì´ì¦ˆ ë“±ê¸‰ ë¶„ë¥˜"""
        if noise_db <= self.quality_thresholds['noise_low']:
            return 'low'
        elif noise_db <= self.quality_thresholds['noise_medium']:
            return 'medium'
        else:
            return 'high'
    
    def _classify_clarity_level(self, clarity_score: float) -> str:
        """ëª…ë£Œë„ ë“±ê¸‰ ë¶„ë¥˜"""
        if clarity_score >= self.quality_thresholds['clarity_excellent']:
            return 'excellent'
        elif clarity_score >= self.quality_thresholds['clarity_good']:
            return 'good'
        elif clarity_score >= self.quality_thresholds['clarity_fair']:
            return 'fair'
        else:
            return 'poor'
    
    def _normalize_snr_score(self, snr_db: float) -> float:
        """SNR ì ìˆ˜ ì •ê·œí™” (0-1)"""
        # 0dB = 0ì , 30dB = 1ì ìœ¼ë¡œ ì •ê·œí™”
        return max(0.0, min(1.0, snr_db / 30.0))
    
    def _normalize_noise_score(self, noise_db: float) -> float:
        """ë…¸ì´ì¦ˆ ì ìˆ˜ ì •ê·œí™” (0-1, ë…¸ì´ì¦ˆê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)"""
        # -50dB = 1ì , 0dB = 0ì ìœ¼ë¡œ ì •ê·œí™”
        return max(0.0, min(1.0, (-noise_db) / 50.0))
    
    def _get_timestamp(self) -> str:
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    checker = AudioQualityChecker()
    
    # í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ
    print("ğŸ™ï¸ Audio Quality Checker v2.1 - í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì œê³µ
    # result = checker.analyze_audio_quality("test_audio.wav")
    # print(f"ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {result['overall_quality']['percentage']}%")
    # print(f"í’ˆì§ˆ ë“±ê¸‰: {result['overall_quality']['status']}")
    
    print("ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ âœ…")
