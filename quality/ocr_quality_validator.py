"""
ğŸ‘ï¸ OCR Quality Validator v2.1
OCR í’ˆì§ˆ ì‹¤ì‹œê°„ ê²€ì¦ ë° í˜„ì¥ ìµœì í™” ëª¨ë“ˆ

ì£¼ìš” ê¸°ëŠ¥:
- PPT/ë¬¸ì„œ ì¸ì‹ë¥  ì‹¤ì‹œê°„ ì¸¡ì •
- í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
- ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€
- ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ì¸ì‹ ì •í™•ë„
- ì¬ì´¬ì˜ ê¶Œì¥ ì•Œê³ ë¦¬ì¦˜
"""

import cv2
import numpy as np
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import re
from typing import Dict, List, Tuple, Optional, Union
import logging
import warnings
warnings.filterwarnings("ignore")

class OCRQualityValidator:
    """OCR í’ˆì§ˆ ì‹¤ì‹œê°„ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # OCR í’ˆì§ˆ ê¸°ì¤€ê°’
        self.quality_thresholds = {
            'confidence_excellent': 90.0,  # ì‹ ë¢°ë„ 90% ì´ìƒ = ìš°ìˆ˜
            'confidence_good': 80.0,       # ì‹ ë¢°ë„ 80-90% = ì–‘í˜¸
            'confidence_fair': 70.0,       # ì‹ ë¢°ë„ 70-80% = ë³´í†µ
            'confidence_poor': 60.0,       # ì‹ ë¢°ë„ 60% ë¯¸ë§Œ = ë¶ˆëŸ‰
            
            'resolution_min': 150,         # ìµœì†Œ DPI
            'resolution_optimal': 300,     # ìµœì  DPI
            
            'contrast_min': 50,            # ìµœì†Œ ëŒ€ë¹„
            'contrast_optimal': 100,       # ìµœì  ëŒ€ë¹„
            
            'blur_threshold': 100,         # ë¸”ëŸ¬ ì„ê³„ê°’ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
        }
        
        # ì£¼ì–¼ë¦¬ ì—…ê³„ ì „ë¬¸ìš©ì–´ ì‚¬ì „
        self.jewelry_terms = {
            'english': [
                'diamond', 'gold', 'silver', 'platinum', 'ruby', 'emerald', 'sapphire',
                'carat', 'cut', 'clarity', 'color', 'certificate', 'appraisal',
                'karat', 'setting', 'prong', 'bezel', 'pavÃ©', 'tennis', 'solitaire',
                'vintage', 'antique', 'fine', 'jewelry', 'gemstone', 'precious',
                'brilliant', 'marquise', 'oval', 'pear', 'heart', 'asscher',
                'cushion', 'radiant', 'princess', 'round', 'GIA', 'AGS', 'AIGS'
            ],
            'korean': [
                'ë‹¤ì´ì•„ëª¬ë“œ', 'ê¸ˆ', 'ì€', 'ë°±ê¸ˆ', 'ë£¨ë¹„', 'ì—ë©”ë„ë“œ', 'ì‚¬íŒŒì´ì–´',
                'ìºëŸ¿', 'ì»·', 'íˆ¬ëª…ë„', 'ìƒ‰ìƒ', 'ê°ì •ì„œ', 'í‰ê°€ì„œ',
                'ì¹´ë¼íŠ¸', 'ì„¸íŒ…', 'í”„ë¡±', 'ë² ì ¤', 'íŒŒë² ', 'í…Œë‹ˆìŠ¤', 'ì†”ë¦¬í…Œì–´',
                'ë¹ˆí‹°ì§€', 'ì•¤í‹±', 'íŒŒì¸', 'ì£¼ì–¼ë¦¬', 'ë³´ì„', 'ê·€ê¸ˆì†',
                'ë¸Œë¦´ë¦¬ì–¸íŠ¸', 'ë§ˆí‚¤ì¦ˆ', 'ì˜¤ë²Œ', 'í˜ì–´', 'í•˜íŠ¸', 'ì•„ì…”',
                'ì¿ ì…˜', 'ë˜ë””ì–¸íŠ¸', 'í”„ë¦°ì„¸ìŠ¤', 'ë¼ìš´ë“œ', 'ì§€ì•„', 'ì—ì´ì§€ì—ìŠ¤'
            ]
        }
        
        # OCR ì„¤ì •
        self.ocr_config = {
            'default': '--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ê°€-í£.,()%-:/',
            'numbers': '--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789.,',
            'text_only': '--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzê°€-í£ '
        }

    def validate_ocr_quality(self, 
                           image_path: str = None, 
                           image_data: np.ndarray = None,
                           ocr_text: str = None,
                           analysis_type: str = 'comprehensive') -> Dict:
        """
        OCR í’ˆì§ˆ ì¢…í•© ê²€ì¦
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            image_data: ì´ë¯¸ì§€ ë°ì´í„° (numpy array)
            ocr_text: ì´ë¯¸ ì¶”ì¶œëœ OCR í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
            analysis_type: ë¶„ì„ ìœ í˜• ('quick', 'comprehensive', 'jewelry_focused')
            
        Returns:
            Dict: OCR í’ˆì§ˆ ê²€ì¦ ê²°ê³¼
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            if image_data is None:
                if image_path is None:
                    raise ValueError("image_path ë˜ëŠ” image_data ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")
                image_data = cv2.imread(image_path)
                if image_data is None:
                    raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            
            # ê¸°ë³¸ ì •ë³´
            results = {
                'timestamp': self._get_timestamp(),
                'image_path': image_path or 'real_time_data',
                'analysis_type': analysis_type,
                'image_shape': image_data.shape
            }
            
            # ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„
            image_quality = self.analyze_image_quality(image_data)
            results.update(image_quality)
            
            # OCR ìˆ˜í–‰ ë° ì‹ ë¢°ë„ ë¶„ì„
            if ocr_text is None:
                ocr_result = self.perform_ocr_with_confidence(image_data)
            else:
                ocr_result = {'text': ocr_text, 'confidence': None}
            results.update(ocr_result)
            
            # í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„
            if ocr_result.get('text'):
                text_quality = self.analyze_text_quality(
                    ocr_result['text'], 
                    analysis_type
                )
                results.update(text_quality)
            
            # ì£¼ì–¼ë¦¬ íŠ¹í™” ë¶„ì„
            if analysis_type in ['comprehensive', 'jewelry_focused']:
                jewelry_analysis = self.analyze_jewelry_terminology(
                    ocr_result.get('text', '')
                )
                results['jewelry_analysis'] = jewelry_analysis
            
            # ì „ì²´ OCR í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            overall_score = self.calculate_overall_ocr_score(results)
            results['overall_quality'] = overall_score
            
            # ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self.generate_ocr_recommendations(results)
            results['recommendations'] = recommendations
            
            return results
            
        except Exception as e:
            self.logger.error(f"OCR í’ˆì§ˆ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            return {
                'error': str(e),
                'overall_quality': {'score': 0, 'level': 'error'}
            }

    def analyze_image_quality(self, image_data: np.ndarray) -> Dict:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image_data.shape) == 3:
                gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)
            else:
                gray = image_data.copy()
            
            # í•´ìƒë„ ë¶„ì„
            height, width = gray.shape
            total_pixels = height * width
            
            # ëŒ€ë¹„ ë¶„ì„
            contrast = self._calculate_contrast(gray)
            
            # ë¸”ëŸ¬ ë¶„ì„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # ë…¸ì´ì¦ˆ ë¶„ì„
            noise_level = self._calculate_noise_level(gray)
            
            # ë°ê¸° ë¶„í¬ ë¶„ì„
            brightness_stats = self._analyze_brightness_distribution(gray)
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
            text_regions = self._detect_text_regions(gray)
            
            return {
                'image_resolution': {
                    'width': width,
                    'height': height,
                    'total_pixels': total_pixels,
                    'estimated_dpi': self._estimate_dpi(width, height)
                },
                'contrast_score': round(contrast, 1),
                'blur_score': round(blur_score, 1),
                'noise_level': round(noise_level, 3),
                'brightness_stats': brightness_stats,
                'text_regions_count': len(text_regions),
                'text_coverage_ratio': self._calculate_text_coverage(text_regions, gray.shape)
            }
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                'image_resolution': {'width': 0, 'height': 0},
                'contrast_score': 0.0,
                'blur_score': 0.0
            }

    def perform_ocr_with_confidence(self, image_data: np.ndarray) -> Dict:
        """ì‹ ë¢°ë„ ì •ë³´ì™€ í•¨ê»˜ OCR ìˆ˜í–‰"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_for_ocr(image_data)
            
            # OCR ìˆ˜í–‰ (ì‹ ë¢°ë„ ì •ë³´ í¬í•¨)
            data = pytesseract.image_to_data(
                processed_image, 
                config=self.ocr_config['default'],
                output_type=pytesseract.Output.DICT
            )
            
            # í…ìŠ¤íŠ¸ì™€ ì‹ ë¢°ë„ ì¶”ì¶œ
            text_parts = []
            confidences = []
            
            for i in range(len(data['text'])):
                if int(data['conf'][i]) > 0:  # ìœ íš¨í•œ ì‹ ë¢°ë„ë§Œ
                    text = data['text'][i].strip()
                    if text:
                        text_parts.append(text)
                        confidences.append(int(data['conf'][i]))
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
            full_text = ' '.join(text_parts)
            
            # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
            avg_confidence = np.mean(confidences) if confidences else 0
            
            # ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„
            confidence_distribution = self._analyze_confidence_distribution(confidences)
            
            return {
                'text': full_text,
                'confidence': round(avg_confidence, 1),
                'word_count': len(text_parts),
                'confidence_distribution': confidence_distribution,
                'low_confidence_words': [
                    text_parts[i] for i, conf in enumerate(confidences) 
                    if conf < self.quality_thresholds['confidence_fair']
                ]
            }
            
        except Exception as e:
            self.logger.error(f"OCR ìˆ˜í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                'text': '',
                'confidence': 0.0,
                'word_count': 0
            }

    def analyze_text_quality(self, text: str, analysis_type: str) -> Dict:
        """í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„"""
        try:
            # ê¸°ë³¸ í…ìŠ¤íŠ¸ í†µê³„
            char_count = len(text)
            word_count = len(text.split())
            line_count = len(text.split('\n'))
            
            # ì–¸ì–´ ê°ì§€
            language_info = self._detect_language(text)
            
            # íŠ¹ìˆ˜ë¬¸ì/ìˆ«ì ë¹„ìœ¨
            special_char_ratio = self._calculate_special_char_ratio(text)
            digit_ratio = self._calculate_digit_ratio(text)
            
            # ê°€ë…ì„± ì ìˆ˜
            readability_score = self._calculate_readability_score(text)
            
            # ì˜¤íƒ€/ì´ìƒ íŒ¨í„´ ê°ì§€
            anomaly_detection = self._detect_text_anomalies(text)
            
            return {
                'text_statistics': {
                    'character_count': char_count,
                    'word_count': word_count,
                    'line_count': line_count,
                    'avg_word_length': round(char_count / max(word_count, 1), 1)
                },
                'language_info': language_info,
                'content_ratios': {
                    'special_char_ratio': round(special_char_ratio, 3),
                    'digit_ratio': round(digit_ratio, 3),
                    'alpha_ratio': round(1 - special_char_ratio - digit_ratio, 3)
                },
                'readability_score': round(readability_score, 3),
                'anomaly_detection': anomaly_detection
            }
            
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                'text_statistics': {'character_count': 0, 'word_count': 0},
                'readability_score': 0.0
            }

    def analyze_jewelry_terminology(self, text: str) -> Dict:
        """ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ë¶„ì„"""
        try:
            text_lower = text.lower()
            
            # ì˜ì–´ ì „ë¬¸ìš©ì–´ ë§¤ì¹­
            english_matches = []
            for term in self.jewelry_terms['english']:
                if term.lower() in text_lower:
                    english_matches.append(term)
            
            # í•œêµ­ì–´ ì „ë¬¸ìš©ì–´ ë§¤ì¹­
            korean_matches = []
            for term in self.jewelry_terms['korean']:
                if term in text:
                    korean_matches.append(term)
            
            # ìˆ«ì íŒ¨í„´ ë¶„ì„ (ìºëŸ¿, ê°€ê²© ë“±)
            number_patterns = self._extract_jewelry_numbers(text)
            
            # ë¸Œëœë“œ/ì¸ì¦ê¸°ê´€ ê°ì§€
            certifications = self._detect_certifications(text)
            
            # ì£¼ì–¼ë¦¬ íŠ¹í™” ì ìˆ˜ ê³„ì‚°
            jewelry_score = self._calculate_jewelry_score(
                english_matches, korean_matches, number_patterns, certifications
            )
            
            return {
                'english_terms_found': english_matches,
                'korean_terms_found': korean_matches,
                'term_count': len(english_matches) + len(korean_matches),
                'number_patterns': number_patterns,
                'certifications': certifications,
                'jewelry_relevance_score': round(jewelry_score, 3),
                'domain_confidence': self._classify_domain_confidence(jewelry_score)
            }
            
        except Exception as e:
            self.logger.error(f"ì£¼ì–¼ë¦¬ ìš©ì–´ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                'english_terms_found': [],
                'korean_terms_found': [],
                'jewelry_relevance_score': 0.0
            }

    def calculate_overall_ocr_score(self, results: Dict) -> Dict:
        """ì „ì²´ OCR í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°€ì¤‘ì¹˜ ì„¤ì •
            weights = {
                'image_quality': 0.3,    # ì´ë¯¸ì§€ í’ˆì§ˆ 30%
                'ocr_confidence': 0.4,   # OCR ì‹ ë¢°ë„ 40%
                'text_quality': 0.2,     # í…ìŠ¤íŠ¸ í’ˆì§ˆ 20%
                'jewelry_relevance': 0.1 # ì£¼ì–¼ë¦¬ ê´€ë ¨ì„± 10%
            }
            
            # ê°œë³„ ì ìˆ˜ ì •ê·œí™”
            image_score = self._normalize_image_score(results)
            confidence_score = self._normalize_confidence_score(results.get('confidence', 0))
            text_score = self._normalize_text_score(results)
            jewelry_score = results.get('jewelry_analysis', {}).get('jewelry_relevance_score', 0)
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            overall_score = (
                image_score * weights['image_quality'] +
                confidence_score * weights['ocr_confidence'] +
                text_score * weights['text_quality'] +
                jewelry_score * weights['jewelry_relevance']
            )
            
            # ë“±ê¸‰ ë¶„ë¥˜
            level, status, color = self._classify_ocr_quality_level(overall_score)
            
            return {
                'score': round(overall_score, 3),
                'percentage': round(overall_score * 100, 1),
                'level': level,
                'status': status,
                'color': color,
                'components': {
                    'image_score': round(image_score, 3),
                    'confidence_score': round(confidence_score, 3),
                    'text_score': round(text_score, 3),
                    'jewelry_score': round(jewelry_score, 3)
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì „ì²´ OCR ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return {
                'score': 0.0,
                'level': 'error',
                'status': 'ì˜¤ë¥˜'
            }

    def generate_ocr_recommendations(self, results: Dict) -> List[Dict]:
        """OCR í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            overall_quality = results.get('overall_quality', {})
            confidence = results.get('confidence', 0)
            blur_score = results.get('blur_score', 0)
            contrast_score = results.get('contrast_score', 0)
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if confidence < self.quality_thresholds['confidence_poor']:
                recommendations.append({
                    'type': 'critical',
                    'icon': 'ğŸ”´',
                    'title': 'OCR ì‹ ë¢°ë„ ë§¤ìš° ë‚®ìŒ',
                    'message': 'ì¡°ëª…ì„ ê°œì„ í•˜ê³  ì¹´ë©”ë¼ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ê³ ì •í•œ í›„ ì¬ì´¬ì˜í•˜ì„¸ìš”',
                    'action': 'improve_lighting_and_stability'
                })
            elif confidence < self.quality_thresholds['confidence_fair']:
                recommendations.append({
                    'type': 'warning',
                    'icon': 'ğŸŸ¡',
                    'title': 'OCR ì‹ ë¢°ë„ ê°œì„  í•„ìš”',
                    'message': 'ë¬¸ì„œë¥¼ í‰í‰í•˜ê²Œ í´ê³  ìˆ˜ì§ìœ¼ë¡œ ì´¬ì˜í•´ë³´ì„¸ìš”',
                    'action': 'flatten_document_and_perpendicular_shot'
                })
            
            # ë¸”ëŸ¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if blur_score < self.quality_thresholds['blur_threshold']:
                recommendations.append({
                    'type': 'warning',
                    'icon': 'ğŸŸ ',
                    'title': 'ì´ë¯¸ì§€ íë¦¼ ê°ì§€',
                    'message': 'ì¹´ë©”ë¼ë¥¼ ê³ ì •í•˜ê³  ì´ˆì ì„ ë§ì¶˜ í›„ ì´¬ì˜í•˜ì„¸ìš”',
                    'action': 'fix_camera_and_focus'
                })
            
            # ëŒ€ë¹„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if contrast_score < self.quality_thresholds['contrast_min']:
                recommendations.append({
                    'type': 'warning',
                    'icon': 'ğŸŸ ',
                    'title': 'ì´ë¯¸ì§€ ëŒ€ë¹„ ë‚®ìŒ',
                    'message': 'ì¡°ëª…ì„ ê°œì„ í•˜ê±°ë‚˜ ë°°ê²½ê³¼ í…ìŠ¤íŠ¸ì˜ ëŒ€ë¹„ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”',
                    'action': 'improve_contrast'
                })
            
            # ì „ì²´ í’ˆì§ˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if overall_quality.get('level') == 'poor':
                recommendations.append({
                    'type': 'critical',
                    'icon': 'ğŸ”´',
                    'title': 'ì¬ì´¬ì˜ ê¶Œì¥',
                    'message': 'í˜„ì¬ OCR í’ˆì§ˆì´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ì„ ê°œì„ í•œ í›„ ë‹¤ì‹œ ì´¬ì˜í•´ë³´ì„¸ìš”',
                    'action': 'retry_capture'
                })
            elif overall_quality.get('level') == 'excellent':
                recommendations.append({
                    'type': 'success',
                    'icon': 'ğŸŸ¢',
                    'title': 'ìµœì  í’ˆì§ˆ',
                    'message': 'í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì—¬ ê³„ì† ì´¬ì˜í•˜ì„¸ìš”',
                    'action': 'maintain_current_settings'
                })
            
            # ì£¼ì–¼ë¦¬ íŠ¹í™” ê¶Œì¥ì‚¬í•­
            jewelry_analysis = results.get('jewelry_analysis', {})
            if jewelry_analysis.get('jewelry_relevance_score', 0) < 0.3:
                recommendations.append({
                    'type': 'info',
                    'icon': 'ğŸ’',
                    'title': 'ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ë¶€ì¡±',
                    'message': 'ì£¼ì–¼ë¦¬ ê´€ë ¨ ë¬¸ì„œì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”',
                    'action': 'verify_jewelry_document'
                })
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"OCR ê¶Œì¥ì‚¬í•­ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return [{
                'type': 'error',
                'icon': 'âŒ',
                'title': 'OCR ë¶„ì„ ì˜¤ë¥˜',
                'message': 'OCR í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
                'action': 'retry_ocr_analysis'
            }]

    # === ë‚´ë¶€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===
    
    def _preprocess_for_ocr(self, image: np.ndarray) -> np.ndarray:
        """OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.medianBlur(gray, 3)
        
        # ëŒ€ë¹„ ê°œì„ 
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        
        # ì´ì§„í™”
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
    
    def _calculate_contrast(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ëŒ€ë¹„ ê³„ì‚°"""
        return float(np.std(image))
    
    def _calculate_noise_level(self, image: np.ndarray) -> float:
        """ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚°"""
        # ë¼í”Œë¼ì‹œì•ˆ í•„í„°ë¥¼ ì´ìš©í•œ ë…¸ì´ì¦ˆ ì¶”ì •
        laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()
        return float(laplacian_var) / 10000  # ì •ê·œí™”
    
    def _analyze_brightness_distribution(self, image: np.ndarray) -> Dict:
        """ë°ê¸° ë¶„í¬ ë¶„ì„"""
        hist = cv2.calcHist([image], [0], None, [256], [0, 256])
        
        return {
            'mean_brightness': round(float(np.mean(image)), 1),
            'brightness_std': round(float(np.std(image)), 1),
            'dark_pixel_ratio': round(float(np.sum(image < 85) / image.size), 3),
            'bright_pixel_ratio': round(float(np.sum(image > 170) / image.size), 3)
        }
    
    def _detect_text_regions(self, image: np.ndarray) -> List:
        """í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€"""
        # MSERì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
        mser = cv2.MSER_create()
        regions, _ = mser.detectRegions(image)
        
        # í…ìŠ¤íŠ¸ ê°™ì€ ì˜ì—­ í•„í„°ë§
        text_regions = []
        for region in regions:
            if len(region) > 50 and len(region) < 2000:  # ì ë‹¹í•œ í¬ê¸°ì˜ ì˜ì—­ë§Œ
                text_regions.append(region)
        
        return text_regions
    
    def _calculate_text_coverage(self, text_regions: List, image_shape: Tuple) -> float:
        """í…ìŠ¤íŠ¸ ì˜ì—­ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
        if not text_regions:
            return 0.0
        
        total_pixels = image_shape[0] * image_shape[1]
        text_pixels = sum(len(region) for region in text_regions)
        
        return min(1.0, text_pixels / total_pixels)
    
    def _estimate_dpi(self, width: int, height: int) -> int:
        """DPI ì¶”ì • (A4 ê¸°ì¤€)"""
        # A4 í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ DPI ì¶”ì •
        a4_width_inch = 8.27
        a4_height_inch = 11.69
        
        dpi_w = width / a4_width_inch
        dpi_h = height / a4_height_inch
        
        return int((dpi_w + dpi_h) / 2)
    
    def _analyze_confidence_distribution(self, confidences: List[int]) -> Dict:
        """ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„"""
        if not confidences:
            return {'high': 0, 'medium': 0, 'low': 0}
        
        high_conf = sum(1 for c in confidences if c >= 80)
        medium_conf = sum(1 for c in confidences if 60 <= c < 80)
        low_conf = sum(1 for c in confidences if c < 60)
        total = len(confidences)
        
        return {
            'high': round(high_conf / total, 3),
            'medium': round(medium_conf / total, 3),
            'low': round(low_conf / total, 3)
        }
    
    def _detect_language(self, text: str) -> Dict:
        """ì–¸ì–´ ê°ì§€"""
        # í•œê¸€ ë¬¸ì ë¹„ìœ¨
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        # ì˜ë¬¸ ë¬¸ì ë¹„ìœ¨
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        # ìˆ«ì ë¹„ìœ¨
        digit_chars = len(re.findall(r'[0-9]', text))
        
        total_chars = max(1, len(re.sub(r'\s', '', text)))
        
        return {
            'korean_ratio': round(korean_chars / total_chars, 3),
            'english_ratio': round(english_chars / total_chars, 3),
            'digit_ratio': round(digit_chars / total_chars, 3),
            'primary_language': 'korean' if korean_chars > english_chars else 'english'
        }
    
    def _calculate_special_char_ratio(self, text: str) -> float:
        """íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ ê³„ì‚°"""
        special_chars = len(re.findall(r'[^a-zA-Z0-9ê°€-í£\s]', text))
        total_chars = max(1, len(text))
        return special_chars / total_chars
    
    def _calculate_digit_ratio(self, text: str) -> float:
        """ìˆ«ì ë¹„ìœ¨ ê³„ì‚°"""
        digits = len(re.findall(r'[0-9]', text))
        total_chars = max(1, len(text))
        return digits / total_chars
    
    def _calculate_readability_score(self, text: str) -> float:
        """ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°"""
        if not text.strip():
            return 0.0
        
        words = text.split()
        if not words:
            return 0.0
        
        # í‰ê·  ë‹¨ì–´ ê¸¸ì´
        avg_word_length = sum(len(word) for word in words) / len(words)
        
        # ë‹¨ì–´ ê¸¸ì´ ê¸°ì¤€ ê°€ë…ì„± (3-7ìê°€ ì ë‹¹)
        length_score = max(0, 1 - abs(avg_word_length - 5) / 10)
        
        # ê³µë°±/êµ¬ë‘ì  ë¹„ìœ¨ (ì ë‹¹í•œ ë¹„ìœ¨ì´ ì¢‹ìŒ)
        spaces = text.count(' ')
        punctuation = len(re.findall(r'[.,!?;:]', text))
        structure_score = min(1.0, (spaces + punctuation) / len(words))
        
        return (length_score + structure_score) / 2
    
    def _detect_text_anomalies(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ ì´ìƒ íŒ¨í„´ ê°ì§€"""
        anomalies = []
        
        # ì—°ì†ëœ ë™ì¼ ë¬¸ì
        repeated_chars = re.findall(r'(.)\1{3,}', text)
        if repeated_chars:
            anomalies.append('repeated_characters')
        
        # ë¹„ì •ìƒì ì¸ ëŒ€ì†Œë¬¸ì íŒ¨í„´
        if re.search(r'[a-z][A-Z][a-z][A-Z]', text):
            anomalies.append('irregular_case_pattern')
        
        # ê³¼ë„í•œ íŠ¹ìˆ˜ë¬¸ì
        special_char_ratio = self._calculate_special_char_ratio(text)
        if special_char_ratio > 0.3:
            anomalies.append('excessive_special_characters')
        
        # ìˆ«ìë§Œ ìˆëŠ” ê¸´ ë¬¸ìì—´
        if re.search(r'\d{15,}', text):
            anomalies.append('excessive_consecutive_digits')
        
        return {
            'anomalies_found': anomalies,
            'anomaly_count': len(anomalies),
            'has_anomalies': len(anomalies) > 0
        }
    
    def _extract_jewelry_numbers(self, text: str) -> Dict:
        """ì£¼ì–¼ë¦¬ ê´€ë ¨ ìˆ«ì íŒ¨í„´ ì¶”ì¶œ"""
        patterns = {
            'carat_weights': re.findall(r'(\d+\.?\d*)\s*(?:ct|carat|ìºëŸ¿|ì¹´ë¼íŠ¸)', text, re.IGNORECASE),
            'prices': re.findall(r'[â‚©$Â¥â‚¬]\s*[\d,]+(?:\.\d{2})?', text),
            'percentages': re.findall(r'\d+(?:\.\d+)?\s*%', text),
            'measurements': re.findall(r'\d+(?:\.\d+)?\s*(?:mm|cm|inch)', text, re.IGNORECASE)
        }
        
        # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì œê±°
        patterns = {k: v for k, v in patterns.items() if v}
        
        return patterns
    
    def _detect_certifications(self, text: str) -> List[str]:
        """ì¸ì¦ê¸°ê´€/ë¸Œëœë“œ ê°ì§€"""
        certifications = []
        
        cert_patterns = [
            r'GIA\b', r'AGS\b', r'AIGS\b', r'SSEF\b', r'GÃ¼belin\b',
            r'Cartier\b', r'Tiffany\b', r'Harry Winston\b', r'Bulgari\b',
            r'ì§€ì•„\b', r'ì—ì´ì§€ì—ìŠ¤\b', r'ê¹Œë¥´ë ì—\b', r'í‹°íŒŒë‹ˆ\b'
        ]
        
        for pattern in cert_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            certifications.extend(matches)
        
        return list(set(certifications))  # ì¤‘ë³µ ì œê±°
    
    def _calculate_jewelry_score(self, english_terms: List, korean_terms: List, 
                                numbers: Dict, certifications: List) -> float:
        """ì£¼ì–¼ë¦¬ íŠ¹í™” ì ìˆ˜ ê³„ì‚°"""
        # ìš©ì–´ ì ìˆ˜ (ìµœëŒ€ 0.4)
        term_score = min(0.4, (len(english_terms) + len(korean_terms)) * 0.05)
        
        # ìˆ«ì íŒ¨í„´ ì ìˆ˜ (ìµœëŒ€ 0.3)
        number_score = min(0.3, len(numbers) * 0.1)
        
        # ì¸ì¦ ì ìˆ˜ (ìµœëŒ€ 0.3)
        cert_score = min(0.3, len(certifications) * 0.15)
        
        return term_score + number_score + cert_score
    
    def _classify_domain_confidence(self, score: float) -> str:
        """ë„ë©”ì¸ ì‹ ë¢°ë„ ë¶„ë¥˜"""
        if score >= 0.7:
            return 'high_jewelry_relevance'
        elif score >= 0.4:
            return 'medium_jewelry_relevance'
        elif score >= 0.1:
            return 'low_jewelry_relevance'
        else:
            return 'non_jewelry_content'
    
    def _normalize_image_score(self, results: Dict) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ì •ê·œí™”"""
        contrast = results.get('contrast_score', 0)
        blur = results.get('blur_score', 0)
        
        # ëŒ€ë¹„ ì ìˆ˜ (0-1)
        contrast_normalized = min(1.0, contrast / 100)
        
        # ë¸”ëŸ¬ ì ìˆ˜ (0-1, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        blur_normalized = min(1.0, blur / 200)
        
        return (contrast_normalized + blur_normalized) / 2
    
    def _normalize_confidence_score(self, confidence: float) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ì •ê·œí™”"""
        return min(1.0, confidence / 100)
    
    def _normalize_text_score(self, results: Dict) -> float:
        """í…ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ì •ê·œí™”"""
        readability = results.get('readability_score', 0)
        anomaly_detection = results.get('anomaly_detection', {})
        
        # ì´ìƒ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì ìˆ˜ ê°ì 
        anomaly_penalty = 0.1 * anomaly_detection.get('anomaly_count', 0)
        
        return max(0.0, readability - anomaly_penalty)
    
    def _classify_ocr_quality_level(self, score: float) -> Tuple[str, str, str]:
        """OCR í’ˆì§ˆ ë“±ê¸‰ ë¶„ë¥˜"""
        if score >= 0.9:
            return 'excellent', 'ìš°ìˆ˜', 'ğŸŸ¢'
        elif score >= 0.8:
            return 'good', 'ì–‘í˜¸', 'ğŸŸ¡'
        elif score >= 0.7:
            return 'fair', 'ë³´í†µ', 'ğŸŸ '
        else:
            return 'poor', 'ë¶ˆëŸ‰', 'ğŸ”´'
    
    def _get_timestamp(self) -> str:
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    validator = OCRQualityValidator()
    
    print("ğŸ‘ï¸ OCR Quality Validator v2.1 - í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì œê³µ
    # result = validator.validate_ocr_quality("test_document.jpg")
    # print(f"ì „ì²´ OCR í’ˆì§ˆ: {result['overall_quality']['percentage']}%")
    # print(f"OCR ì‹ ë¢°ë„: {result['confidence']}%")
    
    print("ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ âœ…")
