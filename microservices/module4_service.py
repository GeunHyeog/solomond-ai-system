#!/usr/bin/env python3
"""
ğŸ—ï¸ Module 4: 3D CAD ë³€í™˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
- ì´ë¯¸ì§€ì—ì„œ 3D CAD ëª¨ë¸ ìƒì„± ê¸°ëŠ¥ì„ FastAPIë¡œ ë³€í™˜
- Ollama AI í†µí•©ìœ¼ë¡œ ì§€ëŠ¥í˜• í˜•ìƒ ì¸ì‹
- í¬íŠ¸ 8004ì—ì„œ ì‹¤í–‰
"""

import logging
import asyncio
import uuid
import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import tempfile
import os
import base64
from io import BytesIO

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
import uvicorn
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFilter
import requests

# ìµœì í™”ëœ ì»´í¬ë„ŒíŠ¸ë“¤ import
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from core.smart_memory_manager import get_memory_stats
from core.robust_file_processor import robust_processor
from config.security_config import get_system_config

logger = logging.getLogger(__name__)

# Pydantic ëª¨ë¸ë“¤
class CADGenerationRequest(BaseModel):
    """3D CAD ìƒì„± ìš”ì²­ ëª¨ë¸"""
    generation_type: str = "basic"  # 'basic', 'advanced', 'professional'
    mesh_quality: str = "medium"  # 'low', 'medium', 'high', 'ultra'
    output_format: str = "stl"  # 'stl', 'obj', 'ply', '3mf'
    use_ai_enhancement: bool = True
    detail_level: int = 5  # 1-10 ë””í…Œì¼ ë ˆë²¨

class CADResult(BaseModel):
    """CAD ë³€í™˜ ê²°ê³¼ ëª¨ë¸"""
    session_id: str
    status: str
    results: Dict[str, Any]
    processing_time: float
    timestamp: datetime

class CADConversionService:
    """3D CAD ë³€í™˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.active_sessions: Dict[str, Dict] = {}
        self.conversion_cache: Dict[str, Any] = {}
        self.ollama_api_url = "http://localhost:11434/api/generate"
        
        # ì§€ì›ë˜ëŠ” ì¶œë ¥ í˜•ì‹
        self.output_formats = {
            'stl': {'extension': '.stl', 'description': 'Stereolithography (3D í”„ë¦°íŒ…)'},
            'obj': {'extension': '.obj', 'description': 'Wavefront OBJ (ë²”ìš©)'},
            'ply': {'extension': '.ply', 'description': 'Polygon File Format'},
            '3mf': {'extension': '.3mf', 'description': 'Microsoft 3D Manufacturing Format'}
        }
        
        # í’ˆì§ˆ ì„¤ì •
        self.quality_settings = {
            'low': {'vertices': 500, 'faces': 1000},
            'medium': {'vertices': 2000, 'faces': 4000},
            'high': {'vertices': 8000, 'faces': 16000},
            'ultra': {'vertices': 32000, 'faces': 64000}
        }
        
    async def convert_image_to_cad(self, file_data: bytes, filename: str,
                                 generation_type: str = "basic",
                                 mesh_quality: str = "medium",
                                 output_format: str = "stl",
                                 use_ai_enhancement: bool = True,
                                 detail_level: int = 5) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ë¥¼ 3D CADë¡œ ë³€í™˜"""
        session_id = str(uuid.uuid4())
        start_time = asyncio.get_event_loop().time()
        
        try:
            # ì„¸ì…˜ ì •ë³´ ì €ì¥
            self.active_sessions[session_id] = {
                'start_time': start_time,
                'status': 'processing',
                'filename': filename,
                'generation_type': generation_type,
                'mesh_quality': mesh_quality,
                'output_format': output_format
            }
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            file_info = await robust_processor.process_file(file_data, filename)
            
            if file_info.conversion_path is None:
                raise Exception("ì´ë¯¸ì§€ íŒŒì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¶„ì„
            image = cv2.imread(file_info.conversion_path)
            if image is None:
                raise Exception("ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            results = {
                'session_id': session_id,
                'filename': filename,
                'file_info': {
                    'size_bytes': file_info.original_size,
                    'format': file_info.format
                },
                'image_analysis': {},
                'shape_detection': {},
                'ai_enhancement': {},
                '3d_generation': {},
                'cad_model': {},
                'export_info': {}
            }
            
            # 1. ì´ë¯¸ì§€ ë¶„ì„
            results['image_analysis'] = await self._analyze_image(image)
            
            # 2. í˜•ìƒ ê°ì§€
            results['shape_detection'] = await self._detect_shapes(image)
            
            # 3. AI ê°•í™” (Ollama ì‚¬ìš©)
            if use_ai_enhancement:
                results['ai_enhancement'] = await self._ai_enhance_analysis(
                    image, results['image_analysis'], results['shape_detection']
                )
            
            # 4. 3D ëª¨ë¸ ìƒì„±
            results['3d_generation'] = await self._generate_3d_model(
                image, results, generation_type, mesh_quality, detail_level
            )
            
            # 5. CAD íŒŒì¼ ìƒì„±
            results['cad_model'] = await self._create_cad_file(
                results['3d_generation'], output_format, session_id
            )
            
            # 6. ë‚´ë³´ë‚´ê¸° ì •ë³´
            results['export_info'] = await self._prepare_export_info(
                results['cad_model'], output_format, mesh_quality
            )
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            # ì„¸ì…˜ ì™„ë£Œ
            self.active_sessions[session_id]['status'] = 'completed'
            self.active_sessions[session_id]['processing_time'] = processing_time
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (CAD íŒŒì¼ì€ ë³´ì¡´)
            robust_processor.cleanup_temp_files(file_info)
            
            return {
                'session_id': session_id,
                'status': 'success',
                'results': results,
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"CAD ë³€í™˜ ì‹¤íŒ¨ {session_id}: {e}")
            
            if session_id in self.active_sessions:
                self.active_sessions[session_id]['status'] = 'failed'
                self.active_sessions[session_id]['error'] = str(e)
            
            raise HTTPException(status_code=500, detail=f"CAD ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
    
    async def _analyze_image(self, image: np.ndarray) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ê¸°ë³¸ ë¶„ì„"""
        try:
            height, width = image.shape[:2]
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ë°ê¸°/ëŒ€ë¹„ ë¶„ì„
            mean_brightness = np.mean(gray)
            contrast = np.std(gray)
            
            # íˆìŠ¤í† ê·¸ë¨ ë¶„ì„
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            
            return {
                'dimensions': {'width': int(width), 'height': int(height)},
                'brightness': {
                    'mean': float(mean_brightness),
                    'level': 'bright' if mean_brightness > 128 else 'dark'
                },
                'contrast': {
                    'value': float(contrast),
                    'level': 'high' if contrast > 50 else 'medium' if contrast > 25 else 'low'
                },
                'image_quality': self._assess_image_quality(gray, contrast),
                'processing_recommendations': self._get_processing_recommendations(mean_brightness, contrast)
            }
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _assess_image_quality(self, gray: np.ndarray, contrast: float) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€"""
        # ì„ ëª…ë„ ì¸¡ì •
        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # ë…¸ì´ì¦ˆ ì¶”ì •
        noise_level = np.std(cv2.GaussianBlur(gray, (5, 5), 0) - gray)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = min(10, (sharpness / 100 + contrast / 10 - noise_level / 5))
        
        return {
            'sharpness': float(sharpness),
            'noise_level': float(noise_level),
            'quality_score': max(0, float(quality_score)),
            'quality_grade': 'excellent' if quality_score > 8 else 'good' if quality_score > 6 else 'fair' if quality_score > 4 else 'poor'
        }
    
    def _get_processing_recommendations(self, brightness: float, contrast: float) -> List[str]:
        """ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        if brightness < 100:
            recommendations.append("ë°ê¸°ë¥¼ ë†’ì—¬ ë””í…Œì¼ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        elif brightness > 180:
            recommendations.append("ë°ê¸°ë¥¼ ë‚®ì¶° ê³¼ë…¸ì¶œì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        if contrast < 30:
            recommendations.append("ëŒ€ë¹„ë¥¼ ë†’ì—¬ í˜•ìƒ ì¸ì‹ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        recommendations.append("ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì •ë°€í•œ 3D ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        return recommendations
    
    async def _detect_shapes(self, image: np.ndarray) -> Dict[str, Any]:
        """í˜•ìƒ ê°ì§€"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ê°€ì¥ìë¦¬ ê²€ì¶œ
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            
            # ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # í˜•ìƒ ë¶„ë¥˜
            shapes = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # ìµœì†Œ í¬ê¸° í•„í„°
                    # ìœ¤ê³½ì„  ê·¼ì‚¬
                    epsilon = 0.02 * cv2.arcLength(contour, True)
                    approx = cv2.approxPolyDP(contour, epsilon, True)
                    
                    # ê¸°ë³¸ì ì¸ í˜•ìƒ ë¶„ë¥˜
                    shape_type = self._classify_shape(approx, area)
                    
                    shapes.append({
                        'type': shape_type,
                        'area': float(area),
                        'vertices': len(approx),
                        'perimeter': float(cv2.arcLength(contour, True)),
                        'bounding_rect': [int(x) for x in cv2.boundingRect(contour)]
                    })
            
            # í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬
            shapes.sort(key=lambda x: x['area'], reverse=True)
            
            return {
                'total_shapes': len(shapes),
                'main_shapes': shapes[:5],  # ìƒìœ„ 5ê°œë§Œ
                'shape_distribution': self._analyze_shape_distribution(shapes),
                'complexity_assessment': self._assess_complexity(shapes)
            }
            
        except Exception as e:
            logger.error(f"í˜•ìƒ ê°ì§€ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _classify_shape(self, approx: np.ndarray, area: float) -> str:
        """í˜•ìƒ ë¶„ë¥˜"""
        vertices = len(approx)
        
        if vertices == 3:
            return "triangle"
        elif vertices == 4:
            # ì§ì‚¬ê°í˜• vs ì •ì‚¬ê°í˜• íŒë³„
            (x, y, w, h) = cv2.boundingRect(approx)
            aspect_ratio = w / h
            if 0.95 <= aspect_ratio <= 1.05:
                return "square"
            else:
                return "rectangle"
        elif vertices == 5:
            return "pentagon"
        elif vertices > 8:
            return "circle"
        else:
            return f"polygon_{vertices}"
    
    def _analyze_shape_distribution(self, shapes: List[Dict]) -> Dict[str, int]:
        """í˜•ìƒ ë¶„í¬ ë¶„ì„"""
        distribution = {}
        for shape in shapes:
            shape_type = shape['type']
            distribution[shape_type] = distribution.get(shape_type, 0) + 1
        return distribution
    
    def _assess_complexity(self, shapes: List[Dict]) -> Dict[str, Any]:
        """ë³µì¡ë„ í‰ê°€"""
        total_shapes = len(shapes)
        avg_vertices = np.mean([s['vertices'] for s in shapes]) if shapes else 0
        
        complexity_score = min(10, total_shapes / 2 + avg_vertices / 4)
        
        return {
            'complexity_score': float(complexity_score),
            'complexity_level': 'high' if complexity_score > 7 else 'medium' if complexity_score > 4 else 'low',
            'processing_difficulty': 'expert' if complexity_score > 8 else 'intermediate' if complexity_score > 5 else 'basic'
        }
    
    async def _ai_enhance_analysis(self, image: np.ndarray, image_analysis: Dict, shape_detection: Dict) -> Dict[str, Any]:
        """AI ê°•í™” ë¶„ì„ (Ollama ì‚¬ìš©)"""
        try:
            # Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
            try:
                response = requests.get("http://localhost:11434/api/tags", timeout=5)
                if response.status_code != 200:
                    return {'error': 'Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ', 'fallback_used': True}
            except:
                return {'error': 'Ollama ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŒ', 'fallback_used': True}
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            _, buffer = cv2.imencode('.jpg', image)
            image_b64 = base64.b64encode(buffer).decode('utf-8')
            
            # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""
ì´ë¯¸ì§€ë¥¼ 3D CAD ëª¨ë¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ë¶„ì„ì„ ë„ì™€ì£¼ì„¸ìš”.

í˜„ì¬ ë¶„ì„ ê²°ê³¼:
- ì´ë¯¸ì§€ í¬ê¸°: {image_analysis.get('dimensions', {})}
- í’ˆì§ˆ: {image_analysis.get('image_quality', {}).get('quality_grade', 'unknown')}
- ê°ì§€ëœ í˜•ìƒ: {len(shape_detection.get('main_shapes', []))}ê°œ
- ë³µì¡ë„: {shape_detection.get('complexity_assessment', {}).get('complexity_level', 'unknown')}

ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. ê°ì²´ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ í˜•íƒœ
2. 3D ë³€í™˜ì— ì í•©í•œ ë°©ë²• ì¶”ì²œ
3. ì˜ˆìƒë˜ëŠ” ëª¨ë¸ì˜ ë³µì¡ë„
4. ìµœì ì˜ ë©”ì‰¬ í’ˆì§ˆ ì„¤ì •

JSONë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
            
            # Ollama API í˜¸ì¶œ
            ollama_data = {
                "model": "llama3.2-vision",
                "prompt": prompt,
                "images": [image_b64],
                "stream": False
            }
            
            response = requests.post(
                self.ollama_api_url,
                json=ollama_data,
                timeout=30
            )
            
            if response.status_code == 200:
                ai_response = response.json()
                ai_text = ai_response.get('response', '')
                
                try:
                    # JSON íŒŒì‹± ì‹œë„
                    ai_analysis = json.loads(ai_text)
                    return {
                        'ai_insights': ai_analysis,
                        'ai_model_used': 'llama3.2-vision',
                        'confidence': 'high'
                    }
                except json.JSONDecodeError:
                    return {
                        'ai_insights': {'raw_response': ai_text},
                        'ai_model_used': 'llama3.2-vision',
                        'confidence': 'medium',
                        'note': 'AI ì‘ë‹µ íŒŒì‹± ë¶€ë¶„ì  ì‹¤íŒ¨'
                    }
            else:
                return {'error': f'Ollama API ì˜¤ë¥˜: {response.status_code}'}
            
        except Exception as e:
            logger.error(f"AI ê°•í™” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e), 'fallback_used': True}
    
    async def _generate_3d_model(self, image: np.ndarray, results: Dict, 
                               generation_type: str, mesh_quality: str, detail_level: int) -> Dict[str, Any]:
        """3D ëª¨ë¸ ìƒì„± (ê¸°ë³¸ êµ¬í˜„)"""
        try:
            quality_config = self.quality_settings.get(mesh_quality, self.quality_settings['medium'])
            
            # ê¹Šì´ ë§µ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
            depth_map = self._create_depth_map(image)
            
            # ì êµ° ìƒì„±
            point_cloud = self._generate_point_cloud(depth_map, quality_config)
            
            # ë©”ì‰¬ ìƒì„± (ì‚¼ê° ë¶„í• )
            mesh_data = self._create_mesh(point_cloud, quality_config)
            
            return {
                'generation_type': generation_type,
                'mesh_quality': mesh_quality,
                'detail_level': detail_level,
                'model_info': {
                    'vertices_count': len(point_cloud),
                    'faces_count': len(mesh_data.get('faces', [])),
                    'mesh_quality_actual': mesh_quality
                },
                'depth_map_info': {
                    'depth_range': f"{depth_map.min():.2f} - {depth_map.max():.2f}",
                    'depth_levels': len(np.unique(depth_map))
                },
                'generation_status': 'completed'
            }
            
        except Exception as e:
            logger.error(f"3D ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _create_depth_map(self, image: np.ndarray) -> np.ndarray:
        """ê¹Šì´ ë§µ ìƒì„± (ê°„ë‹¨í•œ ë°ê¸° ê¸°ë°˜)"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # ì •ê·œí™”
        depth_map = blurred.astype(np.float32) / 255.0
        
        # ê¹Šì´ ê°•í™”
        depth_map = np.power(depth_map, 1.5)
        
        return depth_map
    
    def _generate_point_cloud(self, depth_map: np.ndarray, quality_config: Dict) -> List[Tuple[float, float, float]]:
        """ì êµ° ìƒì„±"""
        height, width = depth_map.shape
        points = []
        
        # í’ˆì§ˆì— ë”°ë¥¸ ìƒ˜í”Œë§ ê°„ê²©
        max_vertices = quality_config['vertices']
        step = max(1, int(np.sqrt(height * width / max_vertices)))
        
        for y in range(0, height, step):
            for x in range(0, width, step):
                z = depth_map[y, x] * 10  # ê¹Šì´ ìŠ¤ì¼€ì¼ë§
                points.append((float(x), float(y), float(z)))
        
        return points[:max_vertices]  # ìµœëŒ€ ì •ì  ìˆ˜ ì œí•œ
    
    def _create_mesh(self, point_cloud: List[Tuple], quality_config: Dict) -> Dict[str, Any]:
        """ë©”ì‰¬ ìƒì„± (ì‚¼ê°ë¶„í• )"""
        # ê°„ë‹¨í•œ ì‚¼ê°ë¶„í•  êµ¬í˜„
        faces = []
        vertices = point_cloud
        
        # ê·¸ë¦¬ë“œ ê¸°ë°˜ ì‚¼ê°ë¶„í•  (ê°„ë‹¨í™”)
        # ì‹¤ì œë¡œëŠ” Delaunay ì‚¼ê°ë¶„í• ì´ë‚˜ ë‹¤ë¥¸ ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
        
        return {
            'vertices': vertices,
            'faces': faces[:quality_config['faces']],  # ë©´ ìˆ˜ ì œí•œ
            'mesh_type': 'triangular'
        }
    
    async def _create_cad_file(self, model_data: Dict, output_format: str, session_id: str) -> Dict[str, Any]:
        """CAD íŒŒì¼ ìƒì„±"""
        try:
            if 'error' in model_data:
                return {'error': 'CAD íŒŒì¼ ìƒì„±ì„ ìœ„í•œ 3D ëª¨ë¸ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ'}
            
            format_info = self.output_formats.get(output_format, self.output_formats['stl'])
            
            # ì„ì‹œ íŒŒì¼ ê²½ë¡œ
            temp_dir = tempfile.gettempdir()
            filename = f"solomond_cad_{session_id}{format_info['extension']}"
            file_path = os.path.join(temp_dir, filename)
            
            # í˜•ì‹ë³„ íŒŒì¼ ìƒì„±
            if output_format == 'stl':
                success = self._create_stl_file(file_path, model_data)
            elif output_format == 'obj':
                success = self._create_obj_file(file_path, model_data)
            elif output_format == 'ply':
                success = self._create_ply_file(file_path, model_data)
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ STL ìƒì„±
                success = self._create_stl_file(file_path, model_data)
            
            if success:
                return {
                    'file_path': file_path,
                    'filename': filename,
                    'format': output_format,
                    'format_description': format_info['description'],
                    'file_size': os.path.getsize(file_path) if os.path.exists(file_path) else 0,
                    'download_available': True
                }
            else:
                return {'error': 'CAD íŒŒì¼ ìƒì„± ì‹¤íŒ¨'}
            
        except Exception as e:
            logger.error(f"CAD íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _create_stl_file(self, file_path: str, model_data: Dict) -> bool:
        """STL íŒŒì¼ ìƒì„±"""
        try:
            model_info = model_data.get('model_info', {})
            
            # STL í—¤ë” ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
            with open(file_path, 'w') as f:
                f.write("solid solomond_generated\n")
                
                # ê°„ë‹¨í•œ ì‚¼ê°í˜• ë©´ ìƒì„± (ì‹¤ì œë¡œëŠ” ë³µì¡í•œ ë©”ì‰¬ ë°ì´í„° ì²˜ë¦¬ í•„ìš”)
                vertices_count = model_info.get('vertices_count', 0)
                for i in range(min(100, vertices_count // 3)):  # ì„ì‹œë¡œ 100ê°œ ë©´ë§Œ
                    f.write("  facet normal 0.0 0.0 1.0\n")
                    f.write("    outer loop\n")
                    f.write(f"      vertex {i}.0 {i}.0 0.0\n")
                    f.write(f"      vertex {i+1}.0 {i}.0 0.0\n")
                    f.write(f"      vertex {i}.0 {i+1}.0 0.0\n")
                    f.write("    endloop\n")
                    f.write("  endfacet\n")
                
                f.write("endsolid solomond_generated\n")
            
            return True
            
        except Exception as e:
            logger.error(f"STL íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_obj_file(self, file_path: str, model_data: Dict) -> bool:
        """OBJ íŒŒì¼ ìƒì„±"""
        try:
            with open(file_path, 'w') as f:
                f.write("# Solomond AI Generated OBJ\n")
                f.write("# 3D Model from Image\n\n")
                
                # ì •ì  ë°ì´í„° (ì˜ˆì‹œ)
                f.write("v 0.0 0.0 0.0\n")
                f.write("v 1.0 0.0 0.0\n")
                f.write("v 0.0 1.0 0.0\n")
                f.write("\n")
                
                # ë©´ ë°ì´í„°
                f.write("f 1 2 3\n")
            
            return True
            
        except Exception as e:
            logger.error(f"OBJ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_ply_file(self, file_path: str, model_data: Dict) -> bool:
        """PLY íŒŒì¼ ìƒì„±"""
        try:
            with open(file_path, 'w') as f:
                f.write("ply\n")
                f.write("format ascii 1.0\n")
                f.write("element vertex 3\n")
                f.write("property float x\n")
                f.write("property float y\n")
                f.write("property float z\n")
                f.write("element face 1\n")
                f.write("property list uchar int vertex_indices\n")
                f.write("end_header\n")
                
                # ë°ì´í„°
                f.write("0.0 0.0 0.0\n")
                f.write("1.0 0.0 0.0\n")
                f.write("0.0 1.0 0.0\n")
                f.write("3 0 1 2\n")
            
            return True
            
        except Exception as e:
            logger.error(f"PLY íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    async def _prepare_export_info(self, cad_model: Dict, output_format: str, mesh_quality: str) -> Dict[str, Any]:
        """ë‚´ë³´ë‚´ê¸° ì •ë³´ ì¤€ë¹„"""
        if 'error' in cad_model:
            return {'error': 'ë‚´ë³´ë‚´ê¸° ì •ë³´ ìƒì„± ì‹¤íŒ¨'}
        
        return {
            'export_ready': True,
            'file_info': {
                'format': output_format,
                'quality': mesh_quality,
                'file_path': cad_model.get('file_path', ''),
                'file_size_mb': round(cad_model.get('file_size', 0) / (1024 * 1024), 2)
            },
            'usage_recommendations': [
                f"{output_format.upper()} íŒŒì¼ì€ ëŒ€ë¶€ë¶„ì˜ 3D ì†Œí”„íŠ¸ì›¨ì–´ì—ì„œ ì§€ì›ë©ë‹ˆë‹¤",
                "3D í”„ë¦°íŒ…ì„ ìœ„í•´ì„œëŠ” STL í˜•ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "CAD ì†Œí”„íŠ¸ì›¨ì–´ í¸ì§‘ì„ ìœ„í•´ì„œëŠ” OBJ í˜•ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                f"{mesh_quality} í’ˆì§ˆë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
            ],
            'next_steps': [
                "ìƒì„±ëœ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”",
                "3D ì†Œí”„íŠ¸ì›¨ì–´ì—ì„œ íŒŒì¼ì„ ì—´ì–´ í™•ì¸í•˜ì„¸ìš”",
                "í•„ìš”ì‹œ ì¶”ê°€ í¸ì§‘ ë° ìµœì í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”"
            ]
        }

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Module 4: 3D CAD ë³€í™˜ ì„œë¹„ìŠ¤",
    description="ì´ë¯¸ì§€ì—ì„œ 3D CAD ëª¨ë¸ ìƒì„±",
    version="4.0.0"
)

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
service = CADConversionService()

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    memory_stats = get_memory_stats()
    
    return {
        "status": "healthy",
        "service": "module4_3d_cad",
        "version": "4.0.0",
        "memory": {
            "memory_percent": memory_stats.get('memory_info', {}).get('percent', 0)
        },
        "capabilities": {
            "output_formats": len(service.output_formats),
            "quality_levels": len(service.quality_settings),
            "active_sessions": len(service.active_sessions),
            "ollama_available": "Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ í•„ìš”"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.post("/convert", response_model=CADResult)
async def convert_to_cad(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    generation_type: str = "basic",
    mesh_quality: str = "medium",
    output_format: str = "stl",
    use_ai_enhancement: bool = True,
    detail_level: int = 5
):
    """ì´ë¯¸ì§€ë¥¼ 3D CADë¡œ ë³€í™˜"""
    if not file.content_type or not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # í˜•ì‹ ë° í’ˆì§ˆ ê²€ì¦
    if output_format not in service.output_formats:
        raise HTTPException(status_code=400, detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¶œë ¥ í˜•ì‹: {output_format}")
    
    if mesh_quality not in service.quality_settings:
        raise HTTPException(status_code=400, detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë©”ì‰¬ í’ˆì§ˆ: {mesh_quality}")
    
    if not (1 <= detail_level <= 10):
        raise HTTPException(status_code=400, detail="ë””í…Œì¼ ë ˆë²¨ì€ 1-10 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤")
    
    # íŒŒì¼ ì½ê¸°
    file_data = await file.read()
    if len(file_data) == 0:
        raise HTTPException(status_code=400, detail="ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤")
    
    # ë³€í™˜ ì‹¤í–‰
    result = await service.convert_image_to_cad(
        file_data, file.filename, generation_type, 
        mesh_quality, output_format, use_ai_enhancement, detail_level
    )
    
    return result

@app.get("/download/{session_id}")
async def download_cad_file(session_id: str):
    """ìƒì„±ëœ CAD íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    if session_id not in service.active_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session = service.active_sessions[session_id]
    if session['status'] != 'completed':
        raise HTTPException(status_code=400, detail="ë³€í™˜ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì„ì‹œë¡œ íŒŒì¼ ê²½ë¡œ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì„¸ì…˜ì— ì €ì¥ëœ ê²½ë¡œ ì‚¬ìš©)
    temp_dir = tempfile.gettempdir()
    filename = f"solomond_cad_{session_id}.stl"
    file_path = os.path.join(temp_dir, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="CAD íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )

@app.get("/formats")
async def get_supported_formats():
    """ì§€ì›ë˜ëŠ” ì¶œë ¥ í˜•ì‹ ì¡°íšŒ"""
    return {
        "output_formats": service.output_formats,
        "quality_settings": {k: v for k, v in service.quality_settings.items()},
        "generation_types": ["basic", "advanced", "professional"],
        "detail_levels": "1-10 (ë‚®ìŒ-ë†’ìŒ)"
    }

@app.get("/sessions/{session_id}")
async def get_session_info(session_id: str):
    """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    if session_id not in service.active_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return service.active_sessions[session_id]

@app.get("/sessions")
async def list_sessions():
    """ì „ì²´ ì„¸ì…˜ ëª©ë¡"""
    return {
        "total_sessions": len(service.active_sessions),
        "sessions": service.active_sessions
    }

@app.get("/stats")
async def get_service_stats():
    """ì„œë¹„ìŠ¤ í†µê³„"""
    memory_stats = get_memory_stats()
    
    return {
        "service_info": {
            "name": "module4_3d_cad",
            "version": "4.0.0",
            "uptime": "ì‹¤í–‰ ì¤‘"
        },
        "memory": memory_stats,
        "sessions": {
            "total": len(service.active_sessions),
            "active": len([s for s in service.active_sessions.values() 
                          if s['status'] == 'processing']),
            "completed": len([s for s in service.active_sessions.values() 
                             if s['status'] == 'completed'])
        },
        "conversion_capabilities": {
            "output_formats": len(service.output_formats),
            "quality_levels": len(service.quality_settings),
            "ai_enhancement": "Ollama ê¸°ë°˜"
        }
    }

if __name__ == "__main__":
    logger.info("ğŸ—ï¸ Module 4 3D CAD ë³€í™˜ ì„œë¹„ìŠ¤ ì‹œì‘: http://localhost:8004")
    
    uvicorn.run(
        "module4_service:app",
        host="0.0.0.0", 
        port=8004,
        reload=True,
        log_level="info"
    )