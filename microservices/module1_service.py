#!/usr/bin/env python3
"""
ğŸ¯ Module 1: ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
- Streamlit UIì˜ í•µì‹¬ ê¸°ëŠ¥ì„ FastAPIë¡œ ë³€í™˜
- ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì €ì™€ ì™„ì „ í†µí•©
- í¬íŠ¸ ì¶©ëŒ í•´ê²° (8501 â†’ 8001)
"""

import logging
import asyncio
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn

# ìµœì í™”ëœ ì»´í¬ë„ŒíŠ¸ë“¤ import
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from core.optimized_ai_loader import optimized_loader
from core.smart_memory_manager import get_memory_stats
from core.robust_file_processor import robust_processor
from config.security_config import get_system_config

logger = logging.getLogger(__name__)

# Pydantic ëª¨ë¸ë“¤
class AnalysisRequest(BaseModel):
    """ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    session_id: Optional[str] = None
    analysis_type: str = "comprehensive"  # 'quick', 'comprehensive', 'detailed'
    context_info: Optional[Dict[str, Any]] = None

class AnalysisResult(BaseModel):
    """ë¶„ì„ ê²°ê³¼ ëª¨ë¸"""
    session_id: str
    status: str
    results: Dict[str, Any]
    processing_time: float
    timestamp: datetime

class ConferenceAnalysisService:
    """ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.active_sessions: Dict[str, Dict] = {}
        self.analysis_cache: Dict[str, Any] = {}
        
    async def analyze_files(self, files: List[UploadFile], 
                          analysis_type: str = "comprehensive",
                          context_info: Optional[Dict] = None) -> Dict[str, Any]:
        """íŒŒì¼ ë¶„ì„ ì‹¤í–‰"""
        session_id = str(uuid.uuid4())
        start_time = asyncio.get_event_loop().time()
        
        try:
            # ì„¸ì…˜ ì •ë³´ ì €ì¥
            self.active_sessions[session_id] = {
                'start_time': start_time,
                'status': 'processing',
                'files_count': len(files),
                'analysis_type': analysis_type
            }
            
            results = {
                'session_id': session_id,
                'files_processed': [],
                'audio_analysis': {},
                'image_analysis': {},
                'video_analysis': {},
                'summary': {}
            }
            
            # íŒŒì¼ë³„ ì²˜ë¦¬
            for file in files:
                file_result = await self._process_single_file(file, analysis_type)
                results['files_processed'].append(file_result)
                
                # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜
                if file_result['type'] == 'audio':
                    results['audio_analysis'][file.filename] = file_result
                elif file_result['type'] == 'image':
                    results['image_analysis'][file.filename] = file_result
                elif file_result['type'] == 'video':
                    results['video_analysis'][file.filename] = file_result
            
            # í†µí•© ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í™œìš©)
            if context_info:
                results['context'] = context_info
                results['summary'] = await self._generate_contextual_summary(
                    results, context_info
                )
            else:
                results['summary'] = await self._generate_summary(results)
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            # ì„¸ì…˜ ì™„ë£Œ
            self.active_sessions[session_id]['status'] = 'completed'
            self.active_sessions[session_id]['processing_time'] = processing_time
            
            return {
                'session_id': session_id,
                'status': 'success',
                'results': results,
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤íŒ¨ {session_id}: {e}")
            
            if session_id in self.active_sessions:
                self.active_sessions[session_id]['status'] = 'failed'
                self.active_sessions[session_id]['error'] = str(e)
            
            raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_single_file(self, file: UploadFile, 
                                 analysis_type: str) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        file_content = await file.read()
        file_size = len(file_content)
        file_extension = Path(file.filename).suffix.lower()
        
        result = {
            'filename': file.filename,
            'size_bytes': file_size,
            'extension': file_extension,
            'type': self._detect_file_type(file_extension),
            'analysis': {}
        }
        
        try:
            # íŒŒì¼ íƒ€ì…ë³„ ë¶„ì„
            if result['type'] == 'audio':
                result['analysis'] = await self._analyze_audio_file(
                    file_content, analysis_type
                )
            elif result['type'] == 'image':
                result['analysis'] = await self._analyze_image_file(
                    file_content, analysis_type
                )
            elif result['type'] == 'video':
                result['analysis'] = await self._analyze_video_file(
                    file_content, analysis_type
                )
            else:
                result['analysis'] = {'error': 'ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹'}
            
            result['status'] = 'success'
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file.filename}: {e}")
            result['status'] = 'failed'
            result['analysis'] = {'error': str(e)}
        
        return result
    
    def _detect_file_type(self, extension: str) -> str:
        """íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… ê°ì§€"""
        audio_exts = {'.mp3', '.wav', '.m4a', '.flac', '.ogg'}
        image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}
        video_exts = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv'}
        
        if extension in audio_exts:
            return 'audio'
        elif extension in image_exts:
            return 'image'
        elif extension in video_exts:
            return 'video'
        else:
            return 'unknown'
    
    async def _analyze_audio_file(self, content: bytes, 
                                analysis_type: str) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ (ê°•í™”ëœ íŒŒì¼ ì²˜ë¦¬ í¬í•¨)"""
        try:
            # robust_file_processorë¡œ íŒŒì¼ ì „ì²˜ë¦¬ (m4a â†’ wav ë³€í™˜ í¬í•¨)
            file_info = await robust_processor.process_file(
                content, "audio_file.tmp", target_format='.wav'
            )
            
            if file_info.conversion_path is None:
                return {'error': 'íŒŒì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨'}
            
            # Whisper STT ëª¨ë¸ ì‚¬ìš©
            model_size = "small" if analysis_type == "detailed" else "base"
            
            with optimized_loader.get_whisper_model(model_size) as whisper_model:
                result = whisper_model.transcribe(file_info.conversion_path)
                
                analysis_result = {
                    'transcript': result['text'],
                    'language': result.get('language', 'unknown'),
                    'confidence': getattr(result, 'avg_logprob', 0.0),
                    'segments': result.get('segments', []),
                    'model_used': f"whisper_{model_size}",
                    'file_info': {
                        'original_size': file_info.original_size,
                        'processed_size': file_info.processed_size,
                        'format_converted': file_info.is_converted,
                        'duration': file_info.duration
                    }
                }
                
                # ì¶”ê°€ ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ë³„)
                if analysis_type in ['comprehensive', 'detailed']:
                    analysis_result['speaker_info'] = self._analyze_speakers(result)
                    analysis_result['key_topics'] = self._extract_topics(result['text'])
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            robust_processor.cleanup_temp_files(file_info)
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    async def _analyze_image_file(self, content: bytes, 
                                analysis_type: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„ (ê°•í™”ëœ íŒŒì¼ ì²˜ë¦¬ í¬í•¨)"""
        try:
            # robust_file_processorë¡œ íŒŒì¼ ì „ì²˜ë¦¬
            file_info = await robust_processor.process_file(
                content, "image_file.tmp"
            )
            
            if file_info.conversion_path is None:
                return {'error': 'ì´ë¯¸ì§€ íŒŒì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨'}
            
            # EasyOCR ì‚¬ìš©
            languages = ['en', 'ko'] if analysis_type == 'detailed' else ['en']
            
            with optimized_loader.get_easyocr_reader(languages) as reader:
                ocr_results = reader.readtext(file_info.conversion_path)
                
                analysis_result = {
                    'text_blocks': [],
                    'total_text': '',
                    'languages_detected': languages,
                    'confidence_avg': 0.0,
                    'file_info': {
                        'original_size': file_info.original_size,
                        'processed_size': file_info.processed_size,
                        'format': file_info.format
                    }
                }
                
                total_confidence = 0
                for (bbox, text, confidence) in ocr_results:
                    analysis_result['text_blocks'].append({
                        'text': text,
                        'confidence': confidence,
                        'bbox': bbox
                    })
                    analysis_result['total_text'] += text + ' '
                    total_confidence += confidence
                
                if ocr_results:
                    analysis_result['confidence_avg'] = total_confidence / len(ocr_results)
                
                # ì¶”ê°€ ë¶„ì„
                if analysis_type in ['comprehensive', 'detailed']:
                    analysis_result['key_info'] = self._extract_key_info(
                        analysis_result['total_text']
                    )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            robust_processor.cleanup_temp_files(file_info)
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    async def _analyze_video_file(self, content: bytes, 
                                analysis_type: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ (ê¸°ë³¸ êµ¬í˜„)"""
        return {
            'message': 'ë¹„ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ ê°œë°œ ì˜ˆì •',
            'size_bytes': len(content),
            'analysis_type': analysis_type
        }
    
    def _analyze_speakers(self, whisper_result: Dict) -> Dict[str, Any]:
        """í™”ì ë¶„ì„ (ê¸°ë³¸ êµ¬í˜„)"""
        segments = whisper_result.get('segments', [])
        
        return {
            'total_segments': len(segments),
            'estimated_speakers': min(len(segments) // 10 + 1, 5),  # ì¶”ì •
            'speaking_time': sum(seg.get('end', 0) - seg.get('start', 0) 
                               for seg in segments)
        }
    
    def _extract_topics(self, text: str) -> List[str]:
        """ì£¼ìš” í† í”½ ì¶”ì¶œ (ê¸°ë³¸ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ë¶„ì„ í•„ìš”
        keywords = ['ì»¨í¼ëŸ°ìŠ¤', 'ë°œí‘œ', 'í† ë¡ ', 'ì§ˆë¬¸', 'ë‹µë³€', 'ì£¼ì–¼ë¦¬', 'ë³´ì„', 'ë‹¤ì´ì•„ëª¬ë“œ']
        found_topics = [kw for kw in keywords if kw in text]
        
        return found_topics or ['ì¼ë°˜ ëŒ€í™”']
    
    def _extract_key_info(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        return {
            'word_count': len(text.split()),
            'char_count': len(text),
            'has_numbers': any(c.isdigit() for c in text),
            'has_korean': any('\uac00' <= c <= '\ud7a3' for c in text)
        }
    
    async def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        return {
            'total_files': len(results['files_processed']),
            'audio_files': len(results['audio_analysis']),
            'image_files': len(results['image_analysis']),
            'video_files': len(results['video_analysis']),
            'processing_summary': 'ë¶„ì„ ì™„ë£Œ',
            'recommendations': ['ì¶”ê°€ ë¶„ì„ ê°€ëŠ¥', 'ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥']
        }
    
    async def _generate_contextual_summary(self, results: Dict[str, Any], 
                                         context: Dict[str, Any]) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìš”ì•½ ìƒì„±"""
        base_summary = await self._generate_summary(results)
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í™œìš©
        if context.get('event_type') == 'conference':
            base_summary['event_analysis'] = {
                'type': 'conference',
                'relevance': 'high',
                'insights': 'ì»¨í¼ëŸ°ìŠ¤ ë‚´ìš© ë¶„ì„ ì™„ë£Œ'
            }
        
        return base_summary

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Module 1: ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤",
    description="ìŒì„±, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ í†µí•© ë¶„ì„",
    version="4.0.0"
)

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
service = ConferenceAnalysisService()

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    memory_stats = get_memory_stats()
    
    return {
        "status": "healthy",
        "service": "module1_conference",
        "version": "4.0.0",
        "memory": {
            "loaded_models": memory_stats.get('loaded_models', 0),
            "memory_percent": memory_stats.get('memory_info', {}).get('percent', 0)
        },
        "timestamp": datetime.now().isoformat()
    }

@app.post("/analyze", response_model=AnalysisResult)
async def analyze_files(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    analysis_type: str = "comprehensive",
    context_info: Optional[str] = None
):
    """íŒŒì¼ ë¶„ì„ API"""
    if not files:
        raise HTTPException(status_code=400, detail="ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    
    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ íŒŒì‹±
    context = {}
    if context_info:
        try:
            import json
            context = json.loads(context_info)
        except:
            context = {"raw_context": context_info}
    
    # ë¶„ì„ ì‹¤í–‰
    result = await service.analyze_files(files, analysis_type, context)
    
    return result

@app.get("/sessions/{session_id}")
async def get_session_info(session_id: str):
    """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    if session_id not in service.active_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return service.active_sessions[session_id]

@app.get("/sessions")
async def list_sessions():
    """ì „ì²´ ì„¸ì…˜ ëª©ë¡"""
    return {
        "total_sessions": len(service.active_sessions),
        "sessions": service.active_sessions
    }

@app.get("/stats")
async def get_service_stats():
    """ì„œë¹„ìŠ¤ í†µê³„"""
    memory_stats = get_memory_stats()
    
    return {
        "service_info": {
            "name": "module1_conference",
            "version": "4.0.0",
            "uptime": "ì‹¤í–‰ ì¤‘"
        },
        "memory": memory_stats,
        "sessions": {
            "total": len(service.active_sessions),
            "active": len([s for s in service.active_sessions.values() 
                          if s['status'] == 'processing']),
            "completed": len([s for s in service.active_sessions.values() 
                             if s['status'] == 'completed'])
        },
        "file_processor": {
            "ffmpeg_available": robust_processor.ffmpeg_available,
            "max_file_size": robust_processor.max_file_size,
            "supported_formats": robust_processor.get_supported_formats()
        }
    }

@app.post("/analyze/large-file")
async def analyze_large_file(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    analysis_type: str = "comprehensive"
):
    """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í‚¹ ë¶„ì„"""
    session_id = str(uuid.uuid4())
    
    try:
        # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í‚¹ ì²˜ë¦¬
        async def chunk_callback(chunk_num: int, chunk_size: int, total_size: int):
            logger.info(f"ì²­í¬ {chunk_num} ì²˜ë¦¬ ì¤‘: {chunk_size} bytes, ì´ {total_size:,} bytes")
        
        # ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì²˜ë¦¬
        file_stream = file.file
        file_info = await robust_processor.process_large_file_chunked(
            file_stream, file.filename, chunk_callback
        )
        
        # ë¶„ì„ ì‹¤í–‰
        result = await service.analyze_files([file], analysis_type)
        
        return {
            "session_id": session_id,
            "status": "success",
            "file_info": {
                "filename": file.filename,
                "original_size": file_info.original_size,
                "processed_size": file_info.processed_size,
                "chunks_processed": "ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í‚¹ ì™„ë£Œ"
            },
            "analysis_result": result
        }
        
    except ValueError as e:
        if "íŒŒì¼ í¬ê¸° ì´ˆê³¼" in str(e):
            raise HTTPException(
                status_code=413, 
                detail=f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (ìµœëŒ€ {robust_processor.max_file_size:,} bytes)"
            )
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@app.get("/supported-formats")
async def get_supported_formats():
    """ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ ì¡°íšŒ"""
    formats = robust_processor.get_supported_formats()
    
    return {
        "file_processor": {
            "ffmpeg_available": robust_processor.ffmpeg_available,
            "max_file_size_bytes": robust_processor.max_file_size,
            "max_file_size_gb": round(robust_processor.max_file_size / (1024**3), 1),
            "chunk_size_mb": round(robust_processor.chunk_size / (1024**2), 1)
        },
        "supported_formats": formats,
        "format_details": {
            "audio": {
                "description": "ìŒì„± íŒŒì¼ (Whisper STTë¡œ ë¶„ì„)",
                "conversion": "m4a, mp3, aac â†’ wav (16kHz, ëª¨ë…¸)"
            },
            "image": {
                "description": "ì´ë¯¸ì§€ íŒŒì¼ (EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)",
                "languages": ["en", "ko"]
            },
            "video": {
                "description": "ë¹„ë””ì˜¤ íŒŒì¼ (ê¸°ë³¸ ì •ë³´ë§Œ ì¶”ì¶œ, í–¥í›„ í™•ì¥ ì˜ˆì •)",
                "status": "ê°œë°œ ì¤‘"
            }
        }
    }

if __name__ == "__main__":
    logger.info("ğŸ¯ Module 1 ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ ì‹œì‘: http://localhost:8001")
    
    uvicorn.run(
        "module1_service:app",
        host="0.0.0.0", 
        port=8001,
        reload=True,
        log_level="info"
    )