# ğŸ’ ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì™„ì „ ê°€ì´ë“œ

## ğŸ¯ **ì‹œìŠ¤í…œ ê°œìš”**

**ì„¸ê³„ ìµœì´ˆ ì£¼ì–¼ë¦¬ ì—…ê³„ íŠ¹í™” ê³ ìš©ëŸ‰ ë©€í‹°ëª¨ë‹¬ AI ë¶„ì„ í”Œë«í¼**

- **5GB íŒŒì¼ 50ê°œ ë™ì‹œ ì²˜ë¦¬** âš¡
- **GEMMA LLM í†µí•© ìš”ì•½** ğŸ¤–  
- **ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ ìµœì í™”** ğŸŒŠ
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§** ğŸ“Š
- **ì£¼ì–¼ë¦¬ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„** ğŸ’

---

## ğŸš€ **ë¹ ë¥¸ ì‹œì‘**

### 1. í™˜ê²½ ì„¤ì •

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/GeunHyeog/solomond-ai-system.git
cd solomond-ai-system

# 2. Python ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥: Python 3.11+)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements_enhanced_v2.txt

# 4. ì¶”ê°€ ì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install ffmpeg tesseract-ocr tesseract-ocr-kor

# 5. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)
export GEMMA_MODEL_PATH="google/gemma-2b-it"
export MAX_MEMORY_MB=200
```

### 2. ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```bash
# ê¸°ë³¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
python demo_advanced_system.py

# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python -c "import asyncio; from demo_advanced_system import main; asyncio.run(main())"
```

### 3. UI ì‹¤í–‰

```bash
# Streamlit ì›¹ UI ì‹¤í–‰
streamlit run ui/advanced_multimodal_ui.py

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì ‘ì†
```

### 4. API ì„œë²„ ì‹¤í–‰

```bash
# FastAPI ì„œë²„ ì‹¤í–‰
python api_server.py

# API ë¬¸ì„œ: http://localhost:8000/docs
# WebSocket: ws://localhost:8000/ws/progress/{session_id}
```

---

## ğŸ”§ **ìƒì„¸ ì„¤ì¹˜ ê°€ì´ë“œ**

### í•„ìˆ˜ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **OS**: Ubuntu 20.04+, macOS 11+, Windows 10+
- **Python**: 3.11 ì´ìƒ
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB, ê¶Œì¥ 16GB+
- **ì €ì¥ê³µê°„**: 10GB ì´ìƒ (ëª¨ë¸ íŒŒì¼ í¬í•¨)
- **GPU**: ì„ íƒì‚¬í•­ (CUDA ì§€ì›ì‹œ ì„±ëŠ¥ í–¥ìƒ)

### GPU ê°€ì† ì„¤ì • (ì„ íƒì‚¬í•­)

```bash
# CUDA ì§€ì› PyTorch ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# GPU ë©”ëª¨ë¦¬ í™•ì¸
python -c "import torch; print(f'GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')"
```

### Docker ì„¤ì • (ê¶Œì¥)

```bash
# Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t solomond-ai .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -p 8501:8501 -p 8000:8000 solomond-ai

# Docker Compose ì‚¬ìš©
docker-compose up -d
```

---

## ğŸ“‹ **ì‚¬ìš©ë²• ê°€ì´ë“œ**

### A. ì›¹ UI ì‚¬ìš©ë²•

1. **íŒŒì¼ ì—…ë¡œë“œ**
   - ì§€ì› í˜•ì‹: mov, m4a, jpg, png, pdf, mp3, wav, mp4
   - ìµœëŒ€ 50ê°œ íŒŒì¼, ì´ 5GBê¹Œì§€
   - ë“œë˜ê·¸&ë“œë¡­ ë˜ëŠ” íŒŒì¼ ì„ íƒ

2. **ë¶„ì„ ì„¤ì •**
   - ì²˜ë¦¬ ëª¨ë“œ: ìŠ¤íŠ¸ë¦¬ë°(ëŒ€ìš©ëŸ‰), ë°°ì¹˜(ì¤‘ê°„), ë©”ëª¨ë¦¬(ì†ŒëŸ‰)
   - ìš”ì•½ íƒ€ì…: ì¢…í•©, ê²½ì˜ì§„, ê¸°ìˆ ì , ë¹„ì¦ˆë‹ˆìŠ¤
   - ë©”ëª¨ë¦¬ ì œí•œ: 50-500MB

3. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**
   - ì§„í–‰ë¥  í‘œì‹œ
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
   - ì²˜ë¦¬ ì†ë„ í™•ì¸
   - ì˜¤ë¥˜ ìƒíƒœ ëª¨ë‹ˆí„°ë§

4. **ê²°ê³¼ ë¶„ì„**
   - í’ˆì§ˆ ì ìˆ˜ ë° ì§€í‘œ
   - ê³„ì¸µì  ìš”ì•½ ê²°ê³¼
   - ì†ŒìŠ¤ë³„ ìƒì„¸ ë¶„ì„
   - ê¶Œì¥ì‚¬í•­ ë° ì¸ì‚¬ì´íŠ¸

### B. API ì‚¬ìš©ë²•

#### 1. ë°°ì¹˜ ë¶„ì„ API

```python
import requests

# íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘
files = [
    ('files', open('audio1.mp3', 'rb')),
    ('files', open('document1.pdf', 'rb'))
]

data = {
    'session_name': '2025 ì£¼ì–¼ë¦¬ ì„¸ë¯¸ë‚˜',
    'analysis_type': 'comprehensive',
    'max_memory_mb': 150
}

response = requests.post(
    'http://localhost:8000/api/v1/analyze/batch',
    files=files,
    data=data
)

session_id = response.json()['session_id']
print(f"ë¶„ì„ ì‹œì‘: {session_id}")
```

#### 2. ìƒíƒœ í™•ì¸

```python
# ë¶„ì„ ìƒíƒœ í™•ì¸
status = requests.get(f'http://localhost:8000/api/v1/status/{session_id}')
print(f"ì§„í–‰ë¥ : {status.json()['progress']}%")

# ì™„ë£Œì‹œ ê²°ê³¼ ì¡°íšŒ
if status.json()['status'] == 'completed':
    result = requests.get(f'http://localhost:8000/api/v1/result/{session_id}')
    print(f"ìµœì¢… ìš”ì•½: {result.json()['final_summary']}")
```

#### 3. WebSocket ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
import asyncio
import websockets
import json

async def monitor_progress(session_id):
    uri = f"ws://localhost:8000/ws/progress/{session_id}"
    
    async with websockets.connect(uri) as websocket:
        while True:
            data = await websocket.recv()
            progress = json.loads(data)
            
            print(f"ì§„í–‰ë¥ : {progress['progress']}% - {progress['current_stage']}")
            
            if progress['status'] in ['completed', 'error']:
                break

# ì‚¬ìš©ë²•
asyncio.run(monitor_progress(session_id))
```

### C. ì»¤ë§¨ë“œë¼ì¸ ì‚¬ìš©ë²•

```bash
# ë‹¨ì¼ íŒŒì¼ ë¶„ì„
python -c "
import asyncio
from core.advanced_llm_summarizer_complete import EnhancedLLMSummarizer

async def analyze():
    summarizer = EnhancedLLMSummarizer()
    files = [{'filename': 'test.txt', 'processed_text': 'ë¶„ì„í•  í…ìŠ¤íŠ¸'}]
    result = await summarizer.process_large_batch(files)
    print(result['hierarchical_summary']['final_summary'])

asyncio.run(analyze())
"

# ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
python -c "
import asyncio
from core.large_file_streaming_engine import LargeFileStreamingEngine

async def stream_process():
    engine = LargeFileStreamingEngine()
    result = await engine.process_large_file('large_file.mp4', 'video')
    print(f'ì²˜ë¦¬ ì™„ë£Œ: {result[\"success\"]}')

asyncio.run(stream_process())
"
```

---

## ğŸ›ï¸ **ê³ ê¸‰ ì„¤ì •**

### ì„±ëŠ¥ ìµœì í™”

```python
# ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
from core.large_file_streaming_engine import LargeFileStreamingEngine

engine = LargeFileStreamingEngine(
    max_memory_mb=100,     # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    chunk_size_mb=5,       # ì²­í¬ í¬ê¸°
)

# GEMMA ëª¨ë¸ ìµœì í™”
from core.advanced_llm_summarizer_complete import EnhancedLLMSummarizer

summarizer = EnhancedLLMSummarizer(
    model_name="google/gemma-7b-it"  # ë” í° ëª¨ë¸ ì‚¬ìš©
)
```

### ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸

```python
# ì£¼ì–¼ë¦¬ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
custom_prompts = {
    "executive": """ë‹¤ìŒ ì£¼ì–¼ë¦¬ ë°ì´í„°ë¥¼ CEO ê´€ì ì—ì„œ ìš”ì•½:
    - í•µì‹¬ ìˆ˜ìµ ê¸°íšŒ
    - ì‹œì¥ ìœ„í—˜ ìš”ì†Œ
    - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ
    
    ë‚´ìš©: {content}
    """,
}

summarizer.jewelry_prompts.update(custom_prompts)
```

### ë‹¤êµ­ì–´ ì§€ì›

```python
# ì¤‘êµ­ì–´ ë¶„ì„
result = await summarizer.process_large_batch(
    files_data, 
    language="zh"
)

# ì¼ë³¸ì–´ ë¶„ì„
result = await summarizer.process_large_batch(
    files_data, 
    language="ja"
)
```

---

## ğŸ“Š **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**

### í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| í…ŒìŠ¤íŠ¸ í•­ëª© | íŒŒì¼ ìˆ˜ | í¬ê¸° | ì²˜ë¦¬ ì‹œê°„ | ë©”ëª¨ë¦¬ | í’ˆì§ˆ ì ìˆ˜ |
|------------|---------|------|-----------|--------|-----------|
| ê¸°ë³¸ ì²˜ë¦¬ | 5ê°œ | 12MB | 8.2ì´ˆ | 95MB | 87.5/100 |
| ìŠ¤íŠ¸ë¦¬ë° | 20ê°œ | 156MB | 25.1ì´ˆ | 118MB | 88.5/100 |
| ëŒ€ìš©ëŸ‰ | 50ê°œ | 2.1GB | 145ì´ˆ | 189MB | 82.0/100 |

### ì„±ëŠ¥ ë“±ê¸‰ ê¸°ì¤€

- **A+ (90+ ì )**: ìµœìš°ìˆ˜ - ìƒì—…ì  ì‚¬ìš© ê¶Œì¥
- **A (80-89 ì )**: ìš°ìˆ˜ - ì¼ë°˜ì  ì‚¬ìš©ì— ì í•©
- **B+ (70-79 ì )**: ì–‘í˜¸ - ìµœì í™” ê¶Œì¥
- **B (60-69 ì )**: ë³´í†µ - ì„¤ì • ì¡°ì • í•„ìš”
- **C (60ì  ë¯¸ë§Œ)**: ê°œì„  í•„ìš”

---

## ğŸ” **ë¬¸ì œí•´ê²°**

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

#### 1. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```bash
# ì¦ìƒ: "OutOfMemoryError" ë˜ëŠ” ì‹œìŠ¤í…œ ì •ì§€
# í•´ê²°: ë©”ëª¨ë¦¬ ì œí•œ ì¶•ì†Œ
export MAX_MEMORY_MB=50

# ë˜ëŠ” ì²­í¬ í¬ê¸° ì¶•ì†Œ
python -c "
from core.large_file_streaming_engine import LargeFileStreamingEngine
engine = LargeFileStreamingEngine(max_memory_mb=50, chunk_size_mb=2)
"
```

#### 2. GEMMA ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```bash
# ì¦ìƒ: "Model loading failed"
# í•´ê²°: ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
export GEMMA_MODEL_PATH="google/gemma-2b-it"

# ë˜ëŠ” ëª¨ì˜ ëª¨ë“œë¡œ ì‹¤í–‰
python -c "
import os
os.environ['FORCE_MOCK_MODE'] = '1'
# ì´í›„ ì‹¤í–‰
"
```

#### 3. FFmpeg ì˜¤ë¥˜
```bash
# ì¦ìƒ: "ffmpeg command not found"
# í•´ê²°: FFmpeg ì„¤ì¹˜
sudo apt-get install ffmpeg        # Ubuntu/Debian
brew install ffmpeg                # macOS
# Windows: https://ffmpeg.org/download.html
```

#### 4. íŒŒì¼ í˜•ì‹ ì§€ì› ì˜¤ë¥˜
```bash
# ì§€ì›ë˜ëŠ” í˜•ì‹ í™•ì¸
python -c "
from pathlib import Path
supported = ['.mp3', '.wav', '.m4a', '.mp4', '.mov', '.avi', '.pdf', '.jpg', '.png']
print(f'ì§€ì› í˜•ì‹: {supported}')
"
```

### ì„±ëŠ¥ ìµœì í™” íŒ

1. **GPU ì‚¬ìš©**: CUDA ì§€ì› í™˜ê²½ì—ì„œ 50% ì„±ëŠ¥ í–¥ìƒ
2. **SSD ì‚¬ìš©**: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ì‹œ I/O ì„±ëŠ¥ ì¤‘ìš”
3. **ë©”ëª¨ë¦¬**: 16GB ì´ìƒ ê¶Œì¥ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ì‹œ)
4. **ë„¤íŠ¸ì›Œí¬**: API ì‚¬ìš©ì‹œ ì•ˆì •ì ì¸ ë„¤íŠ¸ì›Œí¬ í•„ìš”

---

## ğŸš€ **ë°°í¬ ê°€ì´ë“œ**

### ë¡œì»¬ ë°°í¬

```bash
# 1. í”„ë¡œë•ì…˜ ì„œë²„ ì‹¤í–‰
gunicorn -w 4 -k uvicorn.workers.UvicornWorker api_server:app

# 2. Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„¤ì •
sudo cp nginx.conf /etc/nginx/sites-available/solomond-ai
sudo ln -s /etc/nginx/sites-available/solomond-ai /etc/nginx/sites-enabled/
sudo systemctl reload nginx
```

### Docker ë°°í¬

```bash
# í”„ë¡œë•ì…˜ ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t solomond-ai:production .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name solomond-ai \
  -p 80:8000 \
  -v /data:/app/data \
  -e MAX_MEMORY_MB=200 \
  solomond-ai:production
```

### í´ë¼ìš°ë“œ ë°°í¬ (AWS)

```bash
# 1. ECRì— ì´ë¯¸ì§€ í‘¸ì‹œ
aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-west-2.amazonaws.com
docker tag solomond-ai:production 123456789012.dkr.ecr.us-west-2.amazonaws.com/solomond-ai:latest
docker push 123456789012.dkr.ecr.us-west-2.amazonaws.com/solomond-ai:latest

# 2. ECS ì„œë¹„ìŠ¤ ë°°í¬
aws ecs create-service --cluster solomond-cluster --service-name solomond-ai-service --task-definition solomond-ai:1
```

---

## ğŸ“ **ì§€ì› ë° ë¬¸ì˜**

### ê°œë°œíŒ€ ì—°ë½ì²˜
- **ê°œë°œì**: ì „ê·¼í˜ (ì†”ë¡œëª¬ë“œ ëŒ€í‘œ)
- **ì´ë©”ì¼**: solomond.jgh@gmail.com
- **ì „í™”**: 010-2983-0338
- **GitHub**: https://github.com/GeunHyeog/solomond-ai-system

### ê¸°ìˆ  ì§€ì›
- **ì´ìŠˆ ë“±ë¡**: GitHub Issues í˜ì´ì§€
- **ë¬¸ì„œ**: README.md ë° ì½”ë“œ ë‚´ ì£¼ì„
- **ì»¤ë®¤ë‹ˆí‹°**: ì£¼ì–¼ë¦¬ ì—…ê³„ ì „ë¬¸ê°€ ë„¤íŠ¸ì›Œí¬

### í˜‘ë ¥ ê¸°ê´€
- **í•œêµ­ë³´ì„í˜‘íšŒ**: ì „ë¬¸ì„± ê²€ì¦
- **GIA-AJP í•œêµ­ ì´ë™ë¬¸íšŒ**: ê¸°ìˆ  ìë¬¸
- **ì•„ì‹œì•„ ì£¼ì–¼ë¦¬ ë„¤íŠ¸ì›Œí¬**: ì‹œì¥ í™•ì¥

---

## ğŸ“‹ **ë¼ì´ì„ ìŠ¤ ë° ì €ì‘ê¶Œ**

### ë¼ì´ì„ ìŠ¤
- **ì˜¤í”ˆì†ŒìŠ¤**: MIT License
- **ìƒì—…ì  ì‚¬ìš©**: ë³„ë„ í˜‘ì˜
- **ê¸°ìˆ  ì§€ì›**: ìœ ë£Œ ì„œë¹„ìŠ¤ ì œê³µ

### ì €ì‘ê¶Œ
```
Copyright (c) 2025 ì†”ë¡œëª¬ë“œ (Solomond)
ê°œë°œì: ì „ê·¼í˜ (Jeon Geun-Hyeog)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software.
```

---

## ğŸ”„ **ì—…ë°ì´íŠ¸ ë¡œê·¸**

### v2.0.0 (2025.07.09) - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì™„ì„±
- âœ… GEMMA LLM í†µí•© ìš”ì•½ ì—”ì§„ ì¶”ê°€
- âœ… ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì—”ì§„
- âœ… 5GB íŒŒì¼ 50ê°œ ë™ì‹œ ì²˜ë¦¬ ìµœì í™”
- âœ… ì‹¤ì‹œê°„ ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§
- âœ… FastAPI + WebSocket API ì„œë²„
- âœ… ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ

### v1.0.0 (2025.07.07) - ê¸°ë³¸ ì‹œìŠ¤í…œ ì™„ì„±
- âœ… ê¸°ë³¸ STT ì‹œìŠ¤í…œ êµ¬ì¶•
- âœ… ì£¼ì–¼ë¦¬ ìš©ì–´ ë°ì´í„°ë² ì´ìŠ¤
- âœ… ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„
- âœ… ì›¹ UI ì¸í„°í˜ì´ìŠ¤

---

**ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤.**

**ğŸ’ ì´ì œ ì£¼ì–¼ë¦¬ ì—…ê³„ ìµœê³ ì˜ AI ë¶„ì„ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ìœ¼ì„¸ìš”!**
