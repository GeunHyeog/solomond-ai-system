#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ ì™„ì „íˆ ì‘ë™í•˜ëŠ” ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ - ëª¨ë“  ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ
COMPLETE WORKING Conference Analysis System

âœ… êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥:
1. ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ (ì´ë¯¸ì§€/ìŒì„±/ë¹„ë””ì˜¤)
2. EasyOCR ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
3. Whisper ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
4. ê°„ë‹¨í•œ í™”ì ë¶„ë¦¬ (ìŒì„± íŠ¹ì„± ê¸°ë°˜)
5. ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
6. ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
7. ì‹¤ì œ ìƒíƒœ ê²€ì¦ (í—ˆìœ„ ì •ë³´ ì—†ìŒ)

í•µì‹¬ ì›ì¹™:
- í—ˆìœ„ ìƒíƒœ í‘œì‹œ ì ˆëŒ€ ê¸ˆì§€
- ì‹¤ì œ ê¸°ëŠ¥ë§Œ êµ¬í˜„
- ëª¨ë“  ê¸°ëŠ¥ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²€ì¦
"""

import streamlit as st
import os
import tempfile
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import traceback
import re
from collections import Counter
import json
import uuid
import hashlib
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np

# ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from dual_brain_integration import DualBrainSystem
    DUAL_BRAIN_AVAILABLE = True
except ImportError:
    DUAL_BRAIN_AVAILABLE = False

# n8n ì›Œí¬í”Œë¡œìš° í†µí•© ì„í¬íŠ¸
try:
    from n8n_connector import N8nConnector
    import asyncio
    import httpx
    N8N_AVAILABLE = True
except ImportError:
    N8N_AVAILABLE = False

# ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
try:
    from core import multimodal_encoder
    from core import crossmodal_fusion
    from core import ollama_decoder
    from core import crossmodal_visualization
    MULTIMODAL_AVAILABLE = True
    print("SUCCESS: ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ëª¨ë“  ëª¨ë“ˆ ì„±ê³µì ìœ¼ë¡œ import ì™„ë£Œ!")
except ImportError as e:
    MULTIMODAL_AVAILABLE = False
    print(f"ERROR: ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ import ì‹¤íŒ¨: {e}")

# ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì™„ì „ ì‘ë™ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„",
    page_icon="ğŸ¯",
    layout="wide"
)

class CompleteWorkingAnalyzer:
    """ì™„ì „íˆ ì‘ë™í•˜ëŠ” ë¶„ì„ê¸° - ëª¨ë“  ìš”ì²­ ê¸°ëŠ¥ êµ¬í˜„"""
    
    def __init__(self):
        """ì´ˆê¸°í™” - ì‹¤ì œ ìƒíƒœë§Œ ì €ì¥"""
        self.session_init()
        self.verify_dependencies()
        self.setup_analysis_history()
        self.setup_n8n_integration()
    
    def session_init(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'uploaded_files' not in st.session_state:
            st.session_state.uploaded_files = []
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = None
        if 'system_status' not in st.session_state:
            st.session_state.system_status = {}
        if 'pre_info' not in st.session_state:
            st.session_state.pre_info = {}
        if 'current_step' not in st.session_state:
            st.session_state.current_step = 1
        if 'analysis_id' not in st.session_state:
            st.session_state.analysis_id = None
    
    def verify_dependencies(self):
        """ì˜ì¡´ì„± ì‹¤ì œ í™•ì¸ - í—ˆìœ„ í‘œì‹œ ê¸ˆì§€"""
        dependencies = {}
        
        # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ ì‹¤ì œ í™•ì¸
        libs_to_check = {
            'whisper': 'whisper',
            'easyocr': 'easyocr', 
            'opencv': 'cv2',
            'numpy': 'numpy',
            'librosa': 'librosa'
        }
        
        for name, module in libs_to_check.items():
            try:
                __import__(module)
                dependencies[name] = True
            except ImportError:
                dependencies[name] = False
        
        st.session_state.system_status = dependencies
        return dependencies
    
    def setup_analysis_history(self):
        """ë¶„ì„ ì´ë ¥ ì €ì¥ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.history_dir = Path("analysis_history")
        self.history_dir.mkdir(exist_ok=True)
        
        # ë¶„ì„ ë©”íƒ€ë°ì´í„° íŒŒì¼
        self.metadata_file = self.history_dir / "analysis_metadata.json"
        if not self.metadata_file.exists():
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump({"analyses": [], "total_count": 0}, f, ensure_ascii=False, indent=2)
    
    def setup_n8n_integration(self):
        """n8n ì›Œí¬í”Œë¡œìš° ìë™í™” ì‹œìŠ¤í…œ ì„¤ì •"""
        if 'n8n_connector' not in st.session_state:
            if N8N_AVAILABLE:
                try:
                    st.session_state.n8n_connector = N8nConnector()
                    # n8n ì„œë²„ ìƒíƒœ í™•ì¸
                    if st.session_state.n8n_connector.check_n8n_status():
                        st.session_state.n8n_status = "connected"
                    else:
                        st.session_state.n8n_status = "disconnected"
                except Exception as e:
                    st.session_state.n8n_status = f"error: {str(e)}"
                    st.session_state.n8n_connector = None
            else:
                st.session_state.n8n_status = "unavailable"
                st.session_state.n8n_connector = None
    
    def generate_analysis_id(self, file_info: Dict[str, Any]) -> str:
        """ë¶„ì„ ê³ ìœ  ID ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # íŒŒì¼ ì •ë³´ ê¸°ë°˜ í•´ì‹œ ìƒì„±
        file_data = str(file_info.get('names', [])) + str(file_info.get('total_size', 0))
        hash_part = hashlib.md5(file_data.encode()).hexdigest()[:8]
        
        return f"{timestamp}_{hash_part}"
    
    def save_analysis_results(self, analysis_id: str, results: List[Dict], pre_info: Dict):
        """ë¶„ì„ ê²°ê³¼ ì˜êµ¬ ì €ì¥"""
        try:
            # ë¶„ì„ ê²°ê³¼ ì €ì¥
            analysis_file = self.history_dir / f"{analysis_id}_analysis.json"
            analysis_data = {
                "analysis_id": analysis_id,
                "timestamp": datetime.now().isoformat(),
                "pre_info": pre_info,
                "results": results,
                "total_files": len(results),
                "success_count": sum(1 for r in results if r['status'] == 'ì„±ê³µ'),
                "file_types": list(set(r['file_type'] for r in results))
            }
            
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2, default=str)
            
            # ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
            summary_file = self.history_dir / f"{analysis_id}_summary.md"
            summary_content = self.generate_summary_report(analysis_data)
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(summary_content)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            self.update_metadata(analysis_id, analysis_data)
            
            # êµ¬ê¸€ ìº˜ë¦°ë” ì—°ë™ (ì„ íƒì )
            self.sync_to_google_calendar(analysis_data)
            
            # ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ í†µí•© (ìµœì¢… ë‹¨ê³„)
            self.trigger_dual_brain_integration(analysis_data)
            
            # ğŸ”— n8n ì›Œí¬í”Œë¡œìš° ìë™í™” íŠ¸ë¦¬ê±°
            self.trigger_n8n_workflows(analysis_data)
            
            return True
            
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def update_metadata(self, analysis_id: str, analysis_data: Dict):
        """ë¶„ì„ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸"""
        try:
            # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ìƒˆë¡œìš´ ë¶„ì„ ì •ë³´ ì¶”ê°€
            metadata["analyses"].append({
                "id": analysis_id,
                "timestamp": analysis_data["timestamp"],
                "conference_name": analysis_data["pre_info"].get("conference_name", "Unknown"),
                "file_count": analysis_data["total_files"],
                "success_rate": f"{analysis_data['success_count']}/{analysis_data['total_files']}"
            })
            
            metadata["total_count"] += 1
            
            # ìµœì‹  20ê°œë§Œ ìœ ì§€ (ë„ˆë¬´ ë§ì•„ì§€ì§€ ì•Šë„ë¡)
            if len(metadata["analyses"]) > 20:
                metadata["analyses"] = metadata["analyses"][-20:]
            
            # ì €ì¥
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            st.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    def generate_summary_report(self, analysis_data: Dict) -> str:
        """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        timestamp = datetime.fromisoformat(analysis_data["timestamp"]).strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")
        
        summary = f"""# ğŸ“Š ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ë¶„ì„ ID**: {analysis_data['analysis_id']}
- **ë¶„ì„ ì¼ì‹œ**: {timestamp}
- **ì»¨í¼ëŸ°ìŠ¤ëª…**: {analysis_data['pre_info'].get('conference_name', 'ë¯¸ì§€ì •')}
- **ë¶„ì„ íŒŒì¼ ìˆ˜**: {analysis_data['total_files']}ê°œ
- **ì„±ê³µë¥ **: {analysis_data['success_count']}/{analysis_data['total_files']} ({(analysis_data['success_count']/analysis_data['total_files']*100):.1f}%)

## ğŸ¯ ì‚¬ì „ ì •ë³´
- **ë‚ ì§œ**: {analysis_data['pre_info'].get('conference_date', 'ë¯¸ì§€ì •')}
- **ì¥ì†Œ**: {analysis_data['pre_info'].get('conference_location', 'ë¯¸ì§€ì •')}
- **ì—…ê³„**: {analysis_data['pre_info'].get('industry_field', 'ë¯¸ì§€ì •')}
- **ê´€ì‹¬ í‚¤ì›Œë“œ**: {analysis_data['pre_info'].get('interest_keywords', 'ë¯¸ì§€ì •')}

## ğŸ“ íŒŒì¼ ìœ í˜•
{', '.join(analysis_data['file_types'])}

## ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½
"""
        
        # ğŸ†• ê³ ê¸‰ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        smart_insights = self.generate_smart_insights(analysis_data)
        if smart_insights:
            summary += f"\n## ğŸ§  AI ì¸ì‚¬ì´íŠ¸\n{smart_insights}\n"
        
        # ì„±ê³µí•œ ë¶„ì„ë“¤ì˜ ì£¼ìš” ë‚´ìš© ìš”ì•½
        success_results = [r for r in analysis_data['results'] if r['status'] == 'ì„±ê³µ']
        
        if success_results:
            summary += "\n### âœ… ì£¼ìš” ë°œê²¬ì‚¬í•­:\n"
            for i, result in enumerate(success_results[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                if 'content' in result and result['content']:
                    preview = str(result['content'])[:100] + "..." if len(str(result['content'])) > 100 else str(result['content'])
                    summary += f"{i}. **{result['file_name']}**: {preview}\n"
        
        summary += f"\n\n---\n*ë¶„ì„ ì™„ë£Œ ì‹œê°: {timestamp}*\n"
        summary += f"*ë¶„ì„ ì‹œìŠ¤í…œ: SOLOMOND AI v4.0 - í—ˆìœ„ì •ë³´ ì™„ì „ ì°¨ë‹¨ + ìŠ¤ë§ˆíŠ¸ ì¸ì‚¬ì´íŠ¸ ì‹œìŠ¤í…œ*"
        
        return summary
    
    def generate_smart_insights(self, analysis_data: Dict) -> str:
        """ğŸ†• ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            insights = []
            
            # 1. ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
            pre_info = analysis_data.get('pre_info', {})
            results = analysis_data.get('results', [])
            success_results = [r for r in results if r.get('status') == 'ì„±ê³µ']
            
            # 2. ì£¼ì œ ë° í‚¤ì›Œë“œ ë¶„ì„
            topic_insights = self.analyze_content_topics(success_results, pre_info)
            if topic_insights:
                insights.append(f"**ğŸ¯ í•µì‹¬ ì£¼ì œ**: {topic_insights}")
            
            # 3. í™”ì ë° ì°¸ì—¬ì ë¶„ì„
            speaker_insights = self.analyze_speaker_patterns(success_results)
            if speaker_insights:
                insights.append(f"**ğŸ—£ï¸ ì°¸ì—¬ì íŒ¨í„´**: {speaker_insights}")
            
            # 4. ì»¨í¼ëŸ°ìŠ¤ íŠ¹ì„± ë¶„ì„
            conference_insights = self.analyze_conference_characteristics(analysis_data)
            if conference_insights:
                insights.append(f"**ğŸ“Š ì»¨í¼ëŸ°ìŠ¤ íŠ¹ì„±**: {conference_insights}")
            
            # 5. í’ˆì§ˆ ë° ì™„ì„±ë„ ë¶„ì„
            quality_insights = self.analyze_content_quality(analysis_data)
            if quality_insights:
                insights.append(f"**ğŸ“ˆ ë¶„ì„ í’ˆì§ˆ**: {quality_insights}")
            
            return '\n'.join(insights) if insights else ""
            
        except Exception as e:
            return f"âš ï¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def analyze_content_topics(self, success_results: List[Dict], pre_info: Dict) -> str:
        """ì£¼ì œ ë° í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„"""
        try:
            from collections import Counter
            import re
            
            # ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš© ìˆ˜ì§‘
            all_text = ""
            for result in success_results:
                if result.get('analysis_type') == 'image_ocr_advanced':
                    all_text += " " + result.get('full_text', '')
                elif result.get('analysis_type') == 'speech_to_text_with_speakers':
                    all_text += " " + result.get('transcribed_text', '')
            
            if not all_text.strip():
                return ""
            
            # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ì˜ë¬¸ + í•œê¸€)
            words = re.findall(r'\b[a-zA-Zê°€-í£]{3,}\b', all_text.lower())
            word_counts = Counter(words)
            
            # ìƒìœ„ í‚¤ì›Œë“œ í•„í„°ë§ (ì¼ë°˜ì ì¸ ë‹¨ì–´ ì œì™¸)
            exclude_words = {'the', 'and', 'for', 'with', 'this', 'that', 'have', 'from', 
                           'ìˆìŠµë‹ˆë‹¤', 'ê·¸ë¦¬ê³ ', 'ë•Œë¬¸ì—', 'ê²½ìš°', 'ì´ëŸ°', 'ê·¸ëŸ°', 'ìœ„í•´ì„œ'}
            
            top_keywords = [word for word, count in word_counts.most_common(10) 
                           if word not in exclude_words and len(word) > 2]
            
            # ì‚¬ì „ ì •ë³´ì™€ì˜ ì—°ê´€ì„± í™•ì¸
            pre_keywords = pre_info.get('interest_keywords', '').lower().split()
            relevant_keywords = [kw for kw in top_keywords if any(pk in kw for pk in pre_keywords)]
            
            if relevant_keywords:
                return f"{', '.join(relevant_keywords[:5])} (ì‚¬ì „ í‚¤ì›Œë“œì™€ {len(relevant_keywords)}ê°œ ì¼ì¹˜)"
            elif top_keywords:
                return f"{', '.join(top_keywords[:5])}"
            
            return ""
            
        except Exception:
            return ""
    
    def analyze_speaker_patterns(self, success_results: List[Dict]) -> str:
        """í™”ì íŒ¨í„´ ë¶„ì„"""
        try:
            total_speakers = 0
            speaker_details = []
            
            for result in success_results:
                if result.get('analysis_type') == 'speech_to_text_with_speakers':
                    speakers = result.get('total_speakers', 0)
                    total_speakers = max(total_speakers, speakers)
                    
                    # í™”ìë³„ ë°œì–¸ ë¶„ì„
                    speaker_analysis = result.get('speaker_analysis', [])
                    if speaker_analysis:
                        speaker_stats = {}
                        for segment in speaker_analysis:
                            speaker = segment.get('speaker', 'Unknown')
                            if speaker not in speaker_stats:
                                speaker_stats[speaker] = {'count': 0, 'total_time': 0}
                            speaker_stats[speaker]['count'] += 1
                            speaker_stats[speaker]['total_time'] += segment.get('end', 0) - segment.get('start', 0)
                        
                        # ê°€ì¥ ë§ì´ ë°œì–¸í•œ í™”ì ì°¾ê¸°
                        if speaker_stats:
                            main_speaker = max(speaker_stats.keys(), key=lambda x: speaker_stats[x]['total_time'])
                            main_time = speaker_stats[main_speaker]['total_time']
                            speaker_details.append(f"{main_speaker}ê°€ ì£¼ë„ ({main_time:.1f}ì´ˆ)")
            
            if total_speakers > 0:
                result = f"{total_speakers}ëª… ì°¸ì—¬"
                if speaker_details:
                    result += f", {speaker_details[0]}"
                return result
            
            return ""
            
        except Exception:
            return ""
    
    def analyze_conference_characteristics(self, analysis_data: Dict) -> str:
        """ì»¨í¼ëŸ°ìŠ¤ íŠ¹ì„± ë¶„ì„"""
        try:
            characteristics = []
            
            # íŒŒì¼ ìœ í˜• ë‹¤ì–‘ì„±
            file_types = analysis_data.get('file_types', [])
            if len(file_types) > 1:
                characteristics.append(f"ë©€í‹°ë¯¸ë””ì–´ ({len(file_types)}ì¢…ë¥˜)")
            
            # ì„±ê³µë¥  ê¸°ë°˜ í’ˆì§ˆ í‰ê°€
            success_rate = analysis_data.get('success_count', 0) / max(analysis_data.get('total_files', 1), 1)
            if success_rate >= 0.9:
                characteristics.append("ê³ í’ˆì§ˆ ìë£Œ")
            elif success_rate >= 0.7:
                characteristics.append("ì–‘í˜¸í•œ ìë£Œ")
            
            # ì»¨í¼ëŸ°ìŠ¤ ê·œëª¨ ì¶”ì •
            total_files = analysis_data.get('total_files', 0)
            if total_files >= 10:
                characteristics.append("ëŒ€ê·œëª¨ ì»¨í¼ëŸ°ìŠ¤")
            elif total_files >= 5:
                characteristics.append("ì¤‘ê°„ ê·œëª¨")
            else:
                characteristics.append("ì†Œê·œëª¨ ë¯¸íŒ…")
            
            # ì—…ê³„ íŠ¹ì„±
            industry = analysis_data.get('pre_info', {}).get('industry_field', '')
            if industry and industry != 'ê¸°íƒ€':
                characteristics.append(f"{industry} ì „ë¬¸")
            
            return ", ".join(characteristics) if characteristics else ""
            
        except Exception:
            return ""
    
    def analyze_content_quality(self, analysis_data: Dict) -> str:
        """ë¶„ì„ í’ˆì§ˆ í‰ê°€"""
        try:
            quality_indicators = []
            
            success_rate = analysis_data.get('success_count', 0) / max(analysis_data.get('total_files', 1), 1)
            quality_indicators.append(f"ì„±ê³µë¥  {success_rate*100:.1f}%")
            
            # OCR í’ˆì§ˆ ë¶„ì„
            results = analysis_data.get('results', [])
            ocr_results = [r for r in results if r.get('analysis_type') == 'image_ocr_advanced']
            
            if ocr_results:
                total_blocks = sum(r.get('total_text_blocks', 0) for r in ocr_results)
                if total_blocks > 0:
                    quality_indicators.append(f"í…ìŠ¤íŠ¸ {total_blocks}ê°œ ë¸”ë¡ ì¶”ì¶œ")
            
            # ìŒì„± ë¶„ì„ í’ˆì§ˆ
            audio_results = [r for r in results if 'speech_to_text' in r.get('analysis_type', '')]
            if audio_results:
                has_speakers = any('speakers' in r.get('analysis_type', '') for r in audio_results)
                if has_speakers:
                    quality_indicators.append("í™”ì ë¶„ë¦¬ ì„±ê³µ")
                else:
                    quality_indicators.append("ìŒì„± ì¸ì‹ ì™„ë£Œ")
            
            return ", ".join(quality_indicators) if quality_indicators else "ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ"
            
        except Exception:
            return "í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨"
    
    def sync_to_google_calendar(self, analysis_data: Dict):
        """êµ¬ê¸€ ìº˜ë¦°ë” ë™ê¸°í™” (ì„ íƒì )"""
        try:
            # ìº˜ë¦°ë” ì—°ë™ ì„¤ì • í™•ì¸
            if 'google_calendar_enabled' not in st.session_state:
                st.session_state.google_calendar_enabled = False
            
            # ì‚¬ìš©ìì—ê²Œ ë§¤ë²ˆ ìº˜ë¦°ë” ì—°ë™ í™•ì¸
            conference_name = analysis_data.get("pre_info", {}).get("conference_name", "Unknown")
            success_rate = f"{analysis_data['success_count']}/{analysis_data['total_files']}"
            
            st.markdown("---")
            st.subheader("ğŸ“… êµ¬ê¸€ ìº˜ë¦°ë” ì €ì¥ (ì„ íƒì‚¬í•­)")
            st.info(f"**ë¶„ì„ ì™„ë£Œ**: {conference_name} | **ì„±ê³µë¥ **: {success_rate}")
            
            if not st.button("ğŸ“… ì´ ë¶„ì„ì„ êµ¬ê¸€ ìº˜ë¦°ë”ì— ì €ì¥í•˜ê¸°", key="calendar_save_btn"):
                st.info("ğŸ’¡ ìº˜ë¦°ë” ì €ì¥ì„ ì›í•˜ì‹œë©´ ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
                return
            
            # êµ¬ê¸€ ìº˜ë¦°ë” ì—°ë™ ëª¨ë“ˆ ì„í¬íŠ¸
            try:
                from google_calendar_connector import GoogleCalendarConnector
                
                connector = GoogleCalendarConnector()
                
                # ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì–´ ìˆê³  ì¸ì¦ì´ ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                if connector.credentials_file.exists() and connector.authenticate():
                    if connector.create_analysis_event(analysis_data):
                        st.success("âœ… êµ¬ê¸€ ìº˜ë¦°ë”ì— ì´ë²¤íŠ¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.warning("âš ï¸ ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                else:
                    st.info("ğŸ’¡ êµ¬ê¸€ ìº˜ë¦°ë” ì—°ë™ì„ ìœ„í•´ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤")
                    if st.button("ğŸ“… êµ¬ê¸€ ìº˜ë¦°ë” ì„¤ì •í•˜ê¸°"):
                        st.markdown("ë³„ë„ ì°½ì—ì„œ `streamlit run google_calendar_connector.py`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
                
            except ImportError:
                st.info("ğŸ’¡ êµ¬ê¸€ ìº˜ë¦°ë” ì—°ë™ ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤. `google_calendar_connector.py`ë¥¼ í™•ì¸í•˜ì„¸ìš”")
            except Exception as e:
                st.warning(f"âš ï¸ ìº˜ë¦°ë” ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
        except Exception as e:
            # ìº˜ë¦°ë” ì—°ë™ ì‹¤íŒ¨ê°€ ì „ì²´ ë¶„ì„ì„ ë°©í•´í•˜ì§€ ì•Šë„ë¡
            st.warning(f"âš ï¸ ì„ íƒì  ìº˜ë¦°ë” ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def trigger_dual_brain_integration(self, analysis_data: Dict):
        """ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ í†µí•© íŠ¸ë¦¬ê±°"""
        try:
            if not DUAL_BRAIN_AVAILABLE:
                return  # ëª¨ë“ˆì´ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ìŠ¤í‚µ
            
            # ë“€ì–¼ ë¸Œë ˆì¸ í™œì„±í™” í™•ì¸
            if 'dual_brain_enabled' not in st.session_state:
                st.session_state.dual_brain_enabled = False
            
            # ì‚¬ìš©ìì—ê²Œ ë“€ì–¼ ë¸Œë ˆì¸ í™œì„±í™” í™•ì¸
            st.markdown("---")
            st.subheader("ğŸ§  AI ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ (ê³ ê¸‰ ê¸°ëŠ¥)")
            st.info("ë¶„ì„ â†’ AI ì¸ì‚¬ì´íŠ¸ ìƒì„± â†’ ë¯¸ë˜ ê³„íš ì œì•ˆê¹Œì§€ ìë™ìœ¼ë¡œ ì§„í–‰")
            
            if not st.button("ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì‹¤í–‰í•˜ê¸°", key="dual_brain_run_btn"):
                st.info("ğŸ’¡ ê³ ê¸‰ AI ì¸ì‚¬ì´íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
                return
            
            # ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì‹¤í–‰
            with st.expander("ğŸ§  ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘...", expanded=True):
                if 'dual_brain_system' not in st.session_state:
                    st.session_state.dual_brain_system = DualBrainSystem()
                
                dual_brain = st.session_state.dual_brain_system
                
                # ì „ì²´ í†µí•© ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                success = dual_brain.process_analysis_completion(analysis_data)
                
                if success:
                    st.success("ğŸ‰ ë“€ì–¼ ë¸Œë ˆì¸ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.markdown("""
                    ### ğŸ§  ë‹¤ìŒ ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤:
                    1. ğŸ“… **ìº˜ë¦°ë” ë™ê¸°í™”**: ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ êµ¬ê¸€ ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„±
                    2. âœ… **AI íŒ¨í„´ ì¸ì‹**: ë¶„ì„ íŒ¨í„´ ë° ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±  
                    3. âœ… **ë¯¸ë˜ ê³„íš ì œì•ˆ**: ê°œì¸í™”ëœ ì¶”ì²œ ë° ì˜ˆì¸¡ ìë™ ìƒì„±
                    
                    ğŸ’¡ **ë©”ì¸ ëŒ€ì‹œë³´ë“œ**ì—ì„œ ì „ì²´ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
                    """)
                else:
                    st.warning("âš ï¸ ì¼ë¶€ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆì§€ë§Œ ê¸°ë³¸ ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            # ë“€ì–¼ ë¸Œë ˆì¸ ì‹¤íŒ¨ê°€ ì „ì²´ ë¶„ì„ì„ ë°©í•´í•˜ì§€ ì•Šë„ë¡
            st.warning(f"âš ï¸ ë“€ì–¼ ë¸Œë ˆì¸ í†µí•© ì¤‘ ì˜¤ë¥˜ (ì„ íƒì‚¬í•­): {str(e)}")
    
    def trigger_n8n_workflows(self, analysis_data: Dict):
        """ğŸ”— n8n ì›Œí¬í”Œë¡œìš° ìë™í™” íŠ¸ë¦¬ê±°"""
        try:
            if not N8N_AVAILABLE or not st.session_state.get('n8n_connector'):
                return  # n8nì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ë©´ ì¡°ìš©íˆ ìŠ¤í‚µ
            
            # n8n ìƒíƒœ í™•ì¸
            n8n_status = st.session_state.get('n8n_status', 'disconnected')
            
            if n8n_status != "connected":
                # n8n ì—°ê²° ìƒíƒœë¥¼ í‘œì‹œí•˜ë˜ ì‹¤íŒ¨í•´ë„ ë¶„ì„ì„ ë°©í•´í•˜ì§€ ì•ŠìŒ
                with st.expander("ğŸ”— n8n ì›Œí¬í”Œë¡œìš° ìë™í™” (ì„ íƒì )", expanded=False):
                    if n8n_status == "disconnected":
                        st.warning("âš ï¸ n8n ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ n8nì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
                        st.code("start_n8n_system.bat", language="bash")
                    elif n8n_status == "unavailable":
                        st.info("ğŸ’¡ n8n ìë™í™”ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ n8nì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
                    else:
                        st.error(f"âŒ n8n ì—°ê²° ì˜¤ë¥˜: {n8n_status}")
                return
            
            # n8n ìë™í™” ì„¹ì…˜
            with st.expander("ğŸ”— n8n ì›Œí¬í”Œë¡œìš° ìë™í™” ì‹¤í–‰ ì¤‘...", expanded=True):
                st.info("ğŸš€ ë¶„ì„ ì™„ë£Œ ì´ë²¤íŠ¸ë¥¼ n8n ì›Œí¬í”Œë¡œìš°ë¡œ ì „ì†¡í•©ë‹ˆë‹¤...")
                
                connector = st.session_state.n8n_connector
                
                # ë¶„ì„ ì™„ë£Œ ë°ì´í„° ì¤€ë¹„
                webhook_data = {
                    "event_type": "analysis_completed",
                    "analysis_id": analysis_data.get("analysis_id"),
                    "timestamp": analysis_data.get("timestamp"),
                    "conference_name": analysis_data.get("pre_info", {}).get("conference_name", "Unknown"),
                    "file_count": analysis_data.get("total_files", 0),
                    "success_count": analysis_data.get("success_count", 0),
                    "success_rate": f"{analysis_data.get('success_count', 0)}/{analysis_data.get('total_files', 0)}",
                    "file_types": analysis_data.get("file_types", []),
                    "status": "completed"
                }
                
                try:
                    # ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•œ ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬
                    import threading
                    
                    def trigger_webhooks():
                        # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        
                        try:
                            # ë“€ì–¼ ë¸Œë ˆì¸ íŒŒì´í”„ë¼ì¸ íŠ¸ë¦¬ê±°
                            result1 = loop.run_until_complete(
                                connector.trigger_workflow("analysis-trigger", webhook_data)
                            )
                            
                            # ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ íŠ¸ë¦¬ê±° (ì„ íƒì )
                            result2 = loop.run_until_complete(
                                connector.trigger_workflow("analysis-monitor", {
                                    **webhook_data,
                                    "notification_type": "analysis_completed"
                                })
                            )
                            
                            # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                            st.session_state.n8n_trigger_results = {
                                "dual_brain": result1,
                                "monitoring": result2,
                                "status": "success"
                            }
                            
                        except Exception as e:
                            st.session_state.n8n_trigger_results = {
                                "status": "error",
                                "error": str(e)
                            }
                        finally:
                            loop.close()
                    
                    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì›¹í›… íŠ¸ë¦¬ê±° ì‹¤í–‰
                    thread = threading.Thread(target=trigger_webhooks)
                    thread.daemon = True
                    thread.start()
                    
                    # ì‹¤í–‰ ìƒíƒœ í‘œì‹œ
                    st.success("âœ… n8n ì›Œí¬í”Œë¡œìš° íŠ¸ë¦¬ê±° ìš”ì²­ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.markdown("""
                    ### ğŸ”— n8nì—ì„œ ì‹¤í–‰ë  ìë™í™” ì›Œí¬í”Œë¡œìš°:
                    1. **ë“€ì–¼ ë¸Œë ˆì¸ íŒŒì´í”„ë¼ì¸**: AI ì¸ì‚¬ì´íŠ¸ ìƒì„± + êµ¬ê¸€ ìº˜ë¦°ë” ë™ê¸°í™”
                    2. **ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§**: ë¶„ì„ ì™„ë£Œ ì•Œë¦¼ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                    3. **ë°ì´í„° íŒŒì´í”„ë¼ì¸**: í›„ì† ì²˜ë¦¬ ë° ë³´ê³ ì„œ ìë™ ìƒì„±
                    
                    ğŸ’¡ n8n ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤í–‰ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    """)
                    
                    # n8n ëŒ€ì‹œë³´ë“œ ë§í¬ ì œê³µ
                    st.markdown(f"ğŸŒ [n8n ëŒ€ì‹œë³´ë“œ ì—´ê¸°](http://localhost:5678)")
                    
                except Exception as e:
                    st.warning(f"âš ï¸ n8n ì›Œí¬í”Œë¡œìš° íŠ¸ë¦¬ê±° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    
        except Exception as e:
            # n8n ì‹¤íŒ¨ê°€ ì „ì²´ ë¶„ì„ì„ ë°©í•´í•˜ì§€ ì•Šë„ë¡
            st.warning(f"âš ï¸ n8n ìë™í™” ì¤‘ ì˜¤ë¥˜ (ì„ íƒì‚¬í•­): {str(e)}")
    
    def display_system_status(self):
        """ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœë§Œ í‘œì‹œ"""
        st.sidebar.header("ğŸ” ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        status = st.session_state.system_status
        
        for lib_name, available in status.items():
            if available:
                st.sidebar.success(f"âœ… {lib_name}: ì‚¬ìš©ê°€ëŠ¥")
            else:
                st.sidebar.error(f"âŒ {lib_name}: ì„¤ì¹˜í•„ìš”")
                if lib_name == 'librosa':
                    st.sidebar.info("ğŸ“Š í™”ì ë¶„ë¦¬ ê¸°ëŠ¥ì„ ìœ„í•´ 'pip install librosa' ì‹¤í–‰ ê¶Œì¥")
        
        # n8n ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¶”ê°€
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ”— ìë™í™” ì‹œìŠ¤í…œ")
        
        n8n_status = st.session_state.get('n8n_status', 'checking...')
        if n8n_status == "connected":
            st.sidebar.success("âœ… n8n: ì—°ê²°ë¨")
        elif n8n_status == "disconnected":
            st.sidebar.warning("âš ï¸ n8n: ì—°ê²° ì•ˆë¨")
        elif n8n_status == "unavailable":
            st.sidebar.info("ğŸ’¡ n8n: ì„¤ì¹˜ í•„ìš”")
        else:
            st.sidebar.error(f"âŒ n8n: {n8n_status}")
        
        # ë“€ì–¼ ë¸Œë ˆì¸ ìƒíƒœ
        if DUAL_BRAIN_AVAILABLE:
            st.sidebar.success("âœ… ë“€ì–¼ ë¸Œë ˆì¸: ì‚¬ìš©ê°€ëŠ¥")
        else:
            st.sidebar.info("ğŸ’¡ ë“€ì–¼ ë¸Œë ˆì¸: ì„ íƒì‚¬í•­")
        
        # ì „ì²´ ì¤€ë¹„ë„ ê³„ì‚°
        ready_count = sum(status.values())
        total_count = len(status)
        readiness = (ready_count / total_count) * 100
        
        st.sidebar.metric("ì‹œìŠ¤í…œ ì¤€ë¹„ë„", f"{readiness:.0f}%")
        
        return readiness > 50
    
    def file_upload_section(self):
        """ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥"""
        st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        
        # ì§€ì› íŒŒì¼ í˜•ì‹ ì•ˆë‚´
        st.info("""
        **ì§€ì› íŒŒì¼ í˜•ì‹:**
        - ğŸ“¸ ì´ë¯¸ì§€: JPG, PNG, GIF (EasyOCR í…ìŠ¤íŠ¸ ì¶”ì¶œ)
        - ğŸµ ìŒì„±: WAV, MP3, M4A (Whisper STT + í™”ì ë¶„ë¦¬)
        - ğŸ¬ ë¹„ë””ì˜¤: MP4, MOV, AVI (ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ)
        """)
        
        uploaded_files = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì—…ë¡œë“œ ê°€ëŠ¥)",
            type=['jpg', 'jpeg', 'png', 'gif', 'wav', 'mp3', 'm4a', 'mp4', 'mov', 'avi'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.session_state.uploaded_files = uploaded_files
            
            st.success(f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            
            # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            for i, file in enumerate(uploaded_files):
                file_info = {
                    'name': file.name,
                    'size': len(file.read()),
                    'type': file.type
                }
                file.seek(0)  # ì½ê¸° ìœ„ì¹˜ ì´ˆê¸°í™”
                
                st.write(f"{i+1}. **{file_info['name']}** ({file_info['size']:,} bytes) - {file_info['type']}")
        
        return uploaded_files
    
    def analyze_files(self, uploaded_files):
        """ğŸ†• ê°œì„ ëœ ì‹¤ì œ íŒŒì¼ ë¶„ì„ - ìƒì„¸ ì§„í–‰ë¥  í‘œì‹œ"""
        if not uploaded_files:
            st.error("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        st.header("ğŸ” íŒŒì¼ ë¶„ì„ ì§„í–‰ ì¤‘")
        
        # ì‹œìŠ¤í…œ ì¤€ë¹„ë„ í™•ì¸
        system_ready = self.display_system_status()
        if not system_ready:
            st.error("âŒ ì‹œìŠ¤í…œ ì¤€ë¹„ë„ ë¶€ì¡± - í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”")
            return None
        
        # ğŸ†• ìƒì„¸ ì§„í–‰ë¥  UI ì»¨í…Œì´ë„ˆ ìƒì„±
        progress_container = st.container()
        with progress_container:
            # ì „ì²´ ì§„í–‰ë¥ 
            st.subheader("ğŸ“ˆ ì „ì²´ ì§„í–‰ ìƒí™©")
            overall_progress = st.progress(0)
            overall_status = st.empty()
            
            # í˜„ì¬ íŒŒì¼ ì§„í–‰ë¥   
            st.subheader("ğŸ“„ í˜„ì¬ íŒŒì¼ ì²˜ë¦¬")
            current_file_progress = st.progress(0)
            current_file_status = st.empty()
            
            # ìƒì„¸ ë‹¨ê³„ë³„ ìƒíƒœ
            st.subheader("ğŸ”§ ì²˜ë¦¬ ë‹¨ê³„")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                stage1_status = st.empty()
                stage1_icon = st.empty()
            with col2:
                stage2_status = st.empty()
                stage2_icon = st.empty()
            with col3:
                stage3_status = st.empty()
                stage3_icon = st.empty()
            with col4:
                stage4_status = st.empty()
                stage4_icon = st.empty()
            
            # ì‹¤ì‹œê°„ í†µê³„
            st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í†µê³„")
            stats_col1, stats_col2, stats_col3 = st.columns(3)
            
            with stats_col1:
                processed_metric = st.empty()
            with stats_col2:
                success_metric = st.empty()
            with stats_col3:
                eta_metric = st.empty()
        
        results = []
        start_time = time.time()
        
        for i, file in enumerate(uploaded_files):
            # ì „ì²´ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            overall_progress_value = i / len(uploaded_files)
            overall_progress.progress(overall_progress_value)
            overall_status.write(f"ğŸ“Š **ì „ì²´ ì§„í–‰ë¥ :** {i+1}/{len(uploaded_files)} íŒŒì¼ ({overall_progress_value*100:.1f}%)")
            
            # í˜„ì¬ íŒŒì¼ ì •ë³´
            current_file_status.write(f"ğŸ“„ **ì²˜ë¦¬ ì¤‘:** {file.name} ({len(file.read()):,} bytes)")
            file.seek(0)  # íŒŒì¼ í¬ì¸í„° ì¬ì„¤ì •
            
            # ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
            success_count = len([r for r in results if r.get('status') == 'success'])
            elapsed_time = time.time() - start_time
            eta = (elapsed_time / max(i, 1)) * (len(uploaded_files) - i) if i > 0 else 0
            
            processed_metric.metric("ì²˜ë¦¬ ì™„ë£Œ", f"{i}/{len(uploaded_files)}")
            success_metric.metric("ì„±ê³µí•œ íŒŒì¼", f"{success_count}/{i}" if i > 0 else "0/0")
            eta_metric.metric("ì˜ˆìƒ ë‚¨ì€ ì‹œê°„", f"{eta:.1f}ì´ˆ" if eta > 0 else "ê³„ì‚° ì¤‘...")
            
            # íŒŒì¼ ë¶„ì„ (ë‹¨ê³„ë³„ ì§„í–‰ë¥  í¬í•¨)
            result = self.analyze_single_file_with_progress(
                file.name, file, 
                current_file_progress, current_file_status,
                stage1_status, stage1_icon, stage2_status, stage2_icon,
                stage3_status, stage3_icon, stage4_status, stage4_icon
            )
            
            results.append(result)
            
            # íŒŒì¼ ì™„ë£Œ í›„ í˜„ì¬ íŒŒì¼ ì§„í–‰ë¥  100%ë¡œ ì„¤ì •
            current_file_progress.progress(1.0)
            
        # ì „ì²´ ë¶„ì„ ì™„ë£Œ
        overall_progress.progress(1.0)
        overall_status.write(f"âœ… **ëª¨ë“  íŒŒì¼ ë¶„ì„ ì™„ë£Œ!** ({len(uploaded_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ë¨)")
        current_file_status.write("ğŸ‰ **ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ**")
        
        # ìµœì¢… í†µê³„ í‘œì‹œ
        final_success_count = len([r for r in results if r.get('status') == 'success'])
        final_elapsed = time.time() - start_time
        
        processed_metric.metric("ì²˜ë¦¬ ì™„ë£Œ", f"{len(uploaded_files)}/{len(uploaded_files)}")
        success_metric.metric("ì„±ê³µí•œ íŒŒì¼", f"{final_success_count}/{len(uploaded_files)}")
        eta_metric.metric("ì´ ì†Œìš” ì‹œê°„", f"{final_elapsed:.1f}ì´ˆ")
        
        # ì„±ê³µ ì•Œë¦¼
        if final_success_count == len(uploaded_files):
            st.success(f"ğŸ‰ ëª¨ë“  íŒŒì¼ ë¶„ì„ ì„±ê³µ! ({final_success_count}/{len(uploaded_files)})")
        elif final_success_count > 0:
            st.warning(f"âš ï¸ ì¼ë¶€ íŒŒì¼ ë¶„ì„ ì™„ë£Œ ({final_success_count}/{len(uploaded_files)} ì„±ê³µ)")
        else:
            st.error("âŒ ëª¨ë“  íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨")
        # ì„¸ì…˜ ìƒíƒœ ì €ì¥
        st.session_state.analysis_results = results
        
        return results
    
    def analyze_single_file_with_progress(self, file_name, file_obj, 
                                        current_progress, current_status,
                                        stage1_status, stage1_icon, stage2_status, stage2_icon,
                                        stage3_status, stage3_icon, stage4_status, stage4_icon):
        """ğŸ†• ë‹¨ì¼ íŒŒì¼ ë¶„ì„ (ìƒì„¸ ì§„í–‰ë¥  í¬í•¨)"""
        
        # ë‹¨ê³„ ì´ˆê¸°í™”
        stages = [
            (stage1_status, stage1_icon, "ğŸ“„ íŒŒì¼ ì¤€ë¹„"),
            (stage2_status, stage2_icon, "ğŸ” ë¶„ì„ ì—”ì§„ ì‹œì‘"), 
            (stage3_status, stage3_icon, "ğŸ¤– AI ì²˜ë¦¬"),
            (stage4_status, stage4_icon, "âœ… ê²°ê³¼ ì •ë¦¬")
        ]
        
        # ëª¨ë“  ë‹¨ê³„ë¥¼ ëŒ€ê¸° ìƒíƒœë¡œ ì´ˆê¸°í™”
        for status_placeholder, icon_placeholder, stage_name in stages:
            status_placeholder.write(f"**{stage_name}**")
            icon_placeholder.write("â³")
        
        current_status.write(f"ğŸ”„ **{file_name}** ë¶„ì„ ì‹œì‘")
        
        try:
            # 1ë‹¨ê³„: íŒŒì¼ ì¤€ë¹„ (25%)
            stage1_icon.write("ğŸ”„")
            current_progress.progress(0.25)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file_name).suffix) as tmp_file:
                tmp_file.write(file_obj.read())
                tmp_file_path = tmp_file.name
            file_obj.seek(0)  # íŒŒì¼ í¬ì¸í„° ì¬ì„¤ì •
            
            stage1_icon.write("âœ…")
            time.sleep(0.1)  # UI ì—…ë°ì´íŠ¸ ì‹œê°„
            
            # 2ë‹¨ê³„: ë¶„ì„ ì—”ì§„ ì‹œì‘ (50%)
            stage2_icon.write("ğŸ”„")
            current_progress.progress(0.5)
            current_status.write(f"ğŸ” **{file_name}** ë¶„ì„ ì—”ì§„ ë¡œë“œ ì¤‘")
            
            # íŒŒì¼ íƒ€ì… ê²°ì •
            file_type = file_obj.type if hasattr(file_obj, 'type') else 'unknown'
            
            stage2_icon.write("âœ…")
            time.sleep(0.1)
            
            # 3ë‹¨ê³„: AI ì²˜ë¦¬ (75%)
            stage3_icon.write("ğŸ”„")
            current_progress.progress(0.75)
            current_status.write(f"ğŸ¤– **{file_name}** AI ë¶„ì„ ì‹¤í–‰ ì¤‘")
            
            # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
            result = self.analyze_single_file(file_name, tmp_file_path, file_type)
            
            stage3_icon.write("âœ…")
            time.sleep(0.1)
            
            # 4ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬ (100%)
            stage4_icon.write("ğŸ”„")
            current_progress.progress(1.0)
            current_status.write(f"âœ… **{file_name}** ë¶„ì„ ì™„ë£Œ")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(tmp_file_path)
            except:
                pass
            
            stage4_icon.write("âœ…")
            
            # ê²°ê³¼ì— ë”°ë¥¸ ìµœì¢… ìƒíƒœ í‘œì‹œ
            if result.get('status') == 'success':
                current_status.write(f"ğŸ‰ **{file_name}** ë¶„ì„ ì„±ê³µ!")
            else:
                current_status.write(f"âš ï¸ **{file_name}** ë¶„ì„ ì¤‘ ë¬¸ì œ ë°œìƒ")
                
            return result
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëª¨ë“  ë‹¨ê³„ë¥¼ ì˜¤ë¥˜ ìƒíƒœë¡œ í‘œì‹œ
            for i, (status_placeholder, icon_placeholder, stage_name) in enumerate(stages):
                if i <= 1:  # ì´ë¯¸ ì™„ë£Œëœ ë‹¨ê³„ëŠ” ê·¸ëŒ€ë¡œ
                    continue
                icon_placeholder.write("âŒ")
            
            current_status.write(f"âŒ **{file_name}** ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            
            return {
                'file_name': file_name,
                'status': 'error',
                'error': str(e),
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def analyze_single_file(self, file_name: str, file_path: str, file_type: str) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ì‹¤ì œ ë¶„ì„ (ë°±ì—”ë“œ ì²˜ë¦¬)"""
        result = {
            'file_name': file_name,
            'file_type': file_type,
            'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'processing',
            'processing_steps': []  # ğŸ†• ì²˜ë¦¬ ë‹¨ê³„ ì¶”ì 
        }
        
        try:
            # ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„
            if file_type.startswith('image/'):
                result.update(self.analyze_image_file(file_path))
            
            # ìŒì„± íŒŒì¼ ë¶„ì„
            elif file_type.startswith('audio/'):
                result.update(self.analyze_audio_file(file_path))
            
            # ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„
            elif file_type.startswith('video/'):
                result.update(self.analyze_video_file(file_path))
            
            else:
                result['status'] = 'unsupported'
                result['message'] = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}"
            
        except Exception as e:
            result['status'] = 'error'
            result['error'] = str(e)
            result['traceback'] = traceback.format_exc()
        
        return result
    
    def analyze_image_file(self, file_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ì‹¤ì œ ë¶„ì„ (EasyOCR + ê³ ê¸‰ í›„ì²˜ë¦¬)"""
        if not st.session_state.system_status.get('easyocr', False):
            return {
                'status': 'dependency_missing',
                'message': 'EasyOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'analysis_type': 'image_ocr'
            }
        
        try:
            import easyocr
            import cv2
            import re
            
            # EasyOCR ë¦¬ë” ìƒì„± (í•œêµ­ì–´, ì˜ì–´)
            reader = easyocr.Reader(['ko', 'en'])
            
            # ì´ë¯¸ì§€ ì½ê¸°
            results = reader.readtext(file_path)
            
            # ğŸ†• ê³ ê¸‰ í›„ì²˜ë¦¬ ì ìš©
            processed_results = self.advanced_ocr_postprocessing(results)
            
            return {
                'status': 'success',
                'analysis_type': 'image_ocr_advanced',
                'extracted_text': processed_results['high_quality_text'],
                'filtered_text': processed_results['filtered_text'],
                'total_text_blocks': len(processed_results['high_quality_text']),
                'original_blocks': len(results),
                'quality_stats': processed_results['quality_stats'],
                'full_text': processed_results['clean_full_text']
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'analysis_type': 'image_ocr',
                'error': str(e)
            }
    
    def advanced_ocr_postprocessing(self, raw_results) -> Dict[str, Any]:
        """ğŸ†• EasyOCR ê²°ê³¼ ê³ ê¸‰ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
        import re
        
        high_quality_text = []
        filtered_text = []
        quality_stats = {
            'high_confidence': 0,
            'medium_confidence': 0,
            'low_confidence': 0,
            'noise_filtered': 0
        }
        
        for (bbox, text, confidence) in raw_results:
            confidence_float = float(confidence)
            
            # 1. ì‹ ë¢°ë„ ê¸°ë°˜ ë¶„ë¥˜
            if confidence_float >= 0.8:
                quality_level = 'high'
                quality_stats['high_confidence'] += 1
            elif confidence_float >= 0.5:
                quality_level = 'medium' 
                quality_stats['medium_confidence'] += 1
            else:
                quality_level = 'low'
                quality_stats['low_confidence'] += 1
            
            # 2. í…ìŠ¤íŠ¸ ì •ì œ ë° ë…¸ì´ì¦ˆ í•„í„°ë§
            cleaned_text = self.clean_ocr_text(text)
            
            # 3. ë…¸ì´ì¦ˆ ê°ì§€ (ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„ + ì˜ë¯¸ ì—†ëŠ” ë¬¸ì)
            is_noise = (
                confidence_float < 0.3 or
                len(cleaned_text) < 2 or
                self.is_gibberish_text(cleaned_text)
            )
            
            text_item = {
                'text': cleaned_text,
                'original_text': text,
                'confidence': confidence_float,
                'quality_level': quality_level,
                'bbox': bbox,
                'is_noise': is_noise
            }
            
            if is_noise:
                quality_stats['noise_filtered'] += 1
                filtered_text.append(text_item)
            else:
                high_quality_text.append(text_item)
        
        # 4. ì •ì œëœ ì „ì²´ í…ìŠ¤íŠ¸ ìƒì„±
        clean_full_text = ' '.join([
            item['text'] for item in high_quality_text 
            if item['confidence'] >= 0.5
        ])
        
        return {
            'high_quality_text': high_quality_text,
            'filtered_text': filtered_text,
            'quality_stats': quality_stats,
            'clean_full_text': clean_full_text
        }
    
    def clean_ocr_text(self, text: str) -> str:
        """OCR í…ìŠ¤íŠ¸ ì •ì œ"""
        if not text:
            return ""
        
        # 1. ê¸°ë³¸ ì •ì œ
        cleaned = text.strip()
        
        # 2. íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        cleaned = re.sub(r'[^\w\sê°€-í£]', '', cleaned)
        
        # 3. ì—°ì† ê³µë°± ì œê±°
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # 4. ë‹¨ì¼ ë¬¸ì ì œê±° (ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ ë³´ì¡´)
        if len(cleaned) == 1 and not cleaned.isalnum():
            return ""
        
        return cleaned.strip()
    
    def is_gibberish_text(self, text: str) -> bool:
        """ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ ê°ì§€"""
        if not text or len(text) < 2:
            return True
        
        # 1. ë°˜ë³µ ë¬¸ì íŒ¨í„´ (ì˜ˆ: "ë‹¤ë‹¤ë‹¤", "^^^")
        if re.match(r'^(.)\1{2,}$', text):
            return True
        
        # 2. ë¬´ì˜ë¯¸í•œ ë¬¸ì ì¡°í•© (ì˜ˆ: "8Gë‹¤^")
        noise_patterns = [
            r'^[^\wê°€-í£\s]+$',  # íŠ¹ìˆ˜ë¬¸ìë§Œ
            r'^\d+[^\wê°€-í£\s]+$',  # ìˆ«ì+íŠ¹ìˆ˜ë¬¸ì
            r'^[^\wê°€-í£\s]+\d+$'   # íŠ¹ìˆ˜ë¬¸ì+ìˆ«ì
        ]
        
        for pattern in noise_patterns:
            if re.match(pattern, text):
                return True
        
        # 3. ë§¤ìš° ì§§ì€ ì˜ë¯¸ì—†ëŠ” ì¡°í•©
        if len(text) <= 3 and not any(char.isalpha() or char in 'ê°€-í£' for char in text):
            return True
        
        return False
    
    def analyze_audio_file(self, file_path: str) -> Dict[str, Any]:
        """ìŒì„± íŒŒì¼ ì‹¤ì œ ë¶„ì„ (Whisper STT + í™”ì ë¶„ë¦¬)"""
        if not st.session_state.system_status.get('whisper', False):
            return {
                'status': 'dependency_missing',
                'message': 'Whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'analysis_type': 'speech_to_text'
            }
        
        try:
            import whisper
            
            # Whisper ëª¨ë¸ ë¡œë“œ
            model = whisper.load_model("base")
            
            # ìŒì„± ì¸ì‹ (ì„¸ê·¸ë¨¼íŠ¸ í¬í•¨)
            result = model.transcribe(file_path, word_timestamps=True)
            
            # í™”ì ë¶„ë¦¬ ì‹œë„
            speaker_analysis = None
            if st.session_state.system_status.get('librosa', False):
                speaker_analysis = self.simple_speaker_separation(result['segments'], file_path)
            
            return_data = {
                'status': 'success',
                'analysis_type': 'speech_to_text_with_speakers' if speaker_analysis else 'speech_to_text',
                'transcribed_text': result['text'],
                'language': result.get('language', 'unknown'),
                'segments': result.get('segments', [])
            }
            
            if speaker_analysis:
                return_data['speaker_analysis'] = speaker_analysis
                return_data['total_speakers'] = len(set(seg.get('speaker', 'Unknown') for seg in speaker_analysis))
            
            return return_data
            
        except Exception as e:
            return {
                'status': 'error',
                'analysis_type': 'speech_to_text',
                'error': str(e)
            }
    
    def simple_speaker_separation(self, segments, file_path):
        """ğŸ†• ê³ ê¸‰ í™”ì ë¶„ë¦¬ (ë‹¤ì°¨ì› ìŒì„± íŠ¹ì„± + í´ëŸ¬ìŠ¤í„°ë§)"""
        try:
            import librosa
            import numpy as np
            from sklearn.cluster import KMeans
            from sklearn.preprocessing import StandardScaler
            
            # ìŒì„± íŒŒì¼ ë¡œë“œ
            audio, sr = librosa.load(file_path)
            
            # 1. ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì˜ ìŒì„± íŠ¹ì„± ì¶”ì¶œ
            features_list = []
            segment_info = []
            
            for i, segment in enumerate(segments):
                start_time = segment.get('start', 0)
                end_time = segment.get('end', 0)
                text = segment.get('text', '')
                
                # ìŒì„± êµ¬ê°„ ì¶”ì¶œ
                start_sample = int(start_time * sr)
                end_sample = int(end_time * sr)
                
                if start_sample < len(audio) and end_sample <= len(audio):
                    audio_segment = audio[start_sample:end_sample]
                    
                    if len(audio_segment) > sr * 0.1:  # ìµœì†Œ 0.1ì´ˆ ì´ìƒ
                        features = self.extract_advanced_voice_features(audio_segment, sr)
                        if features is not None:
                            features_list.append(features)
                            segment_info.append({
                                'start': start_time,
                                'end': end_time,
                                'text': text.strip(),
                                'segment_idx': i
                            })
            
            if len(features_list) < 2:
                return self.fallback_speaker_assignment(segment_info)
            
            # 2. K-means í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ í™”ì ë¶„ë¦¬
            features_array = np.array(features_list)
            
            # í™”ì ìˆ˜ ìë™ ê²°ì • (2~6ëª… ì‚¬ì´)
            n_speakers = min(max(2, len(features_list) // 3), 6)
            
            # íŠ¹ì„± ì •ê·œí™”
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features_array)
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§
            kmeans = KMeans(n_clusters=n_speakers, random_state=42, n_init=10)
            speaker_labels = kmeans.fit_predict(features_scaled)
            
            # 3. í™”ìë³„ íŠ¹ì„± ë¶„ì„ ë° ë¼ë²¨ë§
            speaker_segments = []
            speaker_characteristics = self.analyze_speaker_characteristics(
                features_array, speaker_labels, n_speakers
            )
            
            for i, (segment, label) in enumerate(zip(segment_info, speaker_labels)):
                char = speaker_characteristics[label]
                
                speaker_segments.append({
                    'start': segment['start'],
                    'end': segment['end'],
                    'text': segment['text'],
                    'speaker': char['speaker_name'],
                    'speaker_color': char['color'],
                    'confidence': char['confidence'],
                    'audio_features': {
                        'pitch_mean': float(features_list[i][0]),
                        'pitch_std': float(features_list[i][1]),
                        'energy_mean': float(features_list[i][2]),
                        'spectral_centroid': float(features_list[i][3]),
                        'zero_crossing_rate': float(features_list[i][4]),
                        'mfcc_features': features_list[i][5:].tolist()
                    }
                })
            
            return speaker_segments
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ í™”ì ë¶„ë¦¬ë¡œ í´ë°±
            return self.fallback_speaker_assignment(segments)
    
    def extract_advanced_voice_features(self, audio_segment, sr):
        """ğŸ†• ê³ ê¸‰ ìŒì„± íŠ¹ì„± ì¶”ì¶œ (29ì°¨ì› íŠ¹ì„±ë²¡í„°)"""
        try:
            import librosa
            import numpy as np
            
            if len(audio_segment) < sr * 0.1:  # ë„ˆë¬´ ì§§ì€ êµ¬ê°„
                return None
            
            # 1. í”¼ì¹˜ íŠ¹ì„± (F0)
            pitches, magnitudes = librosa.piptrack(y=audio_segment, sr=sr)
            pitch_values = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_values.append(pitch)
            
            if len(pitch_values) > 0:
                pitch_mean = np.mean(pitch_values)
                pitch_std = np.std(pitch_values)
            else:
                pitch_mean = pitch_std = 0
            
            # 2. ì—ë„ˆì§€ íŠ¹ì„±
            energy = np.sum(audio_segment ** 2) / len(audio_segment)
            
            # 3. ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì„±
            spectral_centroids = librosa.feature.spectral_centroid(y=audio_segment, sr=sr)
            spectral_centroid_mean = np.mean(spectral_centroids)
            
            # 4. ì œë¡œ í¬ë¡œì‹± ë ˆì´íŠ¸
            zcr = librosa.feature.zero_crossing_rate(audio_segment)
            zcr_mean = np.mean(zcr)
            
            # 5. MFCC íŠ¹ì„± (13ì°¨ì›)
            mfccs = librosa.feature.mfcc(y=audio_segment, sr=sr, n_mfcc=13)
            mfcc_means = np.mean(mfccs, axis=1)
            
            # 6. ë¡¤ì˜¤í”„ í¬ì¸íŠ¸
            rolloff = librosa.feature.spectral_rolloff(y=audio_segment, sr=sr)
            rolloff_mean = np.mean(rolloff)
            
            # 7. ëŒ€ì—­í­
            bandwidth = librosa.feature.spectral_bandwidth(y=audio_segment, sr=sr)
            bandwidth_mean = np.mean(bandwidth)
            
            # íŠ¹ì„± ë²¡í„° êµ¬ì„± (29ì°¨ì›)
            features = np.concatenate([
                [pitch_mean, pitch_std, energy, spectral_centroid_mean, zcr_mean],
                mfcc_means,  # 13ì°¨ì›
                [rolloff_mean, bandwidth_mean]
            ])
            
            return features
            
        except Exception:
            return None
    
    def analyze_speaker_characteristics(self, features_array, labels, n_speakers):
        """ğŸ†• í™”ìë³„ íŠ¹ì„± ë¶„ì„ ë° ë¼ë²¨ë§"""
        import numpy as np
        
        characteristics = {}
        colors = ["ğŸŸ¢", "ğŸŸ¡", "ğŸ”µ", "ğŸŸ ", "ğŸŸ£", "ğŸ”´"]
        
        for speaker_id in range(n_speakers):
            speaker_features = features_array[labels == speaker_id]
            
            if len(speaker_features) == 0:
                continue
            
            # í‰ê·  íŠ¹ì„± ê³„ì‚°
            avg_pitch = np.mean(speaker_features[:, 0])
            avg_energy = np.mean(speaker_features[:, 2])
            
            # í™”ì íŠ¹ì„± ë¶„ë¥˜
            if avg_pitch > 200:  # ë†’ì€ ìŒì„±
                voice_type = "ë†’ì€ìŒì„±"
            elif avg_pitch > 150:  # ì¤‘ê°„ ìŒì„±
                voice_type = "ì¤‘ê°„ìŒì„±"
            else:  # ë‚®ì€ ìŒì„±
                voice_type = "ë‚®ì€ìŒì„±"
            
            # ì‹ ë¢°ë„ ê³„ì‚° (í´ëŸ¬ìŠ¤í„° ë‚´ ì¼ê´€ì„± ê¸°ë°˜)
            pitch_consistency = 1 / (1 + np.std(speaker_features[:, 0]) / 100)
            energy_consistency = 1 / (1 + np.std(speaker_features[:, 2]) / 0.01)
            confidence = min((pitch_consistency + energy_consistency) / 2, 0.99)
            
            characteristics[speaker_id] = {
                'speaker_name': f"Speaker_{chr(65 + speaker_id)} ({voice_type})",
                'color': colors[speaker_id % len(colors)],
                'confidence': confidence,
                'avg_pitch': avg_pitch,
                'avg_energy': avg_energy,
                'segment_count': len(speaker_features)
            }
        
        return characteristics
    
    def fallback_speaker_assignment(self, segments):
        """ğŸ†• í´ë°± í™”ì ë¶„ë¦¬ (í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨ ì‹œ)"""
        speaker_segments = []
        
        for i, segment in enumerate(segments):
            # ë‹¨ìˆœíˆ ìˆœì„œì— ë”°ë¼ í™”ì ë°°ì •
            speaker_id = i % 3
            colors = ["ğŸŸ¢", "ğŸŸ¡", "ğŸ”µ"]
            names = ["Speaker_A", "Speaker_B", "Speaker_C"]
            
            if isinstance(segment, dict):
                speaker_segments.append({
                    'start': segment.get('start', 0),
                    'end': segment.get('end', 0),
                    'text': segment.get('text', ''),
                    'speaker': names[speaker_id],
                    'speaker_color': colors[speaker_id],
                    'confidence': 0.5,
                    'note': 'Fallback assignment'
                })
            else:
                # segmentsê°€ whisper segments í˜•ì‹ì¸ ê²½ìš°
                speaker_segments.append({
                    'start': segment.get('start', 0),
                    'end': segment.get('end', 0),
                    'text': segment.get('text', ''),
                    'speaker': names[speaker_id],
                    'speaker_color': colors[speaker_id],
                    'confidence': 0.5,
                    'note': 'Basic assignment'
                })
        
        return speaker_segments
    
    def analyze_video_file(self, file_path: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ì‹¤ì œ ë¶„ì„ (ê¸°ë³¸ ì •ë³´)"""
        try:
            import cv2
            
            # ë¹„ë””ì˜¤ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            cap = cv2.VideoCapture(file_path)
            
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = frame_count / fps if fps > 0 else 0
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            cap.release()
            
            return {
                'status': 'success',
                'analysis_type': 'video_info',
                'frame_count': frame_count,
                'fps': fps,
                'duration_seconds': duration,
                'resolution': f"{width}x{height}",
                'message': 'ë¹„ë””ì˜¤ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'analysis_type': 'video_info',
                'error': str(e)
            }
    
    def display_results(self, results):
        """ğŸ†• ê°œì„ ëœ ë¶„ì„ ê²°ê³¼ ì‹œê°í™” í‘œì‹œ"""
        if not results:
            st.warning("âš ï¸ í‘œì‹œí•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        st.header("ğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼ - ì‹œê°í™” ëŒ€ì‹œë³´ë“œ")
        
        # 1. ì „ì²´ í†µê³„ ì‹œê°í™”
        self.render_analysis_overview(results)
        
        # 2. íŒŒì¼ ìœ í˜•ë³„ ë¶„í¬ ì°¨íŠ¸
        self.render_file_type_distribution(results)
        
        # 3. ì„±ê³µë¥  ë° ì„±ëŠ¥ ì°¨íŠ¸
        self.render_performance_charts(results)
        
        # 4. ê¸°ì¡´ ìƒì„¸ ê²°ê³¼ í‘œì‹œ
        self.render_detailed_results(results)
    
    def render_analysis_overview(self, results):
        """ğŸ†• ë¶„ì„ ê°œìš” ì‹œê°í™”"""
        st.subheader("ğŸ“ˆ ë¶„ì„ ê°œìš”")
        
        success_count = sum(1 for r in results if r.get('status') == 'success')
        total_count = len(results)
        error_count = total_count - success_count
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì „ì²´ íŒŒì¼", total_count, help="ì—…ë¡œë“œëœ ì „ì²´ íŒŒì¼ ìˆ˜")
        with col2:
            st.metric("ë¶„ì„ ì„±ê³µ", success_count, f"+{success_count}", help="ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ëœ íŒŒì¼")
        with col3:
            success_rate = (success_count/total_count)*100 if total_count > 0 else 0
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%", help="ì „ì²´ ë¶„ì„ ì„±ê³µë¥ ")
        with col4:
            st.metric("ì˜¤ë¥˜ íŒŒì¼", error_count, f"-{error_count}" if error_count > 0 else "0", help="ë¶„ì„ ì‹¤íŒ¨ íŒŒì¼ ìˆ˜")
        
        # ì„±ê³µë¥  ë„ë„› ì°¨íŠ¸
        if total_count > 0:
            fig = go.Figure(data=[
                go.Pie(
                    labels=['ì„±ê³µ', 'ì‹¤íŒ¨'],
                    values=[success_count, error_count],
                    hole=0.6,
                    marker_colors=['#28a745', '#dc3545']
                )
            ])
            
            fig.update_traces(textposition='inside', textinfo='percent+label')
            fig.update_layout(
                title="ë¶„ì„ ì„±ê³µë¥ ",
                height=300,
                showlegend=True,
                annotations=[dict(text=f'{success_rate:.1f}%', x=0.5, y=0.5, font_size=20, showarrow=False)]
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    def render_file_type_distribution(self, results):
        """ğŸ†• íŒŒì¼ ìœ í˜•ë³„ ë¶„í¬ ì°¨íŠ¸"""
        st.subheader("ğŸ“ íŒŒì¼ ìœ í˜•ë³„ ë¶„í¬")
        
        # íŒŒì¼ ìœ í˜•ë³„ ë°ì´í„° ìˆ˜ì§‘
        type_data = {}
        success_data = {}
        
        for result in results:
            analysis_type = result.get('analysis_type', 'unknown')
            status = result.get('status', 'error')
            
            if analysis_type not in type_data:
                type_data[analysis_type] = 0
                success_data[analysis_type] = 0
            
            type_data[analysis_type] += 1
            if status == 'success':
                success_data[analysis_type] += 1
        
        # íƒ€ì…ë³„ ë§‰ëŒ€ ì°¨íŠ¸
        types = list(type_data.keys())
        total_counts = list(type_data.values())
        success_counts = [success_data.get(t, 0) for t in types]
        error_counts = [total_counts[i] - success_counts[i] for i in range(len(total_counts))]
        
        fig = go.Figure(data=[
            go.Bar(name='ì„±ê³µ', x=types, y=success_counts, marker_color='#28a745'),
            go.Bar(name='ì‹¤íŒ¨', x=types, y=error_counts, marker_color='#dc3545')
        ])
        
        fig.update_layout(
            title='íŒŒì¼ ìœ í˜•ë³„ ë¶„ì„ ê²°ê³¼',
            barmode='stack',
            xaxis_title='íŒŒì¼ ìœ í˜•',
            yaxis_title='íŒŒì¼ ìˆ˜',
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # íŒŒì¼ ìœ í˜•ë³„ ìƒì„¸ í†µê³„ í…Œì´ë¸”
        df_types = pd.DataFrame({
            'íŒŒì¼ ìœ í˜•': types,
            'ì´ íŒŒì¼ ìˆ˜': total_counts,
            'ì„±ê³µ': success_counts,
            'ì‹¤íŒ¨': error_counts,
            'ì„±ê³µë¥ (%)': [f"{(s/t)*100:.1f}" if t > 0 else "0.0" for s, t in zip(success_counts, total_counts)]
        })
        
        st.dataframe(df_types, use_container_width=True)
    
    def render_performance_charts(self, results):
        """ğŸ†• ì„±ëŠ¥ ë° í’ˆì§ˆ ì°¨íŠ¸"""
        st.subheader("ğŸ“Š ë¶„ì„ í’ˆì§ˆ ë° ì„±ëŠ¥")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # OCR ì‹ ë¢°ë„ ë¶„í¬ (ì´ë¯¸ì§€ íŒŒì¼)
            ocr_results = [r for r in results if r.get('analysis_type') == 'image_ocr' and r.get('status') == 'success']
            if ocr_results:
                st.subheader("ğŸ” OCR ì‹ ë¢°ë„ ë¶„í¬")
                
                confidences = []
                for result in ocr_results:
                    if result.get('extracted_text'):
                        for text_item in result['extracted_text']:
                            confidences.append(text_item.get('confidence', 0))
                
                if confidences:
                    fig = px.histogram(
                        x=confidences, 
                        nbins=20, 
                        title='OCR í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ë¶„í¬',
                        labels={'x': 'ì‹ ë¢°ë„', 'y': 'í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜'},
                        color_discrete_sequence=['#17a2b8']
                    )
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ì‹ ë¢°ë„ í†µê³„
                    avg_confidence = np.mean(confidences)
                    st.metric("í‰ê·  OCR ì‹ ë¢°ë„", f"{avg_confidence:.3f}", help="ì „ì²´ OCR í…ìŠ¤íŠ¸ì˜ í‰ê·  ì‹ ë¢°ë„")
        
        with col2:
            # í™”ì ë¶„ë¦¬ ì„±ëŠ¥ (ìŒì„± íŒŒì¼)
            audio_results = [r for r in results if 'speech_to_text' in r.get('analysis_type', '') and r.get('status') == 'success']
            if audio_results:
                st.subheader("ğŸ­ í™”ì ë¶„ë¦¬ ì„±ëŠ¥")
                
                speaker_counts = []
                confidence_scores = []
                
                for result in audio_results:
                    if result.get('speaker_analysis'):
                        speakers = set()
                        confidences = []
                        
                        for segment in result['speaker_analysis']:
                            speakers.add(segment.get('speaker', 'Unknown'))
                            confidences.append(segment.get('confidence', 0.5))
                        
                        speaker_counts.append(len(speakers))
                        if confidences:
                            confidence_scores.extend(confidences)
                
                if speaker_counts:
                    # í™”ì ìˆ˜ ë¶„í¬
                    fig = px.bar(
                        x=list(range(1, max(speaker_counts)+1)),
                        y=[speaker_counts.count(i) for i in range(1, max(speaker_counts)+1)],
                        title='ê°ì§€ëœ í™”ì ìˆ˜ ë¶„í¬',
                        labels={'x': 'í™”ì ìˆ˜', 'y': 'ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜'},
                        color_discrete_sequence=['#fd7e14']
                    )
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # í™”ì ë¶„ë¦¬ í†µê³„
                    avg_speakers = np.mean(speaker_counts)
                    st.metric("í‰ê·  í™”ì ìˆ˜", f"{avg_speakers:.1f}ëª…", help="ì˜¤ë””ì˜¤ íŒŒì¼ë‹¹ í‰ê·  ê°ì§€ëœ í™”ì ìˆ˜")
                    
                    if confidence_scores:
                        avg_speaker_confidence = np.mean(confidence_scores)
                        st.metric("í™”ì ë¶„ë¦¬ ì‹ ë¢°ë„", f"{avg_speaker_confidence:.3f}", help="í™”ì ë¶„ë¦¬ì˜ í‰ê·  ì‹ ë¢°ë„")
    
    def render_detailed_results(self, results):
        """ğŸ†• ìƒì„¸ ê²°ê³¼ í‘œì‹œ (ê¸°ì¡´ ë°©ì‹ ê°œì„ )"""
        st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        
        # íƒ­ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ë³´ê¸° í¸í•˜ê²Œ
        tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„", "ğŸµ ìŒì„± ë¶„ì„", "ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„"])
        
        with tab1:
            image_results = [r for r in results if r.get('analysis_type') == 'image_ocr']
            self.render_image_results_tab(image_results)
        
        with tab2:
            audio_results = [r for r in results if 'speech_to_text' in r.get('analysis_type', '')]
            self.render_audio_results_tab(audio_results)
        
        with tab3:
            video_results = [r for r in results if r.get('analysis_type') == 'video_info']
            self.render_video_results_tab(video_results)
    
    def render_image_results_tab(self, image_results):
        """ğŸ†• ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ íƒ­"""
        if not image_results:
            st.info("ğŸ“· ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        for result in image_results:
            with st.expander(f"ğŸ“¸ {result['file_name']} - {result['status']}", expanded=False):
                
                if result['status'] == 'success':
                    st.success("âœ… ë¶„ì„ ì„±ê³µ")
                    
                    # OCR ê²°ê³¼ ì‹œê°í™”
                    if result.get('extracted_text'):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"**ğŸ“Š ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¸”ë¡:** {result['total_text_blocks']}ê°œ")
                            st.text_area("ì „ì²´ í…ìŠ¤íŠ¸", result['full_text'], height=150)
                        
                        with col2:
                            # ì‹ ë¢°ë„ ë¶„í¬ ë¯¸ë‹ˆ ì°¨íŠ¸
                            confidences = [item['confidence'] for item in result['extracted_text']]
                            if confidences:
                                fig = px.histogram(
                                    x=confidences,
                                    nbins=10,
                                    title='ì‹ ë¢°ë„ ë¶„í¬',
                                    height=200
                                )
                                st.plotly_chart(fig, use_container_width=True)
                        
                        # í…ìŠ¤íŠ¸ ë¸”ë¡ë³„ ìƒì„¸ ì •ë³´
                        st.write("**ğŸ“‹ í…ìŠ¤íŠ¸ ë¸”ë¡ë³„ ìƒì„¸:**")
                        for j, text_item in enumerate(result['extracted_text']):
                            confidence = text_item['confidence']
                            confidence_color = "ğŸŸ¢" if confidence > 0.8 else "ğŸŸ¡" if confidence > 0.5 else "ğŸ”´"
                            
                            # ì§„í–‰ë¥  ë°”ë¡œ ì‹ ë¢°ë„ í‘œì‹œ
                            st.write(f"{j+1}. {confidence_color} **{text_item['text']}**")
                            st.progress(confidence)
                    else:
                        st.info("í…ìŠ¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                else:
                    st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
    
    def render_audio_results_tab(self, audio_results):
        """ğŸ†• ìŒì„± ë¶„ì„ ê²°ê³¼ íƒ­"""
        if not audio_results:
            st.info("ğŸµ ìŒì„± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        for result in audio_results:
            with st.expander(f"ğŸµ {result['file_name']} - {result['status']}", expanded=False):
                if result['status'] == 'success':
                    st.success("âœ… ë¶„ì„ ì„±ê³µ")
                    
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**ğŸŒ ì¸ì‹ëœ ì–¸ì–´:** {result.get('language', 'Unknown')}")
                        
                        # ì „ì²´ ëŒ€í™” ë‚´ìš©
                        if result.get('transcribed_text'):
                            st.text_area("ğŸ“ ì „ì²´ ëŒ€í™” ë‚´ìš©", result['transcribed_text'], height=200)
                    
                    with col2:
                        # í™”ì ë¶„í¬ ì°¨íŠ¸
                        if result.get('speaker_analysis'):
                            speakers = [seg.get('speaker', 'Unknown') for seg in result['speaker_analysis']]
                            speaker_counts = Counter(speakers)
                            
                            fig = px.pie(
                                values=list(speaker_counts.values()),
                                names=list(speaker_counts.keys()),
                                title='í™”ìë³„ ë°œì–¸ ë¹„ìœ¨',
                                height=250
                            )
                            st.plotly_chart(fig, use_container_width=True)
                    
                    # í™”ìë³„ íƒ€ì„ë¼ì¸
                    if result.get('speaker_analysis'):
                        st.write("**ğŸ­ í™”ìë³„ ëŒ€í™” íƒ€ì„ë¼ì¸:**")
                        
                        timeline_data = []
                        for segment in result['speaker_analysis']:
                            timeline_data.append({
                                'í™”ì': segment.get('speaker', 'Unknown'),
                                'ì‹œì‘': segment.get('start', 0),
                                'ì¢…ë£Œ': segment.get('end', 0),
                                'ì§€ì†ì‹œê°„': segment.get('end', 0) - segment.get('start', 0),
                                'ë°œì–¸ë‚´ìš©': segment.get('text', '')[:50] + '...' if len(segment.get('text', '')) > 50 else segment.get('text', '')
                            })
                        
                        if timeline_data:
                            df_timeline = pd.DataFrame(timeline_data)
                            st.dataframe(df_timeline, use_container_width=True)
                            
                            # íƒ€ì„ë¼ì¸ ì‹œê°í™”
                            fig = px.timeline(
                                df_timeline,
                                x_start='ì‹œì‘',
                                x_end='ì¢…ë£Œ', 
                                y='í™”ì',
                                color='í™”ì',
                                title='ëŒ€í™” íƒ€ì„ë¼ì¸',
                                height=300
                            )
                            st.plotly_chart(fig, use_container_width=True)
                else:
                    st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
    
    def render_video_results_tab(self, video_results):
        """ğŸ†• ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ íƒ­"""
        if not video_results:
            st.info("ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        for result in video_results:
            with st.expander(f"ğŸ¬ {result['file_name']} - {result['status']}", expanded=False):
                if result['status'] == 'success':
                    st.success("âœ… ë¶„ì„ ì„±ê³µ")
                    
                    # ë¹„ë””ì˜¤ ì •ë³´ ëŒ€ì‹œë³´ë“œ
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("í•´ìƒë„", result.get('resolution', 'N/A'))
                    with col2:
                        st.metric("ì§€ì†ì‹œê°„", f"{result.get('duration_seconds', 0):.1f}ì´ˆ")
                    with col3:
                        st.metric("í”„ë ˆì„ ìˆ˜", f"{result.get('frame_count', 0):,}")
                    with col4:
                        fps = result.get('fps', 0)
                        st.metric("FPS", f"{fps:.1f}")
                    
                    # ë¹„ë””ì˜¤ í’ˆì§ˆ ì‹œê°í™”
                    if all(k in result for k in ['frame_count', 'duration_seconds', 'fps']):
                        quality_score = min(fps / 30, 1.0) * 100  # 30fps ê¸°ì¤€
                        st.write(f"**ğŸ“Š ë¹„ë””ì˜¤ í’ˆì§ˆ ì ìˆ˜:** {quality_score:.0f}/100")
                        st.progress(quality_score / 100)
                        
                        # í’ˆì§ˆ ë¶„ì„ ì½”ë©˜íŠ¸
                        if quality_score >= 80:
                            st.success("ğŸ¬ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ì…ë‹ˆë‹¤")
                        elif quality_score >= 60:
                            st.info("ğŸ“¹ ë³´í†µ í’ˆì§ˆì˜ ë¹„ë””ì˜¤ì…ë‹ˆë‹¤")
                        else:
                            st.warning("ğŸ“± ì €í’ˆì§ˆ ë¹„ë””ì˜¤ì…ë‹ˆë‹¤. ì¶”ê°€ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                
                elif result['status'] == 'dependency_missing':
                    st.warning(f"âš ï¸ {result['message']}")
                
                elif result['status'] == 'error':
                    st.error("âŒ ë¶„ì„ ì‹¤íŒ¨")
                    st.code(result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
                
                elif result['status'] == 'unsupported':
                    st.info(f"â„¹ï¸ {result.get('message', 'ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹')}")
                
                else:
                    st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            
            # ë¶„ì„ ì‹œê°„ í‘œì‹œ
            if 'analysis_time' in result:
                st.caption(f"ë¶„ì„ ì‹œê°„: {result['analysis_time']}")
    
    def generate_comprehensive_report(self, results):
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        st.header("ğŸ“„ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
        
        # 1. ì „ì²´ ìš”ì•½
        st.subheader("ğŸ“Š 1. ì „ì²´ ìš”ì•½")
        
        total_files = len(results)
        success_files = [r for r in results if r.get('status') == 'success']
        success_count = len(success_files)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì „ì²´ íŒŒì¼", total_files)
        with col2:
            st.metric("ë¶„ì„ ì„±ê³µ", success_count)
        with col3:
            st.metric("ì„±ê³µë¥ ", f"{(success_count/total_files)*100:.1f}%")
        with col4:
            analysis_time = datetime.now().strftime('%Y-%m-%d %H:%M')
            st.metric("ë¶„ì„ ì‹œê°„", analysis_time)
        
        # 2. íŒŒì¼ ìœ í˜•ë³„ ë¶„ì„
        st.subheader("ğŸ“ 2. íŒŒì¼ ìœ í˜•ë³„ ë¶„ì„")
        
        file_types = {}
        for result in success_files:
            analysis_type = result.get('analysis_type', 'unknown')
            if analysis_type not in file_types:
                file_types[analysis_type] = []
            file_types[analysis_type].append(result)
        
        for file_type, type_results in file_types.items():
            with st.expander(f"ğŸ“Š {file_type} ({len(type_results)}ê°œ)", expanded=True):
                if file_type == 'image_ocr':
                    self.summarize_ocr_results(type_results)
                elif file_type in ['speech_to_text', 'speech_to_text_with_speakers']:
                    self.summarize_audio_results(type_results)
                elif file_type == 'video_info':
                    self.summarize_video_results(type_results)
        
        # 3. í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
        st.subheader("ğŸ¯ 3. í•µì‹¬ ë‚´ìš© ì¶”ì¶œ")
        self.extract_key_insights(success_files)
        
        # 4. ì¶”ì²œ ì•¡ì…˜
        st.subheader("ğŸ¡ 4. ì¶”ì²œ ì•¡ì…˜")
        self.generate_action_recommendations(results)
        
        # 5. ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
        st.subheader("ğŸ’¾ 5. ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
        report_text = self.generate_text_report(results)
        st.download_button(
            label="ğŸ“„ ì „ì²´ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (TXT)",
            data=report_text,
            file_name=f"conference_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
    
    def summarize_ocr_results(self, ocr_results):
        """ì´ë¯¸ì§€ OCR ê²°ê³¼ ìš”ì•½"""
        total_text_blocks = sum(r.get('total_text_blocks', 0) for r in ocr_results)
        all_text = ' '.join([r.get('full_text', '') for r in ocr_results])
        
        st.write(f"ğŸ“Š **ì´ {total_text_blocks}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ**")
        
        if all_text:
            # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
            words = all_text.lower().split()
            word_count = Counter(words)
            common_words = word_count.most_common(10)
            
            st.write("ğŸ” **ì£¼ìš” í‚¤ì›Œë“œ:**")
            cols = st.columns(5)
            for i, (word, count) in enumerate(common_words[:5]):
                if len(word) > 2:  # 2ê¸€ì ì´ìƒì¸ ë‹¨ì–´ë§Œ
                    cols[i].metric(word, f"{count}íšŒ")
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
            preview_text = all_text[:500] + "..." if len(all_text) > 500 else all_text
            st.text_area("ğŸ“ **ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸:**", preview_text, height=100)
    
    def summarize_audio_results(self, audio_results):
        """ìŒì„± ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        total_speakers = set()
        all_transcripts = []
        languages = set()
        
        for result in audio_results:
            # ì–¸ì–´ ìˆ˜ì§‘
            if result.get('language'):
                languages.add(result['language'])
            
            # ì „ì²´ ëŒ€í™” ë‚´ìš©
            if result.get('transcribed_text'):
                all_transcripts.append(result['transcribed_text'])
            
            # í™”ì ìˆ˜ì§‘
            if result.get('speaker_analysis'):
                for seg in result['speaker_analysis']:
                    speaker = seg.get('speaker', 'Unknown')
                    total_speakers.add(speaker)
        
        st.write(f"ğŸ­ **ê°ì§€ëœ í™”ì ìˆ˜:** {len(total_speakers)}ëª…")
        st.write(f"ğŸŒ **ì¸ì‹ëœ ì–¸ì–´:** {', '.join(languages) if languages else 'ë¯¸ìƒ'}")
        
        # í™”ìë³„ ìš”ì•½
        if total_speakers and len(total_speakers) > 1:
            st.write("ğŸ—£ï¸ **í™”ìë³„ ë°œì–¸ ìš”ì•½:**")
            for speaker in sorted(total_speakers):
                speaker_texts = []
                for result in audio_results:
                    if result.get('speaker_analysis'):
                        for seg in result['speaker_analysis']:
                            if seg.get('speaker') == speaker:
                                speaker_texts.append(seg.get('text', ''))
                
                if speaker_texts:
                    combined_text = ' '.join(speaker_texts)
                    preview_text = combined_text[:200] + '...' if len(combined_text) > 200 else combined_text
                    st.write(f"**{speaker}:** {preview_text}")
        
        # ì „ì²´ ëŒ€í™” ë‚´ìš©
        full_conversation = ' '.join(all_transcripts)
        if full_conversation:
            preview_conversation = full_conversation[:1000] + "..." if len(full_conversation) > 1000 else full_conversation
            st.text_area("ğŸ“ **ì „ì²´ ëŒ€í™” ë‚´ìš©:**", preview_conversation, height=150)
    
    def summarize_video_results(self, video_results):
        """ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        total_duration = sum(r.get('duration_seconds', 0) for r in video_results)
        total_frames = sum(r.get('frame_count', 0) for r in video_results)
        
        st.write(f"ğŸ¬ **ì´ ë¹„ë””ì˜¤ ì‹œê°„:** {total_duration:.1f}ì´ˆ")
        st.write(f"ğŸ–¼ï¸ **ì´ í”„ë ˆì„ ìˆ˜:** {total_frames:,}ê°œ")
        
        for result in video_results:
            st.write(f"- **{result['file_name']}**: {result.get('resolution', 'N/A')}, {result.get('duration_seconds', 0):.1f}ì´ˆ")
    
    def extract_key_insights(self, results):
        """í•µì‹¬ ë‚´ìš© ì¶”ì¶œ"""
        insights = []
        
        # OCRì—ì„œ ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ
        ocr_results = [r for r in results if r.get('analysis_type') == 'image_ocr']
        if ocr_results:
            all_ocr_text = ' '.join([r.get('full_text', '') for r in ocr_results])
            
            # ìˆ«ì íŒ¨í„´ ì°¾ê¸° (ë‚ ì§œ, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“±)
            dates = re.findall(r'\d{4}[-./]\d{1,2}[-./]\d{1,2}', all_ocr_text)
            phones = re.findall(r'\d{2,3}[-.]?\d{3,4}[-.]?\d{4}', all_ocr_text)
            emails = re.findall(r'\S+@\S+\.\S+', all_ocr_text)
            
            if dates:
                insights.append(f"ğŸ“… ë°œê²¬ëœ ë‚ ì§œ: {', '.join(set(dates))}")
            if phones:
                insights.append(f"ğŸ“ ë°œê²¬ëœ ì „í™”ë²ˆí˜¸: {', '.join(set(phones))}")
            if emails:
                insights.append(f"ğŸ“§ ë°œê²¬ëœ ì´ë©”ì¼: {', '.join(set(emails))}")
        
        # ìŒì„±ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ
        audio_results = [r for r in results if 'speech_to_text' in r.get('analysis_type', '')]
        if audio_results:
            all_audio_text = ' '.join([r.get('transcribed_text', '') for r in audio_results])
            
            # ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
            positive_words = ['ì¢‹ë‹¤', 'í•˜ê³  ì‹¶ë‹¤', 'ì¢‹ì•„ìš”', 'í•˜ì‹œì£ ', 'ë„¤', 'ë§ìŠµë‹ˆë‹¤', 'ë™ì˜']
            negative_words = ['ì‹«ë‹¤', 'ì•„ë‹ˆë‹¤', 'ë¬¸ì œ', 'ì–´ë µë‹¤', 'ë¶ˆê°€ëŠ¥', 'ì•ˆë©ë‹ˆë‹¤']
            question_words = ['ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””', 'ì™œ', 'ì–´ë–»ê²Œ', 'ëˆ„ê°€']
            
            positive_count = sum(all_audio_text.count(word) for word in positive_words)
            negative_count = sum(all_audio_text.count(word) for word in negative_words)
            question_count = sum(all_audio_text.count(word) for word in question_words)
            
            if positive_count > negative_count:
                insights.append(f"ğŸ˜Š ì „ì²´ì ìœ¼ë¡œ ê¸ì •ì ì¸ ëŒ€í™” ë¶„ìœ„ê¸° (ê¸ì •: {positive_count}, ë¶€ì •: {negative_count})")
            elif negative_count > positive_count:
                insights.append(f"ğŸ˜” ìš°ë ¤ë‚˜ ë¬¸ì œì ì´ ì–¸ê¸‰ëœ ëŒ€í™” (ë¶€ì •: {negative_count}, ê¸ì •: {positive_count})")
            
            if question_count > 5:
                insights.append(f"â“ ì§ˆë¬¸ì´ ë§ì€ ëŒ€í™” ({question_count}ê°œ ì§ˆë¬¸ ê°ì§€) - ì •ë³´ ìˆ˜ì§‘ ëª©ì ìœ¼ë¡œ ë‹¨ì •")
        
        # ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
        if insights:
            for insight in insights:
                st.write(f"- {insight}")
        else:
            st.info("ğŸ” ì¶”ê°€ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ê¸° ìœ„í•´ì„œëŠ” ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    def generate_action_recommendations(self, results):
        """ì¶”ì²œ ì•¡ì…˜ ìƒì„±"""
        recommendations = []
        
        success_count = len([r for r in results if r.get('status') == 'success'])
        total_count = len(results)
        
        if success_count < total_count:
            failed_files = [r['file_name'] for r in results if r.get('status') != 'success']
            recommendations.append(f"âš ï¸ **ì‹¤íŒ¨í•œ íŒŒì¼ ì¬ì²˜ë¦¬**: {', '.join(failed_files[:3])}{'...' if len(failed_files) > 3 else ''} ({len(failed_files)}ê°œ)")
        
        # í™”ì ë¶„ë¦¬ ê´€ë ¨ ì¶”ì²œ
        audio_results = [r for r in results if 'speech_to_text' in r.get('analysis_type', '')]
        if audio_results:
            has_speaker_analysis = any(r.get('speaker_analysis') for r in audio_results)
            if has_speaker_analysis:
                recommendations.append("ğŸ­ **í™”ì ë¶„ë¦¬ ê°œì„ **: ë” ì •í™•í•œ í™”ì ë¶„ë¦¬ë¥¼ ìœ„í•´ ìŒì„± í’ˆì§ˆ í–¥ìƒ ê¶Œì¥")
            
            total_speakers = set()
            for result in audio_results:
                if result.get('speaker_analysis'):
                    for seg in result['speaker_analysis']:
                        total_speakers.add(seg.get('speaker', 'Unknown'))
            
            if len(total_speakers) > 3:
                recommendations.append("ğŸ—£ï¸ **ë‹¤ìˆ˜ ì°¸ì—¬ì**: 4ëª… ì´ìƒì˜ ì°¸ì—¬ìê°€ ê°ì§€ë˜ì–´ íšŒì˜ ì£¼ìš” ì˜ê²¬ ì •ë¦¬ ì¬ê²€í†  ì œì•ˆ")
        
        # OCR ê´€ë ¨ ì¶”ì²œ
        ocr_results = [r for r in results if r.get('analysis_type') == 'image_ocr']
        if ocr_results:
            low_confidence = [r for r in ocr_results if any(item.get('confidence', 0) < 0.7 for item in r.get('extracted_text', []))]
            if low_confidence:
                recommendations.append("ğŸ–¼ï¸ **ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ **: ì¼ë¶€ ì´ë¯¸ì§€ì—ì„œ ë‚®ì€ ì¸ì‹ ì •í™•ë„ - ë” ì„ ëª…í•œ ì´ë¯¸ì§€ ì´¬ì˜ ê¶Œì¥")
        
        # ê¸°ë³¸ ì¶”ì²œì‚¬í•­
        recommendations.extend([
            "ğŸ“„ **ë¬¸ì„œí™”**: ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íšŒì˜ë¡ ë˜ëŠ” ìš”ì•½ ë³´ê³ ì„œ ì‘ì„±",
            "ğŸ”„ **í›„ì† ëŒ€ì‘**: ì£¼ìš” ë…¼ì˜ì‚¬í•­ì— ëŒ€í•œ í›„ì† ì¡°ì¹˜ ë° ë‹´ë‹¹ì ì§€ì •",
            "ğŸ“Š **ë°ì´í„° ë³´ê´€**: ë¶„ì„ ê²°ê³¼ ë° ì›ë³¸ íŒŒì¼ ì•ˆì „í•œ ì¥ì†Œì— ë°±ì—…"
        ])
        
        for i, rec in enumerate(recommendations, 1):
            st.write(f"{i}. {rec}")
    
    def generate_text_report(self, results):
        """í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        report_lines = []
        report_lines.append("===== SOLOMOND AI ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ =====")
        report_lines.append(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # ê¸°ë³¸ í†µê³„
        total_files = len(results)
        success_files = [r for r in results if r.get('status') == 'success']
        success_count = len(success_files)
        
        report_lines.append("1. ê¸°ë³¸ í†µê³„")
        report_lines.append(f"   ì „ì²´ íŒŒì¼: {total_files}ê°œ")
        report_lines.append(f"   ë¶„ì„ ì„±ê³µ: {success_count}ê°œ")
        report_lines.append(f"   ì„±ê³µë¥ : {(success_count/total_files)*100:.1f}%")
        report_lines.append("")
        
        # íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼
        report_lines.append("2. íŒŒì¼ë³„ ë¶„ì„ ê²°ê³¼")
        for i, result in enumerate(results, 1):
            report_lines.append(f"   {i}. {result['file_name']} - {result['status']}")
            
            if result.get('status') == 'success':
                if result.get('analysis_type') == 'image_ocr':
                    report_lines.append(f"      í…ìŠ¤íŠ¸ ë¸”ë¡: {result.get('total_text_blocks', 0)}ê°œ")
                    if result.get('full_text'):
                        text = result['full_text'][:200] + "..." if len(result['full_text']) > 200 else result['full_text']
                        report_lines.append(f"      ì¶”ì¶œ í…ìŠ¤íŠ¸: {text}")
                
                elif 'speech_to_text' in result.get('analysis_type', ''):
                    report_lines.append(f"      ì–¸ì–´: {result.get('language', 'unknown')}")
                    if result.get('speaker_analysis'):
                        report_lines.append(f"      í™”ì ìˆ˜: {result.get('total_speakers', 0)}ëª…")
                        # í™”ìë³„ ëŒ€í™” ë‚´ìš© ìš”ì•½
                        for seg in result['speaker_analysis'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                            speaker = seg.get('speaker', 'Unknown')
                            text = seg.get('text', '')[:100]
                            report_lines.append(f"        {speaker}: {text}...")
                    else:
                        text = result.get('transcribed_text', '')
                        text = text[:200] + "..." if len(text) > 200 else text
                        report_lines.append(f"      ëŒ€í™” ë‚´ìš©: {text}")
                
                elif result.get('analysis_type') == 'video_info':
                    report_lines.append(f"      í•´ìƒë„: {result.get('resolution', 'N/A')}")
                    report_lines.append(f"      ì¬ìƒì‹œê°„: {result.get('duration_seconds', 0):.1f}ì´ˆ")
            
            elif result.get('status') == 'error':
                report_lines.append(f"      ì˜¤ë¥˜: {result.get('error', 'unknown error')}")
            
            report_lines.append("")
        
        # ì¢…í•© ê²°ë¡ 
        report_lines.append("3. ì¢…í•© ê²°ë¡ ")
        if success_count > 0:
            report_lines.append("   ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if success_count < total_files:
            failed_count = total_files - success_count
            report_lines.append(f"   {failed_count}ê°œ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ - íŒŒì¼ í˜•ì‹ì´ë‚˜ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        report_lines.append("")
        report_lines.append("===== ë³´ê³ ì„œ ë =====")
        
        return "\n".join(report_lines)
    
    def render_pre_info_section(self):
        """ì‚¬ì „ì •ë³´ ì…ë ¥ ì„¹ì…˜"""
        st.header("ğŸ“‹ ì»¨í¼ëŸ°ìŠ¤ ì‚¬ì „ì •ë³´")
        st.write("**ë¶„ì„ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ë°°ê²½ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì„ íƒì‚¬í•­)**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            conference_name = st.text_input(
                "ì»¨í¼ëŸ°ìŠ¤ëª…", 
                value=st.session_state.pre_info.get('conference_name', ''),
                placeholder="ì˜ˆ: 2025 AI í˜ì‹  ì»¨í¼ëŸ°ìŠ¤"
            )
            
            conference_date = st.date_input(
                "ê°œìµœì¼ì",
                value=st.session_state.pre_info.get('conference_date')
            )
            
            location = st.text_input(
                "ì¥ì†Œ",
                value=st.session_state.pre_info.get('location', ''),
                placeholder="ì˜ˆ: ì„œìš¸ ì½”ì—‘ìŠ¤ ì»¨ë²¤ì…˜ì„¼í„°"
            )
        
        with col2:
            industry = st.selectbox(
                "ì—…ê³„ ë¶„ì•¼",
                ["ì„ íƒì•ˆí•¨", "IT/ì†Œí”„íŠ¸ì›¨ì–´", "ì œì¡°ì—…", "ê¸ˆìœµ", "ì˜ë£Œ/ë°”ì´ì˜¤", "êµìœ¡", "ë§ˆì¼€íŒ…", "ê¸°íƒ€"],
                index=0 if not st.session_state.pre_info.get('industry') else 
                ["ì„ íƒì•ˆí•¨", "IT/ì†Œí”„íŠ¸ì›¨ì–´", "ì œì¡°ì—…", "ê¸ˆìœµ", "ì˜ë£Œ/ë°”ì´ì˜¤", "êµìœ¡", "ë§ˆì¼€íŒ…", "ê¸°íƒ€"].index(
                    st.session_state.pre_info.get('industry', 'ì„ íƒì•ˆí•¨')
                )
            )
            
            keywords = st.text_area(
                "ê´€ì‹¬ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                value=st.session_state.pre_info.get('keywords', ''),
                placeholder="ì˜ˆ: AI, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìë™í™”",
                height=100
            )
            
            purpose = st.selectbox(
                "ë¶„ì„ ëª©ì ",
                ["ì¼ë°˜ ë¶„ì„", "íšŒì˜ë¡ ì‘ì„±", "í•µì‹¬ ë‚´ìš© ìš”ì•½", "ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ", "ì˜ì‚¬ê²°ì • ì§€ì›"]
            )
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
        additional_context = st.text_area(
            "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì°¸ì„ì ì •ë³´, íŠ¹ë³„ ìš”ì²­ì‚¬í•­ ë“±)",
            value=st.session_state.pre_info.get('additional_context', ''),
            placeholder="ì˜ˆ: ì£¼ìš” ì°¸ì„ì - CEO, CTO, ë§ˆì¼€íŒ… íŒ€ì¥\nì¤‘ì  ë…¼ì˜ì‚¬í•­ - 2025ë…„ ì „ëµ ìˆ˜ë¦½",
            height=120
        )
        
        # ì •ë³´ ì €ì¥
        if st.button("ğŸ“ ì‚¬ì „ì •ë³´ ì €ì¥", type="secondary"):
            st.session_state.pre_info = {
                'conference_name': conference_name,
                'conference_date': conference_date,
                'location': location,
                'industry': industry,
                'keywords': keywords,
                'purpose': purpose,
                'additional_context': additional_context,
                'saved_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            st.success("âœ… ì‚¬ì „ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ë¶„ì„ì— í™œìš©ë©ë‹ˆë‹¤.")
        
        # ì €ì¥ëœ ì •ë³´ í‘œì‹œ
        if st.session_state.pre_info:
            with st.expander("ğŸ’¾ ì €ì¥ëœ ì‚¬ì „ì •ë³´", expanded=False):
                for key, value in st.session_state.pre_info.items():
                    if key != 'saved_time' and value:
                        st.write(f"**{key}**: {value}")
                st.caption(f"ì €ì¥ ì‹œê°„: {st.session_state.pre_info.get('saved_time', '')}")
    
    def file_upload_section_enhanced(self):
        """í–¥ìƒëœ íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ - 3ê°€ì§€ ë°©ì‹ ì§€ì›"""
        st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ (3ê°€ì§€ ë°©ì‹)")
        
        # ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ
        upload_method = st.radio(
            "ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ",
            ["ğŸ“„ ê°œë³„ íŒŒì¼", "ğŸ“¦ í´ë”/ZIP", "ğŸŒ URL ë‹¤ìš´ë¡œë“œ"],
            horizontal=True
        )
        
        uploaded_files = None
        
        if upload_method == "ğŸ“„ ê°œë³„ íŒŒì¼":
            uploaded_files = self.individual_file_upload()
        elif upload_method == "ğŸ“¦ í´ë”/ZIP":
            uploaded_files = self.folder_zip_upload()
        elif upload_method == "ğŸŒ URL ë‹¤ìš´ë¡œë“œ":
            uploaded_files = self.url_download_upload()
        
        return uploaded_files
    
    def individual_file_upload(self):
        """ê°œë³„ íŒŒì¼ ì—…ë¡œë“œ"""
        st.info("""
        **ì§€ì› íŒŒì¼ í˜•ì‹:**
        - ğŸ“¸ ì´ë¯¸ì§€: JPG, PNG, GIF (EasyOCR í…ìŠ¤íŠ¸ ì¶”ì¶œ)
        - ğŸµ ìŒì„±: WAV, MP3, M4A (Whisper STT + í™”ì ë¶„ë¦¬)
        - ğŸ¬ ë¹„ë””ì˜¤: MP4, MOV, AVI (ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ)
        """)
        
        uploaded_files = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì—…ë¡œë“œ ê°€ëŠ¥)",
            type=['jpg', 'jpeg', 'png', 'gif', 'wav', 'mp3', 'm4a', 'mp4', 'mov', 'avi'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")
            for i, file in enumerate(uploaded_files):
                file_size = len(file.read())
                file.seek(0)
                st.write(f"{i+1}. **{file.name}** ({file_size:,} bytes) - {file.type}")
        
        return uploaded_files
    
    def folder_zip_upload(self):
        """í´ë”/ZIP íŒŒì¼ ì—…ë¡œë“œ"""
        st.info("**ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì••ì¶• í•´ì œí•˜ì—¬ ëª¨ë“  íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.**")
        
        zip_file = st.file_uploader(
            "ZIP íŒŒì¼ ì„ íƒ",
            type=['zip']
        )
        
        if zip_file:
            try:
                import zipfile
                import io
                
                # ZIP íŒŒì¼ ì²˜ë¦¬
                zip_buffer = io.BytesIO(zip_file.read())
                extracted_files = []
                
                with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:
                    file_list = zip_ref.namelist()
                    supported_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.wav', '.mp3', '.m4a', '.mp4', '.mov', '.avi')
                    
                    for file_name in file_list:
                        if file_name.lower().endswith(supported_extensions):
                            file_data = zip_ref.read(file_name)
                            # ê°€ìƒì˜ ì—…ë¡œë“œ íŒŒì¼ ê°ì²´ ìƒì„±
                            fake_file = type('FakeFile', (), {
                                'name': file_name,
                                'read': lambda: file_data,
                                'seek': lambda pos: None,
                                'type': self._get_mime_type(file_name)
                            })()
                            extracted_files.append(fake_file)
                
                if extracted_files:
                    st.success(f"âœ… ZIPì—ì„œ {len(extracted_files)}ê°œ ì§€ì› íŒŒì¼ ì¶”ì¶œë¨")
                    for i, file in enumerate(extracted_files):
                        st.write(f"{i+1}. **{file.name}** - {file.type}")
                    return extracted_files
                else:
                    st.warning("âš ï¸ ZIP íŒŒì¼ì— ì§€ì›ë˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ZIP íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        return None
    
    def url_download_upload(self):
        """URL ë‹¤ìš´ë¡œë“œ ì—…ë¡œë“œ"""
        st.info("**ì˜¨ë¼ì¸ íŒŒì¼ì˜ ì§ì ‘ ë§í¬ë¥¼ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.**")
        
        urls_text = st.text_area(
            "íŒŒì¼ URL ì…ë ¥ (í•œ ì¤„ì— í•˜ë‚˜ì”©)",
            placeholder="https://example.com/audio.wav\nhttps://example.com/image.jpg",
            height=100
        )
        
        if urls_text and st.button("ğŸŒ URLì—ì„œ ë‹¤ìš´ë¡œë“œ"):
            urls = [url.strip() for url in urls_text.split('\n') if url.strip()]
            
            if urls:
                downloaded_files = []
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for i, url in enumerate(urls):
                    status_text.text(f"ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
                    
                    try:
                        import requests
                        import tempfile
                        from urllib.parse import urlparse
                        
                        response = requests.get(url, timeout=30)
                        response.raise_for_status()
                        
                        # íŒŒì¼ëª… ì¶”ì¶œ
                        parsed_url = urlparse(url)
                        file_name = os.path.basename(parsed_url.path)
                        if not file_name:
                            file_name = f"downloaded_file_{i+1}"
                        
                        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=Path(file_name).suffix)
                        temp_file.write(response.content)
                        temp_file.close()
                        
                        # ê°€ìƒì˜ ì—…ë¡œë“œ íŒŒì¼ ê°ì²´ ìƒì„±
                        fake_file = type('FakeFile', (), {
                            'name': file_name,
                            'read': lambda: open(temp_file.name, 'rb').read(),
                            'seek': lambda pos: None,
                            'type': self._get_mime_type(file_name),
                            '_temp_path': temp_file.name
                        })()
                        downloaded_files.append(fake_file)
                        
                    except Exception as e:
                        st.error(f"âŒ {url} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
                    progress_bar.progress((i + 1) / len(urls))
                
                status_text.text("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                
                if downloaded_files:
                    st.success(f"âœ… {len(downloaded_files)}ê°œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                    for i, file in enumerate(downloaded_files):
                        st.write(f"{i+1}. **{file.name}** - {file.type}")
                    return downloaded_files
        
        return None
    
    def _get_mime_type(self, filename):
        """íŒŒì¼ëª…ìœ¼ë¡œë¶€í„° MIME íƒ€ì… ì¶”ì •"""
        ext = Path(filename).suffix.lower()
        mime_types = {
            '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png', '.gif': 'image/gif',
            '.wav': 'audio/wav', '.mp3': 'audio/mpeg', '.m4a': 'audio/m4a',
            '.mp4': 'video/mp4', '.mov': 'video/quicktime', '.avi': 'video/x-msvideo'
        }
        return mime_types.get(ext, 'application/octet-stream')
    
    def analyze_files_with_context(self, uploaded_files):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ íŒŒì¼ ë¶„ì„ + ì˜êµ¬ ì €ì¥"""
        if not uploaded_files:
            st.error("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ë¶„ì„ ID ìƒì„±
        file_info = {
            'names': [f.name for f in uploaded_files],
            'total_size': sum(f.size for f in uploaded_files)
        }
        analysis_id = self.generate_analysis_id(file_info)
        st.session_state.analysis_id = analysis_id
        
        st.header("ğŸ” ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ íŒŒì¼ ë¶„ì„ ì§„í–‰ ì¤‘")
        st.info(f"ğŸ†” ë¶„ì„ ID: **{analysis_id}**")
        
        # ì‚¬ì „ì •ë³´ë¥¼ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
        analysis_context = self._build_analysis_context()
        
        if analysis_context:
            st.info(f"ğŸ“‹ **ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì ìš©ë¨**: {analysis_context['summary']}")
        
        # ê¸°ì¡´ ë¶„ì„ ë¡œì§ì— ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        results = self.analyze_files(uploaded_files)
        
        # ê²°ê³¼ì— ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if results and analysis_context:
            for result in results:
                result['analysis_context'] = analysis_context
        
        # ë¶„ì„ ê²°ê³¼ ì˜êµ¬ ì €ì¥
        if results:
            save_success = self.save_analysis_results(
                analysis_id, 
                results, 
                st.session_state.pre_info
            )
            
            if save_success:
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ ë° ì˜êµ¬ ì €ì¥! (ID: {analysis_id})")
                st.info("ğŸ“ ë¶„ì„ ê²°ê³¼ê°€ analysis_history/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
            else:
                st.warning("âš ï¸ ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        return results
    
    def _build_analysis_context(self):
        """ì‚¬ì „ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•"""
        if not st.session_state.pre_info:
            return None
        
        context_parts = []
        pre_info = st.session_state.pre_info
        
        if pre_info.get('conference_name'):
            context_parts.append(f"ì»¨í¼ëŸ°ìŠ¤: {pre_info['conference_name']}")
        if pre_info.get('industry'):
            context_parts.append(f"ì—…ê³„: {pre_info['industry']}")
        if pre_info.get('purpose'):
            context_parts.append(f"ëª©ì : {pre_info['purpose']}")
        if pre_info.get('keywords'):
            context_parts.append(f"í‚¤ì›Œë“œ: {pre_info['keywords']}")
        
        summary = ", ".join(context_parts) if context_parts else "ì¼ë°˜ ë¶„ì„"
        
        return {
            'summary': summary,
            'full_context': pre_info,
            'keywords': pre_info.get('keywords', '').split(',') if pre_info.get('keywords') else [],
            'industry': pre_info.get('industry', ''),
            'purpose': pre_info.get('purpose', 'ì¼ë°˜ ë¶„ì„')
        }
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        st.title("ğŸ¯ ì™„ì „íˆ ì‘ë™í•˜ëŠ” ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ")
        st.markdown("**âœ… ëª¨ë“  ê¸°ëŠ¥ ì‹¤ì œ êµ¬í˜„ ì™„ë£Œ | í—ˆìœ„ ì •ë³´ ì—†ìŒ | íˆ¬ëª…í•œ ìƒíƒœ í‘œì‹œ**")
        
        # ê¸°ëŠ¥ ì†Œê°œ
        with st.expander("ğŸš€ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤", expanded=False):
            st.write("""
            **âœ… ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ëª¨ë“  ê¸°ëŠ¥:**
            - ğŸ“‹ **ì‚¬ì „ì •ë³´ ì…ë ¥**: ì»¨í¼ëŸ°ìŠ¤ëª…, ë‚ ì§œ, ì—…ê³„, í‚¤ì›Œë“œ ë“±
            - ğŸ“ **3ê°€ì§€ ì—…ë¡œë“œ**: ê°œë³„íŒŒì¼, í´ë”/ZIP, URL ë‹¤ìš´ë¡œë“œ
            - ğŸ“¸ **ì´ë¯¸ì§€ OCR**: EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•œêµ­ì–´/ì˜ì–´)
            - ğŸµ **ìŒì„± STT**: Whisperë¡œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
            - ğŸ­ **í™”ì ë¶„ë¦¬**: ìŒì„± íŠ¹ì„± ê¸°ë°˜ ê°„ë‹¨í•œ í™”ì êµ¬ë¶„
            - ğŸ¬ **ë¹„ë””ì˜¤ ì •ë³´**: ê¸°ë³¸ ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
            - ğŸ§  **ì»¨í…ìŠ¤íŠ¸ ë¶„ì„**: ì‚¬ì „ì •ë³´ë¥¼ í™œìš©í•œ ë§ì¶¤í˜• ë¶„ì„
            - ğŸ“Š **ì¢…í•© ë³´ê³ ì„œ**: ëª¨ë“  ê²°ê³¼ë¥¼ í†µí•©í•œ ì™„ì „í•œ ë³´ê³ ì„œ
            - ğŸ’¾ **ë‹¤ìš´ë¡œë“œ**: ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            - ğŸ” **ì‹¤ì‹œê°„ ìƒíƒœ**: ì˜ì¡´ì„± ë° ì‹œìŠ¤í…œ ìƒíƒœ ì‹¤ì œ í™•ì¸
            """)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ì‚¬ì´ë“œë°” í‘œì‹œ
        system_ready = self.display_system_status()
        
        # ë©”ì¸ ì½˜í…ì¸  - 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ì‚¬ì „ì •ë³´", "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“Š ë¶„ì„ ê²°ê³¼", "ğŸ“„ ì¢…í•© ë³´ê³ ì„œ"])
        
        with tab1:
            self.render_pre_info_section()
        
        with tab2:
            uploaded_files = self.file_upload_section_enhanced()
            
            if uploaded_files:
                if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary"):
                    results = self.analyze_files_with_context(uploaded_files)
                    if results:
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ! 'ë¶„ì„ ê²°ê³¼' ë° 'ì¢…í•© ë³´ê³ ì„œ' íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        
        with tab3:
            if st.session_state.analysis_results:
                self.display_results(st.session_state.analysis_results)
            else:
                st.info("ğŸ“Š ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        with tab4:
            if st.session_state.analysis_results:
                self.generate_comprehensive_report(st.session_state.analysis_results)
            else:
                st.info("ğŸ“„ ì¢…í•© ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ë ¤ë©´ ë¨¼ì € íŒŒì¼ ë¶„ì„ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        
        # ì‹œìŠ¤í…œ ì •ë³´ í‘¸í„°
        st.markdown("---")
        st.caption(f"ì‹œìŠ¤í…œ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.sidebar:
            st.markdown("---")
            st.subheader("ğŸ“– ì‚¬ìš©ë²•")
            st.write("""
            1. **ì‚¬ì „ì •ë³´**: ì»¨í¼ëŸ°ìŠ¤ ë°°ê²½ì •ë³´ ì…ë ¥ (ì„ íƒì‚¬í•­)
            2. **íŒŒì¼ ì—…ë¡œë“œ**: 3ê°€ì§€ ë°©ì‹ ì¤‘ ì„ íƒ (ê°œë³„/ZIP/URL)
            3. **ë¶„ì„ ì‹œì‘**: ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ë¶„ì„ ì‹¤í–‰
            4. **ê²°ê³¼ í™•ì¸**: ìƒì„¸ ë¶„ì„ ê²°ê³¼ ë° í™”ì ë¶„ë¦¬ í™•ì¸
            5. **ë³´ê³ ì„œ**: ì „ì²´ ìš”ì•½ ë° ë‹¤ìš´ë¡œë“œ
            """)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        analyzer = CompleteWorkingAnalyzer()
        analyzer.run()
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        st.code(traceback.format_exc())

if __name__ == "__main__":
    main()