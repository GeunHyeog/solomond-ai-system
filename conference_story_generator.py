#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“– ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ ìƒì„± ì—”ì§„
Conference Story Generator for Holistic Analysis

í•µì‹¬ ëª©í‘œ: ë¶„ì‚°ëœ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ë¡œ ì¬êµ¬ì„±
"""

import json
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import streamlit as st
from dataclasses import dataclass, asdict
import re
from collections import defaultdict, Counter
import networkx as nx

try:
    from sentence_transformers import SentenceTransformer
    import spacy
    ADVANCED_NLP_AVAILABLE = True
except ImportError:
    ADVANCED_NLP_AVAILABLE = False

@dataclass
class StorySegment:
    """ìŠ¤í† ë¦¬ ì„¸ê·¸ë¨¼íŠ¸"""
    segment_id: str
    segment_type: str  # opening, main_topic, discussion, conclusion, action_items
    title: str
    content: str
    participants: List[str]
    key_points: List[str]
    source_fragments: List[str]
    timeline_position: int
    importance_score: float

@dataclass
class ConferenceNarrative:
    """ì»¨í¼ëŸ°ìŠ¤ ë‚´ëŸ¬í‹°ë¸Œ ì „ì²´ êµ¬ì¡°"""
    conference_name: str
    narrative_summary: str
    key_takeaways: List[str]
    story_segments: List[StorySegment]
    participant_journey: Dict[str, List[str]]
    decision_points: List[str]
    unresolved_issues: List[str]
    next_steps: List[str]
    confidence_score: float

class ConferenceStoryGenerator:
    """ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ ìƒì„± ì—”ì§„"""
    
    def __init__(self, conference_name: str = "default"):
        self.conference_name = conference_name
        self.db_path = f"conference_analysis_{conference_name}.db"
        
        # NLP ëª¨ë¸ ì´ˆê¸°í™”
        if ADVANCED_NLP_AVAILABLE:
            try:
                self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                
                # SpaCy ëª¨ë¸
                try:
                    self.nlp = spacy.load("ko_core_news_sm")
                except OSError:
                    try:
                        self.nlp = spacy.load("en_core_web_sm")
                    except OSError:
                        self.nlp = spacy.blank("ko")
                
                self.use_advanced_nlp = True
            except Exception as e:
                st.warning(f"ê³ ê¸‰ NLP ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_advanced_nlp = False
        else:
            self.use_advanced_nlp = False
        
        # ìŠ¤í† ë¦¬ êµ¬ì„± ìš”ì†Œ
        self.fragments = []
        self.connections = []
        self.speaker_profiles = {}
        self.topic_clusters = []
        self.story_segments = []
    
    def load_analysis_data(self) -> bool:
        """ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            # ì¡°ê° ë°ì´í„° ë¡œë“œ
            self.fragments = self._load_fragments()
            if not self.fragments:
                return False
            
            # ì—°ê²° ë°ì´í„° ë¡œë“œ (ì˜ë¯¸ì  ì—°ê²° ì—”ì§„ì—ì„œ ìƒì„±)
            # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œí•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ ì—°ê²° ìƒì„±
            self._generate_basic_connections()
            
            return True
            
        except Exception as e:
            st.error(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _load_fragments(self) -> List[Dict]:
        """ì¡°ê° ë°ì´í„° ë¡œë“œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('SELECT * FROM fragments ORDER BY created_at')
            rows = cursor.fetchall()
            
            fragments = []
            for row in rows:
                fragment = {
                    'fragment_id': row[0],
                    'file_source': row[1],
                    'file_type': row[2],
                    'timestamp': row[3],
                    'speaker': row[4],
                    'content': row[5],
                    'confidence': row[6],
                    'keywords': json.loads(row[7]) if row[7] else []
                }
                fragments.append(fragment)
            
            return fragments
            
        except sqlite3.OperationalError:
            return []
        finally:
            conn.close()
    
    def _generate_basic_connections(self):
        """ê¸°ë³¸ ì—°ê²° ìƒì„± (ì˜ë¯¸ì  ì—°ê²° ì—”ì§„ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°)"""
        # ë°œí‘œìë³„ ê·¸ë£¹í•‘
        speaker_groups = defaultdict(list)
        for fragment in self.fragments:
            speaker = fragment.get('speaker', 'Unknown')
            speaker_groups[speaker].append(fragment)
        
        self.speaker_profiles = speaker_groups
        
        # ì£¼ì œë³„ ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„°ë§ (í‚¤ì›Œë“œ ê¸°ë°˜)
        self._cluster_by_keywords()
    
    def _cluster_by_keywords(self):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„°ë§"""
        # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = []
        for fragment in self.fragments:
            all_keywords.extend(fragment.get('keywords', []))
        
        # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
        keyword_freq = Counter(all_keywords)
        top_keywords = [kw for kw, _ in keyword_freq.most_common(10)]
        
        # í‚¤ì›Œë“œë³„ ì¡°ê° ê·¸ë£¹í•‘
        for keyword in top_keywords:
            cluster_fragments = []
            for fragment in self.fragments:
                if keyword in fragment.get('keywords', []):
                    cluster_fragments.append(fragment['fragment_id'])
            
            if len(cluster_fragments) >= 2:
                self.topic_clusters.append({
                    'cluster_name': keyword,
                    'fragments': cluster_fragments,
                    'keyword': keyword
                })
    
    def generate_conference_story(self) -> ConferenceNarrative:
        """ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ ìƒì„±"""
        if not self.load_analysis_data():
            raise ValueError("ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 1. ìŠ¤í† ë¦¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
        story_segments = self._create_story_segments()
        
        # 2. ì „ì²´ ë‚´ëŸ¬í‹°ë¸Œ êµ¬ì„±
        narrative_summary = self._generate_narrative_summary()
        
        # 3. í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
        key_takeaways = self._extract_key_takeaways()
        
        # 4. ì°¸ì—¬ì ì—¬ì • ì¶”ì 
        participant_journey = self._trace_participant_journey()
        
        # 5. ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ ì‹ë³„
        decision_points = self._identify_decision_points()
        
        # 6. ë¯¸í•´ê²° ì´ìŠˆ ì¶”ì¶œ
        unresolved_issues = self._extract_unresolved_issues()
        
        # 7. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
        next_steps = self._generate_next_steps()
        
        # 8. ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = self._calculate_confidence_score()
        
        narrative = ConferenceNarrative(
            conference_name=self.conference_name,
            narrative_summary=narrative_summary,
            key_takeaways=key_takeaways,
            story_segments=story_segments,
            participant_journey=participant_journey,
            decision_points=decision_points,
            unresolved_issues=unresolved_issues,
            next_steps=next_steps,
            confidence_score=confidence_score
        )
        
        return narrative
    
    def _create_story_segments(self) -> List[StorySegment]:
        """ìŠ¤í† ë¦¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±"""
        segments = []
        
        # 1. ì˜¤í”„ë‹ ì„¸ê·¸ë¨¼íŠ¸
        opening_fragments = self._identify_opening_fragments()
        if opening_fragments:
            opening_segment = StorySegment(
                segment_id="opening",
                segment_type="opening",
                title="ì»¨í¼ëŸ°ìŠ¤ ì‹œì‘",
                content=self._summarize_fragments(opening_fragments),
                participants=self._extract_participants(opening_fragments),
                key_points=self._extract_key_points(opening_fragments),
                source_fragments=[f['fragment_id'] for f in opening_fragments],
                timeline_position=1,
                importance_score=0.8
            )
            segments.append(opening_segment)
        
        # 2. ì£¼ìš” ì£¼ì œë³„ ì„¸ê·¸ë¨¼íŠ¸
        for i, topic_cluster in enumerate(self.topic_clusters):
            topic_fragments = [f for f in self.fragments if f['fragment_id'] in topic_cluster['fragments']]
            
            if topic_fragments:
                topic_segment = StorySegment(
                    segment_id=f"topic_{i}",
                    segment_type="main_topic",
                    title=f"ì£¼ì œ ë…¼ì˜: {topic_cluster['cluster_name']}",
                    content=self._summarize_fragments(topic_fragments),
                    participants=self._extract_participants(topic_fragments),
                    key_points=self._extract_key_points(topic_fragments),
                    source_fragments=[f['fragment_id'] for f in topic_fragments],
                    timeline_position=i + 2,
                    importance_score=len(topic_fragments) / len(self.fragments)
                )
                segments.append(topic_segment)
        
        # 3. í† ë¡ /ì§ˆì˜ì‘ë‹µ ì„¸ê·¸ë¨¼íŠ¸
        discussion_fragments = self._identify_discussion_fragments()
        if discussion_fragments:
            discussion_segment = StorySegment(
                segment_id="discussion",
                segment_type="discussion",
                title="í† ë¡  ë° ì§ˆì˜ì‘ë‹µ",
                content=self._summarize_fragments(discussion_fragments),
                participants=self._extract_participants(discussion_fragments),
                key_points=self._extract_key_points(discussion_fragments),
                source_fragments=[f['fragment_id'] for f in discussion_fragments],
                timeline_position=len(segments) + 1,
                importance_score=0.9
            )
            segments.append(discussion_segment)
        
        # 4. ê²°ë¡ /ì •ë¦¬ ì„¸ê·¸ë¨¼íŠ¸
        conclusion_fragments = self._identify_conclusion_fragments()
        if conclusion_fragments:
            conclusion_segment = StorySegment(
                segment_id="conclusion",
                segment_type="conclusion",
                title="ê²°ë¡  ë° ì •ë¦¬",
                content=self._summarize_fragments(conclusion_fragments),
                participants=self._extract_participants(conclusion_fragments),
                key_points=self._extract_key_points(conclusion_fragments),
                source_fragments=[f['fragment_id'] for f in conclusion_fragments],
                timeline_position=len(segments) + 1,
                importance_score=1.0
            )
            segments.append(conclusion_segment)
        
        return segments
    
    def _identify_opening_fragments(self) -> List[Dict]:
        """ì˜¤í”„ë‹ ì¡°ê° ì‹ë³„"""
        opening_keywords = ['ì‹œì‘', 'ì†Œê°œ', 'ì•ˆë…•', 'í™˜ì˜', 'welcome', 'introduction', 'ê°œíšŒ']
        opening_fragments = []
        
        for fragment in self.fragments[:3]:  # ì²˜ìŒ 3ê°œ ì¡°ê°ì—ì„œ ì°¾ê¸°
            content = fragment['content'].lower()
            if any(keyword in content for keyword in opening_keywords):
                opening_fragments.append(fragment)
        
        return opening_fragments if opening_fragments else self.fragments[:1]
    
    def _identify_discussion_fragments(self) -> List[Dict]:
        """í† ë¡  ì¡°ê° ì‹ë³„"""
        discussion_keywords = ['ì§ˆë¬¸', 'ë‹µë³€', 'í† ë¡ ', 'ì˜ê²¬', 'question', 'discussion', 'ì–´ë–»ê²Œ', 'ì™œ']
        discussion_fragments = []
        
        for fragment in self.fragments:
            content = fragment['content'].lower()
            if any(keyword in content for keyword in discussion_keywords):
                discussion_fragments.append(fragment)
        
        return discussion_fragments
    
    def _identify_conclusion_fragments(self) -> List[Dict]:
        """ê²°ë¡  ì¡°ê° ì‹ë³„"""
        conclusion_keywords = ['ê²°ë¡ ', 'ì •ë¦¬', 'ë§ˆë¬´ë¦¬', 'ë', 'conclusion', 'summary', 'ë‹¤ìŒ', 'ì•ìœ¼ë¡œ']
        conclusion_fragments = []
        
        for fragment in self.fragments[-3:]:  # ë§ˆì§€ë§‰ 3ê°œ ì¡°ê°ì—ì„œ ì°¾ê¸°
            content = fragment['content'].lower()
            if any(keyword in content for keyword in conclusion_keywords):
                conclusion_fragments.append(fragment)
        
        return conclusion_fragments if conclusion_fragments else self.fragments[-1:]
    
    def _summarize_fragments(self, fragments: List[Dict]) -> str:
        """ì¡°ê°ë“¤ì„ ìš”ì•½"""
        if not fragments:
            return "ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ëª¨ë“  ë‚´ìš© ê²°í•©
        all_content = " ".join([f['content'] for f in fragments if f['content']])
        
        # ê¸¸ì´ ì œí•œ (1000ì)
        if len(all_content) > 1000:
            all_content = all_content[:1000] + "..."
        
        return all_content
    
    def _extract_participants(self, fragments: List[Dict]) -> List[str]:
        """ì°¸ì—¬ì ì¶”ì¶œ"""
        participants = set()
        for fragment in fragments:
            if fragment.get('speaker') and fragment['speaker'].strip():
                participants.add(fragment['speaker'])
        
        return list(participants)
    
    def _extract_key_points(self, fragments: List[Dict]) -> List[str]:
        """í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        all_keywords = []
        for fragment in fragments:
            all_keywords.extend(fragment.get('keywords', []))
        
        # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ
        keyword_freq = Counter(all_keywords)
        key_points = [f"â€¢ {kw}" for kw, _ in keyword_freq.most_common(5)]
        
        return key_points
    
    def _generate_narrative_summary(self) -> str:
        """ì „ì²´ ë‚´ëŸ¬í‹°ë¸Œ ìš”ì•½ ìƒì„±"""
        summary_parts = []
        
        # ê¸°ë³¸ ì •ë³´
        summary_parts.append(f"ğŸ“… **{self.conference_name} ì»¨í¼ëŸ°ìŠ¤**")
        summary_parts.append(f"ì´ {len(self.fragments)}ê°œì˜ ìë£Œê°€ ë¶„ì„ë˜ì—ˆìœ¼ë©°, {len(self.speaker_profiles)}ëª…ì˜ ì°¸ì—¬ìì™€ {len(self.topic_clusters)}ê°œì˜ ì£¼ìš” ì£¼ì œê°€ ë…¼ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        summary_parts.append("")
        
        # ì£¼ìš” íë¦„
        summary_parts.append("**ğŸ“– ì»¨í¼ëŸ°ìŠ¤ íë¦„:**")
        
        if self.story_segments:
            for segment in sorted(self.story_segments, key=lambda s: s.timeline_position):
                summary_parts.append(f"{segment.timeline_position}. **{segment.title}** - {len(segment.participants)}ëª… ì°¸ì—¬")
        
        summary_parts.append("")
        
        # ì „ì²´ì ì¸ íŠ¹ì§•
        if self.topic_clusters:
            top_topic = max(self.topic_clusters, key=lambda t: len(t['fragments']))
            summary_parts.append(f"ê°€ì¥ ì§‘ì¤‘ì ìœ¼ë¡œ ë…¼ì˜ëœ ì£¼ì œëŠ” '{top_topic['cluster_name']}'ì˜€ìœ¼ë©°, ")
        
        if self.speaker_profiles:
            most_active_speaker = max(self.speaker_profiles.keys(), key=lambda s: len(self.speaker_profiles[s]))
            summary_parts.append(f"'{most_active_speaker}'ê°€ ê°€ì¥ í™œë°œí•˜ê²Œ ë°œì–¸í–ˆìŠµë‹ˆë‹¤.")
        
        return "\n".join(summary_parts)
    
    def _extract_key_takeaways(self) -> List[str]:
        """í•µì‹¬ ê²°ê³¼ ì¶”ì¶œ"""
        takeaways = []
        
        # ê°€ì¥ ì¤‘ìš”í•œ ì£¼ì œë“¤
        if self.topic_clusters:
            top_topics = sorted(self.topic_clusters, key=lambda t: len(t['fragments']), reverse=True)[:3]
            for i, topic in enumerate(top_topics, 1):
                takeaways.append(f"{i}. {topic['cluster_name']}ì— ëŒ€í•œ ì‹¬ë„ ìˆëŠ” ë…¼ì˜ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.")
        
        # ì°¸ì—¬ì í™œë™ë„
        if self.speaker_profiles:
            active_speakers = sorted(self.speaker_profiles.keys(), key=lambda s: len(self.speaker_profiles[s]), reverse=True)[:2]
            takeaways.append(f"ì£¼ìš” ë°œí‘œìëŠ” {', '.join(active_speakers)}ì˜€ìŠµë‹ˆë‹¤.")
        
        # ì „ì²´ì ì¸ ì„±ê³¼
        avg_confidence = np.mean([f['confidence'] for f in self.fragments]) if self.fragments else 0
        takeaways.append(f"ë¶„ì„ í’ˆì§ˆì´ {avg_confidence:.1%}ë¡œ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.")
        
        return takeaways
    
    def _trace_participant_journey(self) -> Dict[str, List[str]]:
        """ì°¸ì—¬ìë³„ ì—¬ì • ì¶”ì """
        journey = {}
        
        for speaker, fragments in self.speaker_profiles.items():
            speaker_journey = []
            
            # ë°œì–¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            sorted_fragments = sorted(fragments, key=lambda f: f.get('timestamp', ''))
            
            for fragment in sorted_fragments[:5]:  # ìµœëŒ€ 5ê°œ ë°œì–¸
                content_preview = fragment['content'][:50] + "..." if len(fragment['content']) > 50 else fragment['content']
                speaker_journey.append(content_preview)
            
            journey[speaker] = speaker_journey
        
        return journey
    
    def _identify_decision_points(self) -> List[str]:
        """ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸ ì‹ë³„"""
        decision_keywords = ['ê²°ì •', 'ì„ íƒ', 'ì±„íƒ', 'ìŠ¹ì¸', 'í•©ì˜', 'decision', 'agree', 'ì •í•˜']
        decision_points = []
        
        for fragment in self.fragments:
            content = fragment['content'].lower()
            if any(keyword in content for keyword in decision_keywords):
                decision_preview = fragment['content'][:100] + "..." if len(fragment['content']) > 100 else fragment['content']
                decision_points.append(f"â€¢ {decision_preview}")
        
        return decision_points[:5]  # ìµœëŒ€ 5ê°œ
    
    def _extract_unresolved_issues(self) -> List[str]:
        """ë¯¸í•´ê²° ì´ìŠˆ ì¶”ì¶œ"""
        issue_keywords = ['ë¬¸ì œ', 'ì´ìŠˆ', 'í•´ê²°', 'ê²€í† ', 'ê³ ë¯¼', 'issue', 'problem', 'ì¶”í›„', 'ë‚˜ì¤‘']
        unresolved_issues = []
        
        for fragment in self.fragments:
            content = fragment['content'].lower()
            if any(keyword in content for keyword in issue_keywords):
                issue_preview = fragment['content'][:100] + "..." if len(fragment['content']) > 100 else fragment['content']
                unresolved_issues.append(f"â€¢ {issue_preview}")
        
        return unresolved_issues[:5]  # ìµœëŒ€ 5ê°œ
    
    def _generate_next_steps(self) -> List[str]:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        next_steps = []
        
        # ì£¼ìš” ì£¼ì œë³„ í›„ì† ì¡°ì¹˜
        for topic in self.topic_clusters[:3]:
            next_steps.append(f"ğŸ“‹ {topic['cluster_name']} ê´€ë ¨ ìƒì„¸ ê³„íš ìˆ˜ë¦½")
        
        # ì°¸ì—¬ìë³„ í›„ì† ì¡°ì¹˜
        if self.speaker_profiles:
            next_steps.append(f"ğŸ“ ì£¼ìš” ì°¸ì—¬ì {len(self.speaker_profiles)}ëª…ê³¼ ê°œë³„ í›„ì† ë¯¸íŒ…")
        
        # ì¼ë°˜ì ì¸ í›„ì† ì¡°ì¹˜
        next_steps.extend([
            "ğŸ“ íšŒì˜ë¡ ì •ë¦¬ ë° ë°°í¬",
            "ğŸ“… ë‹¤ìŒ ë¯¸íŒ… ì¼ì • ì¡°ìœ¨",
            "ğŸ¯ ì‹¤í–‰ ê³„íš êµ¬ì²´í™”"
        ])
        
        return next_steps[:5]  # ìµœëŒ€ 5ê°œ
    
    def _calculate_confidence_score(self) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not self.fragments:
            return 0.0
        
        # ê°œë³„ ì¡°ê° ì‹ ë¢°ë„ í‰ê· 
        fragment_confidence = np.mean([f['confidence'] for f in self.fragments])
        
        # ì—°ê²°ì„± ë³´ë„ˆìŠ¤ (ë” ë§ì€ ì—°ê²°ì´ ìˆìœ¼ë©´ ë” ì‹ ë¢°í•  ë§Œí•¨)
        connection_bonus = min(0.2, len(self.topic_clusters) * 0.05)
        
        # ì°¸ì—¬ì ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤
        diversity_bonus = min(0.1, len(self.speaker_profiles) * 0.02)
        
        total_confidence = fragment_confidence + connection_bonus + diversity_bonus
        
        return min(1.0, total_confidence)

# Streamlit UI
def main():
    st.title("ğŸ“– ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ ìƒì„± ì—”ì§„")
    st.markdown("**ë¶„ì‚°ëœ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤**")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    conference_name = st.sidebar.text_input("ì»¨í¼ëŸ°ìŠ¤ ì´ë¦„", "my_conference")
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = ConferenceStoryGenerator(conference_name)
    
    # ìŠ¤í† ë¦¬ ìƒì„±
    if st.button("ğŸ“– ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ ìƒì„±"):
        with st.spinner("ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                narrative = generator.generate_conference_story()
                
                st.success("âœ… ì»¨í¼ëŸ°ìŠ¤ ìŠ¤í† ë¦¬ ìƒì„± ì™„ë£Œ!")
                
                # ì‹ ë¢°ë„ í‘œì‹œ
                st.metric("ğŸ“Š ìŠ¤í† ë¦¬ ì‹ ë¢°ë„", f"{narrative.confidence_score:.1%}")
                
                # ì „ì²´ ë‚´ëŸ¬í‹°ë¸Œ
                st.markdown("## ğŸ“– ì»¨í¼ëŸ°ìŠ¤ ì „ì²´ ìŠ¤í† ë¦¬")
                st.markdown(narrative.narrative_summary)
                
                # í•µì‹¬ ê²°ê³¼
                st.markdown("## ğŸ¯ í•µì‹¬ ê²°ê³¼")
                for takeaway in narrative.key_takeaways:
                    st.markdown(f"- {takeaway}")
                
                # ìŠ¤í† ë¦¬ ì„¸ê·¸ë¨¼íŠ¸
                st.markdown("## ğŸ“š ìƒì„¸ ìŠ¤í† ë¦¬ êµ¬ì„±")
                for segment in sorted(narrative.story_segments, key=lambda s: s.timeline_position):
                    with st.expander(f"ğŸ”¸ {segment.title} (ì¤‘ìš”ë„: {segment.importance_score:.1%})"):
                        st.markdown(f"**ì°¸ì—¬ì:** {', '.join(segment.participants) if segment.participants else 'ì—†ìŒ'}")
                        st.markdown(f"**í•µì‹¬ í¬ì¸íŠ¸:**")
                        for point in segment.key_points:
                            st.markdown(point)
                        st.markdown(f"**ë‚´ìš©:**")
                        st.markdown(segment.content)
                
                # ì°¸ì—¬ì ì—¬ì •
                if narrative.participant_journey:
                    st.markdown("## ğŸ‘¥ ì°¸ì—¬ìë³„ ì—¬ì •")
                    for participant, journey in narrative.participant_journey.items():
                        with st.expander(f"ğŸ¤ {participant}"):
                            for i, step in enumerate(journey, 1):
                                st.markdown(f"{i}. {step}")
                
                # ì˜ì‚¬ê²°ì • í¬ì¸íŠ¸
                if narrative.decision_points:
                    st.markdown("## âš–ï¸ ì£¼ìš” ì˜ì‚¬ê²°ì •")
                    for decision in narrative.decision_points:
                        st.markdown(decision)
                
                # ë¯¸í•´ê²° ì´ìŠˆ
                if narrative.unresolved_issues:
                    st.markdown("## â“ ë¯¸í•´ê²° ì´ìŠˆ")
                    for issue in narrative.unresolved_issues:
                        st.markdown(issue)
                
                # ë‹¤ìŒ ë‹¨ê³„
                st.markdown("## â¡ï¸ ë‹¤ìŒ ë‹¨ê³„")
                for step in narrative.next_steps:
                    st.markdown(f"- {step}")
                
                # ìƒì„¸ ì •ë³´
                with st.expander("ğŸ“Š ìƒì„¸ ë¶„ì„ ì •ë³´"):
                    st.json(asdict(narrative))
                
            except ValueError as e:
                st.error(f"âŒ {e}")
            except Exception as e:
                st.error(f"âŒ ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    st.markdown("---")
    st.markdown("**ğŸ’¡ ì‚¬ìš©ë²•:** ë¨¼ì € í™€ë¦¬ìŠ¤í‹± ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ê¸°ì™€ ì˜ë¯¸ì  ì—°ê²° ì—”ì§„ì„ ì‹¤í–‰í•œ í›„ ì´ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()