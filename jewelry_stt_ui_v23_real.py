#!/usr/bin/env python3
"""
ì†”ë¡œëª¬ë“œ AI v2.3 - ì‹¤ì œ ë¶„ì„ í†µí•© ë²„ì „
ê°€ì§œ ë¶„ì„ì„ ì‹¤ì œ ë¶„ì„ìœ¼ë¡œ ì™„ì „ êµì²´

ì£¼ìš” ê°œì„ ì‚¬í•­ (v2.3.1):
- ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ ìš”ì•½ ë° ë¯¸ë¦¬ë³´ê¸° ê°œì„ 
- ê°œë³„ íŒŒì¼ í…ìŠ¤íŠ¸ ë‚´ìš© ì‹¤ì‹œê°„ í‘œì‹œ ì¶”ê°€
- ë¶„ì„ ê²°ê³¼ íƒ­ UI/UX ëŒ€í­ ê°œì„  (í•„í„°ë§, í˜ì´ì§•, ë‹¤ìš´ë¡œë“œ)
- ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¦‰ì‹œ í™œì„±í™” ë° ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
- ì‚¬ìš©ì ê²½í—˜ ê°œì„  (ì• ë‹ˆë©”ì´ì…˜, ëª…í™•í•œ ì•ˆë‚´ ë©”ì‹œì§€)
"""

import streamlit as st
import sys
import os
import asyncio
import tempfile
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
import logging
from datetime import datetime

# NumPy ì„í¬íŠ¸ (ì˜µì…˜)
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì˜µì…˜)
try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ì‹¤ì œ ë¶„ì„ ì—”ì§„ import
try:
    from core.real_analysis_engine import global_analysis_engine, analyze_file_real
    REAL_ANALYSIS_AVAILABLE = True
    print("[SUCCESS] ì‹¤ì œ ë¶„ì„ ì—”ì§„ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    REAL_ANALYSIS_AVAILABLE = False
    print(f"[ERROR] ì‹¤ì œ ë¶„ì„ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ import
try:
    from core.large_file_handler import large_file_handler
    LARGE_FILE_HANDLER_AVAILABLE = True
    print("[SUCCESS] ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    LARGE_FILE_HANDLER_AVAILABLE = False
    print(f"[ERROR] ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ import
try:
    from core.lecture_content_compiler import compile_comprehensive_lecture
    LECTURE_COMPILER_AVAILABLE = True
    print("[SUCCESS] ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    LECTURE_COMPILER_AVAILABLE = False
    print(f"[ERROR] ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from core.performance_monitor import global_performance_monitor, get_system_performance, get_current_success_rate
    PERFORMANCE_MONITOR_AVAILABLE = True
    print("[SUCCESS] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    PERFORMANCE_MONITOR_AVAILABLE = False
    print(f"[ERROR] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ê¸°ì¡´ ëª¨ë“ˆë“¤
try:
    from core.hybrid_llm_manager_v23 import HybridLLMManager
    HYBRID_LLM_AVAILABLE = True
except ImportError:
    HYBRID_LLM_AVAILABLE = False
    
# Streamlit ì„¤ì •
st.set_page_config(
    page_title="ì†”ë¡œëª¬ë“œ AI v2.3 - ì‹¤ì œ ë¶„ì„",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded"
)

def convert_numpy_types(obj):
    """NumPy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif NUMPY_AVAILABLE:
        # NumPyê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ NumPy íƒ€ì… ì²´í¬
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
    
    # NumPyê°€ ì—†ê±°ë‚˜ ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    return obj

class SolomondRealAnalysisUI:
    """ì†”ë¡œëª¬ë“œ AI v2.3 ì‹¤ì œ ë¶„ì„ UI - 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self):
        self.setup_logging()
        self.analysis_engine = global_analysis_engine if REAL_ANALYSIS_AVAILABLE else None
        self.session_stats = {
            "files_analyzed": 0,
            "total_processing_time": 0,
            "successful_analyses": 0,
            "session_start": datetime.now()
        }
        
        # 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬
        if 'workflow_step' not in st.session_state:
            st.session_state.workflow_step = 1
        if 'project_info' not in st.session_state:
            st.session_state.project_info = {}
        if 'uploaded_files_data' not in st.session_state:
            st.session_state.uploaded_files_data = []
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = []
        if 'final_report' not in st.session_state:
            st.session_state.final_report = None
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ - 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°"""
        
        # í—¤ë”
        st.markdown("""
        # ğŸ’ ì†”ë¡œëª¬ë“œ AI v2.3 - ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ì›Œí¬í”Œë¡œìš°
        
        **ğŸš€ 4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤:** ê¸°ë³¸ì •ë³´ â†’ ì—…ë¡œë“œ â†’ ê²€í†  â†’ ë³´ê³ ì„œ
        """)
        
        # ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœ í‘œì‹œ
        self.display_workflow_progress()
        
        # í˜„ì¬ ë‹¨ê³„ì— ë”°ë¥¸ ë Œë”ë§
        if st.session_state.workflow_step == 1:
            self.render_step1_basic_info()
        elif st.session_state.workflow_step == 2:
            self.render_step2_upload()
        elif st.session_state.workflow_step == 3:
            self.render_step3_review()
        elif st.session_state.workflow_step == 4:
            self.render_step4_report()
        
        # í•˜ë‹¨ì— ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"):
            self.display_system_status()
    
    def display_workflow_progress(self):
        """ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœ í‘œì‹œ"""
        steps = [
            "1ï¸âƒ£ ê¸°ë³¸ì •ë³´",
            "2ï¸âƒ£ ì—…ë¡œë“œ", 
            "3ï¸âƒ£ ê²€í† ",
            "4ï¸âƒ£ ë³´ê³ ì„œ"
        ]
        
        cols = st.columns(4)
        for i, (col, step) in enumerate(zip(cols, steps)):
            with col:
                if i + 1 == st.session_state.workflow_step:
                    st.markdown(f"**ğŸ”¸ {step}**")
                elif i + 1 < st.session_state.workflow_step:
                    st.markdown(f"âœ… {step}")
                else:
                    st.markdown(f"âšª {step}")
        
        st.markdown("---")
    
    def render_navigation_bar(self, current_step: int):
        """í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°” ë Œë”ë§"""
        st.markdown("---")
        
        # ì´ì „/ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼ ë¡œì§
        prev_step = current_step - 1 if current_step > 1 else None
        next_step = current_step + 1 if current_step < 4 else None
        
        # ë‹¨ê³„ë³„ ì¡°ê±´ ê²€ì‚¬
        can_go_next = self._can_proceed_to_next_step(current_step)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            if prev_step:
                step_names = {1: "ê¸°ë³¸ì •ë³´", 2: "ì—…ë¡œë“œ", 3: "ê²€í† ", 4: "ë³´ê³ ì„œ"}
                if st.button(f"â¬…ï¸ ì´ì „ ë‹¨ê³„ ({step_names[prev_step]})", type="secondary"):
                    st.session_state.workflow_step = prev_step
                    st.rerun()
        
        with col3:
            if next_step and can_go_next:
                step_names = {2: "ì—…ë¡œë“œ", 3: "ê²€í† ", 4: "ë³´ê³ ì„œ"}
                button_text = f"â¡ï¸ ë‹¤ìŒ ë‹¨ê³„ ({step_names[next_step]})"
                if current_step == 3:
                    button_text = "ğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ìƒì„±"
                
                if st.button(button_text, type="primary"):
                    st.session_state.workflow_step = next_step
                    if current_step == 3:
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ! ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    st.rerun()
            elif next_step and not can_go_next:
                # ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
                if current_step == 1:
                    st.info("ê¸°ë³¸ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ 'ê±´ë„ˆë›°ê¸°' ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                elif current_step == 2:
                    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë™ì˜ìƒ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif current_step == 3:
                    st.info("ë¶„ì„ì„ ì™„ë£Œí•œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    def _can_proceed_to_next_step(self, current_step: int) -> bool:
        """ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•œì§€ í™•ì¸"""
        if current_step == 1:
            # Step 1ì€ í•­ìƒ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŒ
            return True
        elif current_step == 2:
            # Step 2ëŠ” íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆê±°ë‚˜ YouTube URLì´ ìˆì–´ì•¼ í•¨
            return bool(st.session_state.uploaded_files_data)
        elif current_step == 3:
            # Step 3ëŠ” ë¶„ì„ ê²°ê³¼ê°€ ìˆì–´ì•¼ í•¨
            return bool(st.session_state.analysis_results)
        return False
    
    def render_step1_basic_info(self):
        """1ë‹¨ê³„: ê¸°ë³¸ì •ë³´ ì…ë ¥"""
        st.markdown("## 1ï¸âƒ£ í”„ë¡œì íŠ¸ ê¸°ë³¸ì •ë³´ (ì„ íƒì‚¬í•­)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ“‹ í”„ë¡œì íŠ¸ ì •ë³´")
            project_name = st.text_input(
                "í”„ë¡œì íŠ¸ëª…", 
                value=st.session_state.project_info.get('name', ''),
                placeholder="ì˜ˆ: 2024ë…„ ì£¼ì–¼ë¦¬ íŠ¸ë Œë“œ ë¶„ì„"
            )
            
            project_type = st.selectbox(
                "ë¶„ì„ ìœ í˜•",
                ["ì¼ë°˜ ë¶„ì„", "ì£¼ì–¼ë¦¬ ì „ë¬¸ ë¶„ì„", "ê³ ê° í”¼ë“œë°± ë¶„ì„", "ì‹œì¥ì¡°ì‚¬ ë¶„ì„", "êµìœ¡/í›ˆë ¨ ìë£Œ ë¶„ì„"],
                index=["ì¼ë°˜ ë¶„ì„", "ì£¼ì–¼ë¦¬ ì „ë¬¸ ë¶„ì„", "ê³ ê° í”¼ë“œë°± ë¶„ì„", "ì‹œì¥ì¡°ì‚¬ ë¶„ì„", "êµìœ¡/í›ˆë ¨ ìë£Œ ë¶„ì„"].index(
                    st.session_state.project_info.get('type', 'ì¼ë°˜ ë¶„ì„')
                )
            )
            
            priority = st.select_slider(
                "ìš°ì„ ìˆœìœ„",
                options=["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ", "ê¸´ê¸‰"],
                value=st.session_state.project_info.get('priority', 'ë³´í†µ')
            )
        
        with col2:
            st.markdown("### ğŸ¯ ë¶„ì„ ëª©í‘œ")
            objective = st.text_area(
                "ë¶„ì„ ëª©ì  ë° ëª©í‘œ",
                value=st.session_state.project_info.get('objective', ''),
                placeholder="ì˜ˆ: ê³ ê° ìŒì„± ë°ì´í„°ì—ì„œ ì£¼ì–¼ë¦¬ ì„ í˜¸ë„ íŒ¨í„´ ë¶„ì„",
                height=80
            )
            
            target_language = st.selectbox(
                "ì£¼ìš” ì…ë ¥ ì–¸ì–´",
                ["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´", "ìŠ¤í˜ì¸ì–´"],
                index=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´", "ìŠ¤í˜ì¸ì–´"].index(
                    st.session_state.project_info.get('target_language', 'ìë™ ê°ì§€')
                )
            )
        
        # ìƒˆë¡œìš´ ì„¹ì…˜: ì°¸ì„ì ë° ìƒí™© ì •ë³´
        st.markdown("### ğŸ‘¥ ì°¸ì„ì ë° ìƒí™© ì •ë³´ (ë¶„ì„ í’ˆì§ˆ í–¥ìƒ)")
        
        col3, col4 = st.columns(2)
        
        with col3:
            participants = st.text_area(
                "ì°¸ì„ì ì •ë³´",
                value=st.session_state.project_info.get('participants', ''),
                placeholder="ì˜ˆ: ê¹€ì² ìˆ˜ (ë§ˆì¼€íŒ… íŒ€ì¥), ë°•ì˜í¬ (ë””ìì¸ ì‹¤ì¥), ê³ ê° A, B, C",
                height=80,
                help="ì°¸ì„ì ì´ë¦„ê³¼ ì—­í• ì„ ì…ë ¥í•˜ë©´ ìŒì„± ì¸ì‹ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤"
            )
            
            speakers = st.text_input(
                "ì£¼ìš” ë°œí‘œì",
                value=st.session_state.project_info.get('speakers', ''),
                placeholder="ì˜ˆ: ê¹€ì² ìˆ˜, ë°•ì˜í¬",
                help="ì£¼ìš” ë°œí‘œìë¥¼ ëª…ì‹œí•˜ë©´ í™”ì êµ¬ë¶„ê³¼ ë‚´ìš© ë¶„ì„ì´ ê°œì„ ë©ë‹ˆë‹¤"
            )
        
        with col4:
            event_context = st.text_area(
                "ìƒí™© ë° ë°°ê²½",
                value=st.session_state.project_info.get('event_context', ''),
                placeholder="ì˜ˆ: 2024ë…„ Q1 ì£¼ì–¼ë¦¬ íŠ¸ë Œë“œ ì„¸ë¯¸ë‚˜, ê³ ê° í”¼ë“œë°± ìˆ˜ì§‘ íšŒì˜",
                height=80,
                help="ìƒí™© ì •ë³´ëŠ” ë¶„ì„ ê²°ê³¼ì˜ í•´ì„ê³¼ ê°•ì˜ ë‚´ìš© ìƒì„±ì— í™œìš©ë©ë‹ˆë‹¤"
            )
            
            topic_keywords = st.text_input(
                "ì£¼ìš” ì£¼ì œ í‚¤ì›Œë“œ",
                value=st.session_state.project_info.get('topic_keywords', ''),
                placeholder="ì˜ˆ: ë‹¤ì´ì•„ëª¬ë“œ, ê³¨ë“œ, íŠ¸ë Œë“œ, ë¸Œëœë”©, ê³ ê°ë§Œì¡±",
                help="ì˜ˆìƒë˜ëŠ” ì£¼ì œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ OCRê³¼ STT ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤"
            )
        
        # ë‹¤ê°ë„ ë¶„ì„ ì„¤ì •
        st.markdown("### ğŸ”„ ë‹¤ê°ë„ ë¶„ì„ ì„¤ì •")
        
        col5, col6 = st.columns(2)
        
        with col5:
            enable_multi_angle = st.checkbox(
                "ë‹¤ê°ë„ ì¢…í•© ë¶„ì„ í™œì„±í™”",
                value=st.session_state.project_info.get('enable_multi_angle', True),
                help="ë™ì¼ ìƒí™©ì˜ ì—¬ëŸ¬ íŒŒì¼(ì˜ìƒ, ì´ë¯¸ì§€, ìŒì„±)ì„ ì¢…í•©í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤"
            )
            
            output_format = st.multiselect(
                "ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹",
                ["ìš”ì•½ í…ìŠ¤íŠ¸", "í‚¤ì›Œë“œ ì¶”ì¶œ", "ê°ì • ë¶„ì„", "ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜", "í†µê³„ ì°¨íŠ¸", "ì¢…í•© ê°•ì˜ ìë£Œ"],
                default=st.session_state.project_info.get('output_format', ["ìš”ì•½ í…ìŠ¤íŠ¸", "í‚¤ì›Œë“œ ì¶”ì¶œ", "ì¢…í•© ê°•ì˜ ìë£Œ"])
            )
        
        with col6:
            analysis_depth = st.select_slider(
                "ë¶„ì„ ê¹Šì´",
                options=["ê¸°ë³¸", "ìƒì„¸", "ì‹¬ì¸µ", "ì „ë¬¸ê°€ê¸‰"],
                value=st.session_state.project_info.get('analysis_depth', 'ìƒì„¸'),
                help="ê¹Šì´ê°€ ë†’ì„ìˆ˜ë¡ ë” ìƒì„¸í•œ ë¶„ì„ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤"
            )
        
        # ğŸ¯ ë¶„ì„ ëª¨ë“œ ì„ íƒ (ë…ë¦½ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì§ê´€ì„± ê°œì„ )
        st.markdown("---")
        st.markdown("### ğŸ¯ ë¶„ì„ ëª¨ë“œ ì„ íƒ")
        
        col7, col8 = st.columns([3, 2])
        
        with col7:
            st.markdown("**ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ íŒŒì¼ë“¤ì„ ë¶„ì„í• ê¹Œìš”?**")
            analysis_mode = st.radio(
                "ë¶„ì„ ë°©ì‹ ì„ íƒ",
                options=[
                    "ğŸš€ **ë°°ì¹˜ ì¢…í•© ë¶„ì„** (ê¶Œì¥) - ëª¨ë“  íŒŒì¼ì„ í†µí•©í•˜ì—¬ ê³ í’ˆì§ˆ ë¶„ì„",
                    "ğŸ“ **ê°œë³„ íŒŒì¼ ë¶„ì„** - ê° íŒŒì¼ì„ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„"
                ],
                index=0 if st.session_state.project_info.get('correlation_analysis', True) else 1,
                label_visibility="collapsed"
            )
            
            correlation_analysis = "ë°°ì¹˜ ì¢…í•© ë¶„ì„" in analysis_mode
        
        with col8:
            if correlation_analysis:
                st.success("""
                âœ¨ **ë°°ì¹˜ ì¢…í•© ë¶„ì„ì˜ ì¥ì :**
                - íŒŒì¼ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
                - ì¤‘ë³µ ë‚´ìš© ìë™ ì œê±°
                - ì»¨í…ìŠ¤íŠ¸ í†µí•©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
                - ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
                """)
            else:
                st.warning("""
                ğŸ“ **ê°œë³„ íŒŒì¼ ë¶„ì„ íŠ¹ì§•:**
                - íŒŒì¼ë³„ ë…ë¦½ì  ì²˜ë¦¬
                - ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
                - ìƒê´€ê´€ê³„ ë¶„ì„ ë¶ˆê°€
                - ì œí•œì ì¸ í†µí•© ì¸ì‚¬ì´íŠ¸
                """)
        
        # í™•ì¥ëœ ê¸°ë³¸ì •ë³´ ì €ì¥
        st.session_state.project_info = {
            'name': project_name,
            'type': project_type,
            'priority': priority,
            'objective': objective,
            'target_language': target_language,
            'participants': participants,
            'speakers': speakers,
            'event_context': event_context,
            'topic_keywords': topic_keywords,
            'enable_multi_angle': enable_multi_angle,
            'analysis_depth': analysis_depth,
            'correlation_analysis': correlation_analysis,
            'output_format': output_format,
            'created_time': datetime.now().isoformat()
        }
        
        # ê±´ë„ˆë›°ê¸° ë²„íŠ¼ (ì¤‘ì•™ì— ë³„ë„ë¡œ)
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ“‹ ê¸°ë³¸ì •ë³´ ê±´ë„ˆë›°ê³  ì—…ë¡œë“œ ì‹œì‘", type="primary", use_container_width=True):
                st.session_state.workflow_step = 2
                st.rerun()
        
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(1)
    
    def render_step2_upload(self):
        """2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ"""
        st.markdown("## 2ï¸âƒ£ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ")
        
        # í”„ë¡œì íŠ¸ ì •ë³´ ìš”ì•½ í‘œì‹œ
        if st.session_state.project_info.get('name'):
            with st.expander("ğŸ“‹ í”„ë¡œì íŠ¸ ì •ë³´ ìš”ì•½"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**í”„ë¡œì íŠ¸ëª…:** {st.session_state.project_info.get('name', 'N/A')}")
                    st.write(f"**ë¶„ì„ ìœ í˜•:** {st.session_state.project_info.get('type', 'N/A')}")
                with col2:
                    st.write(f"**ìš°ì„ ìˆœìœ„:** {st.session_state.project_info.get('priority', 'N/A')}")
                    st.write(f"**ì£¼ìš” ì–¸ì–´:** {st.session_state.project_info.get('target_language', 'N/A')}")
        
        # ì§€ì› íŒŒì¼ í˜•ì‹ ì•ˆë‚´
        with st.expander("ğŸ“ ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹"):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("""
                **ğŸ¤ ìŒì„±/ë™ì˜ìƒ:**
                - MP3, WAV, FLAC, M4A
                - MP4, MOV, AVI
                - ìœ íŠœë¸Œ URL
                """)
            with col2:
                st.markdown("""
                **ğŸ–¼ï¸ ì´ë¯¸ì§€:**
                - JPG, JPEG, PNG
                - BMP, TIFF, WEBP
                - PDF (ì´ë¯¸ì§€ í¬í•¨)
                """)
            with col3:
                st.markdown("""
                **ğŸ“„ ë¬¸ì„œ:**
                - PDF ë¬¸ì„œ
                - Word (DOCX)
                - í…ìŠ¤íŠ¸ (TXT)
                """)
        
        # íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤
        st.markdown("### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ ì§€ì› (5GBê¹Œì§€)
        if LARGE_FILE_HANDLER_AVAILABLE:
            st.info("ğŸ’ª **ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›**: ë™ì˜ìƒ íŒŒì¼ ìµœëŒ€ 5GBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥ (ìë™ ì²­í¬ ì²˜ë¦¬)")
            
        uploaded_files = st.file_uploader(
            "íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ë™ì‹œ ì„ íƒ ê°€ëŠ¥, ë™ì˜ìƒ ìµœëŒ€ 5GB/íŒŒì¼)",
            type=['wav', 'mp3', 'flac', 'm4a', 'mp4', 'mov', 'avi', 
                  'jpg', 'jpeg', 'png', 'bmp', 'tiff', 'webp',
                  'pdf', 'docx', 'txt'],
            accept_multiple_files=True,
            help="Ctrl/Cmd + í´ë¦­ìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥. ëŒ€ìš©ëŸ‰ ë™ì˜ìƒì€ ìë™ìœ¼ë¡œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë©ë‹ˆë‹¤."
        )
        
        # ë™ì˜ìƒ URL ì…ë ¥
        st.markdown("### ğŸ¬ ë™ì˜ìƒ URL ì¶”ê°€")
        video_urls = st.text_area(
            "ë™ì˜ìƒ URL (YouTube, Brightcove ë“± - í•œ ì¤„ì— í•˜ë‚˜ì”©)",
            placeholder="https://www.youtube.com/watch?v=example1\nhttps://players.brightcove.net/1659762912/default_default/index.html?videoId=6374563565112\nhttps://youtu.be/example3",
            height=120,
            help="ì§€ì› í”Œë«í¼: YouTube, Brightcove, ê¸°íƒ€ ì§ì ‘ ë™ì˜ìƒ ë§í¬"
        )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
        if uploaded_files or video_urls.strip():
            st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
            
            total_files = 0
            total_size = 0
            file_categories = {"audio": [], "video": [], "image": [], "document": [], "youtube": []}
            
            # ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ë¥˜ ë° ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€
            large_files_detected = []
            if uploaded_files:
                for file in uploaded_files:
                    try:
                        file_size_mb = len(file.getvalue()) / (1024 * 1024)
                        file_size_gb = file_size_mb / 1024
                        total_size += file_size_mb
                        total_files += 1
                        
                        file_ext = file.name.split('.')[-1].lower() if '.' in file.name else 'unknown'
                    except Exception as e:
                        st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file.name}): {str(e)}")
                        st.info("ğŸ’¡ **í•´ê²° ë°©ë²•**: íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ë³´ì„¸ìš”")
                        continue
                    
                    # ëŒ€ìš©ëŸ‰ ë™ì˜ìƒ íŒŒì¼ ê°ì§€ (1GB ì´ìƒ)
                    is_large_video = file_ext in ['mp4', 'mov', 'avi'] and file_size_gb >= 1.0
                    if is_large_video:
                        large_files_detected.append((file.name, file_size_gb))
                    
                    if file_ext in ['wav', 'mp3', 'flac', 'm4a']:
                        file_categories["audio"].append((file.name, file_size_mb))
                    elif file_ext in ['mp4', 'mov', 'avi']:
                        size_display = f"{file_size_gb:.2f}GB" if file_size_gb >= 1.0 else f"{file_size_mb:.1f}MB"
                        file_categories["video"].append((file.name, size_display, is_large_video))
                    elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'webp']:
                        file_categories["image"].append((file.name, file_size_mb))
                    elif file_ext in ['pdf', 'docx', 'txt']:
                        file_categories["document"].append((file.name, file_size_mb))
            
            # ë™ì˜ìƒ URL ì²˜ë¦¬
            if video_urls.strip():
                urls = [url.strip() for url in video_urls.strip().split('\n') if url.strip()]
                for url in urls:
                    if 'youtube.com' in url or 'youtu.be' in url:
                        file_categories["youtube"].append((url, 0))
                        total_files += 1
                    elif 'brightcove.net' in url:
                        file_categories["brightcove"] = file_categories.get("brightcove", [])
                        file_categories["brightcove"].append((url, 0))
                        total_files += 1
                    elif any(domain in url.lower() for domain in ['vimeo.com', 'dailymotion.com', '.mp4', '.mov', '.avi']):
                        file_categories["other_video"] = file_categories.get("other_video", [])
                        file_categories["other_video"].append((url, 0))
                        total_files += 1
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ“ ì´ íŒŒì¼", f"{total_files}ê°œ")
            with col2:
                st.metric("ğŸ’¾ ì´ í¬ê¸°", f"{total_size:.2f} MB")
            with col3:
                languages = ["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´"]
                # í”„ë¡œì íŠ¸ ì •ë³´ì—ì„œ ì–¸ì–´ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (í˜¸í™˜ì„± í™•ë³´)
                saved_language = st.session_state.project_info.get('target_language', 'ìë™ ê°ì§€')
                default_index = 0
                try:
                    if saved_language in languages:
                        default_index = languages.index(saved_language)
                except (ValueError, TypeError):
                    default_index = 0
                
                analysis_language = st.selectbox(
                    "ë¶„ì„ ì–¸ì–´", 
                    languages,
                    index=default_index
                )
            
            # ëŒ€ìš©ëŸ‰ íŒŒì¼ ê²½ê³  í‘œì‹œ
            if large_files_detected and LARGE_FILE_HANDLER_AVAILABLE:
                st.warning(f"ğŸš¨ **ëŒ€ìš©ëŸ‰ ë™ì˜ìƒ íŒŒì¼ ê°ì§€**: {len(large_files_detected)}ê°œ íŒŒì¼ì´ 1GB ì´ìƒì…ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ê°€ ì ìš©ë©ë‹ˆë‹¤.")
                with st.expander("ğŸ“Š ëŒ€ìš©ëŸ‰ íŒŒì¼ ìƒì„¸ ì •ë³´"):
                    for filename, size_gb in large_files_detected:
                        st.write(f"ğŸ¬ {filename}: {size_gb:.2f}GB")
                        st.markdown("  - âœ… ì²­í¬ ë‹¨ìœ„ ì—…ë¡œë“œ")
                        st.markdown("  - âœ… ì˜¤ë””ì˜¤ ìë™ ì¶”ì¶œ")
                        st.markdown("  - âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬")
            elif large_files_detected and not LARGE_FILE_HANDLER_AVAILABLE:
                st.error(f"âŒ **ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ë¶ˆê°€**: {len(large_files_detected)}ê°œì˜ ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ ìˆì§€ë§Œ ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            
            # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ë° ì¹´í…Œê³ ë¦¬ë³„ ëª©ë¡
            self.render_file_preview(file_categories, uploaded_files)
            
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            st.markdown("---")
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸš€ ì „ì²´ íŒŒì¼ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                    # íŒŒì¼ ë°ì´í„° ì €ì¥
                    st.session_state.uploaded_files_data = {
                        'files': uploaded_files,
                        'video_urls': video_urls.strip().split('\n') if video_urls.strip() else [],
                        'analysis_language': analysis_language,
                        'total_files': total_files,
                        'total_size': total_size,
                        'categories': file_categories
                    }
                    st.session_state.workflow_step = 3
                    st.success(f"âœ… {total_files}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    st.rerun()
        
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(2)
    
    def render_file_preview(self, file_categories: Dict, uploaded_files: List):
        """íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ë° ìƒì„¸ ì •ë³´ í‘œì‹œ"""
        st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
        
        # íŒŒì¼ ë”•ì…”ë„ˆë¦¬ ìƒì„± (íŒŒì¼ëª…ì„ í‚¤ë¡œ ì‚¬ìš©)
        file_dict = {}
        if uploaded_files:
            for file in uploaded_files:
                file_dict[file.name] = file
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ëª©ë¡ê³¼ ë¯¸ë¦¬ë³´ê¸°
        for category, files in file_categories.items():
            if not files:
                continue
                
            category_names = {
                "audio": "ğŸ¤ ìŒì„± íŒŒì¼",
                "video": "ğŸ¬ ë™ì˜ìƒ íŒŒì¼", 
                "image": "ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼",
                "document": "ğŸ“„ ë¬¸ì„œ íŒŒì¼",
                "youtube": "ğŸ¬ YouTube URL",
                "brightcove": "ğŸ“º Brightcove URL",
                "other_video": "ğŸŒ ê¸°íƒ€ ë™ì˜ìƒ URL"
            }
            
            with st.expander(f"{category_names[category]} ({len(files)}ê°œ)", expanded=True):
                # ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ìš° ì¸ë„¤ì¼ í‘œì‹œ
                if category == "image":
                    # ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ í‘œì‹œ
                    cols = st.columns(min(3, len(files)))
                    for idx, file_info in enumerate(files):
                        name, size_mb = file_info
                        col_idx = idx % 3
                        
                        with cols[col_idx]:
                            # íŒŒì¼ ì •ë³´ í‘œì‹œ
                            st.write(f"**{name}**")
                            st.caption(f"ğŸ“ í¬ê¸°: {size_mb:.2f} MB")
                            
                            # ì´ë¯¸ì§€ ì¸ë„¤ì¼ í‘œì‹œ
                            if name in file_dict:
                                try:
                                    st.image(file_dict[name], width=200, caption=name)
                                except Exception as e:
                                    st.error(f"âš ï¸ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {str(e)}")
                
                # ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ìš° ìƒì„¸ ì •ë³´ì™€ ì¬ìƒ
                elif category == "audio":
                    for file_info in files:
                        name, size_mb = file_info
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"ğŸµ **{name}**")
                            st.caption(f"ğŸ“ í¬ê¸°: {size_mb:.2f} MB")
                            
                            # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ì¶”ì¶œ ì‹œë„
                            if name in file_dict:
                                try:
                                    # ì„ì‹œë¡œ íŒŒì¼ ì €ì¥í•˜ì—¬ ì •ë³´ ì¶”ì¶œ
                                    import tempfile
                                    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{name.split('.')[-1]}") as tmp_file:
                                        tmp_file.write(file_dict[name].getvalue())
                                        tmp_path = tmp_file.name
                                    
                                    # ì˜¤ë””ì˜¤ ì •ë³´ í‘œì‹œ (ì‹¤ì œ ë¶„ì„ ì—”ì§„ í™œìš©)
                                    try:
                                        from core.audio_converter import get_audio_info
                                        audio_info = get_audio_info(tmp_path)
                                        if audio_info['is_valid']:
                                            st.caption(f"â±ï¸ ê¸¸ì´: {audio_info['duration_seconds']:.1f}ì´ˆ")
                                            st.caption(f"ğŸµ ìƒ˜í”Œë§: {audio_info['sample_rate']}Hz")
                                            st.caption(f"ğŸ“» ì±„ë„: {audio_info['channels']}ch")
                                    except ImportError:
                                        st.caption("ğŸ“Š ìƒì„¸ ì •ë³´: ë¶„ì„ ì—”ì§„ ë¡œë“œ í›„ í™•ì¸ ê°€ëŠ¥")
                                    except Exception:
                                        st.caption("ğŸ“Š ìƒì„¸ ì •ë³´: ë¶„ì„ ì¤‘ í™•ì¸ë©ë‹ˆë‹¤")
                                    
                                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                                    try:
                                        os.unlink(tmp_path)
                                    except:
                                        pass
                                        
                                except Exception as e:
                                    st.caption(f"âš ï¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                        
                        with col2:
                            # ì˜¤ë””ì˜¤ ì¬ìƒ ìœ„ì ¯ (ì§€ì›ë˜ëŠ” í˜•ì‹ë§Œ)
                            if name in file_dict and name.lower().endswith(('.wav', '.mp3')):
                                try:
                                    st.audio(file_dict[name])
                                except Exception:
                                    st.caption("ğŸµ ì¬ìƒê¸° ë¡œë“œ ì‹¤íŒ¨")
                
                # ë™ì˜ìƒ íŒŒì¼ì˜ ê²½ìš° ìƒì„¸ ì •ë³´
                elif category == "video":
                    for file_info in files:
                        name, size_display, is_large = file_info
                        
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            icon = "ğŸ¬ğŸš€" if is_large else "ğŸ¬"
                            note = " (ëŒ€ìš©ëŸ‰ ìë™ ì²˜ë¦¬)" if is_large else ""
                            st.write(f"{icon} **{name}**{note}")
                            st.caption(f"ğŸ“ í¬ê¸°: {size_display}")
                            
                            if is_large:
                                st.info("âœ¨ ëŒ€ìš©ëŸ‰ íŒŒì¼ë¡œ ìë™ ì²­í¬ ì²˜ë¦¬ë©ë‹ˆë‹¤")
                        
                        with col2:
                            if name in file_dict:
                                try:
                                    # ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° (ì‘ì€ í¬ê¸°ë¡œ)
                                    st.video(file_dict[name])
                                except Exception:
                                    st.caption("ğŸ¬ ë¯¸ë¦¬ë³´ê¸° ë¡œë“œ ì‹¤íŒ¨")
                
                # ë¬¸ì„œ íŒŒì¼ì˜ ê²½ìš°
                elif category == "document":
                    for file_info in files:
                        name, size_mb = file_info
                        st.write(f"ğŸ“„ **{name}**")
                        st.caption(f"ğŸ“ í¬ê¸°: {size_mb:.2f} MB")
                        
                        # íŒŒì¼ í˜•ì‹ë³„ ì„¤ëª…
                        if name.lower().endswith('.pdf'):
                            st.caption("ğŸ“‘ PDF ë¬¸ì„œ - OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜ˆì •")
                        elif name.lower().endswith('.docx'):
                            st.caption("ğŸ“ Word ë¬¸ì„œ - í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜ˆì •") 
                        elif name.lower().endswith('.txt'):
                            st.caption("ğŸ“‹ í…ìŠ¤íŠ¸ íŒŒì¼ - ì§ì ‘ ì½ê¸°")
                
                # ì˜¨ë¼ì¸ ë™ì˜ìƒ URLì˜ ê²½ìš°
                elif category in ["youtube", "brightcove", "other_video"]:
                    for file_info in files:
                        name = file_info[0]
                        
                        if category == "youtube":
                            st.write(f"ğŸ¬ **YouTube URL**")
                            st.caption("ğŸ¬ ë¹„ë””ì˜¤ ì •ë³´ ë° ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì˜ˆì •")
                        elif category == "brightcove":
                            st.write(f"ğŸ“º **Brightcove URL**")
                            st.caption("ğŸ¬ Brightcove í”Œë ˆì´ì–´ì—ì„œ ë™ì˜ìƒ ë¶„ì„ ì˜ˆì •")
                        elif category == "other_video":
                            st.write(f"ğŸŒ **ë™ì˜ìƒ URL**")
                            st.caption("ğŸ¬ ì§ì ‘ ë§í¬ì—ì„œ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ ì˜ˆì •")
                        
                        st.code(name)
                        
                        # URL ìœ íš¨ì„± ê°„ë‹¨ ì²´í¬
                        if name.startswith(('http://', 'https://')):
                            st.success("âœ… ìœ íš¨í•œ URL í˜•ì‹")
                        else:
                            st.warning("âš ï¸ URLì´ http:// ë˜ëŠ” https://ë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    def render_step3_review(self):
        """3ë‹¨ê³„: ì¤‘ê°„ ê²€í† """
        st.markdown("## 3ï¸âƒ£ ë¶„ì„ ì§„í–‰ ë° ì¤‘ê°„ ê²€í† ")
        
        if not st.session_state.uploaded_files_data:
            st.error("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ì„¸ìš”.")
            return
        
        # ë¶„ì„ ì§„í–‰ ìƒí™© í‘œì‹œ
        st.markdown("### ğŸ”„ ë¶„ì„ ì§„í–‰ ìƒí™©")
        
        uploaded_data = st.session_state.uploaded_files_data
        
        # ë¶„ì„ ì‹¤í–‰ ì „ ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
        analysis_ready, dependency_status = self.check_analysis_readiness()
        
        # ì˜ì¡´ì„± ìƒíƒœ í‘œì‹œ
        if not analysis_ready:
            st.error("ğŸš¨ ë¶„ì„ ì‹œìŠ¤í…œ ì¤€ë¹„ ë¶ˆì™„ë£Œ")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì‹œìŠ¤í…œ ìƒíƒœ:**")
                for component, status in dependency_status.items():
                    icon = "âœ…" if status else "âŒ"
                    st.markdown(f"{icon} {component}")
            with col2:
                st.markdown("**í•´ê²° ë°©ë²•:**")
                if not dependency_status.get('whisper', False):
                    st.markdown("- `pip install openai-whisper` ì‹¤í–‰")
                if not dependency_status.get('easyocr', False):
                    st.markdown("- `pip install easyocr` ì‹¤í–‰")
                if not dependency_status.get('transformers', False):
                    st.markdown("- `pip install transformers` ì‹¤í–‰")
        
        # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
        analysis_button_disabled = not analysis_ready or len(uploaded_data.get('files', [])) == 0
        
        if st.button("â–¶ï¸ ë¶„ì„ ì‹¤í–‰", type="primary", disabled=analysis_button_disabled):
            if analysis_ready:
                with st.spinner("ğŸ”„ í¬ê´„ì  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
                    results = self.execute_comprehensive_analysis()
                    st.session_state.analysis_results = results
            else:
                st.error("ë¶„ì„ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜ì¡´ì„±ì„ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.analysis_results:
            st.markdown("### ğŸ“Š ì¤‘ê°„ ë¶„ì„ ê²°ê³¼")
            
            # ë¶„ì„ ì™„ë£Œ í†µê³„
            total_results = len(st.session_state.analysis_results)
            successful_results = len([r for r in st.session_state.analysis_results if r.get('status') == 'success'])
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì²˜ë¦¬ëœ íŒŒì¼", f"{total_results}ê°œ")
            with col2:
                st.metric("ì„±ê³µ", f"{successful_results}ê°œ")
            with col3:
                success_rate = (successful_results / total_results * 100) if total_results > 0 else 0
                st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
            
            # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            for i, result in enumerate(st.session_state.analysis_results[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                with st.expander(f"ğŸ“„ {result.get('file_name', f'íŒŒì¼ {i+1}')} - {result.get('analysis_type', 'unknown')}"):
                    if result.get('status') == 'success':
                        if result.get('full_text'):
                            st.write("**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**")
                            preview_text = result['full_text'][:300] + ("..." if len(result['full_text']) > 300 else "")
                            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", value=preview_text, height=100, disabled=True, key=f"preview_{i}", label_visibility="collapsed")
                        
                        if result.get('summary'):
                            st.write("**AI ìš”ì•½:**")
                            st.info(result['summary'])
                        
                        if result.get('jewelry_keywords'):
                            st.write("**í‚¤ì›Œë“œ:**")
                            for keyword in result['jewelry_keywords'][:5]:
                                st.badge(keyword)
                    else:
                        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            
            if len(st.session_state.analysis_results) > 5:
                st.info(f"ì¶”ê°€ {len(st.session_state.analysis_results) - 5}ê°œ ê²°ê³¼ê°€ ë” ìˆìŠµë‹ˆë‹¤.")
            
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(3)
    
    def render_step4_report(self):
        """4ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ"""
        st.markdown("## 4ï¸âƒ£ ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ")
        
        if not st.session_state.analysis_results:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ì„œ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        if not st.session_state.final_report:
            with st.spinner("ğŸ“Š ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                st.session_state.final_report = self.generate_final_report()
        
        if st.session_state.final_report:
            report = st.session_state.final_report
            
            # ë³´ê³ ì„œ í—¤ë”
            st.markdown("### ğŸ“‹ í”„ë¡œì íŠ¸ ë¶„ì„ ë³´ê³ ì„œ")
            
            col1, col2 = st.columns([2, 1])
            with col1:
                st.markdown(f"**í”„ë¡œì íŠ¸:** {report['project_name']}")
                st.markdown(f"**ë¶„ì„ ì¼ì‹œ:** {report['analysis_date']}")
                st.markdown(f"**ì´ ì²˜ë¦¬ íŒŒì¼:** {report['total_files']}ê°œ")
            with col2:
                st.markdown(f"**ì„±ê³µë¥ :** {report['success_rate']:.1f}%")
                st.markdown(f"**ì²˜ë¦¬ ì‹œê°„:** {report['total_time']:.1f}ì´ˆ")
            
            st.markdown("---")
            
            # í•µì‹¬ ìš”ì•½
            st.markdown("### ğŸ¯ í•µì‹¬ ìš”ì•½")
            st.markdown(report['executive_summary'])
            
            # ì£¼ìš” ë°œê²¬ì‚¬í•­
            if report['key_findings']:
                st.markdown("### ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­")
                for i, finding in enumerate(report['key_findings'], 1):
                    st.markdown(f"{i}. {finding}")
            
            # í‚¤ì›Œë“œ í´ë¼ìš°ë“œ
            if report['top_keywords']:
                st.markdown("### ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ")
                col1, col2, col3 = st.columns(3)
                for i, (keyword, count) in enumerate(report['top_keywords'][:15]):
                    with [col1, col2, col3][i % 3]:
                        st.metric(keyword, f"{count}íšŒ")
            
            # ğŸ“Š ê³ ê¸‰ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
            st.markdown("### ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
            self.render_advanced_dashboard(report)
            
            # íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼
            with st.expander("ğŸ“„ íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
                for result in st.session_state.analysis_results:
                    if result.get('status') == 'success':
                        st.markdown(f"**{result['file_name']}**")
                        if result.get('full_text'):
                            st.text_area(
                                "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                                value=result['full_text'][:500] + ("..." if len(result['full_text']) > 500 else ""),
                                height=100,
                                disabled=True,
                                key=f"detail_{result['file_name']}"
                            )
                        if result.get('summary'):
                            st.info(f"**ìš”ì•½:** {result['summary']}")
                        st.markdown("---")
            
            # ê²°ë¡  ë° ì œì•ˆì‚¬í•­
            if report['conclusions']:
                st.markdown("### ğŸ’¡ ê²°ë¡  ë° ì œì•ˆì‚¬í•­")
                for i, conclusion in enumerate(report['conclusions'], 1):
                    st.markdown(f"{i}. {conclusion}")
            
            # ì¢…í•© ê°•ì˜ ë‚´ìš©
            if LECTURE_COMPILER_AVAILABLE:
                st.markdown("### ğŸ“ ì¢…í•© ê°•ì˜ ë‚´ìš©")
                
                if not hasattr(st.session_state, 'comprehensive_lecture') or st.session_state.comprehensive_lecture is None:
                    if st.button("ğŸ“š ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„±", type="secondary"):
                        st.session_state.comprehensive_lecture = self.generate_comprehensive_lecture()
                        if st.session_state.comprehensive_lecture:
                            st.success("âœ… ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„± ì™„ë£Œ!")
                            st.rerun()
                else:
                    # ê°•ì˜ ë‚´ìš© í‘œì‹œ
                    lecture = st.session_state.comprehensive_lecture
                    
                    # ê°•ì˜ ì œëª©
                    st.markdown(f"#### ğŸ“– {lecture['title']}")
                    
                    # ê°•ì˜ ê°œìš”
                    with st.expander("ğŸ“‹ ê°•ì˜ ê°œìš”", expanded=True):
                        st.markdown(lecture['overview'])
                    
                    # ì£¼ìš” ì£¼ì œ
                    if lecture['main_topics']:
                        with st.expander("ğŸ¯ ì£¼ìš” ì£¼ì œ"):
                            for i, topic in enumerate(lecture['main_topics'], 1):
                                st.markdown(f"{i}. {topic}")
                    
                    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                    if lecture['key_insights']:
                        with st.expander("ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸"):
                            for i, insight in enumerate(lecture['key_insights'], 1):
                                st.markdown(f"{i}. {insight}")
                    
                    # ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ
                    if lecture['practical_applications']:
                        with st.expander("ğŸ› ï¸ ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ"):
                            for i, application in enumerate(lecture['practical_applications'], 1):
                                st.markdown(f"{i}. {application}")
                    
                    # ì„¸ë¶€ ë‚´ìš© (ì¹´í…Œê³ ë¦¬ë³„)
                    if lecture['detailed_content']:
                        with st.expander("ğŸ“š ì„¸ë¶€ ë‚´ìš© (ì¹´í…Œê³ ë¦¬ë³„)"):
                            for category, content in lecture['detailed_content'].items():
                                if content['summary']:
                                    st.markdown(f"**{category.replace('_', ' ').title()}**")
                                    st.markdown(content['summary'])
                                    
                                    if content['key_points']:
                                        st.markdown("ì£¼ìš” í¬ì¸íŠ¸:")
                                        for point in content['key_points'][:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                                            st.markdown(f"â€¢ {point}")
                                    st.markdown("---")
                    
                    # ê²°ë¡ 
                    if lecture['conclusion']:
                        with st.expander("ğŸ¯ ê°•ì˜ ê²°ë¡ "):
                            st.markdown(lecture['conclusion'])
                    
                    # í’ˆì§ˆ ë° ë©”íƒ€ë°ì´í„°
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("í’ˆì§ˆ ì ìˆ˜", f"{lecture['metadata']['quality_score']:.1f}/100")
                    with col2:
                        st.metric("ì²˜ë¦¬ íŒŒì¼ ìˆ˜", lecture['metadata']['total_files'])
                    with col3:
                        st.metric("ì»´íŒŒì¼ ì‹œê°„", f"{lecture['metadata']['compilation_time']:.1f}ì´ˆ")
                    
                    # ê°•ì˜ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
                    if st.button("ğŸ”„ ê°•ì˜ ë‚´ìš© ì¬ìƒì„±", type="secondary"):
                        st.session_state.comprehensive_lecture = None
                        st.rerun()
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            st.markdown("### ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # ì™„ì „í•œ ë³´ê³ ì„œ JSON
                report_json = json.dumps(convert_numpy_types({
                    'report': report,
                    'detailed_results': st.session_state.analysis_results,
                    'project_info': st.session_state.project_info
                }), indent=2, ensure_ascii=False)
                
                st.download_button(
                    "ğŸ“Š ì™„ì „í•œ ë³´ê³ ì„œ (JSON)",
                    data=report_json,
                    file_name=f"ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
            
            with col2:
                # ìš”ì•½ ë³´ê³ ì„œ í…ìŠ¤íŠ¸
                summary_text = f"""
# {report['project_name']} ë¶„ì„ ë³´ê³ ì„œ

## ë¶„ì„ ê°œìš”
- ë¶„ì„ ì¼ì‹œ: {report['analysis_date']}
- ì´ ì²˜ë¦¬ íŒŒì¼: {report['total_files']}ê°œ
- ì„±ê³µë¥ : {report['success_rate']:.1f}%

## í•µì‹¬ ìš”ì•½
{report['executive_summary']}

## ì£¼ìš” ë°œê²¬ì‚¬í•­
{chr(10).join([f'{i}. {finding}' for i, finding in enumerate(report['key_findings'], 1)])}

## ì£¼ìš” í‚¤ì›Œë“œ
{', '.join([keyword for keyword, _ in report['top_keywords'][:10]])}

## ê²°ë¡  ë° ì œì•ˆì‚¬í•­
{chr(10).join([f'{i}. {conclusion}' for i, conclusion in enumerate(report['conclusions'], 1)])}
"""
                
                st.download_button(
                    "ğŸ“„ ìš”ì•½ ë³´ê³ ì„œ (í…ìŠ¤íŠ¸)",
                    data=summary_text,
                    file_name=f"ìš”ì•½ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )
            
            with col3:
                # ê°•ì˜ ë‚´ìš© ë‹¤ìš´ë¡œë“œ (ìˆëŠ” ê²½ìš°)
                if hasattr(st.session_state, 'comprehensive_lecture') and st.session_state.comprehensive_lecture:
                    lecture = st.session_state.comprehensive_lecture
                    
                    # ê°•ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    lecture_text = f"""
# {lecture['title']}

## ê°•ì˜ ê°œìš”
{lecture['overview']}

## ì£¼ìš” ì£¼ì œ
{chr(10).join([f'{i}. {topic}' for i, topic in enumerate(lecture['main_topics'], 1)])}

## í•µì‹¬ ì¸ì‚¬ì´íŠ¸
{chr(10).join([f'{i}. {insight}' for i, insight in enumerate(lecture['key_insights'], 1)])}

## ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ
{chr(10).join([f'{i}. {app}' for i, app in enumerate(lecture['practical_applications'], 1)])}

## ê²°ë¡ 
{lecture['conclusion']}

---
ìƒì„± ì¼ì‹œ: {lecture['metadata']['compilation_date']}
í’ˆì§ˆ ì ìˆ˜: {lecture['metadata']['quality_score']}/100
"""
                    
                    st.download_button(
                        "ğŸ“ ì¢…í•© ê°•ì˜ ë‚´ìš©",
                        data=lecture_text,
                        file_name=f"ì¢…í•©ê°•ì˜_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                else:
                    # ì „ì²´ ì¶”ì¶œ í…ìŠ¤íŠ¸ (ê°•ì˜ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°)
                    all_texts = []
                    for result in st.session_state.analysis_results:
                        if result.get('status') == 'success' and result.get('full_text'):
                            all_texts.append(f"=== {result['file_name']} ===\n{result['full_text']}\n")
                    
                    combined_text = "\n".join(all_texts)
                    
                    st.download_button(
                        "ğŸ“ ì „ì²´ ì¶”ì¶œ í…ìŠ¤íŠ¸",
                        data=combined_text,
                        file_name=f"ì „ì²´í…ìŠ¤íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
        
        # ì„±ëŠ¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
        if PERFORMANCE_MONITOR_AVAILABLE:
            st.markdown("---")
            st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„")
            
            try:
                performance_summary = get_system_performance()
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    overall = performance_summary["overall_performance"]
                    rate = overall["success_rate"]
                    if rate >= 85:
                        st.metric("ğŸ¯ ì „ì²´ ì„±ê³µë¥ ", f"{rate}%", delta="ìš°ìˆ˜")
                    elif rate >= 70:
                        st.metric("ğŸ¯ ì „ì²´ ì„±ê³µë¥ ", f"{rate}%", delta="ì–‘í˜¸")
                    else:
                        st.metric("ğŸ¯ ì „ì²´ ì„±ê³µë¥ ", f"{rate}%", delta="ê°œì„ í•„ìš”")
                
                with col2:
                    recent = performance_summary["recent_performance"]
                    st.metric("ğŸ“ˆ ìµœê·¼ ì„±ê³µë¥ ", f"{recent['success_rate']}%", 
                             delta=f"ìµœê·¼ {recent['total_analyses']}ê°œ")
                
                with col3:
                    total_processed = performance_summary["system_stats"]["total_files_processed"]
                    st.metric("ğŸ“ ì´ ì²˜ë¦¬ íŒŒì¼", f"{total_processed}ê°œ")
                
                with col4:
                    errors = performance_summary["error_analysis"]["total_errors"]
                    if errors == 0:
                        st.metric("ğŸ›¡ï¸ ì´ ì˜¤ë¥˜", "0ê°œ", delta="ì•ˆì •")
                    else:
                        st.metric("ğŸ›¡ï¸ ì´ ì˜¤ë¥˜", f"{errors}ê°œ", delta="ì ê²€í•„ìš”")
                
                # íŒŒì¼ íƒ€ì…ë³„ ì„±ëŠ¥
                if performance_summary["file_type_performance"]:
                    with st.expander("ğŸ“ˆ íŒŒì¼ íƒ€ì…ë³„ ì„±ëŠ¥ ìƒì„¸"):
                        for file_type, perf in performance_summary["file_type_performance"].items():
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.markdown(f"**{file_type.upper()} íŒŒì¼**")
                            with col2:
                                st.markdown(f"ì„±ê³µë¥ : {perf['success_rate']}%")
                            with col3:
                                st.markdown(f"í‰ê·  ì‹œê°„: {perf['avg_processing_time']}ì´ˆ")
                
                # ì„±ëŠ¥ ê°œì„  ì¶”ì²œì‚¬í•­
                recommendations = global_performance_monitor.get_recommendations()
                if recommendations:
                    with st.expander("ğŸ’¡ ì„±ëŠ¥ ê°œì„  ì¶”ì²œì‚¬í•­"):
                        for rec in recommendations:
                            if rec["priority"] == "high":
                                st.error(f"ğŸ”´ **{rec['category']}**: {rec['recommendation']}")
                            elif rec["priority"] == "medium":
                                st.warning(f"ğŸŸ¡ **{rec['category']}**: {rec['recommendation']}")
                            else:
                                st.info(f"ğŸ”µ **{rec['category']}**: {rec['recommendation']}")
                
            except Exception as e:
                st.error(f"âš ï¸ ì„±ëŠ¥ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ†• ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘", type="primary", use_container_width=True):
                # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.workflow_step = 1
                st.session_state.project_info = {}
                st.session_state.uploaded_files_data = []
                st.session_state.analysis_results = []
                st.session_state.final_report = None
                st.success("âœ… ìƒˆ í”„ë¡œì íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        # í‘œì¤€ ë„¤ë¹„ê²Œì´ì…˜ ë°”
        self.render_navigation_bar(4)
    
    def render_multifile_analysis_tab(self):
        """ë©€í‹°íŒŒì¼ ë¶„ì„ íƒ­"""
        
        st.markdown("## ğŸ“ ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„")
        st.markdown("**ğŸš€ ëª¨ë“  ì§€ì› í˜•ì‹ì„ í•œë²ˆì— ì—…ë¡œë“œí•˜ì—¬ ë°°ì¹˜ ë¶„ì„**")
        
        if not REAL_ANALYSIS_AVAILABLE:
            st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì§€ì› í˜•ì‹ ì•ˆë‚´
        with st.expander("ğŸ“‹ ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ğŸ¤ ìŒì„± íŒŒì¼:**")
                st.markdown("- WAV, MP3, FLAC, M4A, MP4")
                st.markdown("- Whisper STTë¡œ ì‹¤ì œ ë³€í™˜")
            
            with col2:
                st.markdown("**ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼:**")
                st.markdown("- JPG, JPEG, PNG, BMP, TIFF")
                st.markdown("- EasyOCRë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        
        # ë©€í‹°íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ë™ì‹œ ì„ íƒ ê°€ëŠ¥)",
            type=['wav', 'mp3', 'flac', 'm4a', 'mp4', 'jpg', 'jpeg', 'png', 'bmp', 'tiff'],
            accept_multiple_files=True,
            help="Ctrl/Cmd + í´ë¦­ìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥"
        )
        
        if uploaded_files:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
            st.markdown("### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
            
            audio_files = []
            image_files = []
            total_size = 0
            
            # íŒŒì¼ ë¶„ë¥˜
            for file in uploaded_files:
                file_size = len(file.getvalue()) / (1024 * 1024)
                total_size += file_size
                
                file_ext = file.name.split('.')[-1].lower()
                
                if file_ext in ['wav', 'mp3', 'flac', 'm4a', 'mp4']:
                    audio_files.append(file)
                elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                    image_files.append(file)
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ¤ ìŒì„± íŒŒì¼", f"{len(audio_files)}ê°œ")
            
            with col2:
                st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼", f"{len(image_files)}ê°œ")
            
            with col3:
                st.metric("ğŸ“¦ ì´ í¬ê¸°", f"{total_size:.2f} MB")
            
            # íŒŒì¼ ëª©ë¡ ìƒì„¸ í‘œì‹œ
            if audio_files or image_files:
                with st.expander("ğŸ” íŒŒì¼ ìƒì„¸ ì •ë³´"):
                    
                    if audio_files:
                        st.markdown("**ğŸ¤ ìŒì„± íŒŒì¼ë“¤:**")
                        for i, file in enumerate(audio_files, 1):
                            file_size = len(file.getvalue()) / (1024 * 1024)
                            st.write(f"{i}. {file.name} ({file_size:.2f} MB)")
                    
                    if image_files:
                        st.markdown("**ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ë“¤:**")
                        for i, file in enumerate(image_files, 1):
                            file_size = len(file.getvalue()) / (1024 * 1024)
                            st.write(f"{i}. {file.name} ({file_size:.2f} MB)")
            
            # ë¶„ì„ ì„¤ì •
            st.markdown("### âš™ï¸ ë°°ì¹˜ ë¶„ì„ ì„¤ì •")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                audio_language = st.selectbox(
                    "ìŒì„± ì–¸ì–´",
                    ["ko", "en", "auto"],
                    help="ëª¨ë“  ìŒì„± íŒŒì¼ì— ì ìš©"
                )
            
            with col2:
                whisper_model = st.selectbox(
                    "Whisper ëª¨ë¸",
                    ["tiny", "base", "small", "medium"],
                    index=1,
                    help="ì •í™•ë„ vs ì†ë„"
                )
            
            with col3:
                cpu_mode = st.checkbox(
                    "CPU ëª¨ë“œ ê°•ì œ",
                    value=True,
                    help="GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€"
                )
            
            # ë°°ì¹˜ ë¶„ì„ ì‹œì‘
            if st.button("ğŸš€ ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì‹œì‘", type="primary"):
                self.process_multifile_analysis(
                    audio_files, image_files, 
                    audio_language, whisper_model, cpu_mode
                )
        
        else:
            st.info("ğŸ“ ì—¬ëŸ¬ íŒŒì¼ì„ ì„ íƒí•˜ì—¬ ë°°ì¹˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
            st.markdown("**ğŸ’¡ ì‚¬ìš©ë²•:**")
            st.markdown("1. ìœ„ì˜ íŒŒì¼ ì—…ë¡œë“œ ë²„íŠ¼ í´ë¦­")
            st.markdown("2. Ctrl/Cmd + í´ë¦­ìœ¼ë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ")
            st.markdown("3. ìŒì„±ê³¼ ì´ë¯¸ì§€ íŒŒì¼ì„ í•¨ê»˜ ì„ íƒ ê°€ëŠ¥")
            st.markdown("4. ì„¤ì • í™•ì¸ í›„ ë°°ì¹˜ ë¶„ì„ ì‹œì‘")
    
    def process_multifile_analysis(self, audio_files: List, image_files: List, 
                                 language: str, model_size: str, cpu_mode: bool):
        """ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì²˜ë¦¬"""
        
        total_files = len(audio_files) + len(image_files)
        
        if total_files == 0:
            st.warning("âš ï¸ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # CPU ëª¨ë“œ ì„¤ì •
        if cpu_mode:
            os.environ['CUDA_VISIBLE_DEVICES'] = ''
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        st.markdown("### ğŸ”„ ë°°ì¹˜ ë¶„ì„ ì§„í–‰ ìƒí™©")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        results_container = st.container()
        
        batch_results = []
        processed_count = 0
        
        # ë°°ì¹˜ ë¶„ì„ ì‹œì‘ ì‹œê°„
        batch_start_time = time.time()
        
        try:
            # ìŒì„± íŒŒì¼ ë¶„ì„
            for i, audio_file in enumerate(audio_files):
                
                status_text.text(f"ğŸ¤ ìŒì„± ë¶„ì„ ì¤‘: {audio_file.name} ({i+1}/{len(audio_files)})")
                
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                with tempfile.NamedTemporaryFile(
                    delete=False, 
                    suffix=f".{audio_file.name.split('.')[-1]}"
                ) as tmp_file:
                    tmp_file.write(audio_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                try:
                    # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                    result = self.analysis_engine.analyze_audio_file(tmp_file_path, language)
                    result['batch_index'] = processed_count + 1
                    result['file_type'] = 'audio'
                    batch_results.append(result)
                    
                    # ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
                    with results_container:
                        if result.get('status') == 'success':
                            st.success(f"âœ… {audio_file.name}: {result['text_length']}ê¸€ì ì¶”ì¶œ ({result['processing_time']}ì´ˆ)")
                            # ì„±ê³µí•œ ê²°ê³¼ì˜ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                            if result.get('full_text'):
                                preview_text = result['full_text'][:200] + ("..." if len(result['full_text']) > 200 else "")
                                st.text_area(
                                    f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {audio_file.name}",
                                    value=preview_text,
                                    height=80,
                                    disabled=True,
                                    key=f"audio_preview_{processed_count}"
                                )
                        else:
                            st.error(f"âŒ {audio_file.name}: {result.get('error', 'Unknown error')}")
                
                except Exception as e:
                    error_result = {
                        'status': 'error',
                        'error': str(e),
                        'file_name': audio_file.name,
                        'batch_index': processed_count + 1,
                        'file_type': 'audio'
                    }
                    batch_results.append(error_result)
                    
                    with results_container:
                        st.error(f"âŒ {audio_file.name}: {str(e)}")
                
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(tmp_file_path)
                    except:
                        pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                processed_count += 1
                progress_bar.progress(processed_count / total_files)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„
            for i, image_file in enumerate(image_files):
                
                status_text.text(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_file.name} ({i+1}/{len(image_files)})")
                
                # ì„ì‹œ íŒŒì¼ ìƒì„±
                with tempfile.NamedTemporaryFile(
                    delete=False,
                    suffix=f".{image_file.name.split('.')[-1]}"
                ) as tmp_file:
                    tmp_file.write(image_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                try:
                    # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                    result = self.analysis_engine.analyze_image_file(tmp_file_path)
                    result['batch_index'] = processed_count + 1
                    result['file_type'] = 'image'
                    batch_results.append(result)
                    
                    # ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
                    with results_container:
                        if result.get('status') == 'success':
                            st.success(f"âœ… {image_file.name}: {result['blocks_detected']}ê°œ ë¸”ë¡ ì¶”ì¶œ ({result['processing_time']}ì´ˆ)")
                            # ì„±ê³µí•œ ê²°ê³¼ì˜ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                            if result.get('full_text'):
                                preview_text = result['full_text'][:200] + ("..." if len(result['full_text']) > 200 else "")
                                st.text_area(
                                    f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {image_file.name}",
                                    value=preview_text,
                                    height=80,
                                    disabled=True,
                                    key=f"image_preview_{processed_count}"
                                )
                        else:
                            st.error(f"âŒ {image_file.name}: {result.get('error', 'Unknown error')}")
                
                except Exception as e:
                    error_result = {
                        'status': 'error',
                        'error': str(e),
                        'file_name': image_file.name,
                        'batch_index': processed_count + 1,
                        'file_type': 'image'
                    }
                    batch_results.append(error_result)
                    
                    with results_container:
                        st.error(f"âŒ {image_file.name}: {str(e)}")
                
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(tmp_file_path)
                    except:
                        pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                processed_count += 1
                progress_bar.progress(processed_count / total_files)
            
            # ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ
            batch_end_time = time.time()
            total_batch_time = batch_end_time - batch_start_time
            
            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            self.display_batch_results_summary(batch_results, total_batch_time)
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥ (NumPy íƒ€ì… ë³€í™˜ í›„)
            if 'analysis_results' not in st.session_state:
                st.session_state.analysis_results = []
            
            # NumPy íƒ€ì…ì„ JSON í˜¸í™˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            converted_batch_results = convert_numpy_types(batch_results)
            st.session_state.analysis_results.extend(converted_batch_results)
            
            # ì„±ê³µ ë©”ì‹œì§€ì™€ í•¨ê»˜ ë§í¬ ì œê³µ
            status_text.text("âœ… ë©€í‹°íŒŒì¼ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ!")
            st.balloons()  # ì¶•í•˜ ì• ë‹ˆë©”ì´ì…˜
            
            # ê²°ê³¼ í™•ì¸ ë§í¬
            st.markdown("### ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
            st.info("ğŸ“Š **ë¶„ì„ ê²°ê³¼** íƒ­ì—ì„œ ëª¨ë“  ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.error(f"âŒ ë°°ì¹˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"ë°°ì¹˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def display_batch_results_summary(self, batch_results: List[Dict], total_time: float):
        """ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ ìš”ì•½ í‘œì‹œ"""
        
        st.markdown("### ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ ìš”ì•½")
        
        # í†µê³„ ê³„ì‚°
        total_files = len(batch_results)
        successful_files = len([r for r in batch_results if r.get('status') == 'success'])
        audio_files = len([r for r in batch_results if r.get('file_type') == 'audio'])
        image_files = len([r for r in batch_results if r.get('file_type') == 'image'])
        
        # ë©”íŠ¸ë¦­ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ íŒŒì¼", f"{total_files}ê°œ")
        
        with col2:
            st.metric("ì„±ê³µ", f"{successful_files}ê°œ")
        
        with col3:
            success_rate = (successful_files / total_files * 100) if total_files > 0 else 0
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
        
        with col4:
            st.metric("ì´ ì²˜ë¦¬ì‹œê°„", f"{total_time:.1f}ì´ˆ")
        
        # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ¤ ìŒì„± íŒŒì¼ ê²°ê³¼:**")
            audio_success = len([r for r in batch_results 
                               if r.get('file_type') == 'audio' and r.get('status') == 'success'])
            st.write(f"- ì²˜ë¦¬: {audio_files}ê°œ")
            st.write(f"- ì„±ê³µ: {audio_success}ê°œ")
            
            if audio_success > 0:
                total_text = sum(r.get('text_length', 0) for r in batch_results 
                               if r.get('file_type') == 'audio' and r.get('status') == 'success')
                st.write(f"- ì´ ì¶”ì¶œ í…ìŠ¤íŠ¸: {total_text}ê¸€ì")
        
        with col2:
            st.markdown("**ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ê²°ê³¼:**")
            image_success = len([r for r in batch_results 
                               if r.get('file_type') == 'image' and r.get('status') == 'success'])
            st.write(f"- ì²˜ë¦¬: {image_files}ê°œ")
            st.write(f"- ì„±ê³µ: {image_success}ê°œ")
            
            if image_success > 0:
                total_blocks = sum(r.get('blocks_detected', 0) for r in batch_results 
                                 if r.get('file_type') == 'image' and r.get('status') == 'success')
                st.write(f"- ì´ í…ìŠ¤íŠ¸ ë¸”ë¡: {total_blocks}ê°œ")
        
        # ê°œë³„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ì¶”ê°€
        st.markdown("### ğŸ“‹ ê°œë³„ ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        
        successful_results = [r for r in batch_results if r.get('status') == 'success']
        
        if successful_results:
            for i, result in enumerate(successful_results, 1):
                with st.expander(f"ğŸ“„ {result.get('file_name', f'íŒŒì¼ {i}')} - {result.get('file_type', '').upper()} ê²°ê³¼"):
                    
                    # ê¸°ë³¸ ì •ë³´
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.write(f"**íŒŒì¼:** {result.get('file_name', 'Unknown')}")
                    with col2:
                        st.write(f"**íƒ€ì…:** {result.get('file_type', 'Unknown').upper()}")
                    with col3:
                        st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {result.get('processing_time', 'N/A')}ì´ˆ")
                    
                    # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í‘œì‹œ
                    if result.get('full_text'):
                        st.markdown("**ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**")
                        text_preview = result['full_text'][:300] + ("..." if len(result['full_text']) > 300 else "")
                        st.text_area(
                            "í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°",
                            value=text_preview,
                            height=100,
                            disabled=True,
                            key=f"batch_preview_{i}"
                        )
                        
                        # ì „ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ ì˜µì…˜
                        if len(result['full_text']) > 300:
                            if st.button(f"ğŸ“– ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸°", key=f"show_full_{i}"):
                                st.text_area(
                                    "ì „ì²´ í…ìŠ¤íŠ¸",
                                    value=result['full_text'],
                                    height=200,
                                    disabled=True,
                                    key=f"batch_full_{i}"
                                )
                    
                    # ìš”ì•½ í‘œì‹œ
                    if result.get('summary'):
                        st.markdown("**ğŸ“‹ AI ìš”ì•½:**")
                        st.info(result['summary'])
                    
                    # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ í‘œì‹œ
                    if result.get('jewelry_keywords'):
                        st.markdown("**ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ:**")
                        keyword_text = ", ".join(result['jewelry_keywords'])
                        st.write(keyword_text)
        
        # ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ - ë” ëª…í™•í•œ í˜•íƒœë¡œ ì œê³µ
        st.markdown("### ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # JSON ë‹¤ìš´ë¡œë“œ (NumPy íƒ€ì… ë³€í™˜)
            batch_data = {
                'batch_summary': {
                    'total_files': total_files,
                    'successful_files': successful_files,
                    'success_rate': success_rate,
                    'total_processing_time': total_time,
                    'audio_files': audio_files,
                    'image_files': image_files,
                    'analysis_date': datetime.now().isoformat()
                },
                'individual_results': batch_results
            }
            # NumPy íƒ€ì… ë³€í™˜ í›„ JSON ì§ë ¬í™”
            converted_batch_data = convert_numpy_types(batch_data)
            batch_json = json.dumps(converted_batch_data, indent=2, ensure_ascii=False)
            
            st.download_button(
                "ğŸ“„ JSON í˜•ì‹ ë‹¤ìš´ë¡œë“œ",
                data=batch_json,
                file_name=f"batch_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                help="ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"
            )
        
        with col2:
            # í…ìŠ¤íŠ¸ë§Œ ë‹¤ìš´ë¡œë“œ
            text_content = "\n\n" + "="*50 + "\n"
            text_content += f"ì†”ë¡œëª¬ë“œ AI ë°°ì¹˜ ë¶„ì„ ê²°ê³¼\n"
            text_content += f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            text_content += f"ì´ íŒŒì¼: {total_files}ê°œ, ì„±ê³µ: {successful_files}ê°œ\n"
            text_content += "="*50 + "\n\n"
            
            for i, result in enumerate(successful_results, 1):
                text_content += f"{i}. {result.get('file_name', f'íŒŒì¼ {i}')} ({result.get('file_type', '').upper()})\n"
                text_content += "-" * 30 + "\n"
                if result.get('full_text'):
                    text_content += result['full_text'] + "\n"
                if result.get('summary'):
                    text_content += f"\n[ìš”ì•½] {result['summary']}\n"
                if result.get('jewelry_keywords'):
                    text_content += f"\n[í‚¤ì›Œë“œ] {', '.join(result['jewelry_keywords'])}\n"
                text_content += "\n" + "="*50 + "\n\n"
            
            st.download_button(
                "ğŸ“ í…ìŠ¤íŠ¸ í˜•ì‹ ë‹¤ìš´ë¡œë“œ",
                data=text_content,
                file_name=f"batch_texts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                help="ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë§Œ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ"
            )

    def display_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            if REAL_ANALYSIS_AVAILABLE:
                st.success("âœ… ì‹¤ì œ ë¶„ì„ ì—”ì§„")
            else:
                st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„")
        
        with col2:
            try:
                import whisper
                st.success("âœ… Whisper STT")
            except ImportError:
                st.error("âŒ Whisper STT")
        
        with col3:
            try:
                import easyocr
                st.success("âœ… EasyOCR")
            except ImportError:
                st.error("âŒ EasyOCR")
        
        with col4:
            try:
                from transformers import pipeline
                st.success("âœ… Transformers")
            except ImportError:
                st.warning("âš ï¸ Transformers")
        
        with col5:
            st.markdown("**ğŸ“ˆ ì„±ëŠ¥**")
            if PERFORMANCE_MONITOR_AVAILABLE:
                try:
                    success_rate = get_current_success_rate()
                    if success_rate["total_analyses"] > 0:
                        rate = success_rate["success_rate"]
                        if rate >= 85:
                            st.success(f"âœ… {rate}%")
                        elif rate >= 70:
                            st.warning(f"âš ï¸ {rate}%")
                        else:
                            st.error(f"âŒ {rate}%")
                        st.caption(f"ì´ {success_rate['total_analyses']}ê°œ")
                    else:
                        st.info("ğŸ“Š ë¶„ì„ ëŒ€ê¸°")
                except Exception:
                    st.caption("âš ï¸ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜")
            else:
                st.caption("âŒ ëª¨ë‹ˆí„°ë§ ë¶ˆê°€")
    
    def render_audio_analysis_tab(self):
        """ìŒì„± ë¶„ì„ íƒ­"""
        
        st.markdown("## ğŸ¤ ì‹¤ì œ ìŒì„± ë¶„ì„ (Whisper STT)")
        
        if not REAL_ANALYSIS_AVAILABLE:
            st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ìŒì„± íŒŒì¼ ì—…ë¡œë“œ",
            type=['wav', 'mp3', 'flac', 'm4a', 'mp4'],
            help="ì§€ì› í˜•ì‹: WAV, MP3, FLAC, M4A, MP4"
        )
        
        if uploaded_file is not None:
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
            st.info(f"ğŸ“ íŒŒì¼: {uploaded_file.name} ({file_size:.2f} MB)")
            
            # ë¶„ì„ ì„¤ì •
            col1, col2 = st.columns(2)
            with col1:
                language = st.selectbox(
                    "ì–¸ì–´ ì„ íƒ",
                    ["ko", "en", "auto"],
                    help="ko: í•œêµ­ì–´, en: ì˜ì–´, auto: ìë™ ê°ì§€"
                )
            
            with col2:
                whisper_model = st.selectbox(
                    "Whisper ëª¨ë¸",
                    ["tiny", "base", "small", "medium"],
                    index=1,
                    help="tiny: ë¹ ë¦„, medium: ì •í™•"
                )
            
            # ë¶„ì„ ì‹œì‘
            if st.button("ğŸ¯ ì‹¤ì œ ìŒì„± ë¶„ì„ ì‹œì‘", type="primary"):
                self.process_audio_analysis(uploaded_file, language, whisper_model)
    
    def process_audio_analysis(self, uploaded_file, language: str, model_size: str):
        """ì‹¤ì œ ìŒì„± ë¶„ì„ ì²˜ë¦¬"""
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        try:
            with st.spinner("ğŸ¤ Whisper STT ì‹¤ì œ ë¶„ì„ ì¤‘..."):
                
                # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                start_time = time.time()
                result = self.analysis_engine.analyze_audio_file(tmp_file_path, language)
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                if result.get("status") == "success":
                    st.success(f"âœ… ìŒì„± ë¶„ì„ ì™„ë£Œ! ({result['processing_time']}ì´ˆ)")
                    
                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    self.display_audio_results(result)
                    
                    # ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸
                    self.update_session_stats(processing_time, True)
                    
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥ (NumPy íƒ€ì… ë³€í™˜ í›„)
                    if 'analysis_results' not in st.session_state:
                        st.session_state.analysis_results = []
                    converted_result = convert_numpy_types(result)
                    st.session_state.analysis_results.append(converted_result)
                    
                else:
                    st.error(f"âŒ ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    self.update_session_stats(processing_time, False)
                    
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"ìŒì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(tmp_file_path)
            except:
                pass
    
    def display_audio_results(self, result: Dict[str, Any]):
        """ìŒì„± ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ì‚¬ìš©ì ì¹œí™”ì  ë²„ì „"""
        
        # ğŸš€ í–¥ìƒëœ ê²°ê³¼ í‘œì‹œ ì—”ì§„ ì‚¬ìš©
        try:
            from core.user_friendly_presenter import show_enhanced_analysis_result
            show_enhanced_analysis_result(result, st.session_state.project_info)
            return
        except ImportError:
            pass  # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        
        # ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ í‘œì‹œ (fallback)
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['processing_time']}ì´ˆ")
        
        with col2:
            st.metric("ê°ì§€ ì–¸ì–´", result['detected_language'])
        
        with col3:
            st.metric("í…ìŠ¤íŠ¸ ê¸¸ì´", f"{result['text_length']}ì")
        
        with col4:
            st.metric("ì„¸ê·¸ë¨¼íŠ¸", f"{result['segments_count']}ê°œ")
        
        # ğŸ’¡ í•µì‹¬ ê°œì„ : ì¢…í•© ë©”ì‹œì§€ ë¶„ì„ í‘œì‹œ
        if result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success':
            st.markdown("### ğŸ¯ **ì´ ì‚¬ëŒë“¤ì´ ë§í•œ ë‚´ìš© ìš”ì•½**")
            
            comp_msg = result['comprehensive_messages']
            main_summary = comp_msg.get('main_summary', {})
            
            # í•µì‹¬ í•œ ì¤„ ìš”ì•½
            if main_summary.get('one_line_summary'):
                st.success(f"**ğŸ“¢ í•µì‹¬ ë©”ì‹œì§€:** {main_summary['one_line_summary']}")
            
            # ê³ ê° ìƒíƒœ ë° ì¤‘ìš”ë„
            col1, col2 = st.columns(2)
            with col1:
                if main_summary.get('customer_status'):
                    st.info(f"**ğŸ‘¤ ê³ ê° ìƒíƒœ:** {main_summary['customer_status']}")
            with col2:
                if main_summary.get('urgency_indicator'):
                    urgency_colors = {'ë†’ìŒ': 'ğŸ”´', 'ë³´í†µ': 'ğŸŸ¡', 'ë‚®ìŒ': 'ğŸŸ¢'}
                    urgency_emoji = urgency_colors.get(main_summary['urgency_indicator'], 'âšª')
                    st.info(f"**âš¡ ê¸´ê¸‰ë„:** {urgency_emoji} {main_summary['urgency_indicator']}")
            
            # ì£¼ìš” í¬ì¸íŠ¸
            if main_summary.get('key_points'):
                st.markdown("**ğŸ” ì£¼ìš” í¬ì¸íŠ¸:**")
                for point in main_summary['key_points'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    st.markdown(f"â€¢ {point}")
            
            # ì¶”ì²œ ì•¡ì…˜
            if main_summary.get('recommended_actions'):
                st.markdown("**ğŸ’¼ ì¶”ì²œ ì•¡ì…˜:**")
                for action in main_summary['recommended_actions']:
                    st.markdown(f"{action}")
            
            # ìƒì„¸ ë¶„ì„ (ì ‘ì„ ìˆ˜ ìˆê²Œ)
            with st.expander("ğŸ”¬ ìƒì„¸ ëŒ€í™” ë¶„ì„"):
                conv_analysis = comp_msg.get('conversation_analysis', {})
                
                # í™”ì ë¶„ì„
                if conv_analysis.get('speakers'):
                    speakers_info = conv_analysis['speakers']
                    st.markdown("**ğŸ‘¥ ëŒ€í™” ì°¸ì—¬ì:**")
                    if speakers_info.get('speaker_distribution'):
                        for speaker, count in speakers_info['speaker_distribution'].items():
                            st.markdown(f"â€¢ {speaker}: {count}íšŒ ë°œì–¸")
                
                # ëŒ€í™” ì˜ë„
                if conv_analysis.get('intent'):
                    intent_info = conv_analysis['intent']
                    st.markdown(f"**ğŸ¯ ëŒ€í™” ì˜ë„:** {intent_info.get('description', '')}")
                    st.markdown(f"**ğŸ“Š ì‹ ë¢°ë„:** {intent_info.get('confidence', 0)*100:.0f}%")
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ê¸°ìˆ ì  ìƒì„¸ì •ë³´ë¡œ ì´ë™)
        with st.expander("ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸"):
            st.text_area(
                "ì „ì²´ í…ìŠ¤íŠ¸",
                value=result['full_text'],
                height=200,
                disabled=True
            )
        
        # ê¸°ì¡´ ìš”ì•½ (fallback)
        if result.get('summary') and not (result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success'):
            st.markdown("### ğŸ“‹ AI ìš”ì•½")
            st.info(result['summary'])
        
        # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ
        if result.get('jewelry_keywords'):
            st.markdown("### ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ")
            for keyword in result['jewelry_keywords']:
                st.badge(keyword)
        
        # ìƒì„¸ ì„¸ê·¸ë¨¼íŠ¸ (í™•ì¥ ê°€ëŠ¥)
        with st.expander("ğŸ” ìƒì„¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´"):
            for i, segment in enumerate(result.get('segments', []), 1):
                st.write(f"**{i}. [{segment['start']:.1f}s - {segment['end']:.1f}s]**")
                st.write(segment['text'])
                st.write("---")
    
    def render_image_analysis_tab(self):
        """ì´ë¯¸ì§€ ë¶„ì„ íƒ­"""
        
        st.markdown("## ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ (EasyOCR)")
        
        if not REAL_ANALYSIS_AVAILABLE:
            st.error("âŒ ì‹¤ì œ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # GPU ë©”ëª¨ë¦¬ ê²½ê³ 
        st.warning("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ",
            type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
            help="ì§€ì› í˜•ì‹: JPG, PNG, BMP, TIFF"
        )
        
        if uploaded_file is not None:
            # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
            st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
            
            file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
            st.info(f"ğŸ“ íŒŒì¼: {uploaded_file.name} ({file_size:.2f} MB)")
            
            # ë¶„ì„ ì‹œì‘
            if st.button("ğŸ¯ ì‹¤ì œ OCR ë¶„ì„ ì‹œì‘", type="primary"):
                self.process_image_analysis(uploaded_file)
    
    def process_image_analysis(self, uploaded_file):
        """ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬"""
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        try:
            with st.spinner("ğŸ–¼ï¸ EasyOCR ì‹¤ì œ ë¶„ì„ ì¤‘..."):
                
                # CPU ëª¨ë“œ ê°•ì œ ì„¤ì • (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€)
                os.environ['CUDA_VISIBLE_DEVICES'] = ''
                
                # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                start_time = time.time()
                result = self.analysis_engine.analyze_image_file(tmp_file_path)
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                if result.get("status") == "success":
                    st.success(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ! ({result['processing_time']}ì´ˆ)")
                    
                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    self.display_image_results(result)
                    
                    # ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸
                    self.update_session_stats(processing_time, True)
                    
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥ (NumPy íƒ€ì… ë³€í™˜ í›„)
                    if 'analysis_results' not in st.session_state:
                        st.session_state.analysis_results = []
                    converted_result = convert_numpy_types(result)
                    st.session_state.analysis_results.append(converted_result)
                    
                else:
                    st.error(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    self.update_session_stats(processing_time, False)
                    
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                os.unlink(tmp_file_path)
            except:
                pass
    
    def display_image_results(self, result: Dict[str, Any]):
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ì‚¬ìš©ì ì¹œí™”ì  ë²„ì „"""
        
        # ğŸš€ í–¥ìƒëœ ê²°ê³¼ í‘œì‹œ ì—”ì§„ ì‚¬ìš©
        try:
            from core.user_friendly_presenter import show_enhanced_analysis_result
            show_enhanced_analysis_result(result, st.session_state.project_info)
            return
        except ImportError:
            pass  # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        
        # ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ í‘œì‹œ (fallback)
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['processing_time']}ì´ˆ")
        
        with col2:
            st.metric("í…ìŠ¤íŠ¸ ë¸”ë¡", f"{result['blocks_detected']}ê°œ")
        
        with col3:
            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{result['average_confidence']:.3f}")
        
        with col4:
            st.metric("íŒŒì¼ í¬ê¸°", f"{result['file_size_mb']} MB")
        
        # ğŸ’¡ í•µì‹¬ ê°œì„ : ì¢…í•© ë©”ì‹œì§€ ë¶„ì„ í‘œì‹œ
        if result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success':
            st.markdown("### ğŸ¯ **ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ë‚´ìš©**")
            
            comp_msg = result['comprehensive_messages']
            main_summary = comp_msg.get('main_summary', {})
            
            # í•µì‹¬ í•œ ì¤„ ìš”ì•½
            if main_summary.get('one_line_summary'):
                st.success(f"**ğŸ“¢ í•µì‹¬ ë©”ì‹œì§€:** {main_summary['one_line_summary']}")
            
            # ê³ ê° ìƒíƒœ ë° ì¤‘ìš”ë„
            col1, col2 = st.columns(2)
            with col1:
                if main_summary.get('customer_status'):
                    st.info(f"**ğŸ‘¤ ê³ ê° ìƒíƒœ:** {main_summary['customer_status']}")
            with col2:
                if main_summary.get('urgency_indicator'):
                    urgency_colors = {'ë†’ìŒ': 'ğŸ”´', 'ë³´í†µ': 'ğŸŸ¡', 'ë‚®ìŒ': 'ğŸŸ¢'}
                    urgency_emoji = urgency_colors.get(main_summary['urgency_indicator'], 'âšª')
                    st.info(f"**âš¡ ê¸´ê¸‰ë„:** {urgency_emoji} {main_summary['urgency_indicator']}")
            
            # ì£¼ìš” í¬ì¸íŠ¸
            if main_summary.get('key_points'):
                st.markdown("**ğŸ” ì£¼ìš” í¬ì¸íŠ¸:**")
                for point in main_summary['key_points'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    st.markdown(f"â€¢ {point}")
            
            # ì¶”ì²œ ì•¡ì…˜
            if main_summary.get('recommended_actions'):
                st.markdown("**ğŸ’¼ ì¶”ì²œ ì•¡ì…˜:**")
                for action in main_summary['recommended_actions']:
                    st.markdown(f"{action}")
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ê¸°ìˆ ì  ìƒì„¸ì •ë³´ë¡œ ì´ë™)
        with st.expander("ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸"):
            st.text_area(
                "OCR ê²°ê³¼",
                value=result['full_text'],
                height=150,
                disabled=True
            )
        
        # ê¸°ì¡´ ìš”ì•½ (fallback)
        if result.get('summary') and not (result.get('comprehensive_messages') and result['comprehensive_messages'].get('status') == 'success'):
            st.markdown("### ğŸ“‹ AI ìš”ì•½")
            st.info(result['summary'])
        
        # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ
        if result.get('jewelry_keywords'):
            st.markdown("### ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ")
            for keyword in result['jewelry_keywords']:
                st.badge(keyword)
        
        # ìƒì„¸ ê²°ê³¼ (í™•ì¥ ê°€ëŠ¥)
        with st.expander("ğŸ” ìƒì„¸ OCR ê²°ê³¼"):
            for i, item in enumerate(result.get('detailed_results', []), 1):
                st.write(f"**{i}. ì‹ ë¢°ë„: {item['confidence']:.3f}**")
                st.write(f"í…ìŠ¤íŠ¸: {item['text']}")
                st.write("---")
    
    def render_results_tab(self):
        """ë¶„ì„ ê²°ê³¼ íƒ­"""
        
        st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼ ëª¨ìŒ")
        
        # ì„¸ì…˜ í†µê³„
        self.display_session_stats()
        
        # ì €ì¥ëœ ê²°ê³¼ë“¤
        if 'analysis_results' in st.session_state and st.session_state.analysis_results:
            
            st.markdown("### ğŸ“‹ ë¶„ì„ ê¸°ë¡")
            
            # ê²°ê³¼ í•„í„°ë§ ì˜µì…˜
            col1, col2, col3 = st.columns(3)
            with col1:
                filter_type = st.selectbox(
                    "íŒŒì¼ íƒ€ì… í•„í„°",
                    ["ì „ì²´", "ìŒì„±", "ì´ë¯¸ì§€"],
                    help="íŠ¹ì • íƒ€ì…ì˜ ê²°ê³¼ë§Œ í‘œì‹œ"
                )
            
            with col2:
                show_mode = st.selectbox(
                    "í‘œì‹œ ëª¨ë“œ",
                    ["ìš”ì•½", "ì „ì²´ í…ìŠ¤íŠ¸"],
                    help="í…ìŠ¤íŠ¸ í‘œì‹œ ë°©ì‹ ì„ íƒ"
                )
            
            with col3:
                results_per_page = st.selectbox(
                    "í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜",
                    [5, 10, 20, "ì „ì²´"],
                    index=1
                )
            
            # í•„í„°ë§ëœ ê²°ê³¼
            filtered_results = st.session_state.analysis_results
            if filter_type == "ìŒì„±":
                filtered_results = [r for r in filtered_results if r.get('analysis_type') == 'audio' or r.get('file_type') == 'audio']
            elif filter_type == "ì´ë¯¸ì§€":
                filtered_results = [r for r in filtered_results if r.get('analysis_type') == 'image' or r.get('file_type') == 'image']
            
            # í˜ì´ì§• ì²˜ë¦¬
            if results_per_page != "ì „ì²´":
                page_size = int(results_per_page)
                total_pages = (len(filtered_results) + page_size - 1) // page_size
                if total_pages > 1:
                    page_num = st.selectbox(f"í˜ì´ì§€ (ì´ {total_pages}í˜ì´ì§€)", range(1, total_pages + 1))
                    start_idx = (page_num - 1) * page_size
                    end_idx = start_idx + page_size
                    filtered_results = filtered_results[start_idx:end_idx]
            
            # ì „ì²´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ìƒë‹¨ì— ë°°ì¹˜)
            if len(st.session_state.analysis_results) > 1:
                st.markdown("### ğŸ“¥ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # ì „ì²´ JSON ë‹¤ìš´ë¡œë“œ (NumPy íƒ€ì… ë³€í™˜)
                    all_results_data = {
                        'export_info': {
                            'total_results': len(st.session_state.analysis_results),
                            'export_date': datetime.now().isoformat(),
                            'export_source': 'ì†”ë¡œëª¬ë“œ AI v2.3'
                        },
                        'results': st.session_state.analysis_results
                    }
                    # NumPy íƒ€ì… ë³€í™˜ í›„ JSON ì§ë ¬í™”
                    converted_all_results = convert_numpy_types(all_results_data)
                    all_results_json = json.dumps(converted_all_results, indent=2, ensure_ascii=False)
                    
                    st.download_button(
                        "ğŸ“„ ì „ì²´ JSON ë‹¤ìš´ë¡œë“œ",
                        data=all_results_json,
                        file_name=f"solomond_all_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                
                with col2:
                    # ì „ì²´ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
                    all_text_content = f"ì†”ë¡œëª¬ë“œ AI v2.3 - ì „ì²´ ë¶„ì„ ê²°ê³¼\n"
                    all_text_content += f"ë‚´ë³´ë‚´ê¸° ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    all_text_content += f"ì´ ê²°ê³¼ ìˆ˜: {len(st.session_state.analysis_results)}ê°œ\n"
                    all_text_content += "=" * 60 + "\n\n"
                    
                    for i, result in enumerate(st.session_state.analysis_results, 1):
                        all_text_content += f"{i}. {result.get('file_name', f'íŒŒì¼ {i}')}\n"
                        all_text_content += f"íƒ€ì…: {result.get('analysis_type', result.get('file_type', 'Unknown'))}\n"
                        all_text_content += f"ë¶„ì„ ì‹œê°„: {result.get('timestamp', 'N/A')}\n"
                        all_text_content += "-" * 40 + "\n"
                        
                        if result.get('full_text'):
                            all_text_content += "[ì¶”ì¶œëœ í…ìŠ¤íŠ¸]\n"
                            all_text_content += result['full_text'] + "\n\n"
                        
                        if result.get('summary'):
                            all_text_content += "[AI ìš”ì•½]\n"
                            all_text_content += result['summary'] + "\n\n"
                        
                        if result.get('jewelry_keywords'):
                            all_text_content += "[ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ]\n"
                            all_text_content += ", ".join(result['jewelry_keywords']) + "\n\n"
                        
                        all_text_content += "=" * 60 + "\n\n"
                    
                    st.download_button(
                        "ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
                        data=all_text_content,
                        file_name=f"solomond_all_texts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                with col3:
                    # ê²°ê³¼ ì´ˆê¸°í™”
                    if st.button("ğŸ—‘ï¸ ëª¨ë“  ê²°ê³¼ ì´ˆê¸°í™”"):
                        st.session_state.analysis_results = []
                        st.rerun()
            
            st.markdown("---")
            
            # ê°œë³„ ê²°ê³¼ í‘œì‹œ
            for i, result in enumerate(filtered_results):
                
                # íŒŒì¼ íƒ€ì… ê²°ì •
                file_type = result.get('analysis_type', result.get('file_type', 'unknown'))
                type_icon = "ğŸ¤" if file_type in ['audio', 'Audio'] else "ğŸ–¼ï¸" if file_type in ['image', 'Image'] else "ğŸ“„"
                
                with st.expander(f"{type_icon} {result.get('file_name', f'íŒŒì¼ {i+1}')} - {file_type.upper()}"):
                    
                    # ê¸°ë³¸ ì •ë³´
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write(f"**ğŸ“ íŒŒì¼:** {result.get('file_name', 'Unknown')}")
                        st.write(f"**ğŸ“Š íƒ€ì…:** {file_type.upper()}")
                    
                    with col2:
                        timestamp = result.get('timestamp', 'N/A')
                        st.write(f"**ğŸ• ë¶„ì„ ì‹œê°„:** {timestamp}")
                        
                        # ì²˜ë¦¬ ì‹œê°„ ì•ˆì „ ì²˜ë¦¬
                        processing_time = result.get('processing_time')
                        if processing_time is not None:
                            st.write(f"**â±ï¸ ì²˜ë¦¬ ì‹œê°„:** {processing_time}ì´ˆ")
                        else:
                            alt_time = result.get('duration') or result.get('elapsed_time') or result.get('execution_time')
                            if alt_time:
                                st.write(f"**â±ï¸ ì²˜ë¦¬ ì‹œê°„:** {alt_time}ì´ˆ")
                            else:
                                st.write("**â±ï¸ ì²˜ë¦¬ ì‹œê°„:** ì¸¡ì •ë˜ì§€ ì•ŠìŒ")
                    
                    with col3:
                        # ê°œë³„ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (NumPy íƒ€ì… ë³€í™˜)
                        converted_result = convert_numpy_types(result)
                        json_str = json.dumps(converted_result, indent=2, ensure_ascii=False)
                        st.download_button(
                            "ğŸ“¥ ê°œë³„ ë‹¤ìš´ë¡œë“œ",
                            data=json_str,
                            file_name=f"analysis_{result.get('file_name', f'result_{i}')}_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                            mime="application/json",
                            key=f"download_{i}"
                        )
                    
                    # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í‘œì‹œ
                    if result.get('full_text'):
                        st.markdown("### ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                        
                        full_text = result['full_text']
                        
                        if show_mode == "ìš”ì•½" and len(full_text) > 500:
                            # ìš”ì•½ ëª¨ë“œ: ì²˜ìŒ 500ìë§Œ í‘œì‹œ
                            preview_text = full_text[:500] + "..."
                            st.text_area(
                                "í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì)",
                                value=preview_text,
                                height=150,
                                disabled=True,
                                key=f"text_preview_{i}"
                            )
                            
                            # ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸° ë²„íŠ¼
                            if st.button(f"ğŸ“– ì „ì²´ í…ìŠ¤íŠ¸ ë³´ê¸° ({len(full_text)}ì)", key=f"show_full_{i}"):
                                st.text_area(
                                    "ì „ì²´ í…ìŠ¤íŠ¸",
                                    value=full_text,
                                    height=300,
                                    disabled=True,
                                    key=f"text_full_{i}"
                                )
                        else:
                            # ì „ì²´ í…ìŠ¤íŠ¸ ëª¨ë“œ ë˜ëŠ” ì§§ì€ í…ìŠ¤íŠ¸
                            st.text_area(
                                f"ì „ì²´ í…ìŠ¤íŠ¸ ({len(full_text)}ì)",
                                value=full_text,
                                height=200 if len(full_text) < 1000 else 300,
                                disabled=True,
                                key=f"text_full_{i}"
                            )
                    
                    # ìš”ì•½ í‘œì‹œ
                    if result.get('summary'):
                        st.markdown("### ğŸ“‹ AI ìš”ì•½")
                        st.info(result['summary'])
                    
                    # ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ í‘œì‹œ
                    if result.get('jewelry_keywords'):
                        st.markdown("### ğŸ’ ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ")
                        # í‚¤ì›Œë“œë¥¼ ë°°ì§€ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
                        keywords_html = ""
                        for keyword in result['jewelry_keywords']:
                            keywords_html += f'<span style="background-color: #e1f5fe; color: #01579b; padding: 2px 8px; margin: 2px; border-radius: 12px; font-size: 12px;">{keyword}</span> '
                        st.markdown(keywords_html, unsafe_allow_html=True)
                    
                    # ì¶”ê°€ ì •ë³´ (í™•ì¥ ê°€ëŠ¥)
                    with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                        # ì˜¤ë””ì˜¤ ê´€ë ¨ ì •ë³´
                        if file_type in ['audio', 'Audio']:
                            if result.get('detected_language'):
                                st.write(f"**ê°ì§€ëœ ì–¸ì–´:** {result['detected_language']}")
                            if result.get('segments_count'):
                                st.write(f"**ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜:** {result['segments_count']}ê°œ")
                            if result.get('text_length'):
                                st.write(f"**í…ìŠ¤íŠ¸ ê¸¸ì´:** {result['text_length']}ì")
                        
                        # ì´ë¯¸ì§€ ê´€ë ¨ ì •ë³´
                        elif file_type in ['image', 'Image']:
                            if result.get('blocks_detected'):
                                st.write(f"**ê°ì§€ëœ í…ìŠ¤íŠ¸ ë¸”ë¡:** {result['blocks_detected']}ê°œ")
                            if result.get('average_confidence'):
                                st.write(f"**í‰ê·  ì‹ ë¢°ë„:** {result['average_confidence']:.3f}")
                            if result.get('file_size_mb'):
                                st.write(f"**íŒŒì¼ í¬ê¸°:** {result['file_size_mb']} MB")
                        
                        # ê¸°íƒ€ ì •ë³´
                        other_info = {k: v for k, v in result.items() 
                                    if k not in ['file_name', 'analysis_type', 'file_type', 'timestamp', 
                                                'processing_time', 'full_text', 'summary', 'jewelry_keywords',
                                                'detected_language', 'segments_count', 'text_length',
                                                'blocks_detected', 'average_confidence', 'file_size_mb']}
                        
                        if other_info:
                            st.json(other_info)
        
        else:
            st.info("ğŸ“ ì•„ì§ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìŒì„± ë˜ëŠ” ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
            
            # ì‚¬ìš©ë²• ì•ˆë‚´
            st.markdown("### ğŸ’¡ ì‚¬ìš©ë²• ì•ˆë‚´")
            with st.expander("ğŸ“– ë¶„ì„ ê²°ê³¼ í™•ì¸ ë°©ë²•"):
                st.markdown("""
                **1. ë¶„ì„ ì‹¤í–‰ í›„ ê²°ê³¼ í™•ì¸:**
                - ë©€í‹°íŒŒì¼ ë¶„ì„, ìŒì„± ë¶„ì„, ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ì—¬ê¸°ì— ê²°ê³¼ê°€ ì €ì¥ë©ë‹ˆë‹¤.
                
                **2. ê²°ê³¼ í•„í„°ë§:**
                - íŒŒì¼ íƒ€ì…ë³„ë¡œ ê²°ê³¼ë¥¼ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - í‘œì‹œ ëª¨ë“œë¥¼ ì„ íƒí•˜ì—¬ ìš”ì•½ ë˜ëŠ” ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **3. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ:**
                - ê°œë³„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - ì „ì²´ ê²°ê³¼ë¥¼ JSON ë˜ëŠ” í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¼ê´„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **4. ê²°ê³¼ ê´€ë¦¬:**
                - ë¶ˆí•„ìš”í•œ ê²°ê³¼ëŠ” "ëª¨ë“  ê²°ê³¼ ì´ˆê¸°í™”" ë²„íŠ¼ìœ¼ë¡œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
    
    def display_session_stats(self):
        """ì„¸ì…˜ í†µê³„ í‘œì‹œ"""
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë¶„ì„í•œ íŒŒì¼", f"{self.session_stats['files_analyzed']}ê°œ")
        
        with col2:
            st.metric("ì„±ê³µí•œ ë¶„ì„", f"{self.session_stats['successful_analyses']}ê°œ")
        
        with col3:
            success_rate = 0
            if self.session_stats['files_analyzed'] > 0:
                success_rate = (self.session_stats['successful_analyses'] / self.session_stats['files_analyzed']) * 100
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
        
        with col4:
            st.metric("ì´ ì²˜ë¦¬ ì‹œê°„", f"{self.session_stats['total_processing_time']:.1f}ì´ˆ")
    
    def render_settings_tab(self):
        """ì„¤ì • íƒ­"""
        
        st.markdown("## âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
        
        # ë¶„ì„ ì—”ì§„ í†µê³„
        if REAL_ANALYSIS_AVAILABLE and self.analysis_engine:
            st.markdown("### ğŸ“Š ë¶„ì„ ì—”ì§„ í†µê³„")
            
            try:
                stats = self.analysis_engine.get_analysis_stats()
                
                col1, col2 = st.columns(2)
                with col1:
                    st.json({
                        "ì „ì²´ ë¶„ì„ íŒŒì¼": stats.get('total_files', 0),
                        "ì„±ê³µí•œ ë¶„ì„": stats.get('successful_analyses', 0),
                        "ì„±ê³µë¥ ": f"{stats.get('success_rate', 0):.1f}%"
                    })
                
                with col2:
                    st.json({
                        "ì´ ì²˜ë¦¬ ì‹œê°„": f"{stats.get('total_processing_time', 0):.1f}ì´ˆ",
                        "í‰ê·  ì²˜ë¦¬ ì‹œê°„": f"{stats.get('average_processing_time', 0):.1f}ì´ˆ",
                        "ë§ˆì§€ë§‰ ë¶„ì„": stats.get('last_analysis_time', 'N/A')
                    })
            
            except Exception as e:
                st.error(f"í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.markdown("### ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        
        system_info = {
            "ì‹¤ì œ ë¶„ì„ ì—”ì§„": "âœ… ì‚¬ìš© ê°€ëŠ¥" if REAL_ANALYSIS_AVAILABLE else "âŒ ì‚¬ìš© ë¶ˆê°€",
            "Whisper STT": "âœ… ì„¤ì¹˜ë¨" if self._check_module('whisper') else "âŒ ë¯¸ì„¤ì¹˜",
            "EasyOCR": "âœ… ì„¤ì¹˜ë¨" if self._check_module('easyocr') else "âŒ ë¯¸ì„¤ì¹˜",
            "Transformers": "âœ… ì„¤ì¹˜ë¨" if self._check_module('transformers') else "âŒ ë¯¸ì„¤ì¹˜",
            "Google Gemini": "âœ… ì„¤ì¹˜ë¨" if self._check_module('google.generativeai') else "âŒ ë¯¸ì„¤ì¹˜"
        }
        
        st.json(system_info)
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜
        st.markdown("### ğŸ”§ ì„±ëŠ¥ ìµœì í™”")
        
        if st.button("ğŸ—‘ï¸ GPU ë©”ëª¨ë¦¬ ì •ë¦¬"):
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    st.success("âœ… GPU ë©”ëª¨ë¦¬ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info("â„¹ï¸ CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            except ImportError:
                st.warning("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _check_module(self, module_name: str) -> bool:
        """ëª¨ë“ˆ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        try:
            __import__(module_name)
            return True
        except ImportError:
            return False
    
    def update_session_stats(self, processing_time: float, success: bool):
        """ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.session_stats['files_analyzed'] += 1
        self.session_stats['total_processing_time'] += processing_time
        if success:
            self.session_stats['successful_analyses'] += 1
    
    def _check_module_availability(self, module_name):
        """ëª¨ë“ˆ ê°€ìš©ì„± ì²´í¬"""
        try:
            __import__(module_name)
            return True
        except ImportError:
            return False
    
    def check_analysis_readiness(self):
        """ë¶„ì„ ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ ì²´í¬"""
        dependency_status = {
            'whisper': self._check_module_availability('whisper'),
            'easyocr': self._check_module_availability('easyocr'),
            'transformers': self._check_module_availability('transformers'),
            'numpy': self._check_module_availability('numpy'),
            'librosa': self._check_module_availability('librosa'),
            'ffmpeg': self._check_ffmpeg_availability()
        }
        
        # í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸ (whisper, easyocrëŠ” í•„ìˆ˜)
        critical_dependencies = ['whisper', 'easyocr', 'numpy']
        analysis_ready = all(dependency_status.get(dep, False) for dep in critical_dependencies)
        
        return analysis_ready, dependency_status
    
    def _check_ffmpeg_availability(self):
        """FFmpeg ì„¤ì¹˜ ìƒíƒœ í™•ì¸"""
        try:
            import subprocess
            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            return False
    
    def _preload_analysis_models(self):
        """ë¶„ì„ ëª¨ë¸ë“¤ì„ ì‚¬ì „ ë¡œë”©í•˜ì—¬ ì‹¤ì œ ë¶„ì„ ì‹œ ì§€ì—° ìµœì†Œí™”"""
        try:
            if REAL_ANALYSIS_AVAILABLE and self.analysis_engine:
                # ì§„í–‰ ìƒí™©ì„ ìœ„í•œ ì„ì‹œ ì»¨í…Œì´ë„ˆ
                model_status = st.empty()
                
                # Whisper ëª¨ë¸ ë¡œë”©
                model_status.text("ğŸ¤ Whisper STT ëª¨ë¸ ë¡œë”© ì¤‘...")
                if not self.analysis_engine.whisper_model:
                    self.analysis_engine._lazy_load_whisper()
                
                # EasyOCR ëª¨ë¸ ë¡œë”©  
                model_status.text("ğŸ–¼ï¸ EasyOCR ëª¨ë¸ ë¡œë”© ì¤‘...")
                if not self.analysis_engine.ocr_reader:
                    self.analysis_engine._lazy_load_ocr()
                
                # NLP ëª¨ë¸ ë¡œë”© (ì„ íƒì )
                model_status.text("ğŸ§  NLP ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.analysis_engine._lazy_load_nlp()
                
                model_status.text("âœ… ëª¨ë“  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
                import time
                time.sleep(0.5)  # ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ë³¼ ìˆ˜ ìˆë„ë¡
                model_status.empty()
                
        except Exception as e:
            self.logger.warning(f"ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ê°€ ìˆì–´ë„ ë¶„ì„ì€ ê³„ì† ì§„í–‰ (lazy loading ë°©ì‹ìœ¼ë¡œ)
    
    def execute_comprehensive_analysis(self):
        """ğŸš€ ë°°ì¹˜ ì¢…í•© ë¶„ì„ ì‹¤í–‰ - ëª¨ë“  íŒŒì¼ì„ í†µí•© ë¶„ì„"""
        if not st.session_state.uploaded_files_data:
            return []
        
        uploaded_files_data = st.session_state.uploaded_files_data
        
        # ğŸ¯ ë°°ì¹˜ ë¶„ì„ vs ê°œë³„ ë¶„ì„ ì„ íƒ
        enable_batch_analysis = st.session_state.project_info.get('correlation_analysis', True)
        
        if enable_batch_analysis:
            st.success("ğŸš€ **ë°°ì¹˜ ì¢…í•© ë¶„ì„ ì‹œì‘**: ëª¨ë“  íŒŒì¼ì„ í†µí•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤")
            with st.container():
                st.markdown("### ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì§„í–‰ ìƒí™©")
                return self._execute_batch_comprehensive_analysis()
        else:
            st.warning("ğŸ“ **ê°œë³„ ë¶„ì„ ëª¨ë“œ**: íŒŒì¼ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤ (í’ˆì§ˆ ì œí•œì )")
            return self._execute_individual_analysis()
    
    def _execute_batch_comprehensive_analysis(self):
        """ë°°ì¹˜ ì¢…í•© ë¶„ì„ - ëª¨ë“  íŒŒì¼ì„ í†µí•© ì²˜ë¦¬"""
        uploaded_files_data = st.session_state.uploaded_files_data
        all_results = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # 1ï¸âƒ£ ë‹¨ê³„: íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬
        status_text.text("ğŸ” 1ë‹¨ê³„: íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬ ì¤‘...")
        file_categories = self._categorize_and_preprocess_files(uploaded_files_data)
        progress_bar.progress(0.2)
        
        # 2ï¸âƒ£ ë‹¨ê³„: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        status_text.text("ğŸ§  2ë‹¨ê³„: í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì¤‘...")
        integrated_context = self._build_integrated_context(file_categories)
        progress_bar.progress(0.4)
        
        # 3ï¸âƒ£ ë‹¨ê³„: ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰
        status_text.text("âš¡ 3ë‹¨ê³„: ë°°ì¹˜ í†µí•© ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        batch_results = self._execute_batch_analysis(file_categories, integrated_context)
        progress_bar.progress(0.8)
        
        # 4ï¸âƒ£ ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° ìµœì í™”
        status_text.text("ğŸ¯ 4ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° ìµœì í™” ì¤‘...")
        final_results = self._integrate_and_optimize_results(batch_results, integrated_context)
        progress_bar.progress(1.0)
        
        status_text.text("âœ… ë°°ì¹˜ ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
        return final_results
    
    def _execute_individual_analysis(self):
        """ê¸°ì¡´ ê°œë³„ ë¶„ì„ ë°©ì‹ (í˜¸í™˜ì„± ìœ ì§€)"""
        uploaded_files_data = st.session_state.uploaded_files_data
        all_results = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ëª¨ë¸ì€ ì‹¤ì œ ì‚¬ìš© ì‹œì ì— lazy loadingìœ¼ë¡œ ë¡œë”© (ì„œë²„ ì‹œì‘ ì‹œê°„ ë‹¨ì¶•)
        status_text.text("ğŸ”§ ë¶„ì„ ì¤€ë¹„ ì¤‘...")
        
        total_items = len(uploaded_files_data.get('files', [])) + len(uploaded_files_data.get('video_urls', []))
        current_item = 0
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ì„
        for uploaded_file in uploaded_files_data.get('files', []):
            current_item += 1
            progress_bar.progress(current_item / total_items)
            status_text.text(f"ğŸ”„ ë¶„ì„ ì¤‘: {uploaded_file.name} ({current_item}/{total_items})")
            
            tmp_file_path = None
            audio_file_path = None
            is_large_video = False
            try:
                # íŒŒì¼ íƒ€ì… ê²°ì •
                file_ext = uploaded_file.name.split('.')[-1].lower()
                file_size_gb = len(uploaded_file.getvalue()) / (1024 * 1024 * 1024)
                is_large_video = file_ext in ['mp4', 'mov', 'avi'] and file_size_gb >= 1.0
                
                if file_ext in ['wav', 'mp3', 'flac', 'm4a']:
                    file_type = "audio"
                elif file_ext in ['mp4', 'mov', 'avi']:
                    file_type = "video"
                elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                    file_type = "image"
                else:
                    file_type = "unknown"
                
                # ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
                if is_large_video and LARGE_FILE_HANDLER_AVAILABLE:
                    status_text.text(f"ğŸš€ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({file_size_gb:.2f}GB)")
                    
                    # ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥
                    def progress_callback(progress):
                        progress_bar.progress((current_item - 1 + progress * 0.5) / total_items)
                        status_text.text(f"ğŸ“¥ ì—…ë¡œë“œ ì¤‘: {uploaded_file.name} ({progress*100:.1f}%)")
                    
                    tmp_file_path = large_file_handler.save_uploaded_file_chunked(uploaded_file, progress_callback)
                    
                    if tmp_file_path:
                        # ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                        status_text.text(f"ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘: {uploaded_file.name}")
                        audio_file_path = large_file_handler.extract_audio_from_video(tmp_file_path)
                        
                        if audio_file_path:
                            # ì¶”ì¶œëœ ì˜¤ë””ì˜¤ë¡œ ë³€ê²½í•˜ì—¬ ë¶„ì„
                            tmp_file_path = audio_file_path
                            file_type = "audio"
                            status_text.text(f"ğŸ”„ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘: {uploaded_file.name}")
                        else:
                            raise Exception("ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
                    else:
                        raise Exception("ëŒ€ìš©ëŸ‰ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                        
                # ì¼ë°˜ íŒŒì¼ ì²˜ë¦¬
                else:
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_file_path = tmp_file.name
                        
                    # ì‘ì€ ë™ì˜ìƒ íŒŒì¼ë„ ì˜¤ë””ì˜¤ ì¶”ì¶œ í•„ìš”
                    if file_type == "video":
                        if LARGE_FILE_HANDLER_AVAILABLE:
                            status_text.text(f"ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘: {uploaded_file.name}")
                            audio_file_path = large_file_handler.extract_audio_from_video(tmp_file_path)
                            if audio_file_path:
                                tmp_file_path = audio_file_path
                                file_type = "audio"
                        else:
                            # FFmpeg ì—†ì´ëŠ” ë™ì˜ìƒ ì§ì ‘ ì²˜ë¦¬ ë¶ˆê°€
                            file_type = "unsupported_video"
                
                # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
                if REAL_ANALYSIS_AVAILABLE and file_type in ["audio", "image"]:
                    language = uploaded_files_data.get('analysis_language', 'auto')
                    
                    # ğŸ§  ê°•í™”ëœ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
                    context = self._prepare_enhanced_context()
                    
                    # ë¶„ì„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨)
                    self._update_analysis_status(uploaded_file.name, context)
                    
                    result = analyze_file_real(tmp_file_path, file_type, language, context)
                    
                    # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    result = convert_numpy_types(result)
                    
                    # ë™ì˜ìƒì—ì„œ ì¶”ì¶œëœ ì˜¤ë””ì˜¤ì¸ ê²½ìš° ì›ë³¸ íŒŒì¼ëª… ì •ë³´ ì¶”ê°€
                    if audio_file_path and result.get('status') == 'success':
                        result['original_video_file'] = uploaded_file.name
                        result['extracted_audio'] = True
                        result['large_file_processed'] = is_large_video
                        
                else:
                    if not REAL_ANALYSIS_AVAILABLE:
                        error_msg = "ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•„ìˆ˜ íŒ¨í‚¤ì§€(whisper, easyocr)ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
                    elif file_type == "unsupported_video":
                        error_msg = "ë™ì˜ìƒ ì²˜ë¦¬ë¥¼ ìœ„í•´ FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
                    else:
                        error_msg = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}. ì§€ì› í˜•ì‹: ìŒì„±(wav, mp3, m4a), ë™ì˜ìƒ(mp4, mov, avi), ì´ë¯¸ì§€(jpg, png, bmp)"
                    
                    result = {
                        "status": "error",
                        "error": error_msg,
                        "file_name": uploaded_file.name,
                        "file_type": file_type,
                        "suggested_action": "FFmpeg ì„¤ì¹˜ ë˜ëŠ” ì§€ì›ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”." if file_type == "unsupported_video" else "íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ê±°ë‚˜ ì§€ì›ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”."
                    }
                
                all_results.append(result)
                    
            except Exception as e:
                self.logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {uploaded_file.name}: {e}")
                all_results.append({
                    "status": "error",
                    "error": str(e),
                    "file_name": uploaded_file.name
                })
            finally:
                # ì„ì‹œ íŒŒì¼ë“¤ í™•ì‹¤íˆ ì •ë¦¬
                cleanup_files = []
                if tmp_file_path and os.path.exists(tmp_file_path):
                    cleanup_files.append(tmp_file_path)
                if audio_file_path and audio_file_path != tmp_file_path and os.path.exists(audio_file_path):
                    cleanup_files.append(audio_file_path)
                
                for file_path in cleanup_files:
                    try:
                        os.unlink(file_path)
                        self.logger.debug(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {file_path}")
                    except Exception as cleanup_error:
                        self.logger.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {file_path}: {cleanup_error}")
                
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ì˜ ì •ë¦¬ ì‘ì—…ë„ ìˆ˜í–‰
                if LARGE_FILE_HANDLER_AVAILABLE and is_large_video:
                    try:
                        large_file_handler.cleanup_temp_files(max_age_hours=1)  # 1ì‹œê°„ ì´ìƒ ëœ íŒŒì¼ë§Œ ì •ë¦¬
                    except Exception as cleanup_error:
                        self.logger.warning(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ í•¸ë“¤ëŸ¬ ì •ë¦¬ ì‹¤íŒ¨: {cleanup_error}")
        
        # ë™ì˜ìƒ URL ë¶„ì„ (YouTube, Brightcove ë“±)
        for url in uploaded_files_data.get('video_urls', []):
            current_item += 1
            progress_bar.progress(current_item / total_items)
            # URL íƒ€ì…ì— ë”°ë¥¸ ìƒíƒœ ë©”ì‹œì§€
            if 'youtube.com' in url or 'youtu.be' in url:
                status_text.text(f"ğŸ”„ YouTube ë¶„ì„ ì¤‘: {url[:50]}... ({current_item}/{total_items})")
            elif 'brightcove.net' in url:
                status_text.text(f"ğŸ”„ Brightcove ë¶„ì„ ì¤‘: {url[:50]}... ({current_item}/{total_items})")
            else:
                status_text.text(f"ğŸ”„ ë™ì˜ìƒ URL ë¶„ì„ ì¤‘: {url[:50]}... ({current_item}/{total_items})")
            
            # YouTube ë¶„ì„ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •
            all_results.append({
                "status": "pending",
                "message": "YouTube ë¶„ì„ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.",
                "url": url
            })
        
        progress_bar.progress(1.0)
        status_text.text("âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
        
        return all_results
    
    def generate_final_report(self):
        """ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not st.session_state.analysis_results:
            return None
        
        results = st.session_state.analysis_results
        project_info = st.session_state.project_info
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        total_files = len(results)
        successful_analyses = len([r for r in results if r.get('status') == 'success'])
        success_rate = (successful_analyses / total_files * 100) if total_files > 0 else 0
        
        # ì´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_time = sum([r.get('processing_time', 0) for r in results if r.get('processing_time')])
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_texts = []
        for result in results:
            if result.get('status') == 'success' and result.get('full_text'):
                all_texts.append(result['full_text'])
        
        combined_text = ' '.join(all_texts)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¹ˆë„ ê³„ì‚°
        import re
        from collections import Counter
        
        # í•œêµ­ì–´ì™€ ì˜ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        korean_words = re.findall(r'[ê°€-í£]{2,}', combined_text)
        english_words = re.findall(r'[A-Za-z]{3,}', combined_text.lower())
        
        all_keywords = korean_words + english_words
        keyword_freq = Counter(all_keywords)
        top_keywords = keyword_freq.most_common(20)
        
        # ì£¼ì–¼ë¦¬ ê´€ë ¨ í‚¤ì›Œë“œ ìˆ˜ì§‘
        jewelry_keywords = []
        for result in results:
            if result.get('jewelry_keywords'):
                jewelry_keywords.extend(result['jewelry_keywords'])
        
        unique_jewelry_keywords = list(set(jewelry_keywords))
        
        # í•µì‹¬ ìš”ì•½ ìƒì„±
        executive_summary = self._generate_executive_summary(
            total_files, successful_analyses, success_rate, 
            len(combined_text), unique_jewelry_keywords
        )
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­ ìƒì„±
        key_findings = self._generate_key_findings(results, unique_jewelry_keywords)
        
        # ê²°ë¡  ë° ì œì•ˆì‚¬í•­ ìƒì„±
        conclusions = self._generate_conclusions(results, success_rate, unique_jewelry_keywords)
        
        # ìµœì¢… ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±
        report = {
            'project_name': project_info.get('project_name', 'ë¶„ì„ í”„ë¡œì íŠ¸'),
            'analysis_date': datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„'),
            'total_files': total_files,
            'successful_analyses': successful_analyses,
            'success_rate': success_rate,
            'total_time': total_time,
            'total_text_length': len(combined_text),
            'executive_summary': executive_summary,
            'key_findings': key_findings,
            'top_keywords': top_keywords,
            'jewelry_keywords': unique_jewelry_keywords,
            'conclusions': conclusions,
            'analysis_details': {
                'audio_files': len([r for r in results if r.get('analysis_type') == 'real_whisper_stt']),
                'image_files': len([r for r in results if r.get('analysis_type') == 'real_easyocr']),
                'total_processing_time': total_time,
                'average_confidence': self._calculate_average_confidence(results)
            }
        }
        
        return report
    
    def generate_comprehensive_lecture(self):
        """ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„±"""
        if not st.session_state.analysis_results:
            return None
        
        if not LECTURE_COMPILER_AVAILABLE:
            st.error("ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼ëŸ¬ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None
        
        try:
            # ë¶„ì„ ê²°ê³¼ë“¤ ì¤€ë¹„
            analysis_results = st.session_state.analysis_results
            
            # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§ (ë¶€ë¶„ ì„±ê³µ í¬í•¨)
            valid_results = [
                result for result in analysis_results 
                if result.get('status') in ['success', 'partial_success']
            ]
            
            if not valid_results:
                st.warning("ê°•ì˜ ë‚´ìš©ì„ ìƒì„±í•  ìœ íš¨í•œ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í”„ë¡œì íŠ¸ ì •ë³´ì—ì„œ ì œëª© ê°€ì ¸ì˜¤ê¸°
            project_info = st.session_state.get('project_info', {})
            custom_title = project_info.get('project_name')
            
            # ê°•ì˜ ë‚´ìš© ì»´íŒŒì¼
            with st.spinner("ğŸ“ ì¢…í•© ê°•ì˜ ë‚´ìš© ìƒì„± ì¤‘..."):
                lecture_result = compile_comprehensive_lecture(valid_results, custom_title)
            
            if lecture_result.get('status') == 'success':
                return lecture_result['lecture_content']
            else:
                st.error(f"ê°•ì˜ ë‚´ìš© ìƒì„± ì‹¤íŒ¨: {lecture_result.get('error', 'Unknown error')}")
                return None
                
        except Exception as e:
            st.error(f"ê°•ì˜ ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _generate_executive_summary(self, total_files, successful, success_rate, text_length, jewelry_keywords):
        """í•µì‹¬ ìš”ì•½ ìƒì„±"""
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì˜ ì²« 500ìë¥¼ ë¯¸ë¦¬ë³´ê¸°ë¡œ ì¶”ê°€
        results = st.session_state.analysis_results
        content_preview = ""
        main_language = "í•œêµ­ì–´"
        
        # ì‹¤ì œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ë‚´ìš© íŒŒì•…
        all_texts = []
        for result in results:
            if result.get('status') == 'success' and result.get('full_text'):
                text = result['full_text'].strip()
                if text:
                    all_texts.append(text)
                    # ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ë³´ê¸°ë¡œ ì‚¬ìš©
                    if not content_preview and len(text) > 10:
                        content_preview = text[:300] + "..." if len(text) > 300 else text
                        # ì–¸ì–´ ê°ì§€
                        import re
                        korean_chars = len(re.findall(r'[ê°€-í£]', text))
                        english_chars = len(re.findall(r'[a-zA-Z]', text))
                        if english_chars > korean_chars:
                            main_language = "ì˜ì–´"
        
        # ì£¼ì œ ë° í‚¤ì›Œë“œ ê¸°ë°˜ ì»¨í…ì¸  ë¶„ë¥˜
        combined_text = ' '.join(all_texts).lower()
        content_type = "ì¼ë°˜ ë‚´ìš©"
        
        if any(keyword in combined_text for keyword in ['seminar', 'ì„¸ë¯¸ë‚˜', 'conference', 'ì»¨í¼ëŸ°ìŠ¤', 'presentation', 'ë°œí‘œ']):
            content_type = "ì„¸ë¯¸ë‚˜/ì»¨í¼ëŸ°ìŠ¤"
        elif any(keyword in combined_text for keyword in ['jewelry', 'ì£¼ì–¼ë¦¬', 'diamond', 'ë‹¤ì´ì•„ëª¬ë“œ', 'gold', 'ê¸ˆ']):
            content_type = "ì£¼ì–¼ë¦¬ ê´€ë ¨"
        elif any(keyword in combined_text for keyword in ['business', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'market', 'ì‹œì¥', 'trend', 'íŠ¸ë Œë“œ']):
            content_type = "ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„"
        
        summary_parts = [
            f"ğŸ“Š **ë¶„ì„ ê°œìš”**: ì´ {total_files}ê°œ íŒŒì¼ ì¤‘ {successful}ê°œ íŒŒì¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤. (ì„±ê³µë¥ : {success_rate:.1f}%)",
            f"ğŸ“ **ì¶”ì¶œëœ ë‚´ìš©**: {main_language} í…ìŠ¤íŠ¸ {text_length:,}ì ë¶„ëŸ‰ì˜ {content_type} ë‚´ìš©ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
        ]
        
        if content_preview:
            summary_parts.append(f"ğŸ¯ **ì£¼ìš” ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°**: \"{content_preview}\"")
        
        if jewelry_keywords:
            summary_parts.append(f"ğŸ’ **ì£¼ì–¼ë¦¬ í‚¤ì›Œë“œ**: {len(jewelry_keywords)}ê°œì˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ({', '.join(jewelry_keywords[:3])}...)")
        
        if success_rate >= 90:
            summary_parts.append("âœ… **í’ˆì§ˆ í‰ê°€**: ë¶„ì„ í’ˆì§ˆì´ ë§¤ìš° ìš°ìˆ˜í•©ë‹ˆë‹¤.")
        elif success_rate >= 70:
            summary_parts.append("âš ï¸ **í’ˆì§ˆ í‰ê°€**: ë¶„ì„ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        else:
            summary_parts.append("âŒ **í’ˆì§ˆ í‰ê°€**: ì¼ë¶€ íŒŒì¼ì—ì„œ ë¶„ì„ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤.")
        
        return '\n\n'.join(summary_parts)
    
    def _generate_key_findings(self, results, jewelry_keywords):
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ìƒì„±"""
        findings = []
        
        # íŒŒì¼ í˜•ì‹ë³„ ë¶„ì„
        audio_results = [r for r in results if r.get('analysis_type') == 'real_whisper_stt']
        image_results = [r for r in results if r.get('analysis_type') == 'real_easyocr']
        
        # ì‹¤ì œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš© ë¶„ì„
        all_successful_texts = []
        detected_languages = []
        
        for result in results:
            if result.get('status') == 'success' and result.get('full_text'):
                text = result['full_text'].strip()
                if text:
                    all_successful_texts.append(text)
                    # ì–¸ì–´ ê°ì§€ ì •ë³´ ìˆ˜ì§‘
                    if result.get('detected_language'):
                        detected_languages.append(result['detected_language'])
        
        if all_successful_texts:
            combined_content = ' '.join(all_successful_texts)
            
            # ì–¸ì–´ ë¶„ì„
            if detected_languages:
                lang_counts = {}
                for lang in detected_languages:
                    lang_counts[lang] = lang_counts.get(lang, 0) + 1
                main_lang = max(lang_counts.items(), key=lambda x: x[1])[0]
                findings.append(f"ğŸ—£ï¸ **ì£¼ìš” ì–¸ì–´**: {main_lang} ({lang_counts[main_lang]}ê°œ íŒŒì¼)")
            
            # ë‚´ìš© ê¸¸ì´ ë° í’ˆì§ˆ ë¶„ì„
            total_length = len(combined_content)
            word_count = len(combined_content.split())
            findings.append(f"ğŸ“ **í…ìŠ¤íŠ¸ ë¶„ëŸ‰**: ì´ {total_length:,}ì, ì•½ {word_count:,}ë‹¨ì–´ ì¶”ì¶œ")
            
            # ì£¼ìš” ì£¼ì œ í‚¤ì›Œë“œ ë¶„ì„ (í•œêµ­ì–´ + ì˜ì–´)
            import re
            from collections import Counter
            
            # í•œêµ­ì–´ ëª…ì‚¬ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
            korean_words = re.findall(r'[ê°€-í£]{2,}', combined_content)
            # ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ (3ê¸€ì ì´ìƒ)
            english_words = re.findall(r'[A-Za-z]{3,}', combined_content.lower())
            
            # ë¹ˆë„ ë¶„ì„
            all_words = korean_words + english_words
            if all_words:
                word_freq = Counter(all_words)
                top_words = word_freq.most_common(8)
                if top_words:
                    findings.append(f"ğŸ” **í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join([f'{word}({count})' for word, count in top_words[:5]])}")
            
            # íŠ¹ì • ì£¼ì œ ê°ì§€
            topic_keywords = {
                'ì„¸ë¯¸ë‚˜/êµìœ¡': ['seminar', 'conference', 'presentation', 'education', 'training', 'workshop', 'ì„¸ë¯¸ë‚˜', 'êµìœ¡', 'ë°œí‘œ', 'ê°•ì˜', 'ì›Œí¬ìƒµ'],
                'ë¹„ì¦ˆë‹ˆìŠ¤': ['business', 'market', 'sales', 'customer', 'company', 'industry', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'ì‹œì¥', 'ê³ ê°', 'íšŒì‚¬', 'ì‚°ì—…'],
                'ê¸°ìˆ /IT': ['technology', 'software', 'digital', 'system', 'platform', 'ê¸°ìˆ ', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ë””ì§€í„¸', 'ì‹œìŠ¤í…œ', 'í”Œë«í¼'],
                'ì£¼ì–¼ë¦¬': ['jewelry', 'diamond', 'gold', 'silver', 'gem', 'precious', 'ì£¼ì–¼ë¦¬', 'ë‹¤ì´ì•„ëª¬ë“œ', 'ê¸ˆ', 'ì€', 'ë³´ì„']
            }
            
            detected_topics = []
            for topic, keywords in topic_keywords.items():
                matches = sum(1 for keyword in keywords if keyword.lower() in combined_content.lower())
                if matches >= 2:  # 2ê°œ ì´ìƒì˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì£¼ì œë¡œ ë¶„ë¥˜
                    detected_topics.append(f"{topic}({matches}ê°œ í‚¤ì›Œë“œ)")
            
            if detected_topics:
                findings.append(f"ğŸ¯ **ì£¼ì œ ë¶„ë¥˜**: {', '.join(detected_topics)}")
        
        # ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼
        if audio_results:
            audio_success = len([r for r in audio_results if r.get('status') == 'success'])
            total_audio_time = sum([r.get('processing_time', 0) for r in audio_results if r.get('processing_time')])
            findings.append(f"ğŸ¤ **ìŒì„± ë¶„ì„**: {len(audio_results)}ê°œ íŒŒì¼ ì¤‘ {audio_success}ê°œ ì„±ê³µ (ì´ ì²˜ë¦¬ì‹œê°„: {total_audio_time:.1f}ì´ˆ)")
        
        if image_results:
            image_success = len([r for r in image_results if r.get('status') == 'success'])
            avg_confidence = sum([r.get('average_confidence', 0) for r in image_results if r.get('average_confidence')]) / len(image_results) if image_results else 0
            findings.append(f"ğŸ–¼ï¸ **ì´ë¯¸ì§€ ë¶„ì„**: {len(image_results)}ê°œ íŒŒì¼ ì¤‘ {image_success}ê°œ ì„±ê³µ (í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1f}%)")
        
        if jewelry_keywords:
            findings.append(f"ğŸ’ **ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´**: {', '.join(jewelry_keywords[:5])}{'...' if len(jewelry_keywords) > 5 else ''}")
        
        return findings
    
    def _generate_conclusions(self, results, success_rate, jewelry_keywords):
        """ê²°ë¡  ë° ì œì•ˆì‚¬í•­ ìƒì„±"""
        conclusions = []
        
        if success_rate >= 90:
            conclusions.append("ë¶„ì„ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìœ¼ë©°, ëŒ€ë¶€ë¶„ì˜ íŒŒì¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        elif success_rate >= 70:
            conclusions.append("ë¶„ì„ ì‹œìŠ¤í…œì´ ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë™í•˜ê³  ìˆìœ¼ë‚˜, ì¼ë¶€ íŒŒì¼ í˜•ì‹ì´ë‚˜ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            conclusions.append("ë¶„ì„ ì‹¤íŒ¨ìœ¨ì´ ë†’ìœ¼ë¯€ë¡œ íŒŒì¼ í’ˆì§ˆì´ë‚˜ í˜•ì‹ì„ ì ê²€í•˜ê³ , ì‹œìŠ¤í…œ ì„¤ì •ì„ ì¡°ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        if jewelry_keywords:
            conclusions.append("ì£¼ì–¼ë¦¬ ê´€ë ¨ ì»¨í…ì¸ ê°€ ì¶©ë¶„íˆ ê°ì§€ë˜ì–´ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„ì´ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
            conclusions.append("í–¥í›„ ì£¼ì–¼ë¦¬ ì „ë¬¸ ìš©ì–´ ì‚¬ì „ì„ í™•ì¥í•˜ì—¬ ë” ì •í™•í•œ í‚¤ì›Œë“œ ì¶”ì¶œì´ ê°€ëŠ¥í•  ê²ƒì…ë‹ˆë‹¤.")
        
        # ê°œì„  ì œì•ˆ
        error_results = [r for r in results if r.get('status') == 'error']
        if error_results:
            error_types = [r.get('error', '') for r in error_results]
            if any('m4a' in error.lower() for error in error_types):
                conclusions.append("M4A íŒŒì¼ ì²˜ë¦¬ ê°œì„ ì„ ìœ„í•´ FFmpeg ì„¤ì •ì„ ìµœì í™”í•˜ê±°ë‚˜ WAV í˜•ì‹ ì‚¬ì „ ë³€í™˜ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        conclusions.append("ì •ê¸°ì ì¸ ë°°ì¹˜ ë¶„ì„ì„ í†µí•´ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì§€ì†ì ìœ¼ë¡œ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return conclusions
    
    def _calculate_average_confidence(self, results):
        """í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_scores = []
        for result in results:
            if result.get('average_confidence'):
                confidence_scores.append(result['average_confidence'])
        
        return sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
    
    def render_advanced_dashboard(self, report: Dict[str, Any]):
        """ê³ ê¸‰ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        if not PLOTLY_AVAILABLE or not PANDAS_AVAILABLE:
            st.warning("âš ï¸ ê³ ê¸‰ ì°¨íŠ¸ ê¸°ëŠ¥ì„ ìœ„í•´ plotlyì™€ pandas ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.code("pip install plotly pandas")
            return
        
        try:
            # íƒ­ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ êµ¬ì„±
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ íŒŒì¼ ë¶„ì„", "â±ï¸ ì²˜ë¦¬ ì‹œê°„", "ğŸ·ï¸ í‚¤ì›Œë“œ ë¶„ì„", "ğŸ“Š ì„±ëŠ¥ ì§€í‘œ"])
            
            with tab1:
                self._render_file_analysis_charts(report)
            
            with tab2:
                self._render_processing_time_charts(report)
            
            with tab3:
                self._render_keyword_analysis_charts(report)
            
            with tab4:
                self._render_performance_metrics(report)
                
        except Exception as e:
            st.error(f"ëŒ€ì‹œë³´ë“œ ë Œë”ë§ ì˜¤ë¥˜: {str(e)}")
    
    def _render_file_analysis_charts(self, report: Dict[str, Any]):
        """íŒŒì¼ ë¶„ì„ ì°¨íŠ¸"""
        col1, col2 = st.columns(2)
        
        with col1:
            # íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬
            if report.get('file_type_distribution'):
                file_types = list(report['file_type_distribution'].keys())
                file_counts = list(report['file_type_distribution'].values())
                
                fig = px.pie(
                    values=file_counts, 
                    names=file_types,
                    title="ğŸ“ íŒŒì¼ íƒ€ì… ë¶„í¬",
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ë¶„ì„ ì„±ê³µë¥ 
            if hasattr(report, 'success_rate') and hasattr(report, 'total_files'):
                success_count = int((report['success_rate'] / 100) * report['total_files'])
                failed_count = report['total_files'] - success_count
                
                fig = go.Figure(data=[
                    go.Bar(name='ì„±ê³µ', x=['ë¶„ì„ ê²°ê³¼'], y=[success_count], marker_color='green'),
                    go.Bar(name='ì‹¤íŒ¨', x=['ë¶„ì„ ê²°ê³¼'], y=[failed_count], marker_color='red')
                ])
                fig.update_layout(
                    title="âœ… ë¶„ì„ ì„±ê³µë¥ ",
                    barmode='stack',
                    yaxis_title="íŒŒì¼ ìˆ˜"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # íŒŒì¼ í¬ê¸° ë¶„í¬
        if st.session_state.analysis_results:
            file_sizes = []
            file_names = []
            
            for result in st.session_state.analysis_results:
                if result.get('file_size_mb'):
                    file_sizes.append(result['file_size_mb'])
                    file_names.append(result.get('file_name', 'Unknown'))
            
            if file_sizes:
                fig = px.histogram(
                    x=file_sizes,
                    nbins=10,
                    title="ğŸ“ íŒŒì¼ í¬ê¸° ë¶„í¬ (MB)",
                    labels={'x': 'íŒŒì¼ í¬ê¸° (MB)', 'y': 'íŒŒì¼ ìˆ˜'}
                )
                fig.update_traces(marker_color='lightblue')
                st.plotly_chart(fig, use_container_width=True)
    
    def _render_processing_time_charts(self, report: Dict[str, Any]):
        """ì²˜ë¦¬ ì‹œê°„ ì°¨íŠ¸"""
        if not st.session_state.analysis_results:
            st.info("ì²˜ë¦¬ ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„
        processing_times = []
        file_names = []
        file_types = []
        
        for result in st.session_state.analysis_results:
            if result.get('processing_time'):
                processing_times.append(result['processing_time'])
                file_names.append(result.get('file_name', 'Unknown')[:20] + '...')
                file_types.append(result.get('file_type', 'unknown'))
        
        if processing_times:
            col1, col2 = st.columns(2)
            
            with col1:
                # íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„ ë§‰ëŒ€ ì°¨íŠ¸
                fig = px.bar(
                    x=file_names,
                    y=processing_times,
                    title="â±ï¸ íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„",
                    labels={'x': 'íŒŒì¼ëª…', 'y': 'ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)'},
                    color=processing_times,
                    color_continuous_scale='Viridis'
                )
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # íŒŒì¼ íƒ€ì…ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„
                if PANDAS_AVAILABLE:
                    df = pd.DataFrame({
                        'file_type': file_types,
                        'processing_time': processing_times
                    })
                    avg_times = df.groupby('file_type')['processing_time'].mean().reset_index()
                    
                    fig = px.bar(
                        avg_times,
                        x='file_type',
                        y='processing_time',
                        title="ğŸ“Š íŒŒì¼ íƒ€ì…ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„",
                        labels={'file_type': 'íŒŒì¼ íƒ€ì…', 'processing_time': 'í‰ê·  ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # ì²˜ë¦¬ ì‹œê°„ í†µê³„
        if processing_times:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("âš¡ ìµœë‹¨ ì‹œê°„", f"{min(processing_times):.1f}ì´ˆ")
            with col2:
                st.metric("ğŸŒ ìµœì¥ ì‹œê°„", f"{max(processing_times):.1f}ì´ˆ")
            with col3:
                st.metric("ğŸ“Š í‰ê·  ì‹œê°„", f"{sum(processing_times)/len(processing_times):.1f}ì´ˆ")
            with col4:
                st.metric("ğŸ• ì´ ì²˜ë¦¬ ì‹œê°„", f"{sum(processing_times):.1f}ì´ˆ")
    
    def _render_keyword_analysis_charts(self, report: Dict[str, Any]):
        """í‚¤ì›Œë“œ ë¶„ì„ ì°¨íŠ¸"""
        if not report.get('top_keywords'):
            st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë§‰ëŒ€ ì°¨íŠ¸
        keywords = [item[0] for item in report['top_keywords'][:20]]
        counts = [item[1] for item in report['top_keywords'][:20]]
        
        fig = px.bar(
            x=counts,
            y=keywords,
            orientation='h',
            title="ğŸ·ï¸ ìƒìœ„ í‚¤ì›Œë“œ ë¹ˆë„",
            labels={'x': 'ì¶œí˜„ ë¹ˆë„', 'y': 'í‚¤ì›Œë“œ'},
            color=counts,
            color_continuous_scale='Blues'
        )
        fig.update_layout(height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # í‚¤ì›Œë“œ íŠ¸ë Œë“œ (ì‹œê°„ë³„ - ê°€ëŠ¥í•œ ê²½ìš°)
        if len(report['top_keywords']) >= 10:
            # ì›Œë“œí´ë¼ìš°ë“œ ìŠ¤íƒ€ì¼ ì‹œê°í™” (Plotlyë¡œ êµ¬í˜„)
            fig = go.Figure()
            
            for i, (keyword, count) in enumerate(report['top_keywords'][:20]):
                fig.add_trace(go.Scatter(
                    x=[i % 5], 
                    y=[i // 5],
                    text=keyword,
                    mode='text',
                    textfont=dict(size=min(30, 10 + count * 2)),
                    showlegend=False
                ))
            
            fig.update_layout(
                title="â˜ï¸ í‚¤ì›Œë“œ í´ë¼ìš°ë“œ",
                xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
                yaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_performance_metrics(self, report: Dict[str, Any]):
        """ì„±ëŠ¥ ì§€í‘œ ì°¨íŠ¸"""
        col1, col2 = st.columns(2)
        
        with col1:
            # ì„±ëŠ¥ ê²Œì´ì§€ ì°¨íŠ¸
            success_rate = report.get('success_rate', 0)
            
            fig = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = success_rate,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "ì„±ê³µë¥  (%)"},
                delta = {'reference': 90},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 80], 'color': "yellow"},
                        {'range': [80, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ì‹ ë¢°ë„ ë¶„í¬
            if st.session_state.analysis_results:
                confidences = []
                for result in st.session_state.analysis_results:
                    if result.get('average_confidence'):
                        confidences.append(result['average_confidence'])
                
                if confidences:
                    fig = px.histogram(
                        x=confidences,
                        nbins=15,
                        title="ğŸ¯ ì‹ ë¢°ë„ ë¶„í¬",
                        labels={'x': 'ì‹ ë¢°ë„', 'y': 'íŒŒì¼ ìˆ˜'},
                        color_discrete_sequence=['lightcoral']
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # ì¢…í•© ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸
        if st.session_state.analysis_results:
            categories = ['ì†ë„', 'ì •í™•ë„', 'ì•ˆì •ì„±', 'íš¨ìœ¨ì„±', 'ì‚¬ìš©ì„±']
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0-100)
            processing_times = [r.get('processing_time', 0) for r in st.session_state.analysis_results if r.get('processing_time')]
            avg_time = sum(processing_times) / len(processing_times) if processing_times else 0
            speed_score = max(0, 100 - min(100, avg_time * 10))  # ì‹œê°„ì´ ì§§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            
            accuracy_score = min(100, report.get('success_rate', 0))
            stability_score = min(100, (report.get('success_rate', 0) + 20))  # ì„±ê³µë¥  ê¸°ë°˜
            efficiency_score = min(100, speed_score * 0.7 + accuracy_score * 0.3)
            usability_score = 85  # ê³ ì •ê°’ (UI ë³µì¡ë„ ë“± ê³ ë ¤)
            
            values = [speed_score, accuracy_score, stability_score, efficiency_score, usability_score]
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatterpolar(
                r=values,
                theta=categories,
                fill='toself',
                name='ì„±ëŠ¥ ì§€í‘œ'
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 100]
                    )),
                title="ğŸ“Š ì¢…í•© ì„±ëŠ¥ í‰ê°€",
                showlegend=True
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _prepare_enhanced_context(self) -> Dict[str, Any]:
        """ê°•í™”ëœ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ - ì‚¬ì „ì •ë³´ ìµœëŒ€ í™œìš©"""
        base_context = st.session_state.get('project_info', {})
        
        enhanced_context = {
            # ê¸°ë³¸ í”„ë¡œì íŠ¸ ì •ë³´
            'project_name': base_context.get('name', ''),
            'project_type': base_context.get('type', ''),
            'objective': base_context.get('objective', ''),
            'target_language': base_context.get('target_language', 'auto'),
            
            # ğŸ†• ì°¸ì„ì ë° ë°œí‘œì ì •ë³´ (í…ìŠ¤íŠ¸ ë³´ì •ì— í™œìš©)
            'participants': self._extract_names(base_context.get('participants', '')),
            'speakers': self._extract_names(base_context.get('speakers', '')),
            
            # ğŸ†• ì£¼ì œ ë° í‚¤ì›Œë“œ ì •ë³´ (ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì— í™œìš©)
            'topic_keywords': self._extract_keywords(base_context.get('topic_keywords', '')),
            'event_context': base_context.get('event_context', ''),
            
            # ğŸ†• ë¶„ì„ ì„¤ì • ì •ë³´
            'analysis_depth': base_context.get('analysis_depth', 'ìƒì„¸'),
            'enable_multi_angle': base_context.get('enable_multi_angle', True),
            'correlation_analysis': base_context.get('correlation_analysis', True),
            
            # ğŸ†• ì´ë¯¸ ë¶„ì„ëœ íŒŒì¼ë“¤ì˜ ì •ë³´ (ìƒê´€ê´€ê³„ ë¶„ì„ìš©)
            'previous_results': self._get_previous_analysis_summary(),
            
            # ğŸ†• ì‹¤ì‹œê°„ ë¶„ì„ ê°€ì´ë“œë¼ì¸
            'analysis_guidelines': self._generate_analysis_guidelines(base_context)
        }
        
        return enhanced_context
    
    def _extract_names(self, names_text: str) -> List[str]:
        """ì°¸ì„ì/ë°œí‘œì ì´ë¦„ ì¶”ì¶œ ë° ì •ê·œí™”"""
        if not names_text.strip():
            return []
        
        # ì‰¼í‘œ, ì„¸ë¯¸ì½œë¡ , ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„
        names = []
        for separator in [',', ';', '\n']:
            names_text = names_text.replace(separator, '|')
        
        for name in names_text.split('|'):
            name = name.strip()
            if name and len(name) >= 2:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                names.append(name)
        
        return names
    
    def _extract_keywords(self, keywords_text: str) -> List[str]:
        """ì£¼ì œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ê·œí™”"""
        if not keywords_text.strip():
            return []
        
        keywords = []
        for separator in [',', ';', '\n', ' ']:
            keywords_text = keywords_text.replace(separator, '|')
        
        for keyword in keywords_text.split('|'):
            keyword = keyword.strip()
            if keyword and len(keyword) >= 2:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                keywords.append(keyword)
        
        return keywords
    
    def _get_previous_analysis_summary(self) -> Dict[str, Any]:
        """ì´ì „ ë¶„ì„ ê²°ê³¼ ìš”ì•½ (ìƒê´€ê´€ê³„ ë¶„ì„ìš©)"""
        previous_results = getattr(st.session_state, 'analysis_results', [])
        
        if not previous_results:
            return {}
        
        # ì´ì „ ê²°ê³¼ì—ì„œ ì¤‘ìš” ì •ë³´ ì¶”ì¶œ
        summary = {
            'total_files_analyzed': len(previous_results),
            'common_keywords': [],
            'frequent_participants': [],
            'main_topics': []
        }
        
        # ê³µí†µ í‚¤ì›Œë“œ ë° ì°¸ì„ì ì¶”ì¶œ
        all_keywords = []
        all_texts = []
        
        for result in previous_results:
            if result.get('status') == 'success':
                if result.get('jewelry_keywords'):
                    all_keywords.extend(result['jewelry_keywords'])
                if result.get('full_text'):
                    all_texts.append(result['full_text'])
        
        # ë¹ˆë„ ê¸°ë°˜ ì¤‘ìš” ì •ë³´ ì¶”ì¶œ
        if all_keywords:
            from collections import Counter
            keyword_counts = Counter(all_keywords)
            summary['common_keywords'] = [k for k, v in keyword_counts.most_common(5)]
        
        return summary
    
    def _generate_analysis_guidelines(self, context: Dict[str, Any]) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ê°€ì´ë“œë¼ì¸ ìƒì„±"""
        guidelines = []
        
        # í”„ë¡œì íŠ¸ íƒ€ì…ë³„ ê°€ì´ë“œë¼ì¸
        project_type = context.get('type', '')
        if 'íšŒì˜' in project_type:
            guidelines.append("íšŒì˜ë¡ í˜•ì‹ì˜ êµ¬ì¡°í™”ëœ ìš”ì•½ ìƒì„±")
            guidelines.append("ì°¸ì„ìë³„ ë°œì–¸ ë‚´ìš© êµ¬ë¶„")
        elif 'ê°•ì˜' in project_type or 'ì„¸ë¯¸ë‚˜' in project_type:
            guidelines.append("êµìœ¡ ìë£Œë¡œ í™œìš© ê°€ëŠ¥í•œ ì²´ê³„ì  ì •ë¦¬")
            guidelines.append("í•µì‹¬ ê°œë…ê³¼ ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ ë„ì¶œ")
        
        # ì°¸ì„ì ì •ë³´ê°€ ìˆì„ ê²½ìš°
        if context.get('participants'):
            guidelines.append(f"ì°¸ì„ì ì´ë¦„ ì •í™•ì„± ê²€ì¦: {', '.join(context['participants'][:3])}")
        
        # í‚¤ì›Œë“œ ì •ë³´ê°€ ìˆì„ ê²½ìš°
        if context.get('topic_keywords'):
            guidelines.append(f"í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ ë¶„ì„: {', '.join(context['topic_keywords'][:3])}")
        
        return guidelines
    
    def _update_analysis_status(self, filename: str, context: Dict[str, Any]):
        """ë¶„ì„ ì§„í–‰ ìƒí™©ì„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ì™€ í•¨ê»˜ ì—…ë°ì´íŠ¸"""
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í‘œì‹œ
        context_info = []
        if context.get('participants'):
            context_info.append(f"ğŸ‘¥ ì°¸ì„ì {len(context['participants'])}ëª…")
        if context.get('speakers'):
            context_info.append(f"ğŸ¤ ë°œí‘œì {len(context['speakers'])}ëª…")
        if context.get('topic_keywords'):
            context_info.append(f"ğŸ”‘ í‚¤ì›Œë“œ {len(context['topic_keywords'])}ê°œ")
        
        if context_info:
            context_display = " | ".join(context_info)
            st.info(f"ğŸ“‹ **í™œìš© ì¤‘ì¸ ì‚¬ì „ì •ë³´**: {context_display}")
        
        # ë¶„ì„ ê°€ì´ë“œë¼ì¸ í‘œì‹œ
        if context.get('analysis_guidelines'):
            with st.expander("ğŸ¯ ì ìš© ì¤‘ì¸ ë¶„ì„ ê°€ì´ë“œë¼ì¸", expanded=False):
                for guideline in context['analysis_guidelines']:
                    st.write(f"â€¢ {guideline}")
    
    def _categorize_and_preprocess_files(self, uploaded_files_data) -> Dict[str, List]:
        """íŒŒì¼ ë¶„ë¥˜ ë° ì „ì²˜ë¦¬"""
        categories = {
            'audio_files': [],
            'video_files': [],  
            'image_files': [],
            'document_files': [],
            'video_urls': uploaded_files_data.get('video_urls', [])
        }
        
        for uploaded_file in uploaded_files_data.get('files', []):
            file_ext = uploaded_file.name.split('.')[-1].lower()
            file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
            
            file_info = {
                'file': uploaded_file,
                'name': uploaded_file.name,
                'extension': file_ext,
                'size_mb': file_size_mb,
                'temp_path': None
            }
            
            if file_ext in ['wav', 'mp3', 'flac', 'm4a']:
                categories['audio_files'].append(file_info)
            elif file_ext in ['mp4', 'mov', 'avi']:
                categories['video_files'].append(file_info)
            elif file_ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                categories['image_files'].append(file_info)
            elif file_ext in ['pdf', 'docx', 'txt']:
                categories['document_files'].append(file_info)
        
        return categories
    
    def _build_integrated_context(self, file_categories) -> Dict[str, Any]:
        """ëª¨ë“  íŒŒì¼ ì •ë³´ë¥¼ í†µí•©í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        base_context = self._prepare_enhanced_context()
        
        integrated_context = {
            **base_context,
            'file_categories': file_categories,
            'total_files': sum(len(files) for files in file_categories.values() if isinstance(files, list)),
            'file_distribution': {
                'audio': len(file_categories.get('audio_files', [])),
                'video': len(file_categories.get('video_files', [])),
                'image': len(file_categories.get('image_files', [])),
                'document': len(file_categories.get('document_files', [])),
                'video_url': len(file_categories.get('video_urls', []))
            },
            'analysis_strategy': self._determine_analysis_strategy(file_categories),
            'cross_reference_enabled': True,
            'batch_processing': True
        }
        
        return integrated_context
    
    def _determine_analysis_strategy(self, file_categories) -> str:
        """íŒŒì¼ êµ¬ì„±ì— ë”°ë¥¸ ìµœì  ë¶„ì„ ì „ëµ ê²°ì •"""
        audio_count = len(file_categories.get('audio_files', []))
        video_count = len(file_categories.get('video_files', []))
        image_count = len(file_categories.get('image_files', []))
        
        if video_count > 0 and (audio_count > 0 or image_count > 0):
            return "multimodal_integrated"  # ë‹¤ì¤‘ëª¨ë‹¬ í†µí•© ë¶„ì„
        elif audio_count > 0 and image_count > 0:
            return "audio_visual_correlation"  # ìŒì„±-ì‹œê° ìƒê´€ê´€ê³„
        elif video_count > 1:
            return "multi_video_synthesis"  # ë‹¤ì¤‘ ì˜ìƒ ì¢…í•©
        elif image_count > 3:
            return "sequential_image_analysis"  # ì—°ì† ì´ë¯¸ì§€ ë¶„ì„
        else:
            return "standard_batch"  # í‘œì¤€ ë°°ì¹˜ ë¶„ì„
    
    def _execute_batch_analysis(self, file_categories, integrated_context) -> Dict[str, Any]:
        """ë°°ì¹˜ í†µí•© ë¶„ì„ ì‹¤í–‰"""
        batch_results = {
            'audio_results': [],
            'video_results': [],
            'image_results': [],
            'document_results': [],
            'youtube_results': [],
            'cross_correlations': [],
            'integrated_insights': {}
        }
        
        # ğŸ¤ ìŒì„± íŒŒì¼ ë°°ì¹˜ ë¶„ì„
        if file_categories.get('audio_files'):
            batch_results['audio_results'] = self._batch_analyze_audio_files(
                file_categories['audio_files'], integrated_context
            )
        
        # ğŸ¬ ì˜ìƒ íŒŒì¼ ë°°ì¹˜ ë¶„ì„  
        if file_categories.get('video_files'):
            batch_results['video_results'] = self._batch_analyze_video_files(
                file_categories['video_files'], integrated_context
            )
        
        # ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ë°°ì¹˜ ë¶„ì„
        if file_categories.get('image_files'):
            batch_results['image_results'] = self._batch_analyze_image_files(
                file_categories['image_files'], integrated_context
            )
        
        # ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„
        if integrated_context.get('cross_reference_enabled'):
            batch_results['cross_correlations'] = self._analyze_cross_correlations(
                batch_results, integrated_context
            )
        
        return batch_results
    
    def _batch_analyze_audio_files(self, audio_files, context) -> List[Dict]:
        """ìŒì„± íŒŒì¼ ë°°ì¹˜ ë¶„ì„"""
        results = []
        
        # ëª¨ë“  ìŒì„± íŒŒì¼ì„ ì„ì‹œ ì €ì¥
        temp_files = []
        for file_info in audio_files:
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_files.append(tmp_file.name)
                file_info['temp_path'] = tmp_file.name
        
        # ë°°ì¹˜ STT ì²˜ë¦¬ (GPU íš¨ìœ¨ì„± ê·¹ëŒ€í™”)
        try:
            for i, file_info in enumerate(audio_files):
                st.text(f"ğŸ¤ ìŒì„± ë¶„ì„: {file_info['name']} ({i+1}/{len(audio_files)})")
                
                # ê°œë³„ ë¶„ì„ ìˆ˜í–‰ (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
                result = analyze_file_real(file_info['temp_path'], 'audio', 'auto', context)
                result['batch_index'] = i
                result['cross_reference_ready'] = True
                results.append(result)
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
        
        return results
    
    def _batch_analyze_image_files(self, image_files, context) -> List[Dict]:
        """ì´ë¯¸ì§€ íŒŒì¼ ë°°ì¹˜ ë¶„ì„ - GPU ìµœì í™”"""
        results = []
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì„ì‹œ ì €ì¥
        temp_files = []
        for file_info in image_files:
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_files.append(tmp_file.name)
                file_info['temp_path'] = tmp_file.name
        
        try:
            # GPU ëª¨ë¸ í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ë°°ì¹˜ ì²˜ë¦¬
            for i, file_info in enumerate(image_files):
                st.text(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„: {file_info['name']} ({i+1}/{len(image_files)})")
                
                result = analyze_file_real(file_info['temp_path'], 'image', 'auto', context)
                result['batch_index'] = i
                result['cross_reference_ready'] = True
                results.append(result)
                
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                except:
                    pass
        
        return results
    
    def _batch_analyze_video_files(self, video_files, context) -> List[Dict]:
        """ì˜ìƒ íŒŒì¼ ë°°ì¹˜ ë¶„ì„ - ë‹¤ê°ë„ í†µí•©"""
        results = []
        
        for i, file_info in enumerate(video_files):
            st.text(f"ğŸ¬ ì˜ìƒ ë¶„ì„: {file_info['name']} ({i+1}/{len(video_files)})")
            
            # ì„ì‹œ íŒŒì¼ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix=f".{file_info['extension']}", delete=False) as tmp_file:
                tmp_file.write(file_info['file'].getvalue())
                temp_path = tmp_file.name
            
            try:
                result = analyze_file_real(temp_path, 'video', 'auto', context)
                result['batch_index'] = i
                result['cross_reference_ready'] = True
                results.append(result)
            finally:
                try:
                    os.unlink(temp_path)
                except:
                    pass
        
        return results
    
    def _analyze_cross_correlations(self, batch_results, context) -> List[Dict]:
        """ë°°ì¹˜ ê²°ê³¼ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        correlations = []
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_texts = []
        all_keywords = []
        
        for category, results in batch_results.items():
            if isinstance(results, list):
                for result in results:
                    if result.get('status') == 'success':
                        if result.get('full_text'):
                            all_texts.append({
                                'text': result['full_text'],
                                'source': category,
                                'file_name': result.get('file_name', ''),
                                'type': category.replace('_results', '')
                            })
                        if result.get('jewelry_keywords'):
                            all_keywords.extend(result['jewelry_keywords'])
        
        # ê³µí†µ í‚¤ì›Œë“œ ë¶„ì„
        if all_keywords:
            from collections import Counter
            keyword_counts = Counter(all_keywords)
            common_keywords = [k for k, v in keyword_counts.most_common(10) if v > 1]
            
            correlations.append({
                'type': 'common_keywords',
                'keywords': common_keywords,
                'strength': len(common_keywords) / len(set(all_keywords)) if all_keywords else 0
            })
        
        return correlations
    
    def _integrate_and_optimize_results(self, batch_results, context) -> List[Dict]:
        """ë°°ì¹˜ ê²°ê³¼ í†µí•© ë° ìµœì í™”"""
        integrated_results = []
        
        # ëª¨ë“  ê²°ê³¼ë¥¼ í†µí•© ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        for category, results in batch_results.items():
            if isinstance(results, list):
                for result in results:
                    # ë°°ì¹˜ ë¶„ì„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    result['batch_processed'] = True
                    result['correlation_analyzed'] = len(batch_results.get('cross_correlations', [])) > 0
                    result['analysis_strategy'] = context.get('analysis_strategy', 'standard_batch')
                    integrated_results.append(result)
        
        return integrated_results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    ui = SolomondRealAnalysisUI()
    ui.run()

if __name__ == "__main__":
    main()