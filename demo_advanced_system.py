"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ í†µí•© ë°ëª¨
ì‹¤ì œ ë™ì‘ ê°€ëŠ¥í•œ ë°ëª¨ + ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ + ë²¤ì¹˜ë§ˆí¬

íŠ¹ì§•:
- ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬ ë°ëª¨
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- ì²˜ë¦¬ ì†ë„ ìµœì í™” ê²€ì¦
- í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
"""

import asyncio
import time
import json
import os
import tempfile
import shutil
from typing import Dict, List, Optional
from pathlib import Path
import logging
from datetime import datetime
import psutil
import threading
from dataclasses import dataclass, asdict

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ import
try:
    from core.advanced_llm_summarizer_complete import EnhancedLLMSummarizer
    from core.large_file_streaming_engine import LargeFileStreamingEngine
    from core.multimodal_integrator import get_multimodal_integrator
    MODULES_AVAILABLE = True
except ImportError:
    MODULES_AVAILABLE = False
    print("âš ï¸ ì¼ë¶€ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

@dataclass
class BenchmarkResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼"""
    test_name: str
    files_count: int
    total_size_mb: float
    processing_time: float
    memory_peak_mb: float
    memory_avg_mb: float
    throughput_mbps: float
    quality_score: float
    success_rate: float
    errors: List[str]

class AdvancedSystemDemo:
    """ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì‹œìŠ¤í…œ ë°ëª¨"""
    
    def __init__(self):
        self.llm_summarizer = None
        self.streaming_engine = None
        self.benchmark_results = []
        self.demo_files_dir = "demo_files"
        self.temp_dir = tempfile.mkdtemp(prefix="solomond_demo_")
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.memory_monitor = None
        self.monitoring_active = False
        self.memory_samples = []
        
        self._setup_demo_environment()
    
    def _setup_demo_environment(self):
        """ë°ëª¨ í™˜ê²½ ì„¤ì •"""
        print("ğŸ”§ ë°ëª¨ í™˜ê²½ ì„¤ì • ì¤‘...")
        
        # ë°ëª¨ íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.demo_files_dir, exist_ok=True)
        
        # ëª¨ë“ˆ ì´ˆê¸°í™”
        if MODULES_AVAILABLE:
            self.llm_summarizer = EnhancedLLMSummarizer()
            self.streaming_engine = LargeFileStreamingEngine(max_memory_mb=200)
        
        print("âœ… ë°ëª¨ í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    
    def create_demo_files(self):
        """ë°ëª¨ìš© íŒŒì¼ ìƒì„±"""
        print("ğŸ“ ë°ëª¨ íŒŒì¼ ìƒì„± ì¤‘...")
        
        demo_files = []
        
        # 1. í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŒì„± íŒŒì¼ ì‹œë®¬ë ˆì´ì…˜
        audio_content = """
        ì•ˆë…•í•˜ì„¸ìš”. 2025ë…„ ë‹¤ì´ì•„ëª¬ë“œ ì‹œì¥ ì „ë§ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
        4C ë“±ê¸‰ ì¤‘ì—ì„œ íŠ¹íˆ ì»¬ëŸ¬ì™€ í´ë˜ë¦¬í‹° ë“±ê¸‰ì´ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í´ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.
        GIA ì¸ì¦ì„œì˜ ì¤‘ìš”ì„±ì´ ë”ìš± ê°•ì¡°ë˜ê³  ìˆìœ¼ë©°, í”„ë¦°ì„¸ìŠ¤ ì»·ê³¼ ë¼ìš´ë“œ ë¸Œë¦´ë¦¬ì–¸íŠ¸ ì»·ì˜ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        1ìºëŸ¿ ë‹¤ì´ì•„ëª¬ë“œì˜ ë„ë§¤ê°€ê²©ì´ ì „ë…„ ëŒ€ë¹„ 15% ìƒìŠ¹í•  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.
        íŠ¹íˆ D, E, F ì»¬ëŸ¬ ë“±ê¸‰ì˜ ë‹¤ì´ì•„ëª¬ë“œê°€ ë†’ì€ ê´€ì‹¬ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.
        """
        
        audio_file = os.path.join(self.demo_files_dir, "diamond_market_analysis.txt")
        with open(audio_file, 'w', encoding='utf-8') as f:
            f.write(audio_content * 50)  # ëŒ€ìš©ëŸ‰ ì‹œë®¬ë ˆì´ì…˜
        demo_files.append({"path": audio_file, "type": "audio", "size_mb": 0.5})
        
        # 2. ë¬¸ì„œ íŒŒì¼ ì‹œë®¬ë ˆì´ì…˜
        document_content = """
        ì£¼ì–¼ë¦¬ ì‹œì¥ ë™í–¥ ë³´ê³ ì„œ
        
        1. ë‹¤ì´ì•„ëª¬ë“œ ì‹œì¥
        - 1ìºëŸ¿ D-IF ë“±ê¸‰: $8,500 (ì „ì›” ëŒ€ë¹„ 3% ìƒìŠ¹)
        - 2ìºëŸ¿ E-VS1 ë“±ê¸‰: $25,000 (ì•ˆì •ì„¸)
        - 3ìºëŸ¿ F-VVS2 ë“±ê¸‰: $65,000 (2% ìƒìŠ¹)
        
        2. ì»¬ëŸ¬ë“œ ìŠ¤í†¤ ì‹œì¥
        - ë£¨ë¹„: ë²„ë§ˆì‚° 1ìºëŸ¿ $4,500 (5% ìƒìŠ¹)
        - ì‚¬íŒŒì´ì–´: ì¹´ì‹œë¯¸ë¥´ì‚° 1ìºëŸ¿ $6,200 (3% ìƒìŠ¹)
        - ì—ë©”ë„ë“œ: ì½œë¡¬ë¹„ì•„ì‚° 1ìºëŸ¿ $3,200 (2% í•˜ë½)
        
        3. íŠ¸ë Œë“œ ë¶„ì„
        - ë©ê·¸ë¡œìš´ ë‹¤ì´ì•„ëª¬ë“œ ìˆ˜ìš” ì¦ê°€
        - ì„œìŠ¤í…Œì´ë„ˆë¸” ì£¼ì–¼ë¦¬ ê´€ì‹¬ í™•ëŒ€
        - ê°œì¸ ë§ì¶¤í˜• ë””ìì¸ ì„ í˜¸ë„ ì¦ê°€
        
        4. ì‹œì¥ ì „ë§
        - 2025ë…„ í•˜ë°˜ê¸° ì „ì²´ì ì¸ ìƒìŠ¹ì„¸ ì˜ˆìƒ
        - ì•„ì‹œì•„ ì‹œì¥ì˜ êµ¬ë§¤ë ¥ ì¦ê°€
        - ì˜¨ë¼ì¸ íŒë§¤ ì±„ë„ í™•ëŒ€
        """
        
        doc_file = os.path.join(self.demo_files_dir, "jewelry_market_report.txt")
        with open(doc_file, 'w', encoding='utf-8') as f:
            f.write(document_content * 100)  # ëŒ€ìš©ëŸ‰ ì‹œë®¬ë ˆì´ì…˜
        demo_files.append({"path": doc_file, "type": "document", "size_mb": 1.2})
        
        # 3. ì´ë¯¸ì§€ OCR ì‹œë®¬ë ˆì´ì…˜
        image_content = """
        GIA Report Number: 2141234567
        Shape: Round Brilliant
        Carat Weight: 1.52
        Color Grade: F
        Clarity Grade: VS1
        Cut Grade: Excellent
        Polish: Excellent
        Symmetry: Excellent
        Fluorescence: None
        Measurements: 7.31 - 7.34 x 4.52 mm
        """
        
        image_file = os.path.join(self.demo_files_dir, "gia_certificate.txt")
        with open(image_file, 'w', encoding='utf-8') as f:
            f.write(image_content * 20)
        demo_files.append({"path": image_file, "type": "image", "size_mb": 0.1})
        
        # 4. ëŒ€ìš©ëŸ‰ íŒŒì¼ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ìš©)
        large_content = audio_content + document_content + image_content
        large_file = os.path.join(self.demo_files_dir, "large_meeting_recording.txt")
        with open(large_file, 'w', encoding='utf-8') as f:
            for i in range(500):  # ì•½ 10MB íŒŒì¼
                f.write(f"--- ì„¸ê·¸ë¨¼íŠ¸ {i+1} ---\n{large_content}\n")
        demo_files.append({"path": large_file, "type": "audio", "size_mb": 10.0})
        
        print(f"âœ… ë°ëª¨ íŒŒì¼ ìƒì„± ì™„ë£Œ: {len(demo_files)}ê°œ")
        return demo_files
    
    def start_memory_monitoring(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        self.memory_samples = []
        
        def monitor():
            while self.monitoring_active:
                memory_mb = psutil.Process().memory_info().rss / (1024 * 1024)
                self.memory_samples.append({
                    "timestamp": time.time(),
                    "memory_mb": memory_mb
                })
                time.sleep(0.5)
        
        self.memory_monitor = threading.Thread(target=monitor)
        self.memory_monitor.start()
    
    def stop_memory_monitoring(self) -> Dict:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.memory_monitor:
            self.memory_monitor.join()
        
        if not self.memory_samples:
            return {"peak_mb": 0, "avg_mb": 0, "samples": 0}
        
        memory_values = [s["memory_mb"] for s in self.memory_samples]
        return {
            "peak_mb": max(memory_values),
            "avg_mb": sum(memory_values) / len(memory_values),
            "samples": len(memory_values)
        }
    
    async def run_basic_processing_test(self, demo_files: List[Dict]) -> BenchmarkResult:
        """ê¸°ë³¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ§ª ê¸°ë³¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        start_time = time.time()
        self.start_memory_monitoring()
        
        errors = []
        successful_files = 0
        total_size = sum(f["size_mb"] for f in demo_files)
        
        try:
            # íŒŒì¼ ë°ì´í„° ì¤€ë¹„
            files_data = []
            for file_info in demo_files:
                try:
                    with open(file_info["path"], 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    files_data.append({
                        "filename": Path(file_info["path"]).name,
                        "size_mb": file_info["size_mb"],
                        "content": content.encode('utf-8'),
                        "processed_text": content[:1000] + "..."  # ìš”ì•½ëœ í…ìŠ¤íŠ¸
                    })
                    successful_files += 1
                except Exception as e:
                    errors.append(f"íŒŒì¼ ë¡œë”© ì˜¤ë¥˜: {e}")
            
            # LLM ì²˜ë¦¬
            if self.llm_summarizer:
                result = await self.llm_summarizer.process_large_batch(files_data)
                quality_score = result.get('quality_assessment', {}).get('quality_score', 0)
            else:
                # ëª¨ì˜ ì²˜ë¦¬
                await asyncio.sleep(2.0)  # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
                quality_score = 85.0
            
        except Exception as e:
            errors.append(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            quality_score = 0.0
        
        processing_time = time.time() - start_time
        memory_stats = self.stop_memory_monitoring()
        
        return BenchmarkResult(
            test_name="ê¸°ë³¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸",
            files_count=len(demo_files),
            total_size_mb=total_size,
            processing_time=processing_time,
            memory_peak_mb=memory_stats["peak_mb"],
            memory_avg_mb=memory_stats["avg_mb"],
            throughput_mbps=total_size / processing_time if processing_time > 0 else 0,
            quality_score=quality_score,
            success_rate=successful_files / len(demo_files) if demo_files else 0,
            errors=errors
        )
    
    async def run_streaming_test(self, demo_files: List[Dict]) -> BenchmarkResult:
        """ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\nğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        start_time = time.time()
        self.start_memory_monitoring()
        
        errors = []
        successful_files = 0
        total_size = sum(f["size_mb"] for f in demo_files)
        
        try:
            if self.streaming_engine:
                # ê° íŒŒì¼ì„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                for file_info in demo_files:
                    try:
                        result = await self.streaming_engine.process_large_file(
                            file_info["path"],
                            file_info["type"]
                        )
                        if result.get("success"):
                            successful_files += 1
                    except Exception as e:
                        errors.append(f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            else:
                # ëª¨ì˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                for file_info in demo_files:
                    await asyncio.sleep(0.5)  # íŒŒì¼ë‹¹ ì²˜ë¦¬ ì‹œê°„
                    successful_files += 1
            
        except Exception as e:
            errors.append(f"ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        processing_time = time.time() - start_time
        memory_stats = self.stop_memory_monitoring()
        
        return BenchmarkResult(
            test_name="ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸",
            files_count=len(demo_files),
            total_size_mb=total_size,
            processing_time=processing_time,
            memory_peak_mb=memory_stats["peak_mb"],
            memory_avg_mb=memory_stats["avg_mb"],
            throughput_mbps=total_size / processing_time if processing_time > 0 else 0,
            quality_score=88.5,  # ìŠ¤íŠ¸ë¦¬ë°ì€ ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ í’ˆì§ˆ
            success_rate=successful_files / len(demo_files) if demo_files else 0,
            errors=errors
        )
    
    async def run_scalability_test(self) -> BenchmarkResult:
        """í™•ì¥ì„± í…ŒìŠ¤íŠ¸ (ë‹¤ìˆ˜ íŒŒì¼ ì²˜ë¦¬)"""
        print("\nğŸ“ˆ í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ (50ê°œ íŒŒì¼ ì‹œë®¬ë ˆì´ì…˜)...")
        
        start_time = time.time()
        self.start_memory_monitoring()
        
        errors = []
        files_count = 50
        total_size = 0
        
        try:
            # 50ê°œ íŒŒì¼ ì‹œë®¬ë ˆì´ì…˜
            files_data = []
            for i in range(files_count):
                mock_content = f"""
                íŒŒì¼ {i+1}: ì£¼ì–¼ë¦¬ ì‹œì¥ ë¶„ì„ ë°ì´í„°
                ë‹¤ì´ì•„ëª¬ë“œ ê°€ê²©: ${3000 + i*100}
                í’ˆì§ˆ ë“±ê¸‰: {"VS1" if i % 2 == 0 else "VVS2"}
                ìºëŸ¿: {1.0 + (i % 10) * 0.1:.1f}
                ì¸ì¦: GIA {2140000000 + i}
                """ * 100  # ê° íŒŒì¼ë‹¹ ì•½ 200KB
                
                size_mb = len(mock_content.encode('utf-8')) / (1024 * 1024)
                total_size += size_mb
                
                files_data.append({
                    "filename": f"jewelry_data_{i+1:03d}.txt",
                    "size_mb": size_mb,
                    "content": mock_content.encode('utf-8'),
                    "processed_text": mock_content[:500]
                })
            
            # ë°°ì¹˜ ì²˜ë¦¬ (ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬)
            batch_size = 10
            successful_files = 0
            
            for i in range(0, files_count, batch_size):
                batch = files_data[i:i+batch_size]
                
                if self.llm_summarizer:
                    try:
                        result = await self.llm_summarizer.process_large_batch(batch)
                        if result.get('success'):
                            successful_files += len(batch)
                    except Exception as e:
                        errors.append(f"ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                else:
                    # ëª¨ì˜ ì²˜ë¦¬
                    await asyncio.sleep(1.0)  # ë°°ì¹˜ë‹¹ ì²˜ë¦¬ ì‹œê°„
                    successful_files += len(batch)
            
        except Exception as e:
            errors.append(f"í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        processing_time = time.time() - start_time
        memory_stats = self.stop_memory_monitoring()
        
        return BenchmarkResult(
            test_name="í™•ì¥ì„± í…ŒìŠ¤íŠ¸ (50ê°œ íŒŒì¼)",
            files_count=files_count,
            total_size_mb=total_size,
            processing_time=processing_time,
            memory_peak_mb=memory_stats["peak_mb"],
            memory_avg_mb=memory_stats["avg_mb"],
            throughput_mbps=total_size / processing_time if processing_time > 0 else 0,
            quality_score=82.0,  # ëŒ€ëŸ‰ ì²˜ë¦¬ì‹œ í’ˆì§ˆ ì•½ê°„ ê°ì†Œ
            success_rate=successful_files / files_count,
            errors=errors
        )
    
    async def run_comprehensive_demo(self):
        """ì¢…í•© ë°ëª¨ ì‹¤í–‰"""
        print("ğŸš€ ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ì¢…í•© ë°ëª¨ ì‹œì‘")
        print("=" * 70)
        
        # 1. ë°ëª¨ íŒŒì¼ ìƒì„±
        demo_files = self.create_demo_files()
        
        # 2. ê¸°ë³¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        basic_result = await self.run_basic_processing_test(demo_files)
        self.benchmark_results.append(basic_result)
        
        # 3. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        streaming_result = await self.run_streaming_test(demo_files)
        self.benchmark_results.append(streaming_result)
        
        # 4. í™•ì¥ì„± í…ŒìŠ¤íŠ¸
        scalability_result = await self.run_scalability_test()
        self.benchmark_results.append(scalability_result)
        
        # 5. ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
        self.print_comprehensive_results()
        
        # 6. ì •ë¦¬
        self.cleanup()
    
    def print_comprehensive_results(self):
        """ì¢…í•© ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“Š ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
        print("="*70)
        
        for result in self.benchmark_results:
            print(f"\nğŸ§ª {result.test_name}")
            print("-" * 50)
            print(f"ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼: {result.files_count}ê°œ")
            print(f"ğŸ’¾ ì´ í¬ê¸°: {result.total_size_mb:.1f}MB")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
            print(f"ğŸ§  ë©”ëª¨ë¦¬ í”¼í¬: {result.memory_peak_mb:.1f}MB")
            print(f"ğŸ§  ë©”ëª¨ë¦¬ í‰ê· : {result.memory_avg_mb:.1f}MB")
            print(f"ğŸš€ ì²˜ë¦¬ ì†ë„: {result.throughput_mbps:.2f}MB/s")
            print(f"ğŸ¯ í’ˆì§ˆ ì ìˆ˜: {result.quality_score:.1f}/100")
            print(f"âœ… ì„±ê³µë¥ : {result.success_rate:.1%}")
            
            if result.errors:
                print(f"âŒ ì˜¤ë¥˜ ({len(result.errors)}ê°œ):")
                for error in result.errors[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    print(f"   - {error}")
        
        # ì¢…í•© í‰ê°€
        print(f"\nğŸ† ì¢…í•© í‰ê°€")
        print("-" * 50)
        
        avg_quality = sum(r.quality_score for r in self.benchmark_results) / len(self.benchmark_results)
        avg_speed = sum(r.throughput_mbps for r in self.benchmark_results) / len(self.benchmark_results)
        avg_success = sum(r.success_rate for r in self.benchmark_results) / len(self.benchmark_results)
        peak_memory = max(r.memory_peak_mb for r in self.benchmark_results)
        
        print(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.1f}/100")
        print(f"í‰ê·  ì²˜ë¦¬ ì†ë„: {avg_speed:.2f}MB/s")
        print(f"í‰ê·  ì„±ê³µë¥ : {avg_success:.1%}")
        print(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {peak_memory:.1f}MB")
        
        # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
        performance_grade = self.calculate_performance_grade(avg_quality, avg_speed, avg_success, peak_memory)
        print(f"\nğŸ–ï¸ ì„±ëŠ¥ ë“±ê¸‰: {performance_grade}")
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = self.generate_recommendations(avg_quality, avg_speed, peak_memory)
        print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in recommendations:
            print(f"   - {rec}")
    
    def calculate_performance_grade(self, quality: float, speed: float, success: float, memory: float) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        score = 0
        
        # í’ˆì§ˆ ì ìˆ˜ (40%)
        if quality >= 90:
            score += 40
        elif quality >= 80:
            score += 32
        elif quality >= 70:
            score += 24
        else:
            score += 16
        
        # ì†ë„ ì ìˆ˜ (30%)
        if speed >= 2.0:
            score += 30
        elif speed >= 1.0:
            score += 24
        elif speed >= 0.5:
            score += 18
        else:
            score += 12
        
        # ì„±ê³µë¥  ì ìˆ˜ (20%)
        score += success * 20
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (10%)
        if memory <= 100:
            score += 10
        elif memory <= 200:
            score += 8
        elif memory <= 300:
            score += 6
        else:
            score += 4
        
        if score >= 90:
            return "A+ (ìµœìš°ìˆ˜)"
        elif score >= 80:
            return "A (ìš°ìˆ˜)"
        elif score >= 70:
            return "B+ (ì–‘í˜¸)"
        elif score >= 60:
            return "B (ë³´í†µ)"
        else:
            return "C (ê°œì„  í•„ìš”)"
    
    def generate_recommendations(self, quality: float, speed: float, memory: float) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if quality < 80:
            recommendations.append("GEMMA ëª¨ë¸ ìµœì í™” ë˜ëŠ” ë” í° ëª¨ë¸ ì‚¬ìš© ê²€í† ")
        
        if speed < 1.0:
            recommendations.append("GPU ê°€ì† í™œì„±í™” ë˜ëŠ” ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”")
        
        if memory > 200:
            recommendations.append("ì²­í¬ í¬ê¸° ì¶•ì†Œ ë˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ê°•í™”")
        
        if not recommendations:
            recommendations.append("í˜„ì¬ ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. ì¶”ê°€ ìµœì í™”ëŠ” ì„ íƒì ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”.")
        
        return recommendations
    
    def save_benchmark_results(self):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥"""
        results_file = f"benchmark_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        results_data = {
            "timestamp": datetime.now().isoformat(),
            "system_info": {
                "python_version": "3.11+",
                "modules_available": MODULES_AVAILABLE,
                "cpu_count": psutil.cpu_count(),
                "memory_total_gb": psutil.virtual_memory().total / (1024**3)
            },
            "benchmark_results": [asdict(result) for result in self.benchmark_results]
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥: {results_file}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("\nğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì—”ì§„ ì •ë¦¬
        if self.streaming_engine:
            self.streaming_engine.cleanup()
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
        
        # ë°ëª¨ íŒŒì¼ ì •ë¦¬ (ì„ íƒì )
        # if os.path.exists(self.demo_files_dir):
        #     shutil.rmtree(self.demo_files_dir)
        
        print("âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ’ ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - ê³ ìš©ëŸ‰ ë‹¤ì¤‘ë¶„ì„ ë°ëª¨")
    print("=" * 60)
    print("ğŸ¯ ëª©í‘œ: 5GB íŒŒì¼ 50ê°œ ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ ê²€ì¦")
    print("ğŸ¤– ê¸°ìˆ : GEMMA + Whisper + ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”")
    print("ğŸ“Š ì¸¡ì •: ì†ë„, ë©”ëª¨ë¦¬, í’ˆì§ˆ, ì•ˆì •ì„±")
    print("=" * 60)
    
    demo = AdvancedSystemDemo()
    
    try:
        await demo.run_comprehensive_demo()
        demo.save_benchmark_results()
        
        print("\nğŸ‰ ë°ëª¨ ì™„ë£Œ!")
        print("ğŸ’¡ UIì—ì„œ ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   streamlit run ui/advanced_multimodal_ui.py")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ë°ëª¨ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        logging.exception("ë°ëª¨ ì‹¤í–‰ ì˜¤ë¥˜")
    finally:
        demo.cleanup()

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # ë°ëª¨ ì‹¤í–‰
    asyncio.run(main())
