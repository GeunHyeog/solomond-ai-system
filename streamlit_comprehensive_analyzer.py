#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlit í†µí•© ì¢…í•© ìƒí™© ë¶„ì„ê¸°
"""
import streamlit as st
import os
import time
import json
from pathlib import Path
from datetime import datetime
import tempfile

# ìµœì í™” ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['OMP_NUM_THREADS'] = '4'

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'comprehensive_analysis_complete' not in st.session_state:
        st.session_state.comprehensive_analysis_complete = False
    if 'comprehensive_results' not in st.session_state:
        st.session_state.comprehensive_results = None
    if 'analysis_progress' not in st.session_state:
        st.session_state.analysis_progress = 0

@st.cache_resource
def load_ai_models():
    """AI ëª¨ë¸ ìºì‹œëœ ë¡œë”©"""
    models = {}
    
    try:
        import whisper
        models['whisper'] = whisper.load_model("tiny", device="cpu")
        st.success("âœ… Whisper tiny ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ Whisper ë¡œë”© ì‹¤íŒ¨: {e}")
        models['whisper'] = None
    
    try:
        import easyocr
        models['ocr'] = easyocr.Reader(['ko', 'en'], gpu=False)
        st.success("âœ… EasyOCR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ EasyOCR ë¡œë”© ì‹¤íŒ¨: {e}")
        models['ocr'] = None
    
    return models

def discover_user_files():
    """ì‚¬ìš©ì íŒŒì¼ ë°œê²¬"""
    user_files = Path("user_files")
    all_files = []
    
    if user_files.exists():
        for file_path in user_files.rglob("*"):
            if file_path.is_file() and file_path.name != "README.md":
                try:
                    stat = file_path.stat()
                    file_info = {
                        'path': str(file_path),
                        'name': file_path.name,
                        'size_mb': stat.st_size / 1024 / 1024,
                        'modified_time': datetime.fromtimestamp(stat.st_mtime),
                        'ext': file_path.suffix.lower()
                    }
                    all_files.append(file_info)
                except Exception:
                    continue
    
    # ì‹œê°„ìˆœ ì •ë ¬
    all_files.sort(key=lambda x: x['modified_time'])
    return all_files

def analyze_file_batch(files, models, progress_placeholder):
    """íŒŒì¼ ë°°ì¹˜ ë¶„ì„"""
    results = {
        'audio_results': [],
        'image_results': [],
        'video_results': [],
        'timeline': []
    }
    
    total_files = len(files)
    
    for i, file_info in enumerate(files):
        progress = (i + 1) / total_files
        progress_placeholder.progress(progress, f"ë¶„ì„ ì¤‘: {file_info['name']} ({i+1}/{total_files})")
        
        ext = file_info['ext']
        
        try:
            if ext in ['.m4a', '.wav', '.mp3'] and models['whisper']:
                # ì˜¤ë””ì˜¤ ë¶„ì„ (í¬ê¸° ì œí•œ)
                if file_info['size_mb'] < 20:
                    result = models['whisper'].transcribe(file_info['path'])
                    transcript = result.get('text', '').strip()
                    
                    if transcript:
                        audio_data = {
                            'file': file_info['name'],
                            'transcript': transcript,
                            'timestamp': file_info['modified_time'].isoformat(),
                            'size_mb': file_info['size_mb']
                        }
                        results['audio_results'].append(audio_data)
            
            elif ext in ['.jpg', '.jpeg', '.png'] and models['ocr']:
                # ì´ë¯¸ì§€ ë¶„ì„ (í¬ê¸° ì œí•œ)
                if file_info['size_mb'] < 10:
                    ocr_results = models['ocr'].readtext(file_info['path'])
                    texts = [text for (bbox, text, conf) in ocr_results if conf > 0.5]
                    
                    if texts:
                        combined_text = ' '.join(texts)
                        image_data = {
                            'file': file_info['name'],
                            'extracted_text': combined_text,
                            'timestamp': file_info['modified_time'].isoformat(),
                            'text_blocks': len(texts)
                        }
                        results['image_results'].append(image_data)
            
            elif ext in ['.mov', '.mp4']:
                # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°
                video_data = {
                    'file': file_info['name'],
                    'size_mb': file_info['size_mb'],
                    'timestamp': file_info['modified_time'].isoformat(),
                    'type': 'video_metadata'
                }
                results['video_results'].append(video_data)
            
            # íƒ€ì„ë¼ì¸ì— ì¶”ê°€
            results['timeline'].append({
                'timestamp': file_info['modified_time'].isoformat(),
                'file': file_info['name'],
                'type': ext[1:],
                'processed': True
            })
            
        except Exception as e:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            results['timeline'].append({
                'timestamp': file_info['modified_time'].isoformat(),
                'file': file_info['name'],
                'type': ext[1:],
                'processed': False,
                'error': str(e)[:100]
            })
    
    return results

def generate_comprehensive_story(results):
    """ì¢…í•© ìŠ¤í† ë¦¬ ìƒì„±"""
    story_parts = []
    
    # ì‹œê°„ìˆœ ì •ë ¬
    timeline = sorted(results['timeline'], key=lambda x: x['timestamp'])
    
    for event in timeline:
        if not event['processed']:
            continue
            
        file_name = event['file']
        file_type = event['type']
        
        # ë‚´ìš© ì°¾ê¸°
        content = ""
        if file_type in ['m4a', 'wav', 'mp3']:
            for audio in results['audio_results']:
                if audio['file'] == file_name:
                    content = audio['transcript'][:300]
                    break
        elif file_type in ['jpg', 'jpeg', 'png']:
            for image in results['image_results']:
                if image['file'] == file_name:
                    content = image['extracted_text'][:300]
                    break
        elif file_type in ['mov', 'mp4']:
            for video in results['video_results']:
                if video['file'] == file_name:
                    content = f"ë¹„ë””ì˜¤ íŒŒì¼ ({video['size_mb']:.1f}MB)"
                    break
        
        if content:
            story_parts.append({
                'timestamp': event['timestamp'],
                'file': file_name,
                'type': file_type,
                'content': content
            })
    
    return story_parts

def main():
    """ë©”ì¸ Streamlit ì•±"""
    st.set_page_config(
        page_title="ì†”ë¡œëª¬ë“œ AI - ì¢…í•© ìƒí™© ë¶„ì„",
        page_icon="ğŸ¯",
        layout="wide"
    )
    
    st.title("ğŸ¯ ì†”ë¡œëª¬ë“œ AI - ì¢…í•© ìƒí™© ë¶„ì„")
    st.markdown("**ì‹¤ì œ ìƒí™©ì˜ ëª¨ë“  íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•© ë¶„ì„**")
    
    init_session_state()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ”§ ë¶„ì„ ì„¤ì •")
        
        auto_optimize = st.checkbox("ìë™ ìµœì í™”", value=True, help="íŒŒì¼ í¬ê¸°ì— ë”°ë¥¸ ìë™ ìµœì í™”")
        include_videos = st.checkbox("ë¹„ë””ì˜¤ í¬í•¨", value=True, help="ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° í¬í•¨")
        max_file_size = st.slider("ìµœëŒ€ íŒŒì¼ í¬ê¸° (MB)", 1, 50, 20, help="ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ í¬ê¸°")
    
    # íŒŒì¼ ë°œê²¬
    st.header("ğŸ“ ìƒí™© íŒŒì¼ ë°œê²¬")
    
    if st.button("ğŸ” íŒŒì¼ íƒìƒ‰", type="primary"):
        with st.spinner("íŒŒì¼ íƒìƒ‰ ì¤‘..."):
            files = discover_user_files()
        
        if files:
            st.success(f"âœ… {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
            
            # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜
            audio_files = [f for f in files if f['ext'] in ['.m4a', '.wav', '.mp3']]
            image_files = [f for f in files if f['ext'] in ['.jpg', '.jpeg', '.png']]
            video_files = [f for f in files if f['ext'] in ['.mov', '.mp4']]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸµ ì˜¤ë””ì˜¤", len(audio_files))
            with col2:
                st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€", len(image_files))
            with col3:
                st.metric("ğŸ¬ ë¹„ë””ì˜¤", len(video_files))
            
            # íŒŒì¼ ëª©ë¡ í‘œì‹œ
            with st.expander("ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ëª©ë¡"):
                for file_info in files:
                    st.write(f"- **{file_info['name']}** ({file_info['size_mb']:.1f}MB) - {file_info['modified_time'].strftime('%Y-%m-%d %H:%M')}")
            
            st.session_state.discovered_files = files
        else:
            st.warning("âš ï¸ user_files í´ë”ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì¢…í•© ë¶„ì„ ì‹¤í–‰
    if 'discovered_files' in st.session_state:
        st.header("ğŸ¯ ì¢…í•© ìƒí™© ë¶„ì„")
        
        if st.button("ğŸš€ ì¢…í•© ë¶„ì„ ì‹œì‘", type="primary"):
            with st.spinner("AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
                models = load_ai_models()
            
            if models['whisper'] or models['ocr']:
                st.info("ğŸ“Š íŒŒì¼ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_placeholder = st.empty()
                
                # ë°°ì¹˜ ë¶„ì„
                with st.spinner("ì¢…í•© ë¶„ì„ ì¤‘..."):
                    results = analyze_file_batch(
                        st.session_state.discovered_files, 
                        models, 
                        progress_placeholder
                    )
                
                st.session_state.comprehensive_results = results
                st.session_state.comprehensive_analysis_complete = True
                
                st.success("âœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
                st.rerun()
            else:
                st.error("âŒ AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.comprehensive_analysis_complete and st.session_state.comprehensive_results:
        st.header("ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼")
        
        results = st.session_state.comprehensive_results
        
        # ìš”ì•½ í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„", len(results['audio_results']))
        with col2:
            st.metric("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„", len(results['image_results']))
        with col3:
            st.metric("ğŸ¬ ë¹„ë””ì˜¤ ìˆ˜ì§‘", len(results['video_results']))
        with col4:
            processed_count = sum(1 for item in results['timeline'] if item['processed'])
            st.metric("âœ… ì²˜ë¦¬ ì„±ê³µ", processed_count)
        
        # ì¢…í•© ìŠ¤í† ë¦¬
        st.subheader("ğŸ“– ìƒí™© ì¬êµ¬ì„± ìŠ¤í† ë¦¬")
        
        story_parts = generate_comprehensive_story(results)
        
        if story_parts:
            for i, part in enumerate(story_parts):
                with st.expander(f"{i+1}. {part['file']} ({part['type'].upper()})"):
                    st.write(f"**ì‹œê°„:** {part['timestamp']}")
                    st.write(f"**ë‚´ìš©:** {part['content']}")
        else:
            st.info("ë¶„ì„ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìƒì„¸ ê²°ê³¼
        if results['audio_results']:
            st.subheader("ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ ìƒì„¸")
            for audio in results['audio_results']:
                with st.expander(f"ğŸµ {audio['file']}"):
                    st.write(f"**í¬ê¸°:** {audio['size_mb']:.1f}MB")
                    st.write(f"**ì‹œê°„:** {audio['timestamp']}")
                    st.write(f"**ë‚´ìš©:** {audio['transcript']}")
        
        if results['image_results']:
            st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ìƒì„¸")
            for image in results['image_results']:
                with st.expander(f"ğŸ–¼ï¸ {image['file']}"):
                    st.write(f"**í…ìŠ¤íŠ¸ ë¸”ë¡:** {image['text_blocks']}ê°œ")
                    st.write(f"**ì‹œê°„:** {image['timestamp']}")
                    st.write(f"**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:** {image['extracted_text']}")
        
        # ê²°ê³¼ ì €ì¥
        if st.button("ğŸ’¾ ê²°ê³¼ ì €ì¥"):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"comprehensive_analysis_{timestamp}.json"
            
            save_data = {
                'analysis_time': datetime.now().isoformat(),
                'results': results,
                'story': story_parts
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            st.success(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
    
    # ë„ì›€ë§
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ’¡ ì‚¬ìš© ì•ˆë‚´")
        st.markdown("""
        1. **íŒŒì¼ íƒìƒ‰**: user_files í´ë”ì˜ ëª¨ë“  íŒŒì¼ ë°œê²¬
        2. **ì¢…í•© ë¶„ì„**: ì˜¤ë””ì˜¤, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ í†µí•© ë¶„ì„
        3. **ìƒí™© ì¬êµ¬ì„±**: ì‹œê°„ìˆœìœ¼ë¡œ ìŠ¤í† ë¦¬ ìƒì„±
        4. **ê²°ê³¼ ì €ì¥**: JSON í˜•íƒœë¡œ ê²°ê³¼ ì €ì¥
        """)

if __name__ == "__main__":
    main()