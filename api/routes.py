"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - API ë¼ìš°íŠ¸
FastAPI ê¸°ë°˜ REST API ì—”ë“œí¬ì¸íŠ¸ (Phase 3.3 AI ê³ ë„í™”)
"""

from fastapi import APIRouter, File, UploadFile, HTTPException, Query
from fastapi.responses import JSONResponse
import time
from typing import Optional

# Import ì²˜ë¦¬ (ê°œë°œ í™˜ê²½ í˜¸í™˜)
try:
    # ìƒëŒ€ import ì‹œë„
    from ..core.analyzer import get_analyzer, check_whisper_status, get_language_support
    from ..core.video_processor import get_video_processor, check_video_support
    from ..core.speaker_analyzer import get_speaker_analyzer, check_speaker_analysis_support
except ImportError:
    try:
        # ì ˆëŒ€ import ì‹œë„
        import sys
        from pathlib import Path
        sys.path.append(str(Path(__file__).parent.parent))
        from core.analyzer import get_analyzer, check_whisper_status, get_language_support
        from core.video_processor import get_video_processor, check_video_support
        from core.speaker_analyzer import get_speaker_analyzer, check_speaker_analysis_support
    except ImportError:
        # ìµœí›„ì˜ ìˆ˜ë‹¨: í•¨ìˆ˜ ì •ì˜
        print("âš ï¸ core ëª¨ë“ˆë“¤ì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        def get_analyzer(model_size="base"):
            class DummyAnalyzer:
                def get_model_info(self):
                    return {"model_size": "base", "model_loaded": False, "whisper_available": False, "supported_formats": [".mp3", ".wav", ".m4a"]}
                async def analyze_uploaded_file(self, file_content, filename, language="auto"):
                    return {"success": False, "error": "Analyzer not available"}
            return DummyAnalyzer()
        
        def check_whisper_status():
            return {"whisper_available": False, "import_error": "Module not found"}
        
        def get_language_support():
            return {"supported_languages": {}, "auto_detection": False}
        
        def get_video_processor():
            class DummyVideoProcessor:
                def is_video_file(self, filename):
                    return filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))
                async def extract_audio_from_video(self, video_content, filename):
                    return {"success": False, "error": "Video processor not available"}
                async def get_video_info(self, video_content, filename):
                    return {"error": "Video processor not available"}
            return DummyVideoProcessor()
        
        def check_video_support():
            return {"supported_formats": [".mp4", ".avi", ".mov"], "ffmpeg_available": False}
        
        def get_speaker_analyzer():
            class DummySpeakerAnalyzer:
                async def analyze_uploaded_file(self, file_content, filename, use_advanced=True):
                    return {"success": False, "error": "Speaker analyzer not available"}
                def get_capabilities(self):
                    return {"supported_formats": [".mp3", ".wav"], "pyannote_available": False}
            return DummySpeakerAnalyzer()
        
        def check_speaker_analysis_support():
            return {"pyannote_available": False, "algorithms": {}}

# API ë¼ìš°í„° ìƒì„±
router = APIRouter()

@router.post("/process_audio")
async def process_audio(
    audio_file: UploadFile = File(...),
    language: str = Query("auto", description="ì–¸ì–´ ì½”ë“œ (auto, ko, en, zh, ja ë“±)")
):
    """
    ìŒì„± íŒŒì¼ ì²˜ë¦¬ API (ë‹¤êµ­ì–´ ì§€ì›)
    
    ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ì„ STT ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    Args:
        audio_file: ì—…ë¡œë“œí•  ìŒì„± íŒŒì¼
        language: ì¸ì‹í•  ì–¸ì–´ (auto=ìë™ê°ì§€, ko=í•œêµ­ì–´, en=ì˜ì–´, zh=ì¤‘êµ­ì–´, ja=ì¼ë³¸ì–´ ë“±)
    """
    start_time = time.time()
    
    try:
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        filename = audio_file.filename
        file_content = await audio_file.read()
        file_size_mb = round(len(file_content) / (1024 * 1024), 2)
        
        print(f"ğŸ“ íŒŒì¼ ìˆ˜ì‹ : {filename} ({file_size_mb} MB), ì–¸ì–´: {language}")
        
        # Whisper ìƒíƒœ í™•ì¸
        whisper_status = check_whisper_status()
        if not whisper_status["whisper_available"]:
            return JSONResponse({
                "success": False,
                "error": "Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai-whisper' ì‹¤í–‰í•˜ì„¸ìš”."
            })
        
        # ë¶„ì„ê¸° ê°€ì ¸ì˜¤ê¸°
        analyzer = get_analyzer("base")
        
        # ğŸ†• ë‹¤êµ­ì–´ ìŒì„± ë¶„ì„ ì‹¤í–‰
        result = await analyzer.analyze_uploaded_file(
            file_content=file_content,
            filename=filename,
            language=language
        )
        
        # ì‘ë‹µ í˜•ì‹ (ë‹¤êµ­ì–´ ì •ë³´ í¬í•¨)
        if result["success"]:
            return JSONResponse({
                "success": True,
                "filename": result["filename"],
                "file_size": result["file_size"],
                "transcribed_text": result["transcribed_text"],
                "processing_time": result["processing_time"],
                "detected_language": result["detected_language"],
                "language_info": result.get("language_info", {}),
                "requested_language": result.get("requested_language", language),
                "confidence": result.get("confidence", 0.0)
            })
        else:
            return JSONResponse({
                "success": False,
                "error": result["error"],
                "processing_time": result.get("processing_time", round(time.time() - start_time, 2)),
                "requested_language": language
            })
            
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        error_msg = str(e)
        
        print(f"âŒ API ì˜¤ë¥˜: {error_msg}")
        
        return JSONResponse({
            "success": False,
            "error": error_msg,
            "processing_time": processing_time,
            "requested_language": language
        })

@router.post("/analyze_speakers")
async def analyze_speakers(
    audio_file: UploadFile = File(...),
    use_advanced: bool = Query(True, description="ê³ ê¸‰ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€ (PyAnnote AI)")
):
    """
    ğŸ­ í™”ì êµ¬ë¶„ ë¶„ì„ API (Phase 3.3 ì‹ ê·œ)
    
    ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ì—ì„œ ì—¬ëŸ¬ í™”ìë¥¼ êµ¬ë¶„í•˜ê³  ë°œì–¸ ì‹œê°„ì„ ë¶„ì„
    
    Args:
        audio_file: ì—…ë¡œë“œí•  ìŒì„± íŒŒì¼
        use_advanced: ê³ ê¸‰ AI ë¶„ì„ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    start_time = time.time()
    
    try:
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        filename = audio_file.filename
        file_content = await audio_file.read()
        file_size_mb = round(len(file_content) / (1024 * 1024), 2)
        
        print(f"ğŸ­ í™”ì êµ¬ë¶„ íŒŒì¼ ìˆ˜ì‹ : {filename} ({file_size_mb} MB)")
        
        # í™”ì ë¶„ì„ê¸° ê°€ì ¸ì˜¤ê¸°
        speaker_analyzer = get_speaker_analyzer()
        
        # í™”ì êµ¬ë¶„ ë¶„ì„ ì‹¤í–‰
        result = await speaker_analyzer.analyze_uploaded_file(
            file_content=file_content,
            filename=filename,
            use_advanced=use_advanced
        )
        
        # ì‘ë‹µ í˜•ì‹
        if result["success"]:
            return JSONResponse({
                "success": True,
                "filename": result["filename"],
                "file_size": result["file_size"],
                "processing_time": result["processing_time"],
                "analysis_method": result["method"],
                "total_duration": result["total_duration"],
                "num_speakers": result["num_speakers"],
                "segments": result["segments"],
                "speaker_statistics": result["speaker_statistics"],
                "analysis_info": result.get("analysis_info", {}),
                "feature_type": "speaker_diarization"
            })
        else:
            return JSONResponse({
                "success": False,
                "error": result["error"],
                "processing_time": result.get("processing_time", round(time.time() - start_time, 2)),
                "fallback_available": result.get("fallback") is not None,
                "feature_type": "speaker_diarization"
            })
            
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        error_msg = str(e)
        
        print(f"âŒ í™”ì êµ¬ë¶„ API ì˜¤ë¥˜: {error_msg}")
        
        return JSONResponse({
            "success": False,
            "error": error_msg,
            "processing_time": processing_time,
            "feature_type": "speaker_diarization"
        })

@router.get("/speaker_support")
async def get_speaker_support_info():
    """
    ğŸ­ í™”ì êµ¬ë¶„ ì§€ì› ì •ë³´ API (Phase 3.3 ì‹ ê·œ)
    
    ì‹œìŠ¤í…œì˜ í™”ì êµ¬ë¶„ ê¸°ëŠ¥ ì§€ì› ìƒíƒœë¥¼ í™•ì¸
    """
    try:
        support_info = check_speaker_analysis_support()
        speaker_analyzer = get_speaker_analyzer()
        capabilities = speaker_analyzer.get_capabilities()
        
        return JSONResponse({
            "success": True,
            "speaker_diarization": {
                "supported_formats": capabilities["supported_formats"],
                "pyannote_available": capabilities["pyannote_available"],
                "max_speakers": capabilities["max_speakers"],
                "min_segment_duration": capabilities["min_segment_duration"],
                "algorithms": capabilities["algorithms"]
            },
            "recommendations": {
                "pyannote_installation": not capabilities["pyannote_available"],
                "install_guide": {
                    "command": "pip install pyannote.audio torch",
                    "note": "ê³ ê¸‰ AI ê¸°ë°˜ í™”ì êµ¬ë¶„ì„ ìœ„í•´ ê¶Œì¥"
                } if not capabilities["pyannote_available"] else None
            },
            "phase": capabilities["phase"]
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@router.post("/process_video")
async def process_video(
    video_file: UploadFile = File(...),
    language: str = Query("auto", description="ì–¸ì–´ ì½”ë“œ (auto, ko, en, zh, ja ë“±)")
):
    """
    ğŸ¥ ë™ì˜ìƒ íŒŒì¼ ì²˜ë¦¬ API (ë‹¤êµ­ì–´ ì§€ì›)
    
    ì—…ë¡œë“œëœ ë™ì˜ìƒ íŒŒì¼ì—ì„œ ìŒì„±ì„ ì¶”ì¶œí•˜ê³  STT ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    Args:
        video_file: ì—…ë¡œë“œí•  ë™ì˜ìƒ íŒŒì¼
        language: ì¸ì‹í•  ì–¸ì–´ (auto=ìë™ê°ì§€, ko=í•œêµ­ì–´, en=ì˜ì–´, zh=ì¤‘êµ­ì–´, ja=ì¼ë³¸ì–´ ë“±)
    """
    start_time = time.time()
    
    try:
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        filename = video_file.filename
        file_content = await video_file.read()
        file_size_mb = round(len(file_content) / (1024 * 1024), 2)
        
        print(f"ğŸ¬ ë™ì˜ìƒ íŒŒì¼ ìˆ˜ì‹ : {filename} ({file_size_mb} MB), ì–¸ì–´: {language}")
        
        # ë™ì˜ìƒ í”„ë¡œì„¸ì„œ ê°€ì ¸ì˜¤ê¸°
        video_processor = get_video_processor()
        
        # ë™ì˜ìƒ íŒŒì¼ í˜•ì‹ í™•ì¸
        if not video_processor.is_video_file(filename):
            return JSONResponse({
                "success": False,
                "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë™ì˜ìƒ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {check_video_support()['supported_formats']}"
            })
        
        # ë™ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ
        extraction_result = await video_processor.extract_audio_from_video(
            video_content=file_content,
            original_filename=filename
        )
        
        if not extraction_result["success"]:
            return JSONResponse({
                "success": False,
                "error": f"ìŒì„± ì¶”ì¶œ ì‹¤íŒ¨: {extraction_result['error']}",
                "processing_time": round(time.time() - start_time, 2),
                "install_guide": extraction_result.get("install_guide"),
                "requested_language": language
            })
        
        # Whisper ìƒíƒœ í™•ì¸
        whisper_status = check_whisper_status()
        if not whisper_status["whisper_available"]:
            return JSONResponse({
                "success": False,
                "error": "Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai-whisper' ì‹¤í–‰í•˜ì„¸ìš”."
            })
        
        # ğŸ†• ì¶”ì¶œëœ ìŒì„±ì„ ë‹¤êµ­ì–´ STT ë¶„ì„
        analyzer = get_analyzer("base")
        stt_result = await analyzer.analyze_uploaded_file(
            file_content=extraction_result["audio_content"],
            filename=extraction_result["extracted_filename"],
            language=language
        )
        
        # ê²°ê³¼ í†µí•©
        if stt_result["success"]:
            return JSONResponse({
                "success": True,
                "original_filename": filename,
                "original_file_size": file_size_mb,
                "extracted_audio_filename": extraction_result["extracted_filename"],
                "transcribed_text": stt_result["transcribed_text"],
                "processing_time": round(time.time() - start_time, 2),
                "detected_language": stt_result["detected_language"],
                "language_info": stt_result.get("language_info", {}),
                "requested_language": language,
                "confidence": stt_result.get("confidence", 0.0),
                "extraction_method": extraction_result["extraction_method"],
                "file_type": "video"
            })
        else:
            return JSONResponse({
                "success": False,
                "error": f"STT ë¶„ì„ ì‹¤íŒ¨: {stt_result['error']}",
                "processing_time": round(time.time() - start_time, 2),
                "extraction_success": True,
                "extraction_method": extraction_result["extraction_method"],
                "requested_language": language
            })
            
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        error_msg = str(e)
        
        print(f"âŒ ë™ì˜ìƒ ì²˜ë¦¬ API ì˜¤ë¥˜: {error_msg}")
        
        return JSONResponse({
            "success": False,
            "error": error_msg,
            "processing_time": processing_time,
            "file_type": "video",
            "requested_language": language
        })

@router.get("/language_support")
async def get_language_support_info():
    """
    ğŸŒ ì–¸ì–´ ì§€ì› ì •ë³´ API (Phase 3.2)
    
    ì‹œìŠ¤í…œì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ê³¼ ê¸°ëŠ¥ì„ í™•ì¸
    """
    try:
        language_info = get_language_support()
        analyzer = get_analyzer()
        
        return JSONResponse({
            "success": True,
            "supported_languages": language_info["supported_languages"],
            "auto_detection": language_info["auto_detection"],
            "default_language": language_info["default_language"],
            "total_languages": len(language_info["supported_languages"]),
            "phase": language_info["phase"],
            "features": {
                "auto_language_detection": True,
                "confidence_scoring": True,
                "multi_language_batch": True,
                "real_time_detection": True
            }
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@router.post("/detect_language")
async def detect_language(audio_file: UploadFile = File(...)):
    """
    ğŸ” ì–¸ì–´ ê°ì§€ ì „ìš© API (Phase 3.2)
    
    ìŒì„± íŒŒì¼ì˜ ì–¸ì–´ë§Œ ê°ì§€í•˜ê³  STTëŠ” ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
    """
    try:
        filename = audio_file.filename
        file_content = await audio_file.read()
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±í•˜ì—¬ ì–¸ì–´ ê°ì§€
        import tempfile
        import os
        
        file_ext = filename.split('.')[-1] if '.' in filename else 'tmp'
        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_ext}') as temp_file:
            temp_file.write(file_content)
            temp_path = temp_file.name
        
        try:
            analyzer = get_analyzer()
            detection_result = analyzer.detect_language(temp_path)
            
            return JSONResponse({
                "success": detection_result["success"],
                "filename": filename,
                "detected_language": detection_result.get("detected_language"),
                "confidence": detection_result.get("confidence", 0.0),
                "language_info": detection_result.get("language_info", {}),
                "all_probabilities": detection_result.get("all_probabilities", {}),
                "error": detection_result.get("error")
            })
            
        finally:
            try:
                os.unlink(temp_path)
            except:
                pass
                
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@router.post("/video_info")
async def get_video_info(video_file: UploadFile = File(...)):
    """
    ğŸ¬ ë™ì˜ìƒ íŒŒì¼ ì •ë³´ ë¶„ì„ API
    
    ë™ì˜ìƒ íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°ì™€ í˜¸í™˜ì„±ì„ í™•ì¸
    """
    try:
        filename = video_file.filename
        file_content = await video_file.read()
        
        video_processor = get_video_processor()
        info = await video_processor.get_video_info(file_content, filename)
        
        return JSONResponse({
            "success": True,
            "video_info": info
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@router.get("/video_support")
async def check_video_support_status():
    """
    ğŸ”§ ë™ì˜ìƒ ì§€ì› ìƒíƒœ í™•ì¸ API
    
    ì‹œìŠ¤í…œì˜ ë™ì˜ìƒ ì²˜ë¦¬ ì§€ì› ìƒíƒœë¥¼ í™•ì¸
    """
    support_info = check_video_support()
    video_processor = get_video_processor()
    
    return JSONResponse({
        "video_support": {
            "supported_formats": support_info["supported_formats"],
            "ffmpeg_available": support_info["ffmpeg_available"],
            "python_version": support_info.get("python_version", "3.13+"),
            "status": "available" if support_info["ffmpeg_available"] else "ffmpeg_required"
        },
        "recommendations": {
            "ffmpeg_required": not support_info["ffmpeg_available"],
            "install_guide": {
                "windows": "https://ffmpeg.org/download.htmlì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ PATH ì„¤ì •",
                "mac": "brew install ffmpeg",
                "ubuntu": "sudo apt update && sudo apt install ffmpeg"
            } if not support_info["ffmpeg_available"] else None
        }
    })

@router.get("/test")
async def system_test():
    """
    ì‹œìŠ¤í…œ ìƒíƒœ í…ŒìŠ¤íŠ¸ API (Phase 3.3 ì—…ë°ì´íŠ¸)
    
    ì‹œìŠ¤í…œì˜ í˜„ì¬ ìƒíƒœì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤ì„ í™•ì¸
    """
    whisper_status = check_whisper_status()
    analyzer = get_analyzer()
    model_info = analyzer.get_model_info()
    video_support = check_video_support()
    language_support = get_language_support()
    speaker_support = check_speaker_analysis_support()
    
    return JSONResponse({
        "status": "OK",
        "version": "3.3",
        "python_version": "3.13+",
        "whisper_available": whisper_status["whisper_available"],
        "model_info": model_info,
        "supported_formats": {
            "audio": model_info["supported_formats"],
            "video": video_support["supported_formats"]
        },
        "language_support": {
            "total_languages": len(language_support["supported_languages"]),
            "auto_detection": language_support["auto_detection"],
            "supported_languages": list(language_support["supported_languages"].keys())
        },
        "ai_features": {
            "speaker_diarization": speaker_support.get("pyannote_available", False),
            "advanced_algorithms": len(speaker_support.get("algorithms", {}))
        },
        "features": {
            "stt": whisper_status["whisper_available"],
            "translation": True,
            "file_upload": True,
            "modular_architecture": True,
            "video_processing": video_support["ffmpeg_available"],
            "batch_processing": True,
            "multilingual_support": True,
            "auto_language_detection": True,
            "confidence_scoring": True,
            "speaker_diarization": True,  # ğŸ†• í™”ì êµ¬ë¶„
            "ai_enhancement": True  # ğŸ†• AI ê³ ë„í™”
        },
        "phase_status": {
            "phase_3_1": "completed - ë™ì˜ìƒ ì§€ì›",
            "phase_3_2": "completed - ë‹¤êµ­ì–´ í™•ì¥",
            "phase_3_3": "in_progress - AI ê³ ë„í™”",
            "current_milestone": "í™”ì êµ¬ë¶„ ê¸°ëŠ¥ ê°œë°œ",
            "next_goals": ["ê°ì • ë¶„ì„", "ìë™ ìš”ì•½", "ì£¼ì–¼ë¦¬ íŠ¹í™”"]
        }
    })

@router.get("/health")
async def health_check():
    """
    í—¬ìŠ¤ ì²´í¬ API
    
    ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
    """
    return {"status": "healthy", "timestamp": time.time(), "phase": "3.3"}

@router.post("/analyze_batch")
async def analyze_batch_files(
    files: list[UploadFile] = File(...),
    language: str = Query("auto", description="ì–¸ì–´ ì½”ë“œ (auto, ko, en, zh, ja ë“±)")
):
    """
    ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ ë¶„ì„ API (ë‹¤êµ­ì–´ ì§€ì›)
    
    ì—¬ëŸ¬ ìŒì„±/ë™ì˜ìƒ íŒŒì¼ì„ í•œ ë²ˆì— ì²˜ë¦¬
    
    Args:
        files: ì—…ë¡œë“œí•  íŒŒì¼ë“¤
        language: ì¸ì‹í•  ì–¸ì–´ (auto=ìë™ê°ì§€, ko=í•œêµ­ì–´, en=ì˜ì–´ ë“±)
    """
    results = []
    analyzer = get_analyzer()
    video_processor = get_video_processor()
    
    for file in files:
        try:
            file_content = await file.read()
            
            # ë™ì˜ìƒ íŒŒì¼ì¸ì§€ í™•ì¸
            if video_processor.is_video_file(file.filename):
                # ë™ì˜ìƒ ì²˜ë¦¬
                extraction_result = await video_processor.extract_audio_from_video(
                    video_content=file_content,
                    original_filename=file.filename
                )
                
                if extraction_result["success"]:
                    # ì¶”ì¶œëœ ìŒì„±ìœ¼ë¡œ ë‹¤êµ­ì–´ STT ì‹¤í–‰
                    result = await analyzer.analyze_uploaded_file(
                        file_content=extraction_result["audio_content"],
                        filename=extraction_result["extracted_filename"],
                        language=language
                    )
                    result["file_type"] = "video"
                    result["extraction_method"] = extraction_result["extraction_method"]
                else:
                    result = extraction_result
                    result["file_type"] = "video"
            else:
                # ì¼ë°˜ ìŒì„± íŒŒì¼ ì²˜ë¦¬ (ë‹¤êµ­ì–´ ì§€ì›)
                result = await analyzer.analyze_uploaded_file(
                    file_content=file_content,
                    filename=file.filename,
                    language=language
                )
                result["file_type"] = "audio"
            
            # ìš”ì²­ëœ ì–¸ì–´ ì •ë³´ ì¶”ê°€
            result["requested_language"] = language
            
            results.append({
                "filename": file.filename,
                "result": result
            })
            
        except Exception as e:
            results.append({
                "filename": file.filename,
                "result": {
                    "success": False,
                    "error": str(e),
                    "file_type": "unknown",
                    "requested_language": language
                }
            })
    
    successful_count = sum(1 for r in results if r["result"]["success"])
    
    # ì–¸ì–´ë³„ í†µê³„
    language_stats = {}
    for r in results:
        if r["result"]["success"]:
            detected_lang = r["result"].get("detected_language", "unknown")
            language_stats[detected_lang] = language_stats.get(detected_lang, 0) + 1
    
    return JSONResponse({
        "batch_success": True,
        "total_files": len(files),
        "successful_files": successful_count,
        "failed_files": len(files) - successful_count,
        "requested_language": language,
        "language_statistics": language_stats,
        "results": results
    })

@router.get("/models")
async def list_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ Whisper ëª¨ë¸ ëª©ë¡ API
    """
    models = [
        {"name": "tiny", "size": "~39 MB", "speed": "ë§¤ìš° ë¹ ë¦„", "accuracy": "ë‚®ìŒ", "languages": "99ê°œ ì–¸ì–´"},
        {"name": "base", "size": "~74 MB", "speed": "ë¹ ë¦„", "accuracy": "ì¤‘ê°„", "languages": "99ê°œ ì–¸ì–´"},
        {"name": "small", "size": "~244 MB", "speed": "ë³´í†µ", "accuracy": "ì¢‹ìŒ", "languages": "99ê°œ ì–¸ì–´"},
        {"name": "medium", "size": "~769 MB", "speed": "ëŠë¦¼", "accuracy": "ë§¤ìš° ì¢‹ìŒ", "languages": "99ê°œ ì–¸ì–´"},
        {"name": "large", "size": "~1550 MB", "speed": "ë§¤ìš° ëŠë¦¼", "accuracy": "ìµœê³ ", "languages": "99ê°œ ì–¸ì–´"}
    ]
    
    return JSONResponse({
        "available_models": models,
        "current_model": get_analyzer().get_model_info().get("model_size", "base"),
        "recommendation": "base ëª¨ë¸ì´ ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•ì´ ì¢‹ìŠµë‹ˆë‹¤.",
        "multilingual_support": "ëª¨ë“  ëª¨ë¸ì´ 99ê°œ ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
        "auto_detection": "ì–¸ì–´ ìë™ ê°ì§€ ê¸°ëŠ¥ í¬í•¨"
    })

# ì˜¤ë¥˜ ì²˜ë¦¬ëŠ” FastAPI ì•± ë ˆë²¨ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ë³€ê²½
# (APIRouterì—ì„œëŠ” exception_handler ì‚¬ìš© ë¶ˆê°€)
