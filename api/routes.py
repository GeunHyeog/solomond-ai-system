"""
ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ - API ë¼ìš°íŠ¸
FastAPI ê¸°ë°˜ REST API ì—”ë“œí¬ì¸íŠ¸
"""

from fastapi import APIRouter, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
import time
from typing import Optional

# Import ì²˜ë¦¬ (ê°œë°œ í™˜ê²½ í˜¸í™˜)
try:
    # ìƒëŒ€ import ì‹œë„
    from ..core.analyzer import get_analyzer, check_whisper_status
    from ..core.video_processor import get_video_processor, check_video_support
except ImportError:
    try:
        # ì ˆëŒ€ import ì‹œë„
        import sys
        from pathlib import Path
        sys.path.append(str(Path(__file__).parent.parent))
        from core.analyzer import get_analyzer, check_whisper_status
        from core.video_processor import get_video_processor, check_video_support
    except ImportError:
        # ìµœí›„ì˜ ìˆ˜ë‹¨: í•¨ìˆ˜ ì •ì˜
        print("âš ï¸ core ëª¨ë“ˆë“¤ì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        def get_analyzer(model_size="base"):
            class DummyAnalyzer:
                def get_model_info(self):
                    return {"model_size": "base", "model_loaded": False, "whisper_available": False, "supported_formats": [".mp3", ".wav", ".m4a"]}
                async def analyze_uploaded_file(self, file_content, filename, language="ko"):
                    return {"success": False, "error": "Analyzer not available"}
            return DummyAnalyzer()
        
        def check_whisper_status():
            return {"whisper_available": False, "import_error": "Module not found"}
        
        def get_video_processor():
            class DummyVideoProcessor:
                def is_video_file(self, filename):
                    return filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))
                async def extract_audio_from_video(self, video_content, filename):
                    return {"success": False, "error": "Video processor not available"}
                async def get_video_info(self, video_content, filename):
                    return {"error": "Video processor not available"}
            return DummyVideoProcessor()
        
        def check_video_support():
            return {"supported_formats": [".mp4", ".avi", ".mov"], "ffmpeg_available": False}

# API ë¼ìš°í„° ìƒì„±
router = APIRouter()

@router.post("/process_audio")
async def process_audio(audio_file: UploadFile = File(...)):
    """
    ìŒì„± íŒŒì¼ ì²˜ë¦¬ API
    
    ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ì„ STT ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    start_time = time.time()
    
    try:
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        filename = audio_file.filename
        file_content = await audio_file.read()
        file_size_mb = round(len(file_content) / (1024 * 1024), 2)
        
        print(f"ğŸ“ íŒŒì¼ ìˆ˜ì‹ : {filename} ({file_size_mb} MB)")
        
        # Whisper ìƒíƒœ í™•ì¸
        whisper_status = check_whisper_status()
        if not whisper_status["whisper_available"]:
            return JSONResponse({
                "success": False,
                "error": "Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai-whisper' ì‹¤í–‰í•˜ì„¸ìš”."
            })
        
        # ë¶„ì„ê¸° ê°€ì ¸ì˜¤ê¸°
        analyzer = get_analyzer("base")
        
        # ìŒì„± ë¶„ì„ ì‹¤í–‰
        result = await analyzer.analyze_uploaded_file(
            file_content=file_content,
            filename=filename,
            language="ko"
        )
        
        # ì‘ë‹µ í˜•ì‹ì„ ê¸°ì¡´ minimal_stt_test.pyì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤
        if result["success"]:
            return JSONResponse({
                "success": True,
                "filename": result["filename"],
                "file_size": result["file_size"],
                "transcribed_text": result["transcribed_text"],
                "processing_time": result["processing_time"],
                "detected_language": result["detected_language"]
            })
        else:
            return JSONResponse({
                "success": False,
                "error": result["error"],
                "processing_time": result.get("processing_time", round(time.time() - start_time, 2))
            })
            
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        error_msg = str(e)
        
        print(f"âŒ API ì˜¤ë¥˜: {error_msg}")
        
        return JSONResponse({
            "success": False,
            "error": error_msg,
            "processing_time": processing_time
        })

@router.post("/process_video")
async def process_video(video_file: UploadFile = File(...)):
    """
    ğŸ¥ ë™ì˜ìƒ íŒŒì¼ ì²˜ë¦¬ API (Phase 3 ì‹ ê·œ ê¸°ëŠ¥)
    
    ì—…ë¡œë“œëœ ë™ì˜ìƒ íŒŒì¼ì—ì„œ ìŒì„±ì„ ì¶”ì¶œí•˜ê³  STT ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    start_time = time.time()
    
    try:
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        filename = video_file.filename
        file_content = await video_file.read()
        file_size_mb = round(len(file_content) / (1024 * 1024), 2)
        
        print(f"ğŸ¬ ë™ì˜ìƒ íŒŒì¼ ìˆ˜ì‹ : {filename} ({file_size_mb} MB)")
        
        # ë™ì˜ìƒ í”„ë¡œì„¸ì„œ ê°€ì ¸ì˜¤ê¸°
        video_processor = get_video_processor()
        
        # ë™ì˜ìƒ íŒŒì¼ í˜•ì‹ í™•ì¸
        if not video_processor.is_video_file(filename):
            return JSONResponse({
                "success": False,
                "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë™ì˜ìƒ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {check_video_support()['supported_formats']}"
            })
        
        # ë™ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ
        extraction_result = await video_processor.extract_audio_from_video(
            video_content=file_content,
            original_filename=filename
        )
        
        if not extraction_result["success"]:
            return JSONResponse({
                "success": False,
                "error": f"ìŒì„± ì¶”ì¶œ ì‹¤íŒ¨: {extraction_result['error']}",
                "processing_time": round(time.time() - start_time, 2),
                "install_guide": extraction_result.get("install_guide")
            })
        
        # Whisper ìƒíƒœ í™•ì¸
        whisper_status = check_whisper_status()
        if not whisper_status["whisper_available"]:
            return JSONResponse({
                "success": False,
                "error": "Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai-whisper' ì‹¤í–‰í•˜ì„¸ìš”."
            })
        
        # ì¶”ì¶œëœ ìŒì„±ì„ STT ë¶„ì„
        analyzer = get_analyzer("base")
        stt_result = await analyzer.analyze_uploaded_file(
            file_content=extraction_result["audio_content"],
            filename=extraction_result["extracted_filename"],
            language="ko"
        )
        
        # ê²°ê³¼ í†µí•©
        if stt_result["success"]:
            return JSONResponse({
                "success": True,
                "original_filename": filename,
                "original_file_size": file_size_mb,
                "extracted_audio_filename": extraction_result["extracted_filename"],
                "transcribed_text": stt_result["transcribed_text"],
                "processing_time": round(time.time() - start_time, 2),
                "detected_language": stt_result["detected_language"],
                "extraction_method": extraction_result["extraction_method"],
                "file_type": "video"
            })
        else:
            return JSONResponse({
                "success": False,
                "error": f"STT ë¶„ì„ ì‹¤íŒ¨: {stt_result['error']}",
                "processing_time": round(time.time() - start_time, 2),
                "extraction_success": True,
                "extraction_method": extraction_result["extraction_method"]
            })
            
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        error_msg = str(e)
        
        print(f"âŒ ë™ì˜ìƒ ì²˜ë¦¬ API ì˜¤ë¥˜: {error_msg}")
        
        return JSONResponse({
            "success": False,
            "error": error_msg,
            "processing_time": processing_time,
            "file_type": "video"
        })

@router.post("/video_info")
async def get_video_info(video_file: UploadFile = File(...)):
    """
    ğŸ¬ ë™ì˜ìƒ íŒŒì¼ ì •ë³´ ë¶„ì„ API
    
    ë™ì˜ìƒ íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°ì™€ í˜¸í™˜ì„±ì„ í™•ì¸
    """
    try:
        filename = video_file.filename
        file_content = await video_file.read()
        
        video_processor = get_video_processor()
        info = await video_processor.get_video_info(file_content, filename)
        
        return JSONResponse({
            "success": True,
            "video_info": info
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@router.get("/video_support")
async def check_video_support_status():
    """
    ğŸ”§ ë™ì˜ìƒ ì§€ì› ìƒíƒœ í™•ì¸ API
    
    ì‹œìŠ¤í…œì˜ ë™ì˜ìƒ ì²˜ë¦¬ ì§€ì› ìƒíƒœë¥¼ í™•ì¸
    """
    support_info = check_video_support()
    video_processor = get_video_processor()
    
    return JSONResponse({
        "video_support": {
            "supported_formats": support_info["supported_formats"],
            "ffmpeg_available": support_info["ffmpeg_available"],
            "python_version": support_info.get("python_version", "3.13+"),
            "status": "available" if support_info["ffmpeg_available"] else "ffmpeg_required"
        },
        "recommendations": {
            "ffmpeg_required": not support_info["ffmpeg_available"],
            "install_guide": {
                "windows": "https://ffmpeg.org/download.htmlì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ PATH ì„¤ì •",
                "mac": "brew install ffmpeg",
                "ubuntu": "sudo apt update && sudo apt install ffmpeg"
            } if not support_info["ffmpeg_available"] else None
        }
    })

@router.get("/test")
async def system_test():
    """
    ì‹œìŠ¤í…œ ìƒíƒœ í…ŒìŠ¤íŠ¸ API
    
    ì‹œìŠ¤í…œì˜ í˜„ì¬ ìƒíƒœì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤ì„ í™•ì¸
    """
    whisper_status = check_whisper_status()
    analyzer = get_analyzer()
    model_info = analyzer.get_model_info()
    video_support = check_video_support()
    
    return JSONResponse({
        "status": "OK",
        "version": "3.0",
        "python_version": "3.13+",
        "whisper_available": whisper_status["whisper_available"],
        "model_info": model_info,
        "supported_formats": {
            "audio": model_info["supported_formats"],
            "video": video_support["supported_formats"]
        },
        "features": {
            "stt": whisper_status["whisper_available"],
            "translation": True,
            "file_upload": True,
            "modular_architecture": True,
            "video_processing": video_support["ffmpeg_available"],  # ğŸ†• ë™ì˜ìƒ ì§€ì› ìƒíƒœ
            "batch_processing": True
        },
        "phase_3_status": {
            "video_support": "completed",
            "next_goals": ["multi_language", "ai_enhancement", "cloud_deployment"]
        }
    })

@router.get("/health")
async def health_check():
    """
    í—¬ìŠ¤ ì²´í¬ API
    
    ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
    """
    return {"status": "healthy", "timestamp": time.time()}

@router.post("/analyze_batch")
async def analyze_batch_files(
    files: list[UploadFile] = File(...),
    language: Optional[str] = "ko"
):
    """
    ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ ë¶„ì„ API (í™•ì¥ ê¸°ëŠ¥)
    
    ì—¬ëŸ¬ ìŒì„±/ë™ì˜ìƒ íŒŒì¼ì„ í•œ ë²ˆì— ì²˜ë¦¬
    """
    results = []
    analyzer = get_analyzer()
    video_processor = get_video_processor()
    
    for file in files:
        try:
            file_content = await file.read()
            
            # ë™ì˜ìƒ íŒŒì¼ì¸ì§€ í™•ì¸
            if video_processor.is_video_file(file.filename):
                # ë™ì˜ìƒ ì²˜ë¦¬
                extraction_result = await video_processor.extract_audio_from_video(
                    video_content=file_content,
                    original_filename=file.filename
                )
                
                if extraction_result["success"]:
                    # ì¶”ì¶œëœ ìŒì„±ìœ¼ë¡œ STT ì‹¤í–‰
                    result = await analyzer.analyze_uploaded_file(
                        file_content=extraction_result["audio_content"],
                        filename=extraction_result["extracted_filename"],
                        language=language
                    )
                    result["file_type"] = "video"
                    result["extraction_method"] = extraction_result["extraction_method"]
                else:
                    result = extraction_result
                    result["file_type"] = "video"
            else:
                # ì¼ë°˜ ìŒì„± íŒŒì¼ ì²˜ë¦¬
                result = await analyzer.analyze_uploaded_file(
                    file_content=file_content,
                    filename=file.filename,
                    language=language
                )
                result["file_type"] = "audio"
            
            results.append({
                "filename": file.filename,
                "result": result
            })
            
        except Exception as e:
            results.append({
                "filename": file.filename,
                "result": {
                    "success": False,
                    "error": str(e),
                    "file_type": "unknown"
                }
            })
    
    successful_count = sum(1 for r in results if r["result"]["success"])
    
    return JSONResponse({
        "batch_success": True,
        "total_files": len(files),
        "successful_files": successful_count,
        "failed_files": len(files) - successful_count,
        "results": results
    })

@router.get("/models")
async def list_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ Whisper ëª¨ë¸ ëª©ë¡ API
    """
    models = [
        {"name": "tiny", "size": "~39 MB", "speed": "ë§¤ìš° ë¹ ë¦„", "accuracy": "ë‚®ìŒ"},
        {"name": "base", "size": "~74 MB", "speed": "ë¹ ë¦„", "accuracy": "ì¤‘ê°„"},
        {"name": "small", "size": "~244 MB", "speed": "ë³´í†µ", "accuracy": "ì¢‹ìŒ"},
        {"name": "medium", "size": "~769 MB", "speed": "ëŠë¦¼", "accuracy": "ë§¤ìš° ì¢‹ìŒ"},
        {"name": "large", "size": "~1550 MB", "speed": "ë§¤ìš° ëŠë¦¼", "accuracy": "ìµœê³ "}
    ]
    
    return JSONResponse({
        "available_models": models,
        "current_model": get_analyzer().get_model_info().get("model_size", "base"),
        "recommendation": "base ëª¨ë¸ì´ ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•ì´ ì¢‹ìŠµë‹ˆë‹¤."
    })

# ì˜¤ë¥˜ ì²˜ë¦¬ëŠ” FastAPI ì•± ë ˆë²¨ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ë³€ê²½
# (APIRouterì—ì„œëŠ” exception_handler ì‚¬ìš© ë¶ˆê°€)
