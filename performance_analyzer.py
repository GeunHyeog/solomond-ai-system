#!/usr/bin/env python3
"""
Performance Analyzer - SOLOMOND AI ì‹œìŠ¤í…œ ë³‘ëª©ì§€ì  ìë™ ë¶„ì„
"""

import time
import psutil
import requests
import os
import json
import threading
from datetime import datetime
import subprocess

class PerformanceAnalyzer:
    def __init__(self):
        self.start_time = None
        self.metrics = {
            'cpu_usage': [],
            'memory_usage': [],
            'network_speed': [],
            'disk_io': [],
            'ollama_response_times': [],
            'api_response_times': [],
            'file_processing_times': {},
            'bottlenecks': []
        }
        self.monitoring = False
        self.monitor_thread = None
        
    def start_monitoring(self):
        """ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_system, daemon=True)
        self.monitor_thread.start()
        print("ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
        
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ë° ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
        
        self._analyze_bottlenecks()
        return self._generate_report()
        
    def _monitor_system(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
        while self.monitoring:
            try:
                # CPU ì‚¬ìš©ë¥ 
                cpu_percent = psutil.cpu_percent(interval=1)
                self.metrics['cpu_usage'].append({
                    'time': time.time() - self.start_time,
                    'value': cpu_percent
                })
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                memory = psutil.virtual_memory()
                self.metrics['memory_usage'].append({
                    'time': time.time() - self.start_time,
                    'value': memory.percent,
                    'available_gb': memory.available / (1024**3)
                })
                
                # ë””ìŠ¤í¬ I/O
                disk_io = psutil.disk_io_counters()
                if disk_io:
                    self.metrics['disk_io'].append({
                        'time': time.time() - self.start_time,
                        'read_mb': disk_io.read_bytes / (1024**2),
                        'write_mb': disk_io.write_bytes / (1024**2)
                    })
                
                # ë„¤íŠ¸ì›Œí¬ I/O
                network_io = psutil.net_io_counters()
                if network_io:
                    self.metrics['network_speed'].append({
                        'time': time.time() - self.start_time,
                        'bytes_sent': network_io.bytes_sent,
                        'bytes_recv': network_io.bytes_recv
                    })
                    
                time.sleep(1)  # 1ì´ˆë§ˆë‹¤ ì¸¡ì •
                
            except Exception as e:
                print(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                
    def test_ollama_performance(self):
        """Ollama AI ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("ğŸ¤– Ollama ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        test_prompts = [
            "Hello, test response",
            "ë¶„ì„í•´ì£¼ì„¸ìš”: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤.",
            "ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”: " + "í…ŒìŠ¤íŠ¸ " * 100  # ê¸´ í…ìŠ¤íŠ¸
        ]
        
        for i, prompt in enumerate(test_prompts):
            start_time = time.time()
            try:
                response = requests.post('http://localhost:8000/api/analyze', 
                    json={
                        'model': 'qwen2.5:7b',
                        'context': 'Performance Test',
                        'image_texts': [prompt],
                        'audio_texts': []
                    },
                    timeout=60
                )
                
                end_time = time.time()
                response_time = end_time - start_time
                
                self.metrics['ollama_response_times'].append({
                    'test_id': i + 1,
                    'prompt_length': len(prompt),
                    'response_time': response_time,
                    'success': response.status_code == 200
                })
                
                print(f"  í…ŒìŠ¤íŠ¸ {i+1}: {response_time:.2f}ì´ˆ")
                
            except Exception as e:
                print(f"  í…ŒìŠ¤íŠ¸ {i+1} ì‹¤íŒ¨: {e}")
                self.metrics['ollama_response_times'].append({
                    'test_id': i + 1,
                    'prompt_length': len(prompt),
                    'response_time': -1,
                    'success': False,
                    'error': str(e)
                })
                
    def test_api_performance(self):
        """API ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("ğŸŒ API ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        endpoints = [
            {'url': 'http://localhost:8000/api/health', 'name': 'Health Check'},
            {'url': 'http://localhost:8000/', 'name': 'Main Page'},
        ]
        
        for endpoint in endpoints:
            start_time = time.time()
            try:
                response = requests.get(endpoint['url'], timeout=10)
                end_time = time.time()
                response_time = end_time - start_time
                
                self.metrics['api_response_times'].append({
                    'endpoint': endpoint['name'],
                    'response_time': response_time,
                    'status_code': response.status_code,
                    'success': response.status_code == 200
                })
                
                print(f"  {endpoint['name']}: {response_time:.3f}ì´ˆ (HTTP {response.status_code})")
                
            except Exception as e:
                print(f"  {endpoint['name']} ì‹¤íŒ¨: {e}")
                self.metrics['api_response_times'].append({
                    'endpoint': endpoint['name'],
                    'response_time': -1,
                    'success': False,
                    'error': str(e)
                })
    
    def test_file_processing(self):
        """íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ íŒŒì¼ ìƒì„±
        test_files = {
            'small_text.txt': "í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ " * 100,
            'medium_text.txt': "ë¶„ì„ìš© ë°ì´í„° " * 1000,
            'large_text.txt': "ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ ë¶„ì„ ë°ì´í„° " * 10000
        }
        
        for filename, content in test_files.items():
            try:
                # íŒŒì¼ ìƒì„±
                start_time = time.time()
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
                # íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸
                with open(filename, 'r', encoding='utf-8') as f:
                    data = f.read()
                    
                end_time = time.time()
                processing_time = end_time - start_time
                
                self.metrics['file_processing_times'][filename] = {
                    'size_bytes': len(content.encode('utf-8')),
                    'processing_time': processing_time,
                    'speed_mb_per_sec': (len(content.encode('utf-8')) / (1024*1024)) / processing_time if processing_time > 0 else 0
                }
                
                print(f"  {filename}: {processing_time:.4f}ì´ˆ ({len(content.encode('utf-8'))/1024:.1f}KB)")
                
                # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
                os.remove(filename)
                
            except Exception as e:
                print(f"  {filename} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    def test_system_resources(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸"""
        print("ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶„ì„ ì¤‘...")
        
        # CPU ì •ë³´
        cpu_count = psutil.cpu_count()
        cpu_freq = psutil.cpu_freq()
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory = psutil.virtual_memory()
        
        # ë””ìŠ¤í¬ ì •ë³´
        disk = psutil.disk_usage('C:')
        
        # GPU ì •ë³´ (NVIDIA-SMI ìˆì„ ê²½ìš°)
        gpu_info = self._get_gpu_info()
        
        system_info = {
            'cpu': {
                'cores': cpu_count,
                'frequency_mhz': cpu_freq.current if cpu_freq else 'Unknown',
                'usage_percent': cpu_percent
            },
            'memory': {
                'total_gb': memory.total / (1024**3),
                'available_gb': memory.available / (1024**3),
                'usage_percent': memory.percent
            },
            'disk': {
                'total_gb': disk.total / (1024**3),
                'free_gb': disk.free / (1024**3),
                'usage_percent': (disk.used / disk.total) * 100
            },
            'gpu': gpu_info
        }
        
        self.metrics['system_info'] = system_info
        
        print(f"  CPU: {cpu_count}ì½”ì–´, {cpu_percent:.1f}% ì‚¬ìš©ì¤‘")
        print(f"  ë©”ëª¨ë¦¬: {memory.available/(1024**3):.1f}GB ì‚¬ìš© ê°€ëŠ¥ ({memory.percent:.1f}% ì‚¬ìš©ì¤‘)")
        print(f"  ë””ìŠ¤í¬: {disk.free/(1024**3):.1f}GB ì—¬ìœ ê³µê°„")
        if gpu_info:
            print(f"  GPU: {gpu_info}")
            
    def _get_gpu_info(self):
        """GPU ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.used', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                return result.stdout.strip()
        except:
            pass
        return "No NVIDIA GPU detected"
    
    def _analyze_bottlenecks(self):
        """ë³‘ëª©ì§€ì  ìë™ ë¶„ì„"""
        bottlenecks = []
        
        # CPU ë³‘ëª© ë¶„ì„
        if self.metrics['cpu_usage']:
            avg_cpu = sum(m['value'] for m in self.metrics['cpu_usage']) / len(self.metrics['cpu_usage'])
            if avg_cpu > 80:
                bottlenecks.append({
                    'type': 'CPU',
                    'severity': 'HIGH',
                    'description': f'ë†’ì€ CPU ì‚¬ìš©ë¥  ({avg_cpu:.1f}%)',
                    'recommendation': 'CPU ì§‘ì•½ì  ì‘ì—… ìµœì í™” ë˜ëŠ” ë³‘ë ¬ì²˜ë¦¬ ê°œì„  í•„ìš”'
                })
        
        # ë©”ëª¨ë¦¬ ë³‘ëª© ë¶„ì„
        if self.metrics['memory_usage']:
            avg_memory = sum(m['value'] for m in self.metrics['memory_usage']) / len(self.metrics['memory_usage'])
            min_available = min(m['available_gb'] for m in self.metrics['memory_usage'])
            
            if avg_memory > 85:
                bottlenecks.append({
                    'type': 'MEMORY',
                    'severity': 'HIGH',
                    'description': f'ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ({avg_memory:.1f}%)',
                    'recommendation': 'ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™” ë˜ëŠ” RAM ì¦ì„¤ ê¶Œì¥'
                })
            elif min_available < 2:
                bottlenecks.append({
                    'type': 'MEMORY',
                    'severity': 'MEDIUM',
                    'description': f'ë‚®ì€ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ ({min_available:.1f}GB)',
                    'recommendation': 'ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ì‹œ ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„  í•„ìš”'
                })
        
        # Ollama AI ì‘ë‹µ ì‹œê°„ ë¶„ì„
        if self.metrics['ollama_response_times']:
            successful_tests = [t for t in self.metrics['ollama_response_times'] if t['success']]
            if successful_tests:
                avg_response_time = sum(t['response_time'] for t in successful_tests) / len(successful_tests)
                
                if avg_response_time > 30:
                    bottlenecks.append({
                        'type': 'AI_PROCESSING',
                        'severity': 'HIGH',
                        'description': f'ëŠë¦° AI ì‘ë‹µ ì‹œê°„ ({avg_response_time:.1f}ì´ˆ)',
                        'recommendation': 'Ollama ëª¨ë¸ ìµœì í™” ë˜ëŠ” GPU ê°€ì† í™œì„±í™” ê¶Œì¥'
                    })
                elif avg_response_time > 10:
                    bottlenecks.append({
                        'type': 'AI_PROCESSING',
                        'severity': 'MEDIUM',
                        'description': f'ë³´í†µ AI ì‘ë‹µ ì‹œê°„ ({avg_response_time:.1f}ì´ˆ)',
                        'recommendation': 'ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš© ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ìµœì í™” ê³ ë ¤'
                    })
            
            failed_tests = [t for t in self.metrics['ollama_response_times'] if not t['success']]
            if failed_tests:
                bottlenecks.append({
                    'type': 'AI_CONNECTION',
                    'severity': 'CRITICAL',
                    'description': f'AI ì—°ê²° ì‹¤íŒ¨ ({len(failed_tests)}ê°œ í…ŒìŠ¤íŠ¸)',
                    'recommendation': 'Ollama ì„œë²„ ìƒíƒœ í™•ì¸ ë° ì¬ì‹œì‘ í•„ìš”'
                })
        
        # API ì‘ë‹µ ì‹œê°„ ë¶„ì„
        if self.metrics['api_response_times']:
            slow_apis = [api for api in self.metrics['api_response_times'] 
                        if api['success'] and api['response_time'] > 2]
            if slow_apis:
                bottlenecks.append({
                    'type': 'API_RESPONSE',
                    'severity': 'MEDIUM',
                    'description': f'ëŠë¦° API ì‘ë‹µ ({len(slow_apis)}ê°œ ì—”ë“œí¬ì¸íŠ¸)',
                    'recommendation': 'API ì„œë²„ ìµœì í™” ë˜ëŠ” ìºì‹± êµ¬í˜„ ê¶Œì¥'
                })
        
        self.metrics['bottlenecks'] = bottlenecks
    
    def _generate_report(self):
        """ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_test_time': time.time() - self.start_time if self.start_time else 0,
            'summary': {
                'total_bottlenecks': len(self.metrics['bottlenecks']),
                'critical_issues': len([b for b in self.metrics['bottlenecks'] if b['severity'] == 'CRITICAL']),
                'high_priority': len([b for b in self.metrics['bottlenecks'] if b['severity'] == 'HIGH']),
                'medium_priority': len([b for b in self.metrics['bottlenecks'] if b['severity'] == 'MEDIUM'])
            },
            'bottlenecks': self.metrics['bottlenecks'],
            'metrics': self.metrics,
            'recommendations': self._get_optimization_recommendations()
        }
        
        return report
    
    def _get_optimization_recommendations(self):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë³‘ëª©ì§€ì ë³„ ë§ì¶¤ ê¶Œì¥ì‚¬í•­
        bottleneck_types = [b['type'] for b in self.metrics['bottlenecks']]
        
        if 'CPU' in bottleneck_types:
            recommendations.append({
                'priority': 'HIGH',
                'category': 'System Optimization',
                'action': 'CPU ì‚¬ìš©ëŸ‰ ìµœì í™”',
                'details': [
                    'ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ThreadPoolExecutor ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì •',
                    'CPU ì§‘ì•½ì  ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì´ë™',
                    'AI ëª¨ë¸ ì¶”ë¡  ì‹œ ë°°ì¹˜ í¬ê¸° ìµœì í™”'
                ]
            })
        
        if 'MEMORY' in bottleneck_types:
            recommendations.append({
                'priority': 'HIGH',
                'category': 'Memory Management',
                'action': 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”',
                'details': [
                    'í° íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ êµ¬í˜„',
                    'ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì¦‰ì‹œ í•´ì œ',
                    'garbage collection ìµœì í™”'
                ]
            })
        
        if 'AI_PROCESSING' in bottleneck_types:
            recommendations.append({
                'priority': 'HIGH',
                'category': 'AI Performance',
                'action': 'AI ì²˜ë¦¬ ì†ë„ ê°œì„ ',
                'details': [
                    'GPU ê°€ì† í™œì„±í™” (CUDA ì„¤ì •)',
                    'ë” ë¹ ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½ (ì˜ˆ: gemma2:2b)',
                    'AI ì‘ë‹µ ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•'
                ]
            })
        
        # ì¼ë°˜ì ì¸ ìµœì í™” ê¶Œì¥ì‚¬í•­
        recommendations.append({
            'priority': 'MEDIUM',
            'category': 'General Performance',
            'action': 'ì „ë°˜ì  ì„±ëŠ¥ í–¥ìƒ',
            'details': [
                'ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œë¡œ ì‚¬ìš©ì ê²½í—˜ ê°œì„ ',
                'ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìš°ì„ ìˆœìœ„ ì¡°ì •',
                'ë„¤íŠ¸ì›Œí¬ ìš”ì²­ íƒ€ì„ì•„ì›ƒ ìµœì í™”',
                'ì„ì‹œ íŒŒì¼ ìë™ ì •ë¦¬ ì‹œìŠ¤í…œ'
            ]
        })
        
        return recommendations

def run_performance_analysis():
    """ì „ì²´ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰"""
    analyzer = PerformanceAnalyzer()
    
    print("ğŸš€ SOLOMOND AI ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    # ëª¨ë‹ˆí„°ë§ ì‹œì‘
    analyzer.start_monitoring()
    
    try:
        # ê°ì¢… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
        analyzer.test_system_resources()
        print()
        
        analyzer.test_api_performance() 
        print()
        
        analyzer.test_ollama_performance()
        print()
        
        analyzer.test_file_processing()
        print()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ë° ë¶„ì„ ê²°ê³¼ ìƒì„±
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        report = analyzer.stop_monitoring()
        
        # ë³´ê³ ì„œ ì €ì¥
        with open('performance_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ê²°ê³¼ ì¶œë ¥
        print_analysis_results(report)
        
        return report

def print_analysis_results(report):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼")
    print("=" * 60)
    
    # ìš”ì•½ ì •ë³´
    summary = report['summary']
    print(f"ğŸ” ì´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {report['total_test_time']:.1f}ì´ˆ")
    print(f"âš ï¸ ë°œê²¬ëœ ë³‘ëª©ì§€ì : {summary['total_bottlenecks']}ê°œ")
    
    if summary['critical_issues'] > 0:
        print(f"ğŸš¨ ê¸´ê¸‰ ë¬¸ì œ: {summary['critical_issues']}ê°œ")
    if summary['high_priority'] > 0:
        print(f"âš¡ ê³ ìš°ì„ ìˆœìœ„: {summary['high_priority']}ê°œ") 
    if summary['medium_priority'] > 0:
        print(f"ğŸ“‹ ì¤‘ìš°ì„ ìˆœìœ„: {summary['medium_priority']}ê°œ")
    
    # ë³‘ëª©ì§€ì  ìƒì„¸ ì •ë³´
    if report['bottlenecks']:
        print("\nğŸ¯ ë°œê²¬ëœ ë³‘ëª©ì§€ì :")
        for i, bottleneck in enumerate(report['bottlenecks'], 1):
            severity_emoji = {'CRITICAL': 'ğŸš¨', 'HIGH': 'âš¡', 'MEDIUM': 'ğŸ“‹', 'LOW': 'ğŸ’¡'}
            emoji = severity_emoji.get(bottleneck['severity'], 'ğŸ“‹')
            
            print(f"\n{i}. {emoji} {bottleneck['type']}")
            print(f"   ë¬¸ì œ: {bottleneck['description']}")
            print(f"   í•´ê²°ë°©ì•ˆ: {bottleneck['recommendation']}")
    
    # ìµœì í™” ê¶Œì¥ì‚¬í•­
    print("\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
    for i, rec in enumerate(report['recommendations'], 1):
        priority_emoji = {'HIGH': 'ğŸ”¥', 'MEDIUM': 'âš¡', 'LOW': 'ğŸ’¡'}
        emoji = priority_emoji.get(rec['priority'], 'ğŸ’¡')
        
        print(f"\n{i}. {emoji} {rec['action']} ({rec['category']})")
        for detail in rec['details']:
            print(f"   â€¢ {detail}")
    
    print(f"\nğŸ’¾ ìƒì„¸ ë³´ê³ ì„œê°€ 'performance_report.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("=" * 60)

if __name__ == '__main__':
    run_performance_analysis()