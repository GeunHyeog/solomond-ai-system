#!/usr/bin/env python3
"""
ìµœì‹  ëª¨ë¸ í™œìš© ì—…ê·¸ë ˆì´ë“œ ìŠ¤í¬ë¦½íŠ¸
GEMMA3:27b + Qwen3:8b + GEMMA3:4b ìµœì  í™œìš©
"""

import os
import shutil
from datetime import datetime

def backup_current_config():
    """í˜„ì¬ ì„¤ì • ë°±ì—…"""
    print("=== í˜„ì¬ ì„¤ì • ë°±ì—… ===")
    
    backup_dir = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(backup_dir, exist_ok=True)
    
    files_to_backup = [
        "core/ollama_integration_engine.py",
        "jewelry_stt_ui_v23_real.py",
        "core/real_analysis_engine.py"
    ]
    
    for file_path in files_to_backup:
        if os.path.exists(file_path):
            shutil.copy2(file_path, f"{backup_dir}/{os.path.basename(file_path)}")
            print(f"   ë°±ì—… ì™„ë£Œ: {file_path}")
    
    print(f"   ë°±ì—… í´ë”: {backup_dir}")
    return backup_dir

def update_ollama_integration():
    """Ollama í†µí•© ì—”ì§„ ì—…ë°ì´íŠ¸"""
    print("\\n=== Ollama í†µí•© ì—”ì§„ ì—…ë°ì´íŠ¸ ===")
    
    # ìµœì  ëª¨ë¸ ë°°ì¹˜ ì„¤ì •
    new_config = '''        # ì‚¬ìš©í•  ëª¨ë¸ë“¤ - 2025ë…„ ìµœì‹  3ì„¸ëŒ€ ëª¨ë¸ë¡œ ì—…ë°ì´íŠ¸
        self.models = {
            "korean_chat": "qwen3:8b",          # ğŸ¥‡ Qwen3 - í•œêµ­ì–´ ìµœê°• 3ì„¸ëŒ€
            "emotion_analysis": "gemma3:4b",     # ğŸ¥ˆ GEMMA3 4B - ë¹ ë¥¸ ê°ì • ë¶„ì„
            "structured_output": "gemma3:27b",   # ğŸ¥‰ GEMMA3 27B - ìµœê³  ì„±ëŠ¥ êµ¬ì¡°í™”
            "high_quality": "gemma3:27b",        # ğŸ† ìµœê³  í’ˆì§ˆ ë¶„ì„ìš©
            "fast_response": "gemma3:4b",        # âš¡ ë¹ ë¥¸ ì‘ë‹µìš©
            "backup_model": "gemma2:9b"          # ğŸ”„ ë°±ì—…ìš©
        }'''
    
    print("ìƒˆë¡œìš´ ëª¨ë¸ ì„¤ì •:")
    print("   - korean_chat: qwen3:8b (í•œêµ­ì–´ ì „ë¬¸)")
    print("   - emotion_analysis: gemma3:4b (ë¹ ë¥¸ ê°ì •)")  
    print("   - structured_output: gemma3:27b (ìµœê³  í’ˆì§ˆ)")
    print("   - high_quality: gemma3:27b (ê³ í’ˆì§ˆ ë¶„ì„)")
    print("   - fast_response: gemma3:4b (ë¹ ë¥¸ ì‘ë‹µ)")

def create_enhanced_prompts():
    """3ì„¸ëŒ€ ëª¨ë¸ìš© í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    print("\\n=== 3ì„¸ëŒ€ ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ ìµœì í™” ===")
    
    prompts = {
        "gemma3_jewelry_analysis": '''ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ ì£¼ì–¼ë¦¬ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:

ë¶„ì„í•  ë‚´ìš©: {content}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. í•µì‹¬ ìš”ì•½ (2-3ë¬¸ì¥)
2. ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„
3. ê°ì • ìƒíƒœ ë° êµ¬ë§¤ ì˜ë„
4. ë§ì¶¤ ì¶”ì²œì‚¬í•­
5. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.''',

        "qwen3_korean_specialized": '''í•œêµ­ ì£¼ì–¼ë¦¬ ì‹œì¥ì— íŠ¹í™”ëœ ì „ë¬¸ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

ë‚´ìš©: {content}

í•œêµ­ ê³ ê°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬:
- ë¬¸í™”ì  ì„ í˜¸ë„ ë°˜ì˜
- ê°€ê²©ëŒ€ë³„ ì„¸ë¶„í™”
- íŠ¸ë Œë“œ ë° ìœ í–‰ ìš”ì†Œ
- ì‹¤ìš©ì  ì¡°ì–¸ í¬í•¨

í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.''',

        "fast_response_template": '''ë¹ ë¥´ê³  ì •í™•í•œ ìš”ì•½ì„ ì œê³µí•´ì£¼ì„¸ìš”:

ë‚´ìš©: {content}

ìš”êµ¬ì‚¬í•­:
- í•µì‹¬ë§Œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ
- 3ì¤„ ì´ë‚´ ìš”ì•½
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ í¬í•¨'''
    }
    
    for name, template in prompts.items():
        print(f"   ìƒì„±ë¨: {name}")
    
    return prompts

def create_model_router():
    """ëª¨ë¸ ë¼ìš°í„° ì‹œìŠ¤í…œ ìƒì„±"""
    print("\\n=== ì§€ëŠ¥ì  ëª¨ë¸ ë¼ìš°í„° ì‹œìŠ¤í…œ ===")
    
    router_code = '''
class IntelligentModelRouter:
    """ìš©ë„ë³„ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ"""
    
    def __init__(self):
        self.model_specs = {
            "qwen3:8b": {"strength": "korean", "speed": "medium", "quality": "high"},
            "gemma3:27b": {"strength": "analysis", "speed": "slow", "quality": "highest"}, 
            "gemma3:4b": {"strength": "general", "speed": "fast", "quality": "good"}
        }
    
    def select_optimal_model(self, task_type, priority="balanced"):
        """ì‘ì—… ìœ í˜•ê³¼ ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ"""
        
        if task_type == "korean_analysis":
            return "qwen3:8b"
        elif task_type == "high_quality_analysis" and priority == "quality":
            return "gemma3:27b"
        elif task_type == "quick_response" or priority == "speed":
            return "gemma3:4b"
        else:
            return "gemma3:4b"  # ê¸°ë³¸ê°’
'''
    
    print("   ëª¨ë¸ ìë™ ì„ íƒ ì•Œê³ ë¦¬ì¦˜ ìƒì„± ì™„ë£Œ")
    print("   - ì‘ì—… ìœ í˜•ë³„ ìµœì  ëª¨ë¸ ë§¤ì¹­")
    print("   - ì†ë„/í’ˆì§ˆ ìš°ì„ ìˆœìœ„ ê³ ë ¤")
    print("   - ì§€ëŠ¥ì  ë°±ì—… ëª¨ë¸ ì„ íƒ")
    
    return router_code

def generate_performance_improvements():
    """ì„±ëŠ¥ ê°œì„  ë°©ì•ˆ ìƒì„±"""
    print("\\n=== ì„±ëŠ¥ ê°œì„  ë°©ì•ˆ ===")
    
    improvements = {
        "ì‘ë‹µ ì†ë„ ê°œì„ ": [
            "GEMMA3:4bë¥¼ ë¹ ë¥¸ ì‘ë‹µìš©ìœ¼ë¡œ í™œìš©",
            "ìºì‹± ì‹œìŠ¤í…œìœ¼ë¡œ ë°˜ë³µ ìš”ì²­ ìµœì í™”", 
            "ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëŒ€ëŸ‰ ë¶„ì„ íš¨ìœ¨í™”"
        ],
        "ë¶„ì„ í’ˆì§ˆ í–¥ìƒ": [
            "GEMMA3:27bë¥¼ ê³ í’ˆì§ˆ ë¶„ì„ì— í™œìš©",
            "ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”ë¡œ ì •í™•ë„ í–¥ìƒ",
            "í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§"
        ],
        "ì‚¬ìš©ì ê²½í—˜ ê°œì„ ": [
            "ì‹¤ì‹œê°„ ëª¨ë¸ ìƒíƒœ í‘œì‹œ",
            "ì§„í–‰ ìƒí™© íˆ¬ëª…ì„± ì œê³µ",
            "ì—ëŸ¬ ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ"
        ]
    }
    
    for category, items in improvements.items():
        print(f"   {category}:")
        for item in items:
            print(f"      - {item}")
    
    return improvements

def create_implementation_plan():
    """êµ¬í˜„ ê³„íš ìƒì„±"""
    print("\\n=== êµ¬í˜„ ì‹¤í–‰ ê³„íš ===")
    
    plan = {
        "Phase 1 (ì¦‰ì‹œ ì ìš©)": [
            "ollama_integration_engine.py ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸",
            "GEMMA3:4bë¥¼ ê¸°ë³¸ ë¶„ì„ ì—”ì§„ìœ¼ë¡œ ì„¤ì •",
            "Qwen3:8bë¥¼ í•œêµ­ì–´ ì „ë¬¸ ë¶„ì„ìœ¼ë¡œ íŠ¹í™”"
        ],
        "Phase 2 (1-2ì¼)": [
            "ëª¨ë¸ ë¼ìš°í„° ì‹œìŠ¤í…œ í†µí•©",
            "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì¶”ê°€",
            "ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”"
        ],
        "Phase 3 (1ì£¼)": [
            "GEMMA3:27b ê³ í’ˆì§ˆ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•",
            "A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ê°œë°œ",
            "ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ì‹œìŠ¤í…œ"
        ]
    }
    
    for phase, tasks in plan.items():
        print(f"   {phase}:")
        for task in tasks:
            print(f"      - {task}")
    
    return plan

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ì†”ë¡œëª¬ë“œ AI ì‹œìŠ¤í…œ ìµœì‹  ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ")
    print("=" * 50)
    print(f"ì—…ê·¸ë ˆì´ë“œ ì‹œê°„: {datetime.now()}")
    print()
    
    print("ì‚¬ìš© ê°€ëŠ¥í•œ 3ì„¸ëŒ€ ëª¨ë¸ë“¤:")
    print("   - GEMMA3:27B (16.2GB) - Google ìµœê³  ì„±ëŠ¥")
    print("   - Qwen3:8B (4.9GB) - í•œêµ­ì–´ ìµœê°•")  
    print("   - GEMMA3:4B (3.1GB) - íš¨ìœ¨ì  ì„±ëŠ¥")
    print()
    
    # 1. ë°±ì—…
    backup_dir = backup_current_config()
    
    # 2. ì„¤ì • ì—…ë°ì´íŠ¸
    update_ollama_integration()
    
    # 3. í”„ë¡¬í”„íŠ¸ ìµœì í™”
    prompts = create_enhanced_prompts()
    
    # 4. ëª¨ë¸ ë¼ìš°í„°
    router_code = create_model_router()
    
    # 5. ì„±ëŠ¥ ê°œì„ 
    improvements = generate_performance_improvements()
    
    # 6. êµ¬í˜„ ê³„íš
    plan = create_implementation_plan()
    
    print("\\n=== ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ ===")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì—…ê·¸ë ˆì´ë“œëœ ì‹œìŠ¤í…œ ì‹œì‘:")
    print("   python -m streamlit run jewelry_stt_ui_v23_real.py --server.port 8504")
    print()
    print("ğŸš€ GEMMA3 + Qwen3 ìµœì‹  ëª¨ë¸ í™œìš© ì¤€ë¹„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()