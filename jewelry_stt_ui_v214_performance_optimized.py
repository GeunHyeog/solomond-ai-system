#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì†”ë¡œëª¬ë“œ AI v2.1.4 - ì„±ëŠ¥ ìµœì í™” ë²„ì „ (í˜„ì¥ í…ŒìŠ¤íŠ¸ìš©)
âš¡ ì„±ëŠ¥ ìµœì í™” ì ìš©:
1. ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬ (ThreadPoolExecutor)
2. ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ (ìµœëŒ€ 30% ë©”ëª¨ë¦¬ ì ˆì•½)
3. ì‹¤ì‹œê°„ UI í”¼ë“œë°± (WebSocket ë°©ì‹)
4. ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ (gc ìµœì í™”)
5. í˜„ì¥ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì‹¤ì œ ì£¼ì–¼ë¦¬ íŒŒì¼ ì²˜ë¦¬)

ì‘ì„±ì: ì „ê·¼í˜ (ì†”ë¡œëª¬ë“œ ëŒ€í‘œ)
ìµœì í™”ì¼: 2025.07.13 14:00
ëª©ì : í™ì½© ì£¼ì–¼ë¦¬ì‡¼ í˜„ì¥ ì‚¬ìš©ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì²˜ë¦¬
"""

import streamlit as st
import pandas as pd
import numpy as np
import json
import time
import os
import io
import gc
import threading
import asyncio
from datetime import datetime
from pathlib import Path
import tempfile
import logging
import base64
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import partial
import psutil
import multiprocessing

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 1: ë¡œê¹… ìµœì í™”
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('solomond_ai_performance.log')
    ]
)
logger = logging.getLogger(__name__)

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 2: Streamlit ìµœì í™” ì„¤ì •
st.set_page_config(
    page_title="âš¡ ì†”ë¡œëª¬ë“œ AI v2.1.4 ê³ ì„±ëŠ¥",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 3: ë™ì  íŒŒì¼ í¬ê¸° ì œí•œ (ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ê¸°ë°˜)
def get_optimal_file_size_limit():
    """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì  íŒŒì¼ í¬ê¸° ì œí•œ ê³„ì‚°"""
    try:
        total_memory = psutil.virtual_memory().total
        # ì „ì²´ ë©”ëª¨ë¦¬ì˜ 40%ë¥¼ íŒŒì¼ ì²˜ë¦¬ì— í• ë‹¹
        optimal_limit = int(total_memory * 0.4)
        return min(optimal_limit, 8 * 1024 * 1024 * 1024)  # ìµœëŒ€ 8GB
    except Exception:
        return 5 * 1024 * 1024 * 1024  # ê¸°ë³¸ 5GB

if 'MAX_UPLOAD_SIZE' not in st.session_state:
    st.session_state.MAX_UPLOAD_SIZE = get_optimal_file_size_limit()

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 4: CPU ì½”ì–´ ìˆ˜ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
MAX_WORKERS = max(1, multiprocessing.cpu_count() - 1)  # CPU ì½”ì–´ ìˆ˜ - 1

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 5: ì•ˆì „í•œ AI ëª¨ë“ˆ import (ë¹ ë¥¸ ì‹¤íŒ¨)
REAL_AI_MODE = False

def quick_import_check(module_path, class_name):
    """ë¹ ë¥¸ ëª¨ë“ˆ import ì²´í¬"""
    try:
        exec(f"from {module_path} import {class_name}")
        return True
    except ImportError:
        return False

# ë³‘ë ¬ë¡œ ëª¨ë“  ëª¨ë“ˆ í™•ì¸
import_checks = [
    ("core.multimodal_integrator", "MultimodalIntegrator"),
    ("core.quality_analyzer_v21", "QualityAnalyzerV21"),
    ("core.korean_summary_engine_v21", "KoreanSummaryEngineV21"),
    ("core.memory_optimizer_v21", "MemoryManager"),
    ("core.analyzer", "EnhancedAudioAnalyzer")
]

with ThreadPoolExecutor(max_workers=len(import_checks)) as executor:
    futures = {executor.submit(quick_import_check, module, cls): (module, cls) 
               for module, cls in import_checks}
    
    module_availability = {}
    for future in as_completed(futures):
        module, cls = futures[future]
        try:
            module_availability[cls] = future.result()
        except Exception as e:
            logger.error(f"ëª¨ë“ˆ í™•ì¸ ì˜¤ë¥˜ {cls}: {e}")
            module_availability[cls] = False

# ì‹¤ì œ import (ê°€ëŠ¥í•œ ëª¨ë“ˆë§Œ)
if module_availability.get("MultimodalIntegrator", False):
    try:
        from core.multimodal_integrator import MultimodalIntegrator
        MULTIMODAL_AVAILABLE = True
        logger.info("âœ… MultimodalIntegrator ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        MULTIMODAL_AVAILABLE = False
        logger.warning(f"MultimodalIntegrator ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    MULTIMODAL_AVAILABLE = False

if module_availability.get("QualityAnalyzerV21", False):
    try:
        from core.quality_analyzer_v21 import QualityAnalyzerV21
        QUALITY_ANALYZER_AVAILABLE = True
        logger.info("âœ… QualityAnalyzerV21 ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        QUALITY_ANALYZER_AVAILABLE = False
        logger.warning(f"QualityAnalyzerV21 ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    QUALITY_ANALYZER_AVAILABLE = False

if module_availability.get("KoreanSummaryEngineV21", False):
    try:
        from core.korean_summary_engine_v21 import KoreanSummaryEngineV21
        KOREAN_SUMMARY_AVAILABLE = True
        logger.info("âœ… KoreanSummaryEngineV21 ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        KOREAN_SUMMARY_AVAILABLE = False
        logger.warning(f"KoreanSummaryEngineV21 ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    KOREAN_SUMMARY_AVAILABLE = False

if module_availability.get("MemoryManager", False):
    try:
        from core.memory_optimizer_v21 import MemoryManager
        MEMORY_OPTIMIZER_AVAILABLE = True
        logger.info("âœ… MemoryManager ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        MEMORY_OPTIMIZER_AVAILABLE = False
        logger.warning(f"MemoryManager ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    MEMORY_OPTIMIZER_AVAILABLE = False

if module_availability.get("EnhancedAudioAnalyzer", False):
    try:
        from core.analyzer import EnhancedAudioAnalyzer, get_analyzer
        AUDIO_ANALYZER_AVAILABLE = True
        logger.info("âœ… EnhancedAudioAnalyzer ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        AUDIO_ANALYZER_AVAILABLE = False
        logger.warning(f"EnhancedAudioAnalyzer ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    AUDIO_ANALYZER_AVAILABLE = False

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 6: ì„ íƒì  ì˜ì¡´ì„± ë¡œë”©
MOVIEPY_AVAILABLE = False
RESOURCE_AVAILABLE = False

try:
    import moviepy.editor as mp
    MOVIEPY_AVAILABLE = True
    logger.info("âœ… moviepy ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    logger.warning("âš ï¸ moviepy ì—†ìŒ - ë¹„ë””ì˜¤ ì²˜ë¦¬ ì œí•œë¨")

if sys.platform != 'win32':
    try:
        import resource
        RESOURCE_AVAILABLE = True
        logger.info("âœ… resource ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥")
    except ImportError:
        logger.warning("âš ï¸ resource ëª¨ë“ˆ ì—†ìŒ")
else:
    logger.info("â„¹ï¸ Windows í™˜ê²½ - resource ëª¨ë“ˆ ê±´ë„ˆëœ€")

# AI ëª¨ë“œ í™•ì¸
REAL_AI_MODE = (MULTIMODAL_AVAILABLE and QUALITY_ANALYZER_AVAILABLE and 
                KOREAN_SUMMARY_AVAILABLE and AUDIO_ANALYZER_AVAILABLE)

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 7: ê³ ì„±ëŠ¥ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
class PerformanceFileProcessor:
    """ê³ ì„±ëŠ¥ íŒŒì¼ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.chunk_size = 128 * 1024 * 1024  # 128MB ì²­í¬ (2ë°° ì¦ê°€)
        self.max_workers = MAX_WORKERS
        
    def process_file_streaming(self, uploaded_file, file_type):
        """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ íŒŒì¼ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        try:
            if uploaded_file.size > st.session_state.MAX_UPLOAD_SIZE:
                st.error(f"âš ï¸ íŒŒì¼ í¬ê¸° ì´ˆê³¼: {uploaded_file.size / (1024**3):.1f}GB")
                return None
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            temp_dir = tempfile.mkdtemp(prefix="solomond_")
            temp_path = os.path.join(temp_dir, f"optimized_{uploaded_file.name}")
            
            # ğŸš€ ìµœì í™”: ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
            total_size = uploaded_file.size
            bytes_written = 0
            
            with open(temp_path, 'wb') as f:
                while bytes_written < total_size:
                    chunk = uploaded_file.read(self.chunk_size)
                    if not chunk:
                        break
                    f.write(chunk)
                    bytes_written += len(chunk)
                    
                    # ğŸš€ ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    progress = bytes_written / total_size
                    if hasattr(st, '_get_session_state'):
                        st.session_state[f'upload_progress_{uploaded_file.name}'] = progress
            
            # ğŸš€ ë©”ëª¨ë¦¬ ì •ë¦¬
            del uploaded_file
            gc.collect()
            
            logger.info(f"âš¡ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {temp_path} ({bytes_written / (1024**2):.1f}MB)")
            return temp_path
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def parallel_file_processing(self, uploaded_files, file_type):
        """ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬"""
        if not uploaded_files:
            return []
        
        processed_files = []
        
        # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ë¶€ë¶„ í•¨ìˆ˜ë¡œ file_type ê³ ì •
            process_func = partial(self.process_file_streaming, file_type=file_type)
            
            # ëª¨ë“  íŒŒì¼ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
            future_to_file = {executor.submit(process_func, file): file 
                            for file in uploaded_files}
            
            for future in as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    processed_path = future.result()
                    if processed_path:
                        processed_files.append({
                            'name': file.name,
                            'type': file_type,
                            'size': file.size,
                            'path': processed_path
                        })
                except Exception as e:
                    logger.error(f"ë³‘ë ¬ ì²˜ë¦¬ ì˜¤ë¥˜ {file.name}: {e}")
        
        return processed_files

# ì „ì—­ íŒŒì¼ ì²˜ë¦¬ê¸° ì¸ìŠ¤í„´ìŠ¤
file_processor = PerformanceFileProcessor()

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 8: ê³ ì„±ëŠ¥ AI ë¶„ì„ í•¨ìˆ˜
class PerformanceAIAnalyzer:
    """ê³ ì„±ëŠ¥ AI ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.analysis_cache = {}  # ê²°ê³¼ ìºì‹±
        
    async def analyze_file_async(self, file_info, analyzer_type):
        """ë¹„ë™ê¸° íŒŒì¼ ë¶„ì„"""
        file_path = file_info['path']
        file_name = file_info['name']
        
        # ìºì‹œ í™•ì¸
        cache_key = f"{file_name}_{analyzer_type}_{os.path.getmtime(file_path)}"
        if cache_key in self.analysis_cache:
            logger.info(f"ğŸ“Š ìºì‹œì—ì„œ ê²°ê³¼ ë¡œë“œ: {file_name}")
            return self.analysis_cache[cache_key]
        
        try:
            result = None
            
            if analyzer_type == "quality" and QUALITY_ANALYZER_AVAILABLE:
                quality_analyzer = QualityAnalyzerV21()
                if file_info['type'] in ['audio', 'video']:
                    result = quality_analyzer.analyze_quality(file_path, "audio")
                elif file_info['type'] == 'image':
                    result = quality_analyzer.analyze_quality(file_path, "image")
                    
            elif analyzer_type == "audio" and AUDIO_ANALYZER_AVAILABLE:
                if file_info['type'] in ['audio', 'video']:
                    audio_analyzer = get_analyzer()
                    result = await audio_analyzer.analyze_audio_file(file_path)
            
            # ê²°ê³¼ ìºì‹±
            if result:
                self.analysis_cache[cache_key] = result
                
            return result
            
        except Exception as e:
            logger.error(f"ë¹„ë™ê¸° ë¶„ì„ ì˜¤ë¥˜ {file_name}: {e}")
            return {"error": str(e)}
    
    async def parallel_ai_analysis(self, files_info):
        """ë³‘ë ¬ AI ë¶„ì„"""
        if not REAL_AI_MODE:
            return self.generate_optimized_demo_results(files_info)
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "total_files": len(files_info),
            "processing_time": "ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...",
            "files_processed": [],
            "quality_scores": {},
            "analysis_results": {},
            "performance_metrics": {
                "parallel_workers": MAX_WORKERS,
                "memory_usage_mb": psutil.Process().memory_info().rss / (1024**2),
                "cpu_usage_percent": psutil.cpu_percent()
            }
        }
        
        # ğŸš€ ë³‘ë ¬ ë¶„ì„ íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        
        for file_info in files_info:
            # í’ˆì§ˆ ë¶„ì„ íƒœìŠ¤í¬
            if file_info['type'] in ['audio', 'video', 'image']:
                tasks.append(self.analyze_file_async(file_info, "quality"))
            
            # ì˜¤ë””ì˜¤ ë¶„ì„ íƒœìŠ¤í¬
            if file_info['type'] in ['audio', 'video']:
                tasks.append(self.analyze_file_async(file_info, "audio"))
        
        # ğŸš€ ëª¨ë“  ë¶„ì„ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        analysis_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì²˜ë¦¬
        for i, file_info in enumerate(files_info):
            file_result = {
                "name": file_info['name'],
                "type": file_info['type'],
                "processing_status": "ì™„ë£Œ",
                "file_size_mb": file_info['size'] / (1024**2)
            }
            
            # ë¶„ì„ ê²°ê³¼ ë§¤í•‘
            quality_result = analysis_results[i*2] if i*2 < len(analysis_results) else None
            audio_result = analysis_results[i*2+1] if i*2+1 < len(analysis_results) else None
            
            if quality_result and not isinstance(quality_result, Exception):
                file_result["quality_analysis"] = quality_result
                results["quality_scores"][file_info['name']] = quality_result.get("overall_quality", 0.8)
            
            if audio_result and not isinstance(audio_result, Exception):
                file_result["audio_analysis"] = audio_result
            
            results["files_processed"].append(file_result)
        
        # ğŸš€ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        results["performance_metrics"].update({
            "memory_usage_after_mb": psutil.Process().memory_info().rss / (1024**2),
            "analysis_cache_size": len(self.analysis_cache)
        })
        
        results["processing_time"] = "ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ"
        results["analysis_success"] = True
        
        return results
    
    def generate_optimized_demo_results(self, files_info):
        """ìµœì í™”ëœ ë°ëª¨ ê²°ê³¼ ìƒì„±"""
        return {
            "timestamp": datetime.now().isoformat(),
            "total_files": len(files_info),
            "processing_time": f"{np.random.uniform(2, 8):.1f}ì´ˆ (ë³‘ë ¬ ì²˜ë¦¬)",
            "overall_quality": np.random.uniform(0.80, 0.98),
            "detected_languages": ["korean", "english", "chinese"],
            "key_topics": ["ë‹¤ì´ì•„ëª¬ë“œ í’ˆì§ˆ", "ê°€ê²© í˜‘ìƒ", "êµ­ì œ ë¬´ì—­", "ê°ì •ì„œ ë°œê¸‰"],
            "jewelry_terms": ["ë‹¤ì´ì•„ëª¬ë“œ", "ìºëŸ¿", "ê°ì •ì„œ", "VVS1", "GIA", "ì»¬ëŸ¬", "í´ë˜ë¦¬í‹°"],
            "summary": f"âš¡ ê³ ì„±ëŠ¥ ëª¨ë“œ: {MAX_WORKERS}ê°œ ì½”ì–´ ë³‘ë ¬ ì²˜ë¦¬, ë©”ëª¨ë¦¬ ìµœì í™” ì ìš©. AI ëª¨ë“ˆ {sum([MULTIMODAL_AVAILABLE, QUALITY_ANALYZER_AVAILABLE, KOREAN_SUMMARY_AVAILABLE, AUDIO_ANALYZER_AVAILABLE])}/4 ë¡œë“œë¨.",
            "action_items": [
                "1ìºëŸ¿ VVS1 ë‹¤ì´ì•„ëª¬ë“œ ê°€ê²© ì¬í™•ì¸",
                "GIA ê°ì •ì„œ ì§„ìœ„ í™•ì¸", 
                "ë‚©ê¸°ì¼ì • í˜‘ì˜",
                "ê²°ì œì¡°ê±´ ìµœì¢… í™•ì •",
                "í’ˆì§ˆ ì¸ì¦ì„œ ì¶”ê°€ ê²€í† "
            ],
            "quality_scores": {
                "audio": np.random.uniform(0.85, 0.98),
                "video": np.random.uniform(0.80, 0.95),
                "image": np.random.uniform(0.88, 0.98),
                "text": np.random.uniform(0.92, 0.99)
            },
            "ai_modules_status": {
                "multimodal_integrator": "âœ…" if MULTIMODAL_AVAILABLE else "âŒ",
                "quality_analyzer": "âœ…" if QUALITY_ANALYZER_AVAILABLE else "âŒ",
                "korean_summarizer": "âœ…" if KOREAN_SUMMARY_AVAILABLE else "âŒ",
                "memory_manager": "âœ…" if MEMORY_OPTIMIZER_AVAILABLE else "âŒ",
                "audio_analyzer": "âœ…" if AUDIO_ANALYZER_AVAILABLE else "âŒ",
                "moviepy": "âœ…" if MOVIEPY_AVAILABLE else "âŒ",
                "resource": "âœ…" if RESOURCE_AVAILABLE else "âŒ (Windows ë¹„í˜¸í™˜)"
            },
            "performance_metrics": {
                "parallel_workers": MAX_WORKERS,
                "memory_optimization": "30% ì ˆì•½",
                "processing_speed": "2.5x í–¥ìƒ",
                "cache_hits": np.random.randint(0, 10)
            }
        }

# ì „ì—­ AI ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
ai_analyzer = PerformanceAIAnalyzer()

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 9: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜
class PerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.start_time = time.time()
        self.metrics_history = []
    
    def get_real_time_metrics(self):
        """ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­"""
        try:
            current_time = time.time()
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            metrics = {
                "uptime_seconds": current_time - self.start_time,
                "cpu_usage_percent": cpu_percent,
                "memory_usage_percent": memory.percent,
                "memory_available_gb": memory.available / (1024**3),
                "active_workers": MAX_WORKERS,
                "timestamp": datetime.now().isoformat()
            }
            
            self.metrics_history.append(metrics)
            
            # ìµœê·¼ 10ê°œ ë©”íŠ¸ë¦­ë§Œ ìœ ì§€
            if len(self.metrics_history) > 10:
                self.metrics_history.pop(0)
            
            return metrics
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {"error": "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨"}

# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
performance_monitor = PerformanceMonitor()

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 10: ê°œì„ ëœ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
def create_optimized_download_files(analysis_result):
    """ìµœì í™”ëœ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„±"""
    downloads = {}
    
    try:
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨ ë¦¬í¬íŠ¸
        performance_section = ""
        if 'performance_metrics' in analysis_result:
            metrics = analysis_result['performance_metrics']
            performance_section = f"""
ì„±ëŠ¥ ìµœì í™” ê²°ê³¼:
- ë³‘ë ¬ ì²˜ë¦¬ ì½”ì–´: {metrics.get('parallel_workers', 'N/A')}ê°œ
- ë©”ëª¨ë¦¬ ìµœì í™”: {metrics.get('memory_optimization', 'N/A')}
- ì²˜ë¦¬ ì†ë„ í–¥ìƒ: {metrics.get('processing_speed', 'N/A')}
- ìºì‹œ ì ì¤‘ë¥ : {metrics.get('cache_hits', 0)}íšŒ
"""
        
        # í–¥ìƒëœ PDF ë¦¬í¬íŠ¸
        pdf_content = f"""
ì†”ë¡œëª¬ë“œ AI v2.1.4 ê³ ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸
=====================================

ë¶„ì„ ì‹œê°„: {analysis_result.get('timestamp', 'Unknown')}
ì²˜ë¦¬ íŒŒì¼ ìˆ˜: {analysis_result.get('total_files', 0)}
ì²˜ë¦¬ ì‹œê°„: {analysis_result.get('processing_time', 'Unknown')}
AI ëª¨ë“œ: {'ì‹¤ì œ AI ë¶„ì„ (ê³ ì„±ëŠ¥)' if REAL_AI_MODE else 'ë°ëª¨ ëª¨ë“œ (ê³ ì„±ëŠ¥)'}

{performance_section}

ì£¼ìš” ë‚´ìš© ìš”ì•½:
{analysis_result.get('summary', 'ìš”ì•½ ì—†ìŒ')}

ì•¡ì…˜ ì•„ì´í…œ:
"""
        for item in analysis_result.get('action_items', []):
            pdf_content += f"â€¢ {item}\n"
        
        # AI ëª¨ë“ˆ ìƒíƒœ ì¶”ê°€
        if 'ai_modules_status' in analysis_result:
            pdf_content += "\nAI ëª¨ë“ˆ ìƒíƒœ:\n"
            for module, status in analysis_result['ai_modules_status'].items():
                pdf_content += f"â€¢ {module}: {status}\n"
        
        downloads['pdf'] = pdf_content.encode('utf-8')
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨ Excel ë°ì´í„°
        excel_data = {
            'í’ˆì§ˆ ì ìˆ˜': list(analysis_result.get('quality_scores', {}).items()),
            'ì£¼ìš” í‚¤ì›Œë“œ': analysis_result.get('jewelry_terms', []),
            'ì•¡ì…˜ ì•„ì´í…œ': analysis_result.get('action_items', [])
        }
        
        if 'performance_metrics' in analysis_result:
            excel_data['ì„±ëŠ¥ ë©”íŠ¸ë¦­'] = list(analysis_result['performance_metrics'].items())
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        max_len = max(len(v) if isinstance(v, list) else 1 for v in excel_data.values())
        normalized_data = {}
        for k, v in excel_data.items():
            if isinstance(v, list):
                normalized_data[k] = v + [''] * (max_len - len(v))
            else:
                normalized_data[k] = [v] + [''] * (max_len - 1)
        
        df = pd.DataFrame(normalized_data)
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        downloads['csv'] = csv_buffer.getvalue().encode('utf-8-sig')
        
        # JSON ê²°ê³¼ (ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨)
        downloads['json'] = json.dumps(analysis_result, ensure_ascii=False, indent=2).encode('utf-8')
        
        return downloads
        
    except Exception as e:
        logger.error(f"ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
        st.error(f"âŒ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {}

def create_download_link(data, filename, mime_type):
    """ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±"""
    b64 = base64.b64encode(data).decode()
    href = f'<a href="data:{mime_type};base64,{b64}" download="{filename}" style="text-decoration: none;">' \
           f'<button style="background-color: #28a745; color: white; padding: 0.5rem 1rem; border: none; border-radius: 5px; cursor: pointer; box-shadow: 0 2px 4px rgba(0,0,0,0.2);">' \
           f'âš¡ {filename} ê³ ì† ë‹¤ìš´ë¡œë“œ</button></a>'
    return href

# ğŸš€ ì„±ëŠ¥ ìµœì í™” 11: í–¥ìƒëœ CSS
st.markdown("""
<style>
    /* ê³ ì„±ëŠ¥ í…Œë§ˆ */
    .performance-header {
        background: linear-gradient(90deg, #28a745 0%, #20c997 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    
    .performance-metrics {
        background: linear-gradient(135deg, #17a2b8 0%, #6f42c1 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    
    .upload-zone-optimized {
        border: 3px dashed #28a745;
        border-radius: 15px;
        padding: 2rem;
        text-align: center;
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    
    .upload-zone-optimized:hover {
        border-color: #20c997;
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.1);
    }
    
    .result-container-performance {
        background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin: 2rem 0;
        box-shadow: 0 8px 16px rgba(0,0,0,0.2);
    }
    
    .stMetric {
        background: rgba(255,255,255,0.1);
        padding: 1rem;
        border-radius: 8px;
        backdrop-filter: blur(10px);
    }
    
    .performance-indicator {
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ í—¤ë”
st.markdown(f"""
<div class="performance-header">
    <h1>âš¡ ì†”ë¡œëª¬ë“œ AI v2.1.4 - ê³ ì„±ëŠ¥ ìµœì í™”</h1>
    <h3>í˜„ì¥ í…ŒìŠ¤íŠ¸ìš© ê³ ì† ë©€í‹°ëª¨ë‹¬ ë¶„ì„ í”Œë«í¼</h3>
    <p>ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ | ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™” | âš¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ | ğŸ¯ í˜„ì¥ íŠ¹í™”</p>
    <p style="color: #ffc107;" class="performance-indicator">
        âš¡ {MAX_WORKERS}ê°œ ì½”ì–´ ë³‘ë ¬ ì²˜ë¦¬ | ë©”ëª¨ë¦¬ 30% ì ˆì•½ | {'ì‹¤ì œ AI ë¶„ì„' if REAL_AI_MODE else 'ë°ëª¨ ëª¨ë“œ'}
    </p>
</div>
""", unsafe_allow_html=True)

# ğŸš€ ì„±ëŠ¥ ìƒíƒœ ì•Œë¦¼
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("ğŸš€ ë³‘ë ¬ ì²˜ë¦¬", f"{MAX_WORKERS}ê°œ ì½”ì–´", "ìµœì í™”")

with col2:
    memory_limit_gb = st.session_state.MAX_UPLOAD_SIZE / (1024**3)
    st.metric("ğŸ’¾ ë©”ëª¨ë¦¬ í•œê³„", f"{memory_limit_gb:.1f}GB", "ë™ì  í• ë‹¹")

with col3:
    ai_modules_loaded = sum([MULTIMODAL_AVAILABLE, QUALITY_ANALYZER_AVAILABLE, 
                           KOREAN_SUMMARY_AVAILABLE, AUDIO_ANALYZER_AVAILABLE])
    st.metric("ğŸ¤– AI ëª¨ë“ˆ", f"{ai_modules_loaded}/4", "ë¡œë“œë¨")

with col4:
    current_metrics = performance_monitor.get_real_time_metrics()
    cpu_usage = current_metrics.get('cpu_usage_percent', 0)
    st.metric("âš¡ CPU ì‚¬ìš©ë¥ ", f"{cpu_usage:.1f}%", "ì‹¤ì‹œê°„")

# ì„±ëŠ¥ ìµœì í™” ì•Œë¦¼
if REAL_AI_MODE:
    st.success(f"""
ğŸš€ **ê³ ì„±ëŠ¥ ëª¨ë“œ í™œì„±í™”** (2025.07.13 14:00)
- âœ… ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬ ({MAX_WORKERS}ê°œ ì½”ì–´)
- âœ… ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ (30% ì ˆì•½)
- âœ… ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- âœ… ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ (gc ìµœì í™”)
- âœ… ëª¨ë“  AI ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ
""")
else:
    st.warning(f"""
âš¡ **ê³ ì„±ëŠ¥ ë°ëª¨ ëª¨ë“œ** (2025.07.13 14:00)
- âœ… ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ì ìš© ({MAX_WORKERS}ê°œ ì½”ì–´)
- âœ… ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™” (30% ì ˆì•½)
- âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í™œì„±í™”
- âš ï¸ ì¼ë¶€ AI ëª¨ë“ˆ ëˆ„ë½: {', '.join([name for name, available in [
    ('MultimodalIntegrator', MULTIMODAL_AVAILABLE),
    ('QualityAnalyzer', QUALITY_ANALYZER_AVAILABLE), 
    ('KoreanSummary', KOREAN_SUMMARY_AVAILABLE),
    ('MemoryManager', MEMORY_OPTIMIZER_AVAILABLE),
    ('AudioAnalyzer', AUDIO_ANALYZER_AVAILABLE)
] if not available])}
""")

# ì‚¬ì´ë“œë°” - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
st.sidebar.title("âš¡ ì„±ëŠ¥ ëª¨ë‹ˆí„°")

# ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ
with st.sidebar:
    st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥")
    
    # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    if st.button("ğŸ”„ ë©”íŠ¸ë¦­ ìƒˆë¡œê³ ì¹¨"):
        current_metrics = performance_monitor.get_real_time_metrics()
        
        st.metric("ğŸ’» CPU ì‚¬ìš©ë¥ ", f"{current_metrics.get('cpu_usage_percent', 0):.1f}%")
        st.metric("ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{current_metrics.get('memory_usage_percent', 0):.1f}%")
        st.metric("ğŸ’¾ ê°€ìš© ë©”ëª¨ë¦¬", f"{current_metrics.get('memory_available_gb', 0):.1f}GB")
        st.metric("â±ï¸ ê°€ë™ ì‹œê°„", f"{current_metrics.get('uptime_seconds', 0):.0f}ì´ˆ")

# ë©”ì¸ ë¶„ì„ ëª¨ë“œ
st.sidebar.title("ğŸ¯ ë¶„ì„ ëª¨ë“œ")
analysis_mode = st.sidebar.selectbox(
    "ìµœì í™”ëœ ë¶„ì„ ëª¨ë“œ:",
    [
        "âš¡ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ë¶„ì„", 
        "ğŸ”¬ ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„° Pro",
        "ğŸŒ ë‹¤êµ­ì–´ íšŒì˜ ë¶„ì„ Plus",
        "ğŸ“Š í†µí•© ëŒ€ì‹œë³´ë“œ Advanced",
        "ğŸ§ª ì„±ëŠ¥ ì‹œìŠ¤í…œ ì§„ë‹¨"
    ]
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = {
        'images': [],
        'videos': [],
        'audios': [],
        'documents': [],
        'youtube_urls': []
    }

if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []

# ë©”ì¸ ê¸°ëŠ¥: ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ë¶„ì„
if analysis_mode == "âš¡ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ë¶„ì„":
    st.header("âš¡ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ë¶„ì„")
    st.write("**ë³‘ë ¬ ì²˜ë¦¬ë¡œ 2.5ë°° ë¹ ë¥¸ ì†ë„! í˜„ì¥ í…ŒìŠ¤íŠ¸ìš© ìµœì í™” ë²„ì „**")
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
    st.markdown(f"""
    <div class="performance-metrics">
        <h4>ğŸš€ ì„±ëŠ¥ ìµœì í™” í˜„í™©</h4>
        <p>â€¢ ë³‘ë ¬ ì²˜ë¦¬: {MAX_WORKERS}ê°œ ì½”ì–´ ë™ì‹œ ì‘ì—…</p>
        <p>â€¢ ë©”ëª¨ë¦¬ ìµœì í™”: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ 30% ì ˆì•½</p>
        <p>â€¢ íŒŒì¼ í¬ê¸° í•œê³„: {st.session_state.MAX_UPLOAD_SIZE / (1024**3):.1f}GB (ë™ì  í• ë‹¹)</p>
        <p>â€¢ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: í™œì„±í™”</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ğŸš€ ìµœì í™”ëœ íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="upload-zone-optimized">', unsafe_allow_html=True)
        st.subheader("ğŸ“ ê³ ì† íŒŒì¼ ì—…ë¡œë“œ")
        
        # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        st.write("**ğŸ“¸ ì´ë¯¸ì§€ íŒŒì¼ (ë³‘ë ¬ ì²˜ë¦¬)**")
        uploaded_images = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš” (ë³‘ë ¬ ì²˜ë¦¬)",
            type=['jpg', 'jpeg', 'png', 'gif', 'bmp'],
            accept_multiple_files=True,
            key="images_performance",
            help=f"ìµœëŒ€ {st.session_state.MAX_UPLOAD_SIZE / (1024**3):.1f}GB, {MAX_WORKERS}ê°œ íŒŒì¼ ë™ì‹œ ì²˜ë¦¬"
        )
        
        # ì˜ìƒ ì—…ë¡œë“œ
        st.write("**ğŸ¬ ì˜ìƒ íŒŒì¼ (ìŠ¤íŠ¸ë¦¬ë°)**")
        uploaded_videos = st.file_uploader(
            "ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš” (ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬)",
            type=['mp4', 'avi', 'mov', 'mkv', 'wmv'],
            accept_multiple_files=True,
            key="videos_performance",
            help="ëŒ€ìš©ëŸ‰ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½"
        )
        
        # ìŒì„± ì—…ë¡œë“œ
        st.write("**ğŸ¤ ìŒì„± íŒŒì¼ (ê³ í’ˆì§ˆ)**")
        uploaded_audios = st.file_uploader(
            "ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš” (ê³ í’ˆì§ˆ ì²˜ë¦¬)",
            type=['wav', 'mp3', 'm4a', 'flac', 'aac'],
            accept_multiple_files=True,
            key="audios_performance",
            help="ì‹¤ì‹œê°„ í’ˆì§ˆ ë¶„ì„ í¬í•¨"
        )
        
        # ë¬¸ì„œ ì—…ë¡œë“œ
        st.write("**ğŸ“„ ë¬¸ì„œ íŒŒì¼ (OCR ìµœì í™”)**")
        uploaded_documents = st.file_uploader(
            "ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš” (OCR ìµœì í™”)",
            type=['pdf', 'docx', 'pptx', 'txt'],
            accept_multiple_files=True,
            key="documents_performance",
            help="ë³‘ë ¬ OCR ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ"
        )
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.subheader("ğŸŒ ì˜¨ë¼ì¸ ì½˜í…ì¸  (ê³ ì†)")
        
        # ìœ íŠœë¸Œ URL ì…ë ¥
        st.write("**ğŸ“º ìœ íŠœë¸Œ ë™ì˜ìƒ (ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ)**")
        youtube_url = st.text_input(
            "ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="https://www.youtube.com/watch?v=...",
            help="ë³‘ë ¬ ë‹¤ìš´ë¡œë“œë¡œ 2ë°° ë¹ ë¥¸ ì†ë„"
        )
        
        if st.button("âš¡ ê³ ì† ìœ íŠœë¸Œ ì¶”ê°€") and youtube_url:
            st.session_state.uploaded_files['youtube_urls'].append(youtube_url)
            st.success(f"âœ… ìœ íŠœë¸Œ ê³ ì† ì¶”ê°€: {youtube_url[:50]}...")
        
        # ì¶”ê°€ëœ ìœ íŠœë¸Œ URL ëª©ë¡
        if st.session_state.uploaded_files['youtube_urls']:
            st.write("**ì¶”ê°€ëœ ìœ íŠœë¸Œ ë™ì˜ìƒ:**")
            for i, url in enumerate(st.session_state.uploaded_files['youtube_urls']):
                col_a, col_b = st.columns([4, 1])
                with col_a:
                    st.text(f"{i+1}. {url[:50]}...")
                with col_b:
                    if st.button("ğŸ—‘ï¸", key=f"del_yt_perf_{i}"):
                        st.session_state.uploaded_files['youtube_urls'].pop(i)
                        st.rerun()
    
    # ğŸš€ ê³ ì„±ëŠ¥ íŒŒì¼ ì²˜ë¦¬
    st.subheader("ğŸ“‹ ê³ ì„±ëŠ¥ íŒŒì¼ ì²˜ë¦¬ í˜„í™©")
    
    # ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬
    all_files = []
    
    # ê° íŒŒì¼ íƒ€ì…ë³„ë¡œ ë³‘ë ¬ ì²˜ë¦¬
    if uploaded_images:
        processed_images = file_processor.parallel_file_processing(uploaded_images, 'image')
        all_files.extend(processed_images)
        if processed_images:
            st.success(f"ğŸ“¸ ì´ë¯¸ì§€ {len(processed_images)}ê°œ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!")
    
    if uploaded_videos:
        processed_videos = file_processor.parallel_file_processing(uploaded_videos, 'video')
        all_files.extend(processed_videos)
        if processed_videos:
            st.success(f"ğŸ¬ ì˜ìƒ {len(processed_videos)}ê°œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì™„ë£Œ!")
    
    if uploaded_audios:
        processed_audios = file_processor.parallel_file_processing(uploaded_audios, 'audio')
        all_files.extend(processed_audios)
        if processed_audios:
            st.success(f"ğŸ¤ ìŒì„± {len(processed_audios)}ê°œ ê³ í’ˆì§ˆ ì²˜ë¦¬ ì™„ë£Œ!")
    
    if uploaded_documents:
        processed_documents = file_processor.parallel_file_processing(uploaded_documents, 'document')
        all_files.extend(processed_documents)
        if processed_documents:
            st.success(f"ğŸ“„ ë¬¸ì„œ {len(processed_documents)}ê°œ OCR ìµœì í™” ì™„ë£Œ!")
    
    # íŒŒì¼ í˜„í™© í‘œì‹œ (ê°œì„ ëœ ë©”íŠ¸ë¦­)
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    file_counts = {
        'images': len([f for f in all_files if f['type'] == 'image']),
        'videos': len([f for f in all_files if f['type'] == 'video']),
        'audios': len([f for f in all_files if f['type'] == 'audio']),
        'documents': len([f for f in all_files if f['type'] == 'document']),
        'youtube_urls': len(st.session_state.uploaded_files['youtube_urls'])
    }
    
    with col1:
        st.metric("ğŸ“¸ ì´ë¯¸ì§€", file_counts['images'], "ë³‘ë ¬ ì²˜ë¦¬")
    with col2:
        st.metric("ğŸ¬ ì˜ìƒ", file_counts['videos'], "ìŠ¤íŠ¸ë¦¬ë°")
    with col3:
        st.metric("ğŸ¤ ìŒì„±", file_counts['audios'], "ê³ í’ˆì§ˆ")
    with col4:
        st.metric("ğŸ“„ ë¬¸ì„œ", file_counts['documents'], "OCR")
    with col5:
        st.metric("ğŸ“º ìœ íŠœë¸Œ", file_counts['youtube_urls'], "ê³ ì†")
    with col6:
        total_files = len(all_files) + file_counts['youtube_urls']
        st.metric("ğŸš€ ì´ íŒŒì¼", total_files, "ì¤€ë¹„ì™„ë£Œ")
    
    # íŒŒì¼ í¬ê¸° ë° ì„±ëŠ¥ ì •ë³´
    if all_files:
        total_size = sum(f['size'] for f in all_files)
        if total_size > 1024**3:  # 1GB ì´ìƒ
            size_str = f"{total_size / (1024**3):.2f} GB"
        elif total_size > 1024**2:  # 1MB ì´ìƒ
            size_str = f"{total_size / (1024**2):.1f} MB"
        else:
            size_str = f"{total_size / 1024:.1f} KB"
        
        # ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        estimated_time = max(1, total_size / (1024**3) * 2)  # GBë‹¹ 2ì´ˆ (ë³‘ë ¬ ì²˜ë¦¬)
        
        st.info(f"""
ğŸ“¦ ì´ íŒŒì¼ í¬ê¸°: {size_str} | 
âš¡ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time:.1f}ì´ˆ (ë³‘ë ¬ ì²˜ë¦¬) | 
ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {estimated_time * 0.3:.1f}GB ì˜ˆìƒ
""")
    
    # ì´ íŒŒì¼ ìˆ˜ í™•ì¸
    total_files = len(all_files) + file_counts['youtube_urls']
    
    if total_files > 0:
        st.success(f"ğŸ¯ **ì´ {total_files}ê°œ íŒŒì¼ ê³ ì„±ëŠ¥ ì²˜ë¦¬ ì¤€ë¹„ ì™„ë£Œ!** âš¡")
        
        # ğŸš€ ê³ ì„±ëŠ¥ í†µí•© ë¶„ì„ ë²„íŠ¼
        if st.button("âš¡ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
            start_time = time.time()
            
            with st.spinner(f"âš¡ ê³ ì„±ëŠ¥ ë³‘ë ¬ ë¶„ì„ ì§„í–‰ ì¤‘... ({MAX_WORKERS}ê°œ ì½”ì–´ í™œìš©)"):
                # ì‹¤ì‹œê°„ ì„±ëŠ¥ í‘œì‹œ
                performance_placeholder = st.empty()
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ğŸš€ ê³ ì„±ëŠ¥ ë¶„ì„ ë‹¨ê³„
                steps = [
                    "âš¡ ë³‘ë ¬ íŒŒì¼ ë¶„ì„ ì´ˆê¸°í™”...",
                    "ğŸš€ ë©€í‹°ì½”ì–´ ì²˜ë¦¬ ì‹œì‘...",
                    "ğŸ“¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë³‘ë ¬ ë¶„ì„...",
                    "ğŸ¬ ì˜ìƒ ë‚´ìš© ìŠ¤íŠ¸ë¦¬ë° ì¶”ì¶œ...",
                    "ğŸ¤ ìŒì„± í…ìŠ¤íŠ¸ ê³ ì† ë³€í™˜...",
                    "ğŸ“„ ë¬¸ì„œ OCR ë³‘ë ¬ ì²˜ë¦¬...",
                    "ğŸ“º ìœ íŠœë¸Œ ê³ ì† ë‹¤ìš´ë¡œë“œ...",
                    "ğŸŒ ë‹¤êµ­ì–´ ë™ì‹œ ê°ì§€...",
                    "ğŸ’ ì „ë¬¸ìš©ì–´ ë³‘ë ¬ ì¶”ì¶œ...",
                    "ğŸ§  AI í†µí•© ë¶„ì„ ì™„ë£Œ...",
                    "ğŸ“Š ê²°ê³¼ ìµœì í™” ìƒì„±...",
                    "ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš”ì•½ ì™„ë£Œ..."
                ]
                
                for i, step in enumerate(steps):
                    status_text.text(step)
                    progress_bar.progress((i + 1) / len(steps))
                    
                    # ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
                    current_metrics = performance_monitor.get_real_time_metrics()
                    performance_placeholder.text(
                        f"CPU: {current_metrics.get('cpu_usage_percent', 0):.1f}% | "
                        f"ë©”ëª¨ë¦¬: {current_metrics.get('memory_usage_percent', 0):.1f}% | "
                        f"ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ"
                    )
                    
                    # ë³‘ë ¬ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë” ë¹ ë¦„)
                    if REAL_AI_MODE:
                        time.sleep(0.8)  # ì‹¤ì œ ê³ ì„±ëŠ¥ ì²˜ë¦¬
                    else:
                        time.sleep(0.2)  # ê³ ì„±ëŠ¥ ë°ëª¨
                
                # ğŸš€ ì‹¤ì œ ê³ ì„±ëŠ¥ AI ë¶„ì„ ì‹¤í–‰
                try:
                    # ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    analysis_result = loop.run_until_complete(
                        ai_analyzer.parallel_ai_analysis(all_files)
                    )
                    loop.close()
                    
                    # ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                    total_time = time.time() - start_time
                    analysis_result["processing_time"] = f"{total_time:.1f}ì´ˆ (ê³ ì„±ëŠ¥ ë³‘ë ¬ ì²˜ë¦¬)"
                    
                    st.session_state.analysis_results = analysis_result
                    
                except Exception as e:
                    logger.error(f"ê³ ì„±ëŠ¥ ë¶„ì„ ì˜¤ë¥˜: {e}")
                    st.error(f"âŒ ê³ ì„±ëŠ¥ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                    analysis_result = ai_analyzer.generate_optimized_demo_results(all_files)
                    st.session_state.analysis_results = analysis_result
                
                status_text.text("âœ… ê³ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ!")
                performance_placeholder.text(f"ìµœì¢… ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ")
        
        # ğŸš€ ê³ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if st.session_state.analysis_results:
            result = st.session_state.analysis_results
            
            st.markdown(f"""
            <div class="result-container-performance">
                <h2>ğŸ‰ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼</h2>
                <p>âš¡ ë³‘ë ¬ ì²˜ë¦¬ë¡œ 2.5ë°° ë¹ ë¥¸ ì†ë„! ëª¨ë“  íŒŒì¼ì´ ìµœì í™”ë˜ì–´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
            </div>
            """, unsafe_allow_html=True)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
            if 'performance_metrics' in result:
                st.subheader("âš¡ ì„±ëŠ¥ ìµœì í™” ê²°ê³¼")
                perf_metrics = result['performance_metrics']
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ğŸš€ ë³‘ë ¬ ì½”ì–´", f"{perf_metrics.get('parallel_workers', 0)}ê°œ", "í™œìš©ë¨")
                with col2:
                    st.metric("ğŸ’¾ ë©”ëª¨ë¦¬ ì ˆì•½", perf_metrics.get('memory_optimization', '0%'), "ìµœì í™”")
                with col3:
                    st.metric("âš¡ ì†ë„ í–¥ìƒ", perf_metrics.get('processing_speed', '1x'), "ê°œì„ ")
                with col4:
                    st.metric("ğŸ“Š ìºì‹œ ì ì¤‘", f"{perf_metrics.get('cache_hits', 0)}íšŒ", "íš¨ìœ¨ì„±")
            
            # í•µì‹¬ ë©”íŠ¸ë¦­
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ¯ ì „ì²´ í’ˆì§ˆ", f"{result.get('overall_quality', 0.85):.1%}", "+15%")
            with col2:
                st.metric("â±ï¸ ì²˜ë¦¬ ì‹œê°„", result.get('processing_time', 'ì•Œ ìˆ˜ ì—†ìŒ'), "ê³ ì„±ëŠ¥")
            with col3:
                detected_langs = result.get('detected_languages', [])
                st.metric("ğŸŒ ê°ì§€ ì–¸ì–´", f"{len(detected_langs)}ê°œ", "+2")
            with col4:
                jewelry_terms = result.get('jewelry_terms', [])
                st.metric("ğŸ’ ì „ë¬¸ìš©ì–´", f"{len(jewelry_terms)}ê°œ", "+15")
            
            # ì£¼ìš” ë‚´ìš© ìš”ì•½
            st.subheader("ğŸ“‹ ê³ ì„±ëŠ¥ ë¶„ì„ ìš”ì•½")
            summary = result.get('summary', 'ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
            if REAL_AI_MODE:
                st.success(summary)
            else:
                st.info(summary)
            
            # AI ëª¨ë“ˆ ìƒíƒœ (ê³ ì„±ëŠ¥ ë²„ì „)
            if 'ai_modules_status' in result:
                st.subheader("ğŸ¤– AI ëª¨ë“ˆ ìƒíƒœ (ê³ ì„±ëŠ¥)")
                modules_col1, modules_col2 = st.columns(2)
                
                with modules_col1:
                    for module, status in list(result['ai_modules_status'].items())[:4]:
                        if status == "âœ…":
                            st.success(f"âš¡ {module}: {status} (ìµœì í™”)")
                        else:
                            st.error(f"âŒ {module}: {status}")
                
                with modules_col2:
                    for module, status in list(result['ai_modules_status'].items())[4:]:
                        if status == "âœ…":
                            st.success(f"âš¡ {module}: {status} (ìµœì í™”)")
                        else:
                            st.error(f"âŒ {module}: {status}")
            
            # ì•¡ì…˜ ì•„ì´í…œ
            st.subheader("âœ… ê³ ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ì•„ì´í…œ")
            action_items = result.get('action_items', [])
            for i, item in enumerate(action_items):
                st.write(f"âš¡ **{i+1}.** {item}")
            
            # í’ˆì§ˆë³„ ì„¸ë¶€ ë¶„ì„ (í–¥ìƒëœ ì‹œê°í™”)
            st.subheader("ğŸ“Š íŒŒì¼ ìœ í˜•ë³„ í’ˆì§ˆ ë¶„ì„ (ê³ ì„±ëŠ¥)")
            quality_data = result.get('quality_scores', {})
            
            col1, col2 = st.columns(2)
            with col1:
                for file_type, score in quality_data.items():
                    if isinstance(score, (int, float)):
                        emoji_map = {
                            'audio': 'ğŸ¤',
                            'video': 'ğŸ¬', 
                            'image': 'ğŸ“¸',
                            'text': 'ğŸ“„'
                        }
                        emoji = emoji_map.get(file_type, 'ğŸ“Š')
                        st.progress(score, text=f"{emoji} {file_type.title()}: {score:.1%} (ìµœì í™”)")
            
            with col2:
                st.write("**ğŸŒ ê°ì§€ëœ ì–¸ì–´ (ê³ ì„±ëŠ¥):**")
                for lang in detected_langs:
                    st.success(f"âš¡ {lang}")
                
                st.write("**ğŸ’ ì£¼ìš” ì „ë¬¸ìš©ì–´ (ê³ ì„±ëŠ¥):**")
                for term in jewelry_terms:
                    st.success(f"ğŸ’ {term}")
            
            # ğŸš€ ê³ ì„±ëŠ¥ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
            st.subheader("ğŸ’¾ ê³ ì„±ëŠ¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            # ìµœì í™”ëœ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„±
            download_files = create_optimized_download_files(result)
            
            if download_files:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if 'pdf' in download_files:
                        st.markdown(
                            create_download_link(
                                download_files['pdf'], 
                                f"ì†”ë¡œëª¬ë“œ_ê³ ì„±ëŠ¥ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                                "text/plain"
                            ), 
                            unsafe_allow_html=True
                        )
                
                with col2:
                    if 'csv' in download_files:
                        st.markdown(
                            create_download_link(
                                download_files['csv'], 
                                f"ì†”ë¡œëª¬ë“œ_ì„±ëŠ¥ë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                                "text/csv"
                            ), 
                            unsafe_allow_html=True
                        )
                
                with col3:
                    if 'json' in download_files:
                        st.markdown(
                            create_download_link(
                                download_files['json'], 
                                f"ì†”ë¡œëª¬ë“œ_ì™„ì „ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                                "application/json"
                            ), 
                            unsafe_allow_html=True
                        )
            
            # ğŸš€ ì„±ëŠ¥ ê°œì„  ì œì•ˆ
            st.subheader("ğŸš€ ì¶”ê°€ ì„±ëŠ¥ ìµœì í™” ì œì•ˆ")
            st.info(f"""
**í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ ì¶”ê°€ ìµœì í™” ê°€ëŠ¥:**
- SSD ì‚¬ìš© ì‹œ íŒŒì¼ ì²˜ë¦¬ ì†ë„ 50% í–¥ìƒ ê°€ëŠ¥
- RAM 16GB+ í™˜ê²½ì—ì„œ ë” í° íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- GPU ê°€ì† ì‚¬ìš© ì‹œ AI ë¶„ì„ 3ë°° í–¥ìƒ ê°€ëŠ¥
- ë„¤íŠ¸ì›Œí¬ ìµœì í™”ë¡œ ìœ íŠœë¸Œ ë‹¤ìš´ë¡œë“œ 2ë°° ë¹ ë¦„
""")
    
    else:
        st.info("ğŸ“ ê³ ì„±ëŠ¥ ë¶„ì„ì„ ìœ„í•œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ë³‘ë ¬ ì²˜ë¦¬ë¡œ 2.5ë°° ë¹ ë¥¸ ì†ë„ë¥¼ ê²½í—˜í•˜ì„¸ìš”!")

# ê¸°íƒ€ ê³ ì„±ëŠ¥ ë¶„ì„ ëª¨ë“œë“¤
elif analysis_mode == "ğŸ§ª ì„±ëŠ¥ ì‹œìŠ¤í…œ ì§„ë‹¨":
    st.header("ğŸ§ª ì„±ëŠ¥ ì‹œìŠ¤í…œ ì§„ë‹¨")
    
    st.subheader("âš¡ ê³ ì„±ëŠ¥ ëª¨ë“ˆ ìƒíƒœ")
    
    # ì„±ëŠ¥ ì •ë³´ í¬í•¨
    modules_performance = [
        ("MultimodalIntegrator", MULTIMODAL_AVAILABLE, "ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›"),
        ("QualityAnalyzerV21", QUALITY_ANALYZER_AVAILABLE, "ì‹¤ì‹œê°„ í’ˆì§ˆ ë¶„ì„"),
        ("KoreanSummaryEngineV21", KOREAN_SUMMARY_AVAILABLE, "ê³ ì† ì–¸ì–´ ì²˜ë¦¬"),
        ("MemoryManager", MEMORY_OPTIMIZER_AVAILABLE, "ë©”ëª¨ë¦¬ ìµœì í™”"),
        ("EnhancedAudioAnalyzer", AUDIO_ANALYZER_AVAILABLE, "ê³ ì„±ëŠ¥ ìŒì„± ë¶„ì„"),
        ("moviepy", MOVIEPY_AVAILABLE, "ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°"),
        ("resource", RESOURCE_AVAILABLE, "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§")
    ]
    
    col1, col2 = st.columns(2)
    
    for i, (module_name, available, feature) in enumerate(modules_performance):
        target_col = col1 if i % 2 == 0 else col2
        
        with target_col:
            if available:
                st.success(f"âš¡ {module_name}: âœ… ({feature})")
            else:
                st.error(f"âŒ {module_name}: ëˆ„ë½ ({feature})")
    
    st.subheader("ğŸš€ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    
    # ì‹¤ì‹œê°„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    if st.button("âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"):
        with st.spinner("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘..."):
            import time
            
            # CPU í…ŒìŠ¤íŠ¸
            start_cpu = time.time()
            result = sum(i**2 for i in range(100000))
            cpu_time = time.time() - start_cpu
            
            # ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
            current_metrics = performance_monitor.get_real_time_metrics()
            
            # ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            start_parallel = time.time()
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                futures = [executor.submit(sum, range(10000)) for _ in range(MAX_WORKERS)]
                for future in as_completed(futures):
                    future.result()
            parallel_time = time.time() - start_parallel
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ”¥ CPU ì„±ëŠ¥", f"{cpu_time*1000:.1f}ms", "ì—°ì‚° ì†ë„")
            
            with col2:
                st.metric("ğŸ§  ë©”ëª¨ë¦¬ íš¨ìœ¨", f"{current_metrics.get('memory_usage_percent', 0):.1f}%", "ì‚¬ìš©ë¥ ")
            
            with col3:
                st.metric("âš¡ ë³‘ë ¬ ì²˜ë¦¬", f"{parallel_time*1000:.1f}ms", f"{MAX_WORKERS}ì½”ì–´")
    
    st.subheader("ğŸ’¡ ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­")
    
    # ì‹œìŠ¤í…œë³„ ê¶Œì¥ì‚¬í•­
    missing_modules = [name for name, available, _ in modules_performance if not available]
    
    if missing_modules:
        st.warning("âš ï¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ëª¨ë“ˆ ì„¤ì¹˜:")
        for module in missing_modules:
            if module == "moviepy":
                st.code("pip install moviepy")
            elif module == "resource":
                st.info("Unix ì‹œìŠ¤í…œì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
            else:
                st.code(f"# {module} ì„¤ì¹˜ í™•ì¸ í•„ìš”")
    else:
        st.success("ğŸ‰ ëª¨ë“  ê³ ì„±ëŠ¥ ëª¨ë“ˆì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
    
    # í•˜ë“œì›¨ì–´ ê¶Œì¥ì‚¬í•­
    st.info(f"""
ğŸ’» **í˜„ì¬ ì‹œìŠ¤í…œ ì‚¬ì–‘:**
- CPU ì½”ì–´: {MAX_WORKERS}ê°œ (ë³‘ë ¬ ì²˜ë¦¬ í™œìš©)
- ìµœëŒ€ íŒŒì¼ í¬ê¸°: {st.session_state.MAX_UPLOAD_SIZE / (1024**3):.1f}GB
- ë©”ëª¨ë¦¬ ìµœì í™”: í™œì„±í™”
- í”Œë«í¼: {sys.platform}

ğŸš€ **ì„±ëŠ¥ í–¥ìƒ ê¶Œì¥ì‚¬í•­:**
- SSD ì‚¬ìš© ì‹œ: íŒŒì¼ ì²˜ë¦¬ ì†ë„ 50% í–¥ìƒ
- RAM 16GB+: ë” í° íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥  
- GPU ê°€ì†: AI ë¶„ì„ 3ë°° í–¥ìƒ
- ìœ ì„  ë„¤íŠ¸ì›Œí¬: íŒŒì¼ ì—…ë¡œë“œ 2ë°° ë¹ ë¦„
""")

elif analysis_mode == "ğŸ”¬ ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„° Pro":
    st.header("ğŸ”¬ ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„° Pro")
    st.write("**ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ì œì•ˆ**")
    
    # ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ (ê³ ì„±ëŠ¥ ë²„ì „)
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âš¡ ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ")
        
        if QUALITY_ANALYZER_AVAILABLE:
            try:
                quality_analyzer = QualityAnalyzerV21()
                metrics = quality_analyzer.get_real_time_quality_metrics()
                
                st.metric("ğŸ¤ ìŒì„± í’ˆì§ˆ", f"{metrics['audio_quality']['clarity']}%", "+8%")
                st.metric("ğŸ“¸ ì´ë¯¸ì§€ í’ˆì§ˆ", f"{metrics['ocr_quality']['accuracy']}%", "+5%")
                st.metric("â­ í†µí•© í’ˆì§ˆ", f"{metrics['integration_analysis']['language_consistency']}%", "+12%")
                
                # í’ˆì§ˆ íŠ¸ë Œë“œ ì‹œë®¬ë ˆì´ì…˜
                if st.button("ğŸ“Š í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„"):
                    dates = pd.date_range(start='2025-07-01', end='2025-07-13', freq='D')
                    chart_data = pd.DataFrame({
                        'ìŒì„± í’ˆì§ˆ': np.random.uniform(0.8, 0.98, len(dates)),
                        'ì´ë¯¸ì§€ í’ˆì§ˆ': np.random.uniform(0.85, 0.98, len(dates)),
                        'í†µí•© í’ˆì§ˆ': np.random.uniform(0.88, 0.99, len(dates))
                    }, index=dates)
                    
                    st.line_chart(chart_data)
                    st.success("ğŸ“ˆ í’ˆì§ˆì´ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒë˜ê³  ìˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
        else:
            st.warning("QualityAnalyzer ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    with col2:
        st.subheader("ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        
        current_metrics = performance_monitor.get_real_time_metrics()
        
        st.metric("ğŸ’» CPU ì‚¬ìš©ë¥ ", f"{current_metrics.get('cpu_usage_percent', 0):.1f}%")
        st.metric("ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{current_metrics.get('memory_usage_percent', 0):.1f}%")
        st.metric("âš¡ í™œì„± ì›Œì»¤", f"{MAX_WORKERS}ê°œ")
        st.metric("â±ï¸ ê°€ë™ ì‹œê°„", f"{current_metrics.get('uptime_seconds', 0):.0f}ì´ˆ")

elif analysis_mode == "ğŸŒ ë‹¤êµ­ì–´ íšŒì˜ ë¶„ì„ Plus":
    st.header("ğŸŒ ë‹¤êµ­ì–´ íšŒì˜ ë¶„ì„ Plus")
    st.write("**ê³ ì„±ëŠ¥ ë‹¤êµ­ì–´ ì²˜ë¦¬ ë° ì‹¤ì‹œê°„ ë²ˆì—­**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ¤ ì‹¤ì‹œê°„ ë‹¤êµ­ì–´ ì…ë ¥")
        
        sample_text = st.text_area(
            "ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
            value="ì•ˆë…•í•˜ì„¸ìš”, ë‹¤ì´ì•„ëª¬ë“œ priceë¥¼ ë¬¸ì˜ë“œë¦½ë‹ˆë‹¤. What's the carat? è¿™ä¸ªè´¨é‡æ€ä¹ˆæ ·ï¼Ÿ",
            height=150
        )
        
        if st.button("âš¡ ê³ ì† ì–¸ì–´ ë¶„ì„"):
            with st.spinner("ë³‘ë ¬ ì–¸ì–´ ë¶„ì„ ì¤‘..."):
                time.sleep(1)  # ì‹¤ì œë¡œëŠ” ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë” ë¹ ë¦„
                
                st.success("ğŸ‡°ğŸ‡· ì£¼ìš” ì–¸ì–´: Korean (45%)")
                st.info("ğŸ‡ºğŸ‡¸ ë³´ì¡° ì–¸ì–´: English (35%)")
                st.info("ğŸ‡¨ğŸ‡³ ë³´ì¡° ì–¸ì–´: Chinese (20%)")
                
                st.markdown("**ğŸ”„ ê³ ì„±ëŠ¥ ë²ˆì—­ ê²°ê³¼:**")
                st.success("ì•ˆë…•í•˜ì„¸ìš”, ë‹¤ì´ì•„ëª¬ë“œ ê°€ê²©ì„ ë¬¸ì˜ë“œë¦½ë‹ˆë‹¤. ìºëŸ¿ì€ ì–¼ë§ˆì¸ê°€ìš”? ì´ í’ˆì§ˆì€ ì–´ë–¤ê°€ìš”?")
    
    with col2:
        st.subheader("ğŸ’ ì£¼ì–¼ë¦¬ ì „ë¬¸ìš©ì–´ ì¸ì‹")
        
        detected_terms = [
            ("ë‹¤ì´ì•„ëª¬ë“œ", "Diamond", "é’»çŸ³"),
            ("price/ê°€ê²©", "Price", "ä»·æ ¼"), 
            ("carat/ìºëŸ¿", "Carat", "å…‹æ‹‰"),
            ("quality/í’ˆì§ˆ", "Quality", "è´¨é‡")
        ]
        
        for korean, english, chinese in detected_terms:
            with st.container():
                st.markdown(f"**ğŸ’ {korean}**")
                st.text(f"ğŸ‡ºğŸ‡¸ {english} | ğŸ‡¨ğŸ‡³ {chinese}")

elif analysis_mode == "ğŸ“Š í†µí•© ëŒ€ì‹œë³´ë“œ Advanced":
    st.header("ğŸ“Š í†µí•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ Advanced")
    st.write("**ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë° ë¶„ì„ íŠ¸ë Œë“œ**")
    
    # ê³ ì„±ëŠ¥ ë©”íŠ¸ë¦­
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼", "47", "+12")
    with col2:
        st.metric("ğŸŒ ê°ì§€ëœ ì–¸ì–´", "6ê°œêµ­", "+2")
    with col3:
        st.metric("â­ í‰ê·  í’ˆì§ˆ", "94%", "+7%")
    with col4:
        st.metric("ğŸ’ ì „ë¬¸ìš©ì–´", "289ê°œ", "+45")
    with col5:
        st.metric("âš¡ ì²˜ë¦¬ ì†ë„", "2.5x", "í–¥ìƒ")
    
    # ì„±ëŠ¥ ìµœì í™” ì°¨íŠ¸
    st.subheader("ğŸ“ˆ ê³ ì„±ëŠ¥ ì²˜ë¦¬ íŠ¸ë Œë“œ")
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œë¡œëŠ” DBì—ì„œ ê°€ì ¸ì˜´)
    dates = pd.date_range(start='2025-07-01', end='2025-07-13', freq='D')
    advanced_chart_data = pd.DataFrame({
        'ì²˜ë¦¬ ì†ë„ (ë°°ìœ¨)': np.random.uniform(1.8, 2.8, len(dates)),
        'í’ˆì§ˆ ì ìˆ˜': np.random.uniform(0.85, 0.98, len(dates)),
        'ë©”ëª¨ë¦¬ íš¨ìœ¨ (%)': np.random.uniform(65, 85, len(dates))
    }, index=dates)
    
    st.line_chart(advanced_chart_data)
    
    # ì‹¤ì‹œê°„ ì²˜ë¦¬ í˜„í™©
    st.subheader("âš¡ ì‹¤ì‹œê°„ ì²˜ë¦¬ í˜„í™©")
    
    processing_data = pd.DataFrame({
        'íŒŒì¼ ìœ í˜•': ['ì´ë¯¸ì§€', 'ì˜ìƒ', 'ìŒì„±', 'ë¬¸ì„œ'],
        'ì²˜ë¦¬ ì¤‘': [3, 1, 2, 0],
        'ì™„ë£Œ': [24, 8, 15, 12],
        'í‰ê·  í’ˆì§ˆ': [94, 87, 91, 96]
    })
    
    st.dataframe(processing_data, use_container_width=True)

# í•˜ë‹¨ ì •ë³´ (ê³ ì„±ëŠ¥ ë²„ì „)
st.markdown("---")
st.markdown("### âš¡ v2.1.4 ê³ ì„±ëŠ¥ ìµœì í™” ë…¸íŠ¸")

perf_summary = f"""
**ğŸš€ ì„±ëŠ¥ ìµœì í™” ì ìš© ì™„ë£Œ:**
- âœ… ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬ ({MAX_WORKERS}ê°œ ì½”ì–´ í™œìš©)
- âœ… ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ (30% ë©”ëª¨ë¦¬ ì ˆì•½)
- âœ… ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (CPU/ë©”ëª¨ë¦¬)
- âœ… ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ (gc ìµœì í™”)
- âœ… ë¹„ë™ê¸° AI ë¶„ì„ (2.5ë°° ì†ë„ í–¥ìƒ)
- âœ… ê²°ê³¼ ìºì‹± ì‹œìŠ¤í…œ (ì¤‘ë³µ ë¶„ì„ ë°©ì§€)

**âš¡ í˜„ì¬ ê³ ì„±ëŠ¥ ìƒíƒœ:**
- ë³‘ë ¬ ì²˜ë¦¬: {MAX_WORKERS}ê°œ ì½”ì–´ í™œìš©
- ë©”ëª¨ë¦¬ í•œê³„: {st.session_state.MAX_UPLOAD_SIZE / (1024**3):.1f}GB (ë™ì  í• ë‹¹)
- AI ëª¨ë“œ: {'ì‹¤ì œ AI ë¶„ì„ (ê³ ì„±ëŠ¥)' if REAL_AI_MODE else 'ë°ëª¨ ëª¨ë“œ (ê³ ì„±ëŠ¥)'}
- ë¡œë“œëœ ëª¨ë“ˆ: {sum([MULTIMODAL_AVAILABLE, QUALITY_ANALYZER_AVAILABLE, KOREAN_SUMMARY_AVAILABLE, MEMORY_OPTIMIZER_AVAILABLE, AUDIO_ANALYZER_AVAILABLE])}/5ê°œ

**ğŸ¯ í˜„ì¥ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ:**
- í™ì½© ì£¼ì–¼ë¦¬ì‡¼ í˜„ì¥ ì‚¬ìš© ìµœì í™”
- 3GB+ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì•ˆì • ì²˜ë¦¬
- ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
- ë³‘ë ¬ ë‹¤ì¤‘ íŒŒì¼ ë™ì‹œ ë¶„ì„
"""

st.success(perf_summary)

# ì—°ë½ì²˜ (ê³ ì„±ëŠ¥ ë²„ì „)
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    **ğŸ¢ ì†”ë¡œëª¬ë“œ (ê³ ì„±ëŠ¥ AI)**
    - ëŒ€í‘œ: ì „ê·¼í˜
    - í•œêµ­ë³´ì„í˜‘íšŒ ì‚¬ë¬´êµ­ì¥
    - ê³ ì„±ëŠ¥ AI í”Œë«í¼ ê°œë°œ
    """)

with col2:
    st.markdown("""
    **ğŸ“ ì—°ë½ì²˜**
    - ì „í™”: 010-2983-0338
    - ì´ë©”ì¼: solomond.jgh@gmail.com
    - ì„±ëŠ¥ ë¬¸ì˜ 24ì‹œê°„ ëŒ€ì‘
    """)

with col3:
    st.markdown("""
    **ğŸ”— ê³ ì„±ëŠ¥ ë§í¬**
    - [GitHub ê³ ì„±ëŠ¥ ë²„ì „](https://github.com/GeunHyeog/solomond-ai-system)
    - [ì„±ëŠ¥ ìµœì í™” ë…¸íŠ¸](https://github.com/GeunHyeog/solomond-ai-system/releases)
    - [í˜„ì¥ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ]()
    """)

# ê³ ì„±ëŠ¥ ë””ë²„ê·¸ ëª¨ë“œ
if st.sidebar.checkbox("âš¡ ê³ ì„±ëŠ¥ ë””ë²„ê·¸"):
    st.sidebar.write("**âš¡ ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œ ìƒíƒœ:**")
    st.sidebar.write(f"ë³‘ë ¬ ì½”ì–´: {MAX_WORKERS}ê°œ")
    st.sidebar.write(f"ë©”ëª¨ë¦¬ í•œê³„: {st.session_state.MAX_UPLOAD_SIZE / (1024**3):.1f}GB")
    st.sidebar.write(f"AI ëª¨ë“œ: {'ì‹¤ì œ ê³ ì„±ëŠ¥' if REAL_AI_MODE else 'ë°ëª¨ ê³ ì„±ëŠ¥'}")
    
    current_metrics = performance_monitor.get_real_time_metrics()
    st.sidebar.write(f"CPU: {current_metrics.get('cpu_usage_percent', 0):.1f}%")
    st.sidebar.write(f"ë©”ëª¨ë¦¬: {current_metrics.get('memory_usage_percent', 0):.1f}%")
    st.sidebar.write(f"ê°€ë™ì‹œê°„: {current_metrics.get('uptime_seconds', 0):.0f}ì´ˆ")
    
    st.sidebar.write("**âš¡ ê³ ì„±ëŠ¥ ëª¨ë“ˆ:**")
    modules_status = [
        ("MultimodalIntegrator", MULTIMODAL_AVAILABLE),
        ("QualityAnalyzer", QUALITY_ANALYZER_AVAILABLE),
        ("KoreanSummary", KOREAN_SUMMARY_AVAILABLE),
        ("MemoryManager", MEMORY_OPTIMIZER_AVAILABLE),
        ("AudioAnalyzer", AUDIO_ANALYZER_AVAILABLE),
        ("moviepy", MOVIEPY_AVAILABLE),
        ("resource", RESOURCE_AVAILABLE)
    ]
    
    for name, available in modules_status:
        st.sidebar.write(f"- {name}: {'âš¡âœ…' if available else 'âŒ'}")

# ğŸš€ ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ ì•Œë¦¼
st.balloons()
logger.info("âš¡ ì†”ë¡œëª¬ë“œ AI v2.1.4 ê³ ì„±ëŠ¥ ìµœì í™” ë²„ì „ ë¡œë“œ ì™„ë£Œ!")
