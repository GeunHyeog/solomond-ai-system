#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”— Serena MCP Integration Module
Claude Code MCP ë„êµ¬ë“¤ê³¼ Serena ì—ì´ì „íŠ¸ ì™„ì „ í†µí•©

ì´ ëª¨ë“ˆì€ Claude Codeì˜ MCP (Model Context Protocol) ë„êµ¬ë“¤ì„ í™œìš©í•˜ì—¬
Serena ì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

MCP ë„êµ¬ í™œìš©:
- Read: íŒŒì¼ ë‚´ìš© ì •ë°€ ë¶„ì„
- Glob: í”„ë¡œì íŠ¸ íŒŒì¼ íŒ¨í„´ ë§¤ì¹­
- Edit/MultiEdit: ìë™ ì½”ë“œ ìˆ˜ì •
- Grep: ê³ ê¸‰ íŒ¨í„´ ê²€ìƒ‰
- Git: ë²„ì „ ê´€ë¦¬ í†µí•©

Author: SOLOMOND AI Team & Serena
Version: 1.0.0
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

@dataclass
class SerenaAnalysisConfig:
    """Serena ë¶„ì„ ì„¤ì •"""
    project_name: str = "SOLOMOND_AI"
    analysis_depth: str = "comprehensive"  # basic, standard, comprehensive
    focus_areas: List[str] = None
    exclude_patterns: List[str] = None
    
    def __post_init__(self):
        if self.focus_areas is None:
            self.focus_areas = [
                "threadpool_management",
                "memory_optimization", 
                "streamlit_performance",
                "ollama_integration",
                "gpu_memory_handling"
            ]
        
        if self.exclude_patterns is None:
            self.exclude_patterns = [
                "venv/*", "__pycache__/*", ".git/*", 
                "*.backup", "*.log", "archive/*"
            ]

class SerenaMCPIntegration:
    """Serenaì™€ Claude Code MCP ë„êµ¬ í†µí•©"""
    
    def __init__(self, config: SerenaAnalysisConfig = None):
        self.config = config or SerenaAnalysisConfig()
        self.analysis_patterns = self._load_analysis_patterns()
        self.project_root = Path.cwd()
        
    def _load_analysis_patterns(self) -> Dict[str, Dict[str, Any]]:
        """SOLOMOND AI íŠ¹í™” ë¶„ì„ íŒ¨í„´ ë¡œë“œ"""
        return {
            # í¬ë¦¬í‹°ì»¬ ì´ìŠˆ íŒ¨í„´
            "threadpool_resource_leak": {
                "pattern": r"ThreadPoolExecutor\([^)]*\)(?!\s*as\s+\w+:)(?!\s*with)",
                "severity": "critical",
                "category": "resource_management",
                "description": "ThreadPoolExecutor without proper resource management",
                "impact": "Memory leak and resource exhaustion",
                "fix_template": "with ThreadPoolExecutor({params}) as executor:",
                "solomond_impact": "ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì— ì§ì ‘ì  ì˜í–¥"
            },
            
            "gpu_memory_leak": {
                "pattern": r"torch\.cuda\.(?!empty_cache).*\n(?!.*torch\.cuda\.empty_cache)",
                "severity": "critical", 
                "category": "memory_management",
                "description": "CUDA operations without memory cleanup",
                "impact": "GPU memory accumulation leading to OOM errors",
                "fix_template": "# Add: torch.cuda.empty_cache() after CUDA operations",
                "solomond_impact": "AI ëª¨ë¸ ë¡œë”© ë° GPU ê¸°ë°˜ ë¶„ì„ì—ì„œ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ"
            },
            
            "streamlit_performance_issue": {
                "pattern": r"def\s+\w+.*:\s*\n(?:.*\n)*?.*(?:heavy_computation|model\.load|large_file_processing).*\n(?!.*@st\.cache)",
                "severity": "high",
                "category": "performance",
                "description": "Heavy computation without Streamlit caching",
                "impact": "Poor user experience and resource waste",
                "fix_template": "@st.cache_data\ndef function_name():",
                "solomond_impact": "ì‚¬ìš©ì ëŒ€ê¸°ì‹œê°„ ì¦ê°€, ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë‚­ë¹„"
            },
            
            "ollama_error_handling_missing": {
                "pattern": r"ollama\.(?:generate|chat|pull)\([^)]*\)(?!\s*\n\s*(?:try|except))",
                "severity": "high",
                "category": "error_handling", 
                "description": "Ollama API calls without error handling",
                "impact": "Application crashes on API failures",
                "fix_template": "try:\n    ollama.{method}({params})\nexcept Exception as e:\n    handle_error(e)",
                "solomond_impact": "AI ë¶„ì„ ì¤‘ë‹¨, ì‚¬ìš©ì ê²½í—˜ ì €í•˜"
            },
            
            "file_io_resource_leak": {
                "pattern": r"open\([^)]*\)(?!\s*as\s+\w+:)(?!\s*with)",
                "severity": "medium",
                "category": "resource_management",
                "description": "File operations without context manager",
                "impact": "File handle leaks",
                "fix_template": "with open({params}) as file:",
                "solomond_impact": "íŒŒì¼ ì²˜ë¦¬ ê³¼ì •ì—ì„œ ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜ ë°œìƒ"
            },
            
            "multimodal_sync_issue": {
                "pattern": r"(?:audio|image|video)_process.*\n.*(?:threading|concurrent).*(?!.*join|wait)",
                "severity": "medium",
                "category": "concurrency",
                "description": "Multimodal processing without proper synchronization",
                "impact": "Race conditions in media processing",
                "fix_template": "# Add proper thread synchronization",
                "solomond_impact": "ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±"
            }
        }
    
    def analyze_with_mcp_tools(self, target_files: List[str] = None) -> Dict[str, Any]:
        """
        MCP ë„êµ¬ë“¤ì„ í™œìš©í•œ ì¢…í•© ë¶„ì„
        
        ì´ ë©”ì„œë“œëŠ” Claude Codeì˜ MCP ë„êµ¬ë“¤ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬
        ì‹¤ì œ ì„œë¸Œì—ì´ì „íŠ¸ í™˜ê²½ì—ì„œì˜ ë™ì‘ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
        """
        analysis_start = datetime.now()
        
        result = {
            "serena_agent": {
                "name": "Serena SOLOMOND AI ì „ë¬¸ê°€",
                "version": "1.0.0",
                "analysis_type": "MCP í†µí•© ë¶„ì„"
            },
            "analysis_metadata": {
                "timestamp": analysis_start.isoformat(),
                "config": self.config.__dict__,
                "tools_used": ["Read", "Glob", "Grep", "Git"],
                "duration_ms": 0
            },
            "project_summary": {
                "files_analyzed": 0,
                "total_lines": 0,
                "total_issues": 0,
                "critical_issues": 0,
                "high_issues": 0,
                "medium_issues": 0
            },
            "detailed_findings": [],
            "optimization_recommendations": [],
            "auto_fix_candidates": [],
            "solomond_specific_insights": []
        }
        
        try:
            # 1. Glob íŒ¨í„´ìœ¼ë¡œ ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ì°¾ê¸°
            if not target_files:
                target_files = self._find_target_files()
            
            # 2. ê° íŒŒì¼ ì •ë°€ ë¶„ì„ 
            for file_path in target_files:
                file_analysis = self._analyze_file_with_mcp(file_path)
                if file_analysis:
                    result["detailed_findings"].append(file_analysis)
                    result["project_summary"]["files_analyzed"] += 1
                    result["project_summary"]["total_lines"] += file_analysis.get("line_count", 0)
                    
                    # ì´ìŠˆ ì¹´ìš´íŠ¸
                    for issue in file_analysis.get("issues", []):
                        severity = issue.get("severity", "medium")
                        result["project_summary"]["total_issues"] += 1
                        result["project_summary"][f"{severity}_issues"] += 1
            
            # 3. ìµœì í™” ì¶”ì²œì‚¬í•­ ìƒì„±
            result["optimization_recommendations"] = self._generate_mcp_recommendations(result)
            
            # 4. ìë™ ìˆ˜ì • í›„ë³´ ì‹ë³„
            result["auto_fix_candidates"] = self._identify_auto_fix_candidates(result)
            
            # 5. SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸
            result["solomond_specific_insights"] = self._generate_solomond_insights(result)
            
            # ë¶„ì„ ì‹œê°„ ê³„ì‚°
            analysis_end = datetime.now()
            duration = (analysis_end - analysis_start).total_seconds() * 1000
            result["analysis_metadata"]["duration_ms"] = round(duration, 2)
            
        except Exception as e:
            result["error"] = {
                "message": f"MCP ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
        
        return result
    
    def _find_target_files(self) -> List[str]:
        """ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ì°¾ê¸° (Glob ì‹œë®¬ë ˆì´ì…˜)"""
        # SOLOMOND AI í•µì‹¬ íŒŒì¼ë“¤ ìš°ì„ ìˆœìœ„
        priority_files = [
            "conference_analysis_COMPLETE_WORKING.py",
            "solomond_ai_main_dashboard.py",
            "dual_brain_integration.py", 
            "ai_insights_engine.py",
            "google_calendar_connector.py",
            "hybrid_compute_manager.py"
        ]
        
        target_files = []
        
        # ìš°ì„ ìˆœìœ„ íŒŒì¼ë“¤ ì¶”ê°€
        for file_name in priority_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                target_files.append(str(file_path))
        
        # core ë””ë ‰í† ë¦¬ ì¶”ê°€ ë¶„ì„
        core_dir = self.project_root / "core"
        if core_dir.exists():
            core_files = [
                "multimodal_pipeline.py",
                "batch_processing_engine.py", 
                "memory_optimizer.py",
                "ollama_integration_engine.py"
            ]
            
            for file_name in core_files:
                file_path = core_dir / file_name
                if file_path.exists():
                    target_files.append(str(file_path))
        
        return target_files
    
    def _analyze_file_with_mcp(self, file_path: str) -> Optional[Dict[str, Any]]:
        """MCP Read ë„êµ¬ë¥¼ í™œìš©í•œ íŒŒì¼ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            file_analysis = {
                "file_path": str(Path(file_path).name),
                "full_path": file_path,
                "line_count": len(lines),
                "issues": [],
                "metrics": {
                    "complexity_score": 0,
                    "solomond_relevance": 0,
                    "performance_impact": 0
                }
            }
            
            # íŒ¨í„´ë³„ ë¶„ì„
            for pattern_name, pattern_info in self.analysis_patterns.items():
                matches = re.finditer(
                    pattern_info["pattern"],
                    content, 
                    re.MULTILINE | re.DOTALL
                )
                
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    
                    issue = {
                        "line": line_num,
                        "pattern": pattern_name,
                        "severity": pattern_info["severity"],
                        "category": pattern_info["category"],
                        "description": pattern_info["description"],
                        "impact": pattern_info["impact"],
                        "solomond_impact": pattern_info["solomond_impact"],
                        "code_snippet": lines[line_num - 1].strip() if line_num <= len(lines) else "",
                        "fix_suggestion": pattern_info["fix_template"],
                        "confidence": 0.9
                    }
                    
                    file_analysis["issues"].append(issue)
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            file_analysis["metrics"] = self._calculate_file_metrics(file_path, content, file_analysis["issues"])
            
            return file_analysis
            
        except Exception as e:
            return {
                "file_path": str(Path(file_path).name),
                "error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            }
    
    def _calculate_file_metrics(self, file_path: str, content: str, issues: List[Dict]) -> Dict[str, float]:
        """íŒŒì¼ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {
            "complexity_score": 0,
            "solomond_relevance": 0, 
            "performance_impact": 0
        }
        
        # ë³µì¡ë„ ì ìˆ˜ (ì´ìŠˆ ì‹¬ê°ë„ ê¸°ë°˜)
        severity_weights = {"critical": 10, "high": 6, "medium": 3, "low": 1}
        complexity = sum(severity_weights.get(issue["severity"], 1) for issue in issues)
        metrics["complexity_score"] = min(complexity / 10.0, 10.0)  # 0-10 ìŠ¤ì¼€ì¼
        
        # SOLOMOND AI ê´€ë ¨ì„± ì ìˆ˜
        solomond_keywords = [
            "streamlit", "conference", "analysis", "ollama", "whisper",
            "easyocr", "multimodal", "threadpool", "gpu", "solomond"
        ]
        
        keyword_count = sum(1 for keyword in solomond_keywords if keyword.lower() in content.lower())
        metrics["solomond_relevance"] = min(keyword_count / 5.0, 10.0)  # 0-10 ìŠ¤ì¼€ì¼
        
        # ì„±ëŠ¥ ì˜í–¥ ì ìˆ˜ (í¬ë¦¬í‹°ì»¬/í•˜ì´ ì´ìŠˆ ê¸°ë°˜)
        performance_issues = [i for i in issues if i["severity"] in ["critical", "high"]]
        metrics["performance_impact"] = min(len(performance_issues) * 2.0, 10.0)
        
        return metrics
    
    def _generate_mcp_recommendations(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """MCP ë„êµ¬ ê¸°ë°˜ ìµœì í™” ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        project_summary = analysis_result["project_summary"]
        
        # í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ì¶”ì²œ
        if project_summary["critical_issues"] > 0:
            recommendations.append({
                "priority": "critical",
                "category": "stability",
                "title": "ì‹œìŠ¤í…œ ì•ˆì •ì„± í¬ë¦¬í‹°ì»¬ ì´ìŠˆ í•´ê²°",
                "description": f"{project_summary['critical_issues']}ê°œì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                             "ThreadPool ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì™€ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ê°€ ìš°ì„  í•„ìš”í•©ë‹ˆë‹¤.",
                "action": "ì¦‰ì‹œ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰",
                "estimated_time": "30ë¶„",
                "tools": ["Edit", "MultiEdit"],
                "solomond_benefit": "ì‹œìŠ¤í…œ í¬ë˜ì‹œ ë°©ì§€, ì•ˆì •ì  ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ë³´ì¥"
            })
        
        # ì„±ëŠ¥ ìµœì í™” ì¶”ì²œ
        if project_summary["high_issues"] > 2:
            recommendations.append({
                "priority": "high",
                "category": "performance", 
                "title": "Streamlit ìºì‹± ì‹œìŠ¤í…œ ë„ì…",
                "description": "ë¬´ê±°ìš´ AI ëª¨ë¸ ë¡œë”©ê³¼ ë°ì´í„° ì²˜ë¦¬ì— ìºì‹±ì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
                "action": "@st.cache_data ë°ì½”ë ˆì´í„° ì¶”ê°€",
                "estimated_time": "1ì‹œê°„",
                "tools": ["Edit", "Grep"],
                "solomond_benefit": "ì‚¬ìš©ì ëŒ€ê¸°ì‹œê°„ 50% ë‹¨ì¶•, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê°ì†Œ"
            })
        
        # ì½”ë“œ í’ˆì§ˆ ê°œì„ 
        total_issues = project_summary["total_issues"]
        if total_issues > 5:
            recommendations.append({
                "priority": "medium",
                "category": "quality",
                "title": "ì½”ë“œ í’ˆì§ˆ ì „ë°˜ì  ê°œì„ ",
                "description": f"ì´ {total_issues}ê°œì˜ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                             "ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”ì™€ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "action": "ë‹¨ê³„ë³„ ë¦¬íŒ©í† ë§ ìˆ˜í–‰",
                "estimated_time": "2-3ì‹œê°„",
                "tools": ["Read", "Edit", "Git"],
                "solomond_benefit": "ì‹œìŠ¤í…œ ì‹ ë¢°ì„± í–¥ìƒ, ìœ ì§€ë³´ìˆ˜ì„± ê°œì„ "
            })
        
        return recommendations
    
    def _identify_auto_fix_candidates(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ìë™ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆë“¤ ì‹ë³„"""
        auto_fix_candidates = []
        
        for file_analysis in analysis_result["detailed_findings"]:
            for issue in file_analysis.get("issues", []):
                # ThreadPool ì´ìŠˆëŠ” ìë™ ìˆ˜ì • ê°€ëŠ¥
                if issue["pattern"] == "threadpool_resource_leak":
                    auto_fix_candidates.append({
                        "file": file_analysis["file_path"],
                        "line": issue["line"],
                        "issue_type": issue["pattern"],
                        "current_code": issue["code_snippet"],
                        "fixed_code": "with ThreadPoolExecutor() as executor:",
                        "confidence": 0.95,
                        "description": "ThreadPoolExecutorë¥¼ with ë¬¸ìœ¼ë¡œ ë³€ê²½"
                    })
                
                # íŒŒì¼ IO ì´ìŠˆë„ ìë™ ìˆ˜ì • ê°€ëŠ¥
                elif issue["pattern"] == "file_io_resource_leak":
                    auto_fix_candidates.append({
                        "file": file_analysis["file_path"],
                        "line": issue["line"],
                        "issue_type": issue["pattern"],
                        "current_code": issue["code_snippet"],
                        "fixed_code": "with open(...) as file:",
                        "confidence": 0.90,
                        "description": "íŒŒì¼ ì—´ê¸°ë¥¼ with ë¬¸ìœ¼ë¡œ ë³€ê²½"
                    })
        
        return auto_fix_candidates
    
    def _generate_solomond_insights(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """SOLOMOND AI ì‹œìŠ¤í…œ íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ì‹œìŠ¤í…œ ì•ˆì •ì„± ì¸ì‚¬ì´íŠ¸
        critical_count = analysis_result["project_summary"]["critical_issues"]
        if critical_count == 0:
            insights.append({
                "category": "stability",
                "level": "positive",
                "title": "ì‹œìŠ¤í…œ ì•ˆì •ì„± ì–‘í˜¸",
                "message": "í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•„ SOLOMOND AI ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "impact": "ì‚¬ìš©ì ê²½í—˜ ì•ˆì •ì„± ë³´ì¥"
            })
        else:
            insights.append({
                "category": "stability", 
                "level": "warning",
                "title": "ì‹œìŠ¤í…œ ì•ˆì •ì„± ì£¼ì˜ í•„ìš”",
                "message": f"{critical_count}ê°œì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆë¡œ ì¸í•´ ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.",
                "impact": "ë¶„ì„ ì¤‘ë‹¨, ë°ì´í„° ì†ì‹¤ ìœ„í—˜"
            })
        
        # ì„±ëŠ¥ ì¸ì‚¬ì´íŠ¸
        files_with_performance_issues = sum(
            1 for file_analysis in analysis_result["detailed_findings"]
            if any(issue["category"] == "performance" for issue in file_analysis.get("issues", []))
        )
        
        if files_with_performance_issues > 0:
            insights.append({
                "category": "performance",
                "level": "improvement",
                "title": "ì„±ëŠ¥ ìµœì í™” ê¸°íšŒ",
                "message": f"{files_with_performance_issues}ê°œ íŒŒì¼ì—ì„œ ì„±ëŠ¥ ê°œì„  ì—¬ì§€ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                          "Streamlit ìºì‹±ê³¼ ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”ë¡œ ì‚¬ìš©ì ê²½í—˜ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "impact": "ì‘ë‹µ ì†ë„ í–¥ìƒ, ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ì¦ëŒ€"
            })
        
        # AI í†µí•© ì¸ì‚¬ì´íŠ¸
        ollama_issues = sum(
            1 for file_analysis in analysis_result["detailed_findings"]
            for issue in file_analysis.get("issues", [])
            if "ollama" in issue["pattern"]
        )
        
        if ollama_issues > 0:
            insights.append({
                "category": "ai_integration",
                "level": "enhancement",
                "title": "AI ëª¨ë¸ í†µí•© ê°œì„ ",
                "message": f"Ollama AI í†µí•©ì—ì„œ {ollama_issues}ê°œì˜ ê°œì„ ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "
                          "ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”ë¡œ AI ë¶„ì„ì˜ ì‹ ë¢°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "impact": "AI ë¶„ì„ ì„±ê³µë¥  í–¥ìƒ, ì˜¤ë¥˜ ë³µêµ¬ ëŠ¥ë ¥ ê°•í™”"
            })
        
        return insights

def run_serena_analysis():
    """Serena MCP í†µí•© ë¶„ì„ ì‹¤í–‰"""
    print("ğŸ¤– Serena - SOLOMOND AI ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸")
    print("ğŸ”— Claude Code MCP í†µí•© ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    # ë¶„ì„ ì„¤ì •
    config = SerenaAnalysisConfig(
        analysis_depth="comprehensive",
        focus_areas=[
            "threadpool_management",
            "memory_optimization",
            "streamlit_performance", 
            "ollama_integration",
            "solomond_stability"
        ]
    )
    
    # MCP í†µí•© ë¶„ì„ ì‹¤í–‰
    serena_mcp = SerenaMCPIntegration(config)
    result = serena_mcp.analyze_with_mcp_tools()
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ - {result['analysis_metadata']['duration_ms']:.1f}ms")
    print(f"ğŸ“ ë¶„ì„ëœ íŒŒì¼: {result['project_summary']['files_analyzed']}ê°œ")
    print(f"ğŸ“ ì´ ì½”ë“œ ë¼ì¸: {result['project_summary']['total_lines']:,}ì¤„")
    print(f"ğŸ” ë°œê²¬ëœ ì´ìŠˆ: {result['project_summary']['total_issues']}ê°œ")
    
    if result['project_summary']['critical_issues'] > 0:
        print(f"ğŸš¨ í¬ë¦¬í‹°ì»¬: {result['project_summary']['critical_issues']}ê°œ")
    if result['project_summary']['high_issues'] > 0:
        print(f"âš ï¸  ë†’ìŒ: {result['project_summary']['high_issues']}ê°œ")
    if result['project_summary']['medium_issues'] > 0:
        print(f"ğŸ“‹ ë³´í†µ: {result['project_summary']['medium_issues']}ê°œ")
    
    # ì¶”ì²œì‚¬í•­ í‘œì‹œ
    if result['optimization_recommendations']:
        print(f"\nğŸ’¡ Serenaì˜ ìµœì í™” ì¶”ì²œì‚¬í•­:")
        for i, rec in enumerate(result['optimization_recommendations'], 1):
            print(f"  {i}. [{rec['priority'].upper()}] {rec['title']}")
            print(f"     {rec['description']}")
            print(f"     ğŸ’ SOLOMOND íš¨ê³¼: {rec['solomond_benefit']}")
    
    # SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸
    if result['solomond_specific_insights']:
        print(f"\nğŸ§  SOLOMOND AI ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸:")
        for insight in result['solomond_specific_insights']:
            emoji = {"positive": "âœ…", "warning": "âš ï¸", "improvement": "ğŸ“ˆ", "enhancement": "ğŸ”§"}
            print(f"  {emoji.get(insight['level'], 'ğŸ’¡')} {insight['title']}")
            print(f"     {insight['message']}")
    
    # ìë™ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆë“¤
    if result['auto_fix_candidates']:
        print(f"\nğŸ”§ ìë™ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆ: {len(result['auto_fix_candidates'])}ê°œ")
        print("ğŸ’¡ Serenaê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ì´ìŠˆë“¤ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return result

if __name__ == "__main__":
    run_serena_analysis()