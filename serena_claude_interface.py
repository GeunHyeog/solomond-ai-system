#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– Serena Claude Code Interface
Claude Codeì˜ /agent serena ëª…ë ¹ì–´ ì¸í„°í˜ì´ìŠ¤

ì´ ëª¨ë“ˆì€ Claude Codeì—ì„œ /agent serena ëª…ë ¹ì–´ë¡œ í˜¸ì¶œë˜ëŠ”
ì‹¤ì œ ì„œë¸Œì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
/agent serena analyze          # ì½”ë“œ ë¶„ì„ ìˆ˜í–‰
/agent serena fix             # ìë™ ìˆ˜ì • ì ìš©
/agent serena health          # í”„ë¡œì íŠ¸ ê±´ê°•ë„ ì²´í¬  
/agent serena optimize        # ì„±ëŠ¥ ìµœì í™” ì œì•ˆ
/agent serena info            # ì—ì´ì „íŠ¸ ì •ë³´
/agent serena help            # ë„ì›€ë§

Author: Serena & SOLOMOND AI Team
Version: 1.0.0
For: Claude Code Sub-Agent System
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# Serena ëª¨ë“ˆë“¤ ì„í¬íŠ¸
try:
    from serena_claude_agent import SerenaClaudeAgent
    from serena_mcp_integration import SerenaMCPIntegration, SerenaAnalysisConfig
    from serena_auto_optimizer import SerenaAutoOptimizer
    from agent_serena_integration import SerenaCodeAnalyzer
except ImportError as e:
    print(f"âŒ Serena ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ’¡ ëª¨ë“  serena_*.py íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

class SerenaClaudeInterface:
    """Serena Claude Code ì„œë¸Œì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.agent_name = "serena"
        self.version = "1.0.0"
        self.persona = {
            "name": "Serena",
            "role": "SOLOMOND AI ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸",
            "greeting": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” SOLOMOND AI ì‹œìŠ¤í…œ ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸ Serenaì…ë‹ˆë‹¤. ğŸ¤–",
            "expertise": [
                "Python ì½”ë“œ Symbol-level ë¶„ì„",
                "ThreadPool ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ìµœì í™”", 
                "GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íƒì§€ ë° í•´ê²°",
                "Streamlit ì„±ëŠ¥ ìµœì í™”",
                "Ollama AI í†µí•© ì•ˆì •ì„± ê°œì„ ",
                "SOLOMOND AI ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¶„ì„"
            ]
        }
        
        # ëª…ë ¹ì–´ ë§¤í•‘
        self.commands = {
            "analyze": self.cmd_analyze,
            "fix": self.cmd_fix,
            "health": self.cmd_health,
            "optimize": self.cmd_optimize,
            "info": self.cmd_info,
            "help": self.cmd_help,
            "status": self.cmd_status,
            "report": self.cmd_report
        }
    
    def process_command(self, command: str, args: List[str] = None) -> Dict[str, Any]:
        """ëª…ë ¹ì–´ ì²˜ë¦¬"""
        if command not in self.commands:
            return self._error_response(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}. 'help'ë¥¼ ì…ë ¥í•˜ì—¬ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        try:
            return self.commands[command](args or [])
        except Exception as e:
            return self._error_response(f"ëª…ë ¹ì–´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def cmd_analyze(self, args: List[str]) -> Dict[str, Any]:
        """ì½”ë“œ ë¶„ì„ ëª…ë ¹ì–´"""
        print("ğŸ” Serena: SOLOMOND AI ì‹œìŠ¤í…œ ì½”ë“œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            # MCP í†µí•© ë¶„ì„ ì‹¤í–‰
            config = SerenaAnalysisConfig(
                analysis_depth="comprehensive",
                focus_areas=[
                    "threadpool_management",
                    "memory_optimization",
                    "streamlit_performance",
                    "ollama_integration"
                ]
            )
            
            mcp_integration = SerenaMCPIntegration(config)
            result = mcp_integration.analyze_with_mcp_tools()
            
            # ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ ìƒì„±
            response = {
                "status": "success",
                "command": "analyze",
                "serena_response": self._format_analysis_response(result),
                "raw_data": result,
                "timestamp": datetime.now().isoformat()
            }
            
            return response
            
        except Exception as e:
            return self._error_response(f"ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
    
    def cmd_fix(self, args: List[str]) -> Dict[str, Any]:
        """ìë™ ìˆ˜ì • ëª…ë ¹ì–´"""
        print("ğŸ”§ Serena: ìë™ ìˆ˜ì • ì‹œìŠ¤í…œì„ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        
        # í™•ì¸ ëª¨ë“œ (ê¸°ë³¸ê°’)
        auto_apply = "--auto" in args
        
        if not auto_apply:
            print("ğŸ’¡ ì•ˆì „ì„ ìœ„í•´ ë¶„ì„ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‹¤ì œ ìˆ˜ì •ì„ ì›í•˜ë©´ --auto í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        try:
            optimizer = SerenaAutoOptimizer()
            result = optimizer.analyze_and_fix_project(auto_apply=auto_apply)
            
            # ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ìˆëŠ” ê²½ìš°)
            script_generated = False
            if result["analysis_summary"]["critical_fixes"] > 0:
                fix_script = optimizer.generate_auto_fix_script(result)
                script_path = Path("serena_auto_fix.py")
                
                with open(script_path, 'w', encoding='utf-8') as f:
                    f.write(fix_script)
                
                script_generated = True
                print(f"ğŸ“ ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")
            
            response = {
                "status": "success",
                "command": "fix",
                "serena_response": self._format_fix_response(result, auto_apply, script_generated),
                "raw_data": result,
                "timestamp": datetime.now().isoformat()
            }
            
            return response
            
        except Exception as e:
            return self._error_response(f"ìë™ ìˆ˜ì • ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
    
    def cmd_health(self, args: List[str]) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ê±´ê°•ë„ ì²´í¬ ëª…ë ¹ì–´"""
        print("ğŸ¥ Serena: SOLOMOND AI ì‹œìŠ¤í…œ ê±´ê°•ë„ë¥¼ ê²€ì§„í•©ë‹ˆë‹¤...")
        
        try:
            claude_agent = SerenaClaudeAgent()
            result = claude_agent.analyze_project()
            
            # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°
            health_score = result.get("health_score", 0)
            
            # ê±´ê°•ë„ ë“±ê¸‰ ê²°ì •
            if health_score >= 90:
                health_grade = "ìµœìš°ìˆ˜ ğŸ†"
                health_emoji = "ğŸ’š"
            elif health_score >= 80:
                health_grade = "ìš°ìˆ˜ â­"
                health_emoji = "ğŸ’š"
            elif health_score >= 70:
                health_grade = "ì–‘í˜¸ ğŸ‘"
                health_emoji = "ğŸ’›"
            elif health_score >= 60:
                health_grade = "ë³´í†µ ğŸ‘Œ"
                health_emoji = "ğŸ§¡"
            else:
                health_grade = "ì£¼ì˜ í•„ìš” âš ï¸"
                health_emoji = "â¤ï¸"
            
            response = {
                "status": "success",
                "command": "health",
                "serena_response": self._format_health_response(result, health_score, health_grade, health_emoji),
                "raw_data": result,
                "timestamp": datetime.now().isoformat()
            }
            
            return response
            
        except Exception as e:
            return self._error_response(f"ê±´ê°•ë„ ì²´í¬ ì‹¤íŒ¨: {str(e)}")
    
    def cmd_optimize(self, args: List[str]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìµœì í™” ì œì•ˆ ëª…ë ¹ì–´"""
        print("âš¡ Serena: ì„±ëŠ¥ ìµœì í™” ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        
        try:
            # ì¢…í•© ë¶„ì„ ì‹¤í–‰
            mcp_integration = SerenaMCPIntegration()
            analysis_result = mcp_integration.analyze_with_mcp_tools()
            
            # ìµœì í™” ì œì•ˆ ì¶”ì¶œ
            recommendations = analysis_result.get("optimization_recommendations", [])
            insights = analysis_result.get("solomond_specific_insights", [])
            
            response = {
                "status": "success", 
                "command": "optimize",
                "serena_response": self._format_optimize_response(recommendations, insights),
                "raw_data": analysis_result,
                "timestamp": datetime.now().isoformat()
            }
            
            return response
            
        except Exception as e:
            return self._error_response(f"ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    def cmd_info(self, args: List[str]) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì •ë³´ ëª…ë ¹ì–´"""
        claude_agent = SerenaClaudeAgent()
        agent_info = claude_agent.get_agent_info()
        
        response = {
            "status": "success",
            "command": "info",
            "serena_response": self._format_info_response(agent_info),
            "raw_data": agent_info,
            "timestamp": datetime.now().isoformat()
        }
        
        return response
    
    def cmd_help(self, args: List[str]) -> Dict[str, Any]:
        """ë„ì›€ë§ ëª…ë ¹ì–´"""
        help_text = """
ğŸ¤– Serena - SOLOMOND AI ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸

ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:

ğŸ” analyze          - SOLOMOND AI ì‹œìŠ¤í…œ ì¢…í•© ì½”ë“œ ë¶„ì„
                      Symbol-level ë¶„ì„ìœ¼ë¡œ ThreadPool, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜, 
                      ì„±ëŠ¥ ë³‘ëª©ì ì„ ì •ë°€í•˜ê²Œ íƒì§€í•©ë‹ˆë‹¤.

ğŸ”§ fix [--auto]     - ìë™ ìˆ˜ì • ì‹œìŠ¤í…œ
                      --auto: ì¦‰ì‹œ ìˆ˜ì • ì ìš© (ìœ„í—˜)
                      ê¸°ë³¸ê°’: ë¶„ì„ í›„ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

ğŸ¥ health           - í”„ë¡œì íŠ¸ ê±´ê°•ë„ ì§„ë‹¨
                      ì‹œìŠ¤í…œ ì•ˆì •ì„±ê³¼ ì½”ë“œ í’ˆì§ˆì„ ì ìˆ˜ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

âš¡ optimize         - ì„±ëŠ¥ ìµœì í™” ì œì•ˆ
                      Streamlit ìºì‹±, GPU ë©”ëª¨ë¦¬ ê´€ë¦¬, 
                      Ollama í†µí•© ìµœì í™” ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.

â„¹ï¸  info             - Serena ì—ì´ì „íŠ¸ ì •ë³´
                      ì „ë¬¸ ë¶„ì•¼, ê¸°ëŠ¥, ë²„ì „ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

ğŸ“Š status           - í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ê°„ë‹¨ ì²´í¬

ğŸ“ˆ report           - ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±

â“ help             - ì´ ë„ì›€ë§

ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:
   /agent serena analyze
   /agent serena fix --auto
   /agent serena health
   /agent serena optimize

ğŸ¯ Serenaì˜ íŠ¹í™” ì˜ì—­:
   â€¢ SOLOMOND AI ì»¨í¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ ìµœì í™”
   â€¢ ThreadPoolExecutor ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ìë™í™”
   â€¢ GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íƒì§€ ë° í•´ê²°
   â€¢ Streamlit ì„±ëŠ¥ íŠœë‹
   â€¢ Ollama AI ëª¨ë¸ í†µí•© ì•ˆì •ì„± ê°œì„ 
"""
        
        response = {
            "status": "success",
            "command": "help",
            "serena_response": help_text,
            "timestamp": datetime.now().isoformat()
        }
        
        return response
    
    def cmd_status(self, args: List[str]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ê°„ë‹¨ ì²´í¬"""
        print("ğŸ“Š Serena: ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤...")
        
        try:
            # í•µì‹¬ íŒŒì¼ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            core_files = [
                "conference_analysis_COMPLETE_WORKING.py",
                "solomond_ai_main_dashboard.py",
                "dual_brain_integration.py"
            ]
            
            file_status = {}
            for file_name in core_files:
                file_path = Path(file_name)
                file_status[file_name] = {
                    "exists": file_path.exists(),
                    "size_kb": file_path.stat().st_size // 1024 if file_path.exists() else 0
                }
            
            # ê°„ë‹¨í•œ ë¶„ì„ ì‹¤í–‰
            claude_agent = SerenaClaudeAgent()
            quick_result = claude_agent.analyze_project(core_files[:2])  # 2ê°œ íŒŒì¼ë§Œ ë¹ ë¥´ê²Œ
            
            response = {
                "status": "success",
                "command": "status",
                "serena_response": self._format_status_response(file_status, quick_result),
                "raw_data": {"file_status": file_status, "analysis": quick_result},
                "timestamp": datetime.now().isoformat()
            }
            
            return response
            
        except Exception as e:
            return self._error_response(f"ìƒíƒœ ì²´í¬ ì‹¤íŒ¨: {str(e)}")
    
    def cmd_report(self, args: List[str]) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“ˆ Serena: ì¢…í•© ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        
        try:
            # ì „ì²´ ë¶„ì„ ì‹¤í–‰
            mcp_integration = SerenaMCPIntegration()
            mcp_result = mcp_integration.analyze_with_mcp_tools()
            
            optimizer = SerenaAutoOptimizer()
            opt_result = optimizer.analyze_and_fix_project(auto_apply=False)
            
            # ë³´ê³ ì„œ ìƒì„±
            report = self._generate_comprehensive_report(mcp_result, opt_result)
            
            # íŒŒì¼ë¡œ ì €ì¥
            report_file = Path("serena_comprehensive_report.md")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            response = {
                "status": "success",
                "command": "report",
                "serena_response": f"ğŸ“„ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}\\n\\n{report[:500]}...",
                "raw_data": {"mcp_result": mcp_result, "opt_result": opt_result},
                "report_file": str(report_file),
                "timestamp": datetime.now().isoformat()
            }
            
            return response
            
        except Exception as e:
            return self._error_response(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def _format_analysis_response(self, result: Dict[str, Any]) -> str:
        """ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        summary = result.get("project_summary", {})
        insights = result.get("solomond_specific_insights", [])
        recommendations = result.get("optimization_recommendations", [])
        
        response_parts = [
            f"ğŸ” **SOLOMOND AI ì‹œìŠ¤í…œ ë¶„ì„ ì™„ë£Œ**",
            f"",
            f"ğŸ“Š **ë¶„ì„ ê²°ê³¼ ìš”ì•½:**",
            f"â€¢ ë¶„ì„ëœ íŒŒì¼: {summary.get('files_analyzed', 0)}ê°œ",
            f"â€¢ ì½”ë“œ ë¼ì¸ ìˆ˜: {summary.get('total_lines', 0):,}ì¤„",  
            f"â€¢ ë°œê²¬ëœ ì´ìŠˆ: {summary.get('total_issues', 0)}ê°œ",
            f"â€¢ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ: {summary.get('critical_issues', 0)}ê°œ ğŸš¨",
            f"â€¢ ë†’ì€ ìš°ì„ ìˆœìœ„: {summary.get('high_issues', 0)}ê°œ âš ï¸",
            f"â€¢ ë³´í†µ ìš°ì„ ìˆœìœ„: {summary.get('medium_issues', 0)}ê°œ ğŸ“‹",
        ]
        
        if insights:
            response_parts.extend([
                f"",
                f"ğŸ§  **SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸:**"
            ])
            for insight in insights[:3]:  # ìƒìœ„ 3ê°œë§Œ
                emoji = {"positive": "âœ…", "warning": "âš ï¸", "improvement": "ğŸ“ˆ", "enhancement": "ğŸ”§"}
                response_parts.append(
                    f"â€¢ {emoji.get(insight.get('level'), 'ğŸ’¡')} {insight.get('title', '')}"
                )
        
        if recommendations:
            response_parts.extend([
                f"",
                f"ğŸ’¡ **ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­:**"
            ])
            for rec in recommendations[:2]:  # ìƒìœ„ 2ê°œë§Œ
                priority_emoji = {"critical": "ğŸš¨", "high": "âš ï¸", "medium": "ğŸ“‹"}
                response_parts.append(
                    f"â€¢ {priority_emoji.get(rec.get('priority'), 'ğŸ’¡')} {rec.get('title', '')}"
                )
                response_parts.append(f"  {rec.get('description', '')}")
        
        response_parts.extend([
            f"",
            f"ğŸ¯ **Serenaì˜ ë¶„ì„**: SOLOMOND AI ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì¡°ë¥¼ Symbol-levelë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
            f"ThreadPool ê´€ë¦¬, GPU ë©”ëª¨ë¦¬ ìµœì í™”, Streamlit ì„±ëŠ¥ ë“± ì „ë¬¸ ì˜ì—­ì„ ì¤‘ì ì ìœ¼ë¡œ ê²€í† í–ˆìŠµë‹ˆë‹¤."
        ])
        
        return "\\n".join(response_parts)
    
    def _format_fix_response(self, result: Dict[str, Any], auto_applied: bool, script_generated: bool) -> str:
        """ìˆ˜ì • ê²°ê³¼ í¬ë§·íŒ…"""
        summary = result.get("analysis_summary", {})
        
        response_parts = [
            f"ğŸ”§ **ìë™ ìˆ˜ì • ì‹œìŠ¤í…œ ê²°ê³¼**",
            f"",
            f"ğŸ“Š **ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆ ë¶„ì„:**",
            f"â€¢ ë¶„ì„ëœ íŒŒì¼: {summary.get('files_analyzed', 0)}ê°œ",
            f"â€¢ ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆ: {summary.get('fixable_issues', 0)}ê°œ",
            f"â€¢ í¬ë¦¬í‹°ì»¬ ìˆ˜ì •ì‚¬í•­: {summary.get('critical_fixes', 0)}ê°œ"
        ]
        
        if auto_applied:
            response_parts.extend([
                f"",
                f"âœ… **ìë™ ìˆ˜ì • ì ìš©ë¨:** {summary.get('auto_fixes_applied', 0)}ê°œ íŒŒì¼",
                f"ğŸ’¾ ë°±ì—… íŒŒì¼ì´ serena_backups/ ë””ë ‰í† ë¦¬ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
            ])
        else:
            response_parts.extend([
                f"",
                f"ğŸ“‹ **ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰ë¨** (ì‹¤ì œ ìˆ˜ì • ì•ˆí•¨)"
            ])
        
        if script_generated:
            response_parts.extend([
                f"",
                f"ğŸ“ **ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±:**",
                f"â€¢ íŒŒì¼: serena_auto_fix.py",
                f"â€¢ ì‹¤í–‰ ë°©ë²•: python serena_auto_fix.py",
                f"âš ï¸  **ì£¼ì˜**: ì‹¤í–‰ ì „ ì¤‘ìš” íŒŒì¼ì„ ë°±ì—…í•˜ì„¸ìš”!"
            ])
        
        response_parts.extend([
            f"",
            f"ğŸ¯ **Serenaì˜ ì œì•ˆ**: ThreadPoolExecutorì™€ íŒŒì¼ I/Oë¥¼ with ë¬¸ìœ¼ë¡œ ê°ì‹¸ê³ ,",
            f"GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ì¶”ê°€í•˜ë©´ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤."
        ])
        
        return "\\n".join(response_parts)
    
    def _format_health_response(self, result: Dict[str, Any], health_score: float, health_grade: str, health_emoji: str) -> str:
        """ê±´ê°•ë„ ê²°ê³¼ í¬ë§·íŒ…"""
        response_parts = [
            f"ğŸ¥ **SOLOMOND AI ì‹œìŠ¤í…œ ê±´ê°• ì§„ë‹¨**",
            f"",
            f"{health_emoji} **ì „ì²´ ê±´ê°•ë„: {health_score:.1f}/100 ({health_grade})**",
            f"",
            f"ğŸ“Š **ê±´ê°• ì§€í‘œ:**",
            f"â€¢ ë¶„ì„ëœ íŒŒì¼: {result.get('files_analyzed', 0)}ê°œ",
            f"â€¢ ë°œê²¬ëœ ì´ìŠˆ: {len(result.get('issues_found', []))}ê°œ"
        ]
        
        # ê±´ê°•ë„ë³„ ë§ì¶¤ ì¡°ì–¸
        if health_score >= 90:
            response_parts.extend([
                f"",
                f"ğŸ‰ **í›Œë¥­í•©ë‹ˆë‹¤!** SOLOMOND AI ì‹œìŠ¤í…œì´ ë§¤ìš° ê±´ê°•í•œ ìƒíƒœì…ë‹ˆë‹¤.",
                f"í˜„ì¬ ì½”ë“œ í’ˆì§ˆì„ ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ê¸°ëŠ¥ ê°œë°œì— ì§‘ì¤‘í•˜ì„¸ìš”."
            ])
        elif health_score >= 70:
            response_parts.extend([
                f"",
                f"ğŸ‘ **ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤.** ëª‡ ê°€ì§€ ê°œì„ ì‚¬í•­ì´ ìˆì§€ë§Œ ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤.",
                f"í¬ë¦¬í‹°ì»¬ ì´ìŠˆë¶€í„° ìš°ì„ ì ìœ¼ë¡œ í•´ê²°í•˜ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤."
            ])
        else:
            response_parts.extend([
                f"",
                f"âš ï¸  **ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.** ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìœ„í•´ ì¦‰ì‹œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                f"ThreadPool ê´€ë¦¬ì™€ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¬¸ì œë¥¼ ìš°ì„  í•´ê²°í•˜ì„¸ìš”."
            ])
        
        # ì¶”ì²œì‚¬í•­ ì¶”ê°€
        recommendations = result.get("recommendations", [])
        if recommendations:
            response_parts.extend([
                f"",
                f"ğŸ’¡ **ê±´ê°• ê°œì„  ë°©ì•ˆ:**"
            ])
            for rec in recommendations[:3]:
                response_parts.append(f"â€¢ {rec}")
        
        return "\\n".join(response_parts)
    
    def _format_optimize_response(self, recommendations: List[Dict], insights: List[Dict]) -> str:
        """ìµœì í™” ê²°ê³¼ í¬ë§·íŒ…"""
        response_parts = [
            f"âš¡ **SOLOMOND AI ì„±ëŠ¥ ìµœì í™” ë¶„ì„**",
            f"",
            f"ğŸ¯ **Serenaì˜ ìµœì í™” ì „ëµ**"
        ]
        
        if recommendations:
            response_parts.append(f"")
            response_parts.append(f"ğŸš€ **ìš°ì„ ìˆœìœ„ ìµœì í™” í•­ëª©:**")
            
            for i, rec in enumerate(recommendations[:3], 1):
                priority_emoji = {"critical": "ğŸš¨", "high": "âš ï¸", "medium": "ğŸ“‹"}
                response_parts.extend([
                    f"",
                    f"{i}. {priority_emoji.get(rec.get('priority'), 'ğŸ’¡')} **{rec.get('title', '')}**",
                    f"   {rec.get('description', '')}",
                    f"   ğŸ’ **SOLOMOND íš¨ê³¼**: {rec.get('solomond_benefit', 'ì„±ëŠ¥ í–¥ìƒ')}"
                ])
        
        if insights:
            response_parts.extend([
                f"",
                f"ğŸ§  **ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸:**"
            ])
            
            for insight in insights[:2]:
                emoji = {"positive": "âœ…", "warning": "âš ï¸", "improvement": "ğŸ“ˆ", "enhancement": "ğŸ”§"}
                response_parts.extend([
                    f"â€¢ {emoji.get(insight.get('level'), 'ğŸ’¡')} {insight.get('title', '')}",
                    f"  {insight.get('message', '')}"
                ])
        
        response_parts.extend([
            f"",
            f"ğŸ¯ **Serenaì˜ í•µì‹¬ ì œì•ˆ:**",
            f"1. ThreadPoolExecutorë¥¼ with ë¬¸ìœ¼ë¡œ ê°ì‹¸ ë¦¬ì†ŒìŠ¤ ì•ˆì „ ê´€ë¦¬",
            f"2. Streamlit @st.cache_dataë¡œ AI ëª¨ë¸ ë¡œë”© ìµœì í™”", 
            f"3. torch.cuda.empty_cache()ë¡œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬",
            f"4. Ollama API í˜¸ì¶œì— ì¬ì‹œë„ ë¡œì§ ì¶”ê°€"
        ])
        
        return "\\n".join(response_parts)
    
    def _format_info_response(self, agent_info: Dict[str, Any]) -> str:
        """ì—ì´ì „íŠ¸ ì •ë³´ í¬ë§·íŒ…"""
        response_parts = [
            f"ğŸ¤– **{agent_info.get('name', 'Serena')} v{agent_info.get('version', '1.0.0')}**",
            f"",
            f"ğŸ¯ **ì—­í• **: {agent_info.get('role', '')}",
            f"",
            f"âš¡ **ì „ë¬¸ ë¶„ì•¼:**"
        ]
        
        for expertise in agent_info.get("expertise", [])[:6]:
            response_parts.append(f"â€¢ {expertise}")
        
        response_parts.extend([
            f"",
            f"ğŸ› ï¸  **í•µì‹¬ ê¸°ëŠ¥:**"
        ])
        
        for capability in agent_info.get("capabilities", [])[:5]:
            response_parts.append(f"â€¢ {capability}")
        
        response_parts.extend([
            f"",
            f"ğŸ“‹ **ì§€ì› ëª…ë ¹ì–´:**"
        ])
        
        for command in agent_info.get("supported_commands", []):
            response_parts.append(f"â€¢ {command}")
        
        response_parts.extend([
            f"",
            f"ğŸ’¬ **ì‘ë‹µ ìŠ¤íƒ€ì¼**: {agent_info.get('response_style', 'ì •ë°€í•˜ê³  ì‹¤ìš©ì ì¸ ê¸°ìˆ  ì¡°ì–¸')}",
            f"",
            f"ğŸ† **Serenaì˜ íŠ¹ë³„í•¨**: SOLOMOND AI ì‹œìŠ¤í…œì— íŠ¹í™”ëœ ì½”ë”© ì—ì´ì „íŠ¸ë¡œì„œ",
            f"Symbol-level ë¶„ì„ê³¼ ìë™ ìµœì í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."
        ])
        
        return "\\n".join(response_parts)
    
    def _format_status_response(self, file_status: Dict[str, Any], analysis_result: Dict[str, Any]) -> str:
        """ìƒíƒœ ì²´í¬ ê²°ê³¼ í¬ë§·íŒ…"""
        response_parts = [
            f"ğŸ“Š **SOLOMOND AI ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬**",
            f"",
            f"ğŸ“ **í•µì‹¬ íŒŒì¼ ìƒíƒœ:**"
        ]
        
        for file_name, status in file_status.items():
            emoji = "âœ…" if status["exists"] else "âŒ"
            size_info = f"({status['size_kb']}KB)" if status["exists"] else ""
            response_parts.append(f"â€¢ {emoji} {file_name} {size_info}")
        
        # ë¹ ë¥¸ ë¶„ì„ ê²°ê³¼
        health_score = analysis_result.get("health_score", 0)
        status_emoji = "ğŸŸ¢" if health_score >= 80 else "ğŸŸ¡" if health_score >= 60 else "ğŸ”´"
        
        response_parts.extend([
            f"",
            f"ğŸ¥ **ì‹œìŠ¤í…œ ê±´ê°•ë„**: {status_emoji} {health_score:.1f}/100",
            f"ğŸ” **ë°œê²¬ëœ ì´ìŠˆ**: {len(analysis_result.get('issues_found', []))}ê°œ",
            f"",
            f"ğŸ’¡ **ë¹ ë¥¸ ì§„ë‹¨**: í•µì‹¬ íŒŒì¼ë“¤ì´ {'ì •ìƒ' if all(s['exists'] for s in file_status.values()) else 'ì¼ë¶€ ëˆ„ë½'}ì´ë©°,",
            f"ì‹œìŠ¤í…œì´ {'ì–‘í˜¸í•œ' if health_score >= 70 else 'ê°œì„ ì´ í•„ìš”í•œ'} ìƒíƒœì…ë‹ˆë‹¤."
        ])
        
        return "\\n".join(response_parts)
    
    def _generate_comprehensive_report(self, mcp_result: Dict[str, Any], opt_result: Dict[str, Any]) -> str:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report_lines = [
            f"# ğŸ¤– Serena - SOLOMOND AI ì‹œìŠ¤í…œ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ",
            f"",
            f"**ìƒì„± ì‹œê°„**: {timestamp}  ",
            f"**ë¶„ì„ ì—”ì§„**: Serena v1.0.0 (Claude Code Sub-Agent)  ",
            f"**ëŒ€ìƒ ì‹œìŠ¤í…œ**: SOLOMOND AI Conference Analysis Platform",
            f"",
            f"## ğŸ“Š ë¶„ì„ ìš”ì•½",
            f"",
            f"### ğŸ” MCP í†µí•© ë¶„ì„",
            f"- **ë¶„ì„ëœ íŒŒì¼**: {mcp_result.get('project_summary', {}).get('files_analyzed', 0)}ê°œ",
            f"- **ì´ ì½”ë“œ ë¼ì¸**: {mcp_result.get('project_summary', {}).get('total_lines', 0):,}ì¤„", 
            f"- **ë°œê²¬ëœ ì´ìŠˆ**: {mcp_result.get('project_summary', {}).get('total_issues', 0)}ê°œ",
            f"- **ë¶„ì„ ì‹œê°„**: {mcp_result.get('analysis_metadata', {}).get('duration_ms', 0):.1f}ms",
            f"",
            f"### ğŸ”§ ìë™ ìµœì í™” ë¶„ì„",
            f"- **ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆ**: {opt_result.get('analysis_summary', {}).get('fixable_issues', 0)}ê°œ",
            f"- **í¬ë¦¬í‹°ì»¬ ìˆ˜ì •ì‚¬í•­**: {opt_result.get('analysis_summary', {}).get('critical_fixes', 0)}ê°œ",
            f"",
            f"## ğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­",
            f""
        ]
        
        # SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸
        insights = mcp_result.get("solomond_specific_insights", [])
        if insights:
            report_lines.extend([
                f"### ğŸ§  SOLOMOND AI íŠ¹í™” ì¸ì‚¬ì´íŠ¸",
                f""
            ])
            
            for insight in insights:
                emoji = {"positive": "âœ…", "warning": "âš ï¸", "improvement": "ğŸ“ˆ", "enhancement": "ğŸ”§"}
                report_lines.extend([
                    f"#### {emoji.get(insight.get('level'), 'ğŸ’¡')} {insight.get('title', '')}",
                    f"{insight.get('message', '')}",
                    f"**ì˜í–¥**: {insight.get('impact', '')}",
                    f""
                ])
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­
        recommendations = mcp_result.get("optimization_recommendations", [])
        if recommendations:
            report_lines.extend([
                f"### ğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­",
                f""
            ])
            
            for i, rec in enumerate(recommendations, 1):
                priority_emoji = {"critical": "ğŸš¨", "high": "âš ï¸", "medium": "ğŸ“‹"}
                report_lines.extend([
                    f"#### {i}. {priority_emoji.get(rec.get('priority'), 'ğŸ’¡')} {rec.get('title', '')}",
                    f"**ìš°ì„ ìˆœìœ„**: {rec.get('priority', '').upper()}  ",
                    f"**ì„¤ëª…**: {rec.get('description', '')}  ",
                    f"**ì˜ˆìƒ íš¨ê³¼**: {rec.get('solomond_benefit', '')}  ",
                    f"**ì†Œìš” ì‹œê°„**: {rec.get('estimated_time', 'N/A')}",
                    f""
                ])
        
        # ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„
        total_issues = mcp_result.get("project_summary", {}).get("total_issues", 0)
        critical_issues = mcp_result.get("project_summary", {}).get("critical_issues", 0)
        
        report_lines.extend([
            f"## ğŸ ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„",
            f"",
            f"### ğŸ“ˆ ì „ì²´ í‰ê°€",
            f"SOLOMOND AI ì‹œìŠ¤í…œì€ ",
        ])
        
        if critical_issues == 0:
            report_lines.append(f"**ì–‘í˜¸í•œ ìƒíƒœ**ì…ë‹ˆë‹¤. í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•„ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif critical_issues <= 2:
            report_lines.append(f"**ê°œì„ ì´ í•„ìš”í•œ ìƒíƒœ**ì…ë‹ˆë‹¤. {critical_issues}ê°œì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆë¥¼ ìš°ì„  í•´ê²°í•˜ì„¸ìš”.")
        else:
            report_lines.append(f"**ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•œ ìƒíƒœ**ì…ë‹ˆë‹¤. {critical_issues}ê°œì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆê°€ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìœ„í˜‘í•©ë‹ˆë‹¤.")
        
        report_lines.extend([
            f"",
            f"### ğŸ¯ ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ì•„ì´í…œ",
            f"1. **ThreadPool ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**: with ë¬¸ì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì‹¤í–‰ì ê´€ë¦¬",
            f"2. **GPU ë©”ëª¨ë¦¬ ìµœì í™”**: torch.cuda.empty_cache() ì •ê¸° í˜¸ì¶œ",
            f"3. **Streamlit ì„±ëŠ¥ í–¥ìƒ**: @st.cache_data ë°ì½”ë ˆì´í„° ì ìš©",
            f"4. **ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”**: Ollama API í˜¸ì¶œì— ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€",
            f"",
            f"### ğŸ¤– Serenaì˜ ìµœì¢… ì œì•ˆ",
            f"SOLOMOND AI ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ ìœ„í•´ ThreadPool ê´€ë¦¬ë¥¼ ê°€ì¥ ìš°ì„ ìœ¼ë¡œ ê°œì„ í•˜ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤. ",
            f"ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™œìš©í•˜ë©´ ëŒ€ë¶€ë¶„ì˜ í¬ë¦¬í‹°ì»¬ ì´ìŠˆë¥¼ ì‹ ì†í•˜ê²Œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            f"",
            f"---",
            f"*ì´ ë³´ê³ ì„œëŠ” Serena (SOLOMOND AI ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸)ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"
        ])
        
        return "\\n".join(report_lines)
    
    def _error_response(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            "status": "error",
            "serena_response": f"âŒ **ì˜¤ë¥˜ ë°œìƒ**: {error_message}\\n\\nğŸ’¡ 'help' ëª…ë ¹ì–´ë¡œ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ê±°ë‚˜, ë¬¸ì œê°€ ì§€ì†ë˜ë©´ SOLOMOND AI íŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”.",
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }

def main():
    """CLI ì¸í„°í˜ì´ìŠ¤ ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="Serena - SOLOMOND AI ì „ë¬¸ ì½”ë”© ì—ì´ì „íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python serena_claude_interface.py analyze
  python serena_claude_interface.py fix --auto
  python serena_claude_interface.py health
  python serena_claude_interface.py help
        """
    )
    
    parser.add_argument("command", nargs="?", default="help",
                       help="ì‹¤í–‰í•  ëª…ë ¹ì–´ (analyze, fix, health, optimize, info, help, status, report)")
    parser.add_argument("--auto", action="store_true",
                       help="fix ëª…ë ¹ì–´ì—ì„œ ìë™ ìˆ˜ì • ì ìš©")
    
    args = parser.parse_args()
    
    # Serena ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
    interface = SerenaClaudeInterface()
    
    # ëª…ë ¹ì–´ ì²˜ë¦¬
    cmd_args = []
    if args.auto:
        cmd_args.append("--auto")
    
    result = interface.process_command(args.command, cmd_args)
    
    # ê²°ê³¼ ì¶œë ¥
    if result["status"] == "success":
        print(result["serena_response"])
        return 0
    else:
        print(result["serena_response"])
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)