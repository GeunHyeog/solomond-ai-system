#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” Enhanced OCR Engine - PPT ì´ë¯¸ì§€ íŠ¹í™” OCR ì‹œìŠ¤í…œ
Advanced Multi-Engine OCR System for Presentation Images

í•µì‹¬ ê¸°ëŠ¥:
1. PPT ì´ë¯¸ì§€ íŠ¹í™” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
2. ë‹¤ì¤‘ OCR ì—”ì§„ í†µí•© (EasyOCR + Tesseract + PaddleOCR)
3. ê²°ê³¼ êµì°¨ ê²€ì¦ ë° ìµœì  ì„ íƒ
4. í”„ë¡œì ì…˜ ìƒ‰ìƒ ì™œê³¡ ìë™ ë³´ì •
5. ë³µì¡í•œ ë°°ê²½ì—ì„œ í…ìŠ¤íŠ¸ ë¶„ë¦¬
6. ì ì‘í˜• ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •
"""

import os
import sys
import cv2
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass
import time
import logging
from pathlib import Path
import json
import hashlib
from PIL import Image, ImageEnhance, ImageFilter
import math

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# OCR ì—”ì§„ import (ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒë§Œ)
OCR_ENGINES = {}

try:
    import easyocr
    OCR_ENGINES['easyocr'] = True
    logger.info("âœ… EasyOCR ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    OCR_ENGINES['easyocr'] = False
    logger.warning("âš ï¸ EasyOCR ì‚¬ìš© ë¶ˆê°€")

try:
    import pytesseract
    from PIL import Image
    OCR_ENGINES['tesseract'] = True
    logger.info("âœ… Tesseract ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    OCR_ENGINES['tesseract'] = False
    logger.warning("âš ï¸ Tesseract ì‚¬ìš© ë¶ˆê°€")

try:
    # PaddleOCRì€ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©
    import paddleocr
    OCR_ENGINES['paddleocr'] = True
    logger.info("âœ… PaddleOCR ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    OCR_ENGINES['paddleocr'] = False
    logger.info("â„¹ï¸ PaddleOCR ì‚¬ìš© ë¶ˆê°€ (ì„ íƒì‚¬í•­)")

@dataclass
class OCRResult:
    """OCR ê²°ê³¼ êµ¬ì¡°"""
    engine: str
    text: str
    confidence: float
    processing_time: float
    bbox_count: int
    metadata: Dict[str, Any]

@dataclass 
class EnhancedOCRResult:
    """ê°•í™”ëœ OCR ìµœì¢… ê²°ê³¼"""
    final_text: str
    confidence: float
    processing_time: float
    engines_used: List[str]
    best_engine: str
    individual_results: List[OCRResult]
    preprocessing_applied: List[str]
    image_quality_score: float

class PPTImagePreprocessor:
    """PPT ì´ë¯¸ì§€ ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.preprocess_history = []
    
    def enhance_ppt_image(self, image_array: np.ndarray) -> Tuple[np.ndarray, List[str]]:
        """PPT ì´ë¯¸ì§€ íŠ¹í™” ì „ì²˜ë¦¬"""
        applied_operations = []
        processed_image = image_array.copy()
        
        try:
            # 1. ê¸°ë³¸ ìƒ‰ìƒ ê³µê°„ ë³€í™˜ ë° ì •ê·œí™”
            if len(processed_image.shape) == 3:
                # ë°ê¸° ë° ëŒ€ë¹„ ìë™ ì¡°ì •
                processed_image = self._auto_adjust_brightness_contrast(processed_image)
                applied_operations.append("brightness_contrast_adjustment")
                
                # ìƒ‰ìƒ ì •ê·œí™” (í”„ë¡œì í„° ìƒ‰ì™œê³¡ ë³´ì •)
                processed_image = self._normalize_projection_colors(processed_image)
                applied_operations.append("projection_color_normalization")
            
            # 2. ë…¸ì´ì¦ˆ ì œê±°
            processed_image = cv2.bilateralFilter(processed_image, 9, 75, 75)
            applied_operations.append("bilateral_noise_reduction")
            
            # 3. ì„ ëª…ë„ í–¥ìƒ
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            processed_image = cv2.filter2D(processed_image, -1, kernel)
            applied_operations.append("sharpening")
            
            # 4. ê°ë„ ë³´ì • (ê¸°ìš¸ì–´ì§„ ì‚¬ì§„ ë³´ì •)
            processed_image, angle = self._correct_skew(processed_image)
            if abs(angle) > 0.5:  # 0.5ë„ ì´ìƒ ë³´ì •ëœ ê²½ìš°
                applied_operations.append(f"skew_correction_{angle:.1f}deg")
            
            # 5. í…ìŠ¤íŠ¸ ì˜ì—­ ê°•ì¡°
            processed_image = self._enhance_text_regions(processed_image)
            applied_operations.append("text_region_enhancement")
            
            return processed_image, applied_operations
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
            return image_array, ["preprocessing_failed"]
    
    def _auto_adjust_brightness_contrast(self, image: np.ndarray) -> np.ndarray:
        """ìë™ ë°ê¸°/ëŒ€ë¹„ ì¡°ì •"""
        # íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ìë™ ì¡°ì •
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # íˆìŠ¤í† ê·¸ë¨ ë¶„ì„
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        
        # ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ ê³„ì‚°
        cdf = hist.cumsum()
        cdf_normalized = cdf * 255 / cdf[-1]
        
        # 1%ì™€ 99% ì§€ì  ì°¾ê¸°
        low_percentile = np.searchsorted(cdf_normalized, 1)
        high_percentile = np.searchsorted(cdf_normalized, 99)
        
        if high_percentile > low_percentile:
            # ëŒ€ë¹„ ìŠ¤íŠ¸ë ˆì¹­ ì ìš©
            alpha = 255.0 / (high_percentile - low_percentile)
            beta = -low_percentile * alpha
            
            adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
            return adjusted
        
        return image
    
    def _normalize_projection_colors(self, image: np.ndarray) -> np.ndarray:
        """í”„ë¡œì í„° ìƒ‰ì™œê³¡ ë³´ì •"""
        # LAB ìƒ‰ê³µê°„ì—ì„œ ìƒ‰ìƒ ì •ê·œí™”
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # L ì±„ë„ (ë°ê¸°) íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
        l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(l)
        
        # A, B ì±„ë„ ì •ê·œí™”
        a = cv2.normalize(a, None, alpha=127-30, beta=127+30, norm_type=cv2.NORM_MINMAX)
        b = cv2.normalize(b, None, alpha=127-30, beta=127+30, norm_type=cv2.NORM_MINMAX)
        
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    
    def _correct_skew(self, image: np.ndarray) -> Tuple[np.ndarray, float]:
        """ê¸°ìš¸ì–´ì§„ ì´ë¯¸ì§€ ìë™ ë³´ì •"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # ê°€ì¥ìë¦¬ ê²€ì¶œ
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        
        # í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ì§ì„  ê²€ì¶œ
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
        
        if lines is not None and len(lines) > 0:
            # ê°ë„ ê³„ì‚°
            angles = []
            for line in lines[:20]:  # ìƒìœ„ 20ê°œ ì§ì„ ë§Œ ì‚¬ìš©
                rho, theta = line[0]
                angle = (theta - np.pi/2) * 180 / np.pi
                if -45 < angle < 45:  # ìœ íš¨í•œ ê°ë„ ë²”ìœ„
                    angles.append(angle)
            
            if angles:
                # ì¤‘ì•™ê°’ ì‚¬ìš© (ë…¸ì´ì¦ˆì— ê°•í•¨)
                median_angle = np.median(angles)
                
                # ê¸°ìš¸ê¸° ë³´ì •
                if abs(median_angle) > 0.5:
                    center = (image.shape[1]//2, image.shape[0]//2)
                    rotation_matrix = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                    corrected = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]),
                                             borderMode=cv2.BORDER_REPLICATE)
                    return corrected, median_angle
        
        return image, 0.0
    
    def _enhance_text_regions(self, image: np.ndarray) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì˜ì—­ ê°•ì¡°"""
        # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°•ì¡°
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # í…ìŠ¤íŠ¸ì™€ ë°°ê²½ ë¶„ë¦¬ë¥¼ ìœ„í•œ ì ì‘í˜• ì´ì§„í™”
        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                     cv2.THRESH_BINARY, 11, 2)
        
        # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ê¸€ì ì—°ê²°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
        processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # ì›ë³¸ ì´ë¯¸ì§€ì™€ ê²°í•©
        if len(image.shape) == 3:
            enhanced = image.copy()
            # í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ ì„ ëª…í•˜ê²Œ 
            mask = processed < 128
            enhanced[mask] = cv2.addWeighted(enhanced[mask], 0.7, 
                                           cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR)[mask], 0.3, 0)
            return enhanced
        
        return processed

class EnhancedOCREngine:
    """ê°•í™”ëœ ë‹¤ì¤‘ OCR ì—”ì§„"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        self.preprocessor = PPTImagePreprocessor()
        self.ocr_instances = {}
        self.cache = {}
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ OCR ì—”ì§„ ì´ˆê¸°í™”
        self._initialize_engines()
        logger.info(f"ğŸ” Enhanced OCR ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ ({len(self.ocr_instances)}ê°œ ì—”ì§„)")
    
    def _get_default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            'engines': {
                'easyocr': {'enabled': True, 'languages': ['ko', 'en'], 'gpu': False},
                'tesseract': {'enabled': True, 'config': '--psm 6'},
                'paddleocr': {'enabled': True, 'use_angle_cls': True, 'lang': 'korean'}
            },
            'preprocessing': {
                'enabled': True,
                'ppt_optimization': True,
                'max_image_size': 2048
            },
            'confidence': {
                'min_threshold': 0.7,  # ê¸°ì¡´ë³´ë‹¤ ë†’ìŒ
                'adaptive_threshold': True,
                'cross_validation': True
            },
            'performance': {
                'parallel_processing': True,
                'cache_results': True,
                'max_processing_time': 60
            }
        }
    
    def _initialize_engines(self):
        """OCR ì—”ì§„ë“¤ ì´ˆê¸°í™”"""
        # EasyOCR
        if OCR_ENGINES['easyocr'] and self.config['engines']['easyocr']['enabled']:
            try:
                self.ocr_instances['easyocr'] = easyocr.Reader(
                    self.config['engines']['easyocr']['languages'],
                    gpu=self.config['engines']['easyocr']['gpu']
                )
                logger.info("âœ… EasyOCR ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Tesseract
        if OCR_ENGINES['tesseract'] and self.config['engines']['tesseract']['enabled']:
            try:
                # Tesseract ì„¤ì¹˜ í™•ì¸
                pytesseract.get_tesseract_version()
                self.ocr_instances['tesseract'] = True
                logger.info("âœ… Tesseract ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ Tesseract ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # PaddleOCR
        if OCR_ENGINES['paddleocr'] and self.config['engines']['paddleocr']['enabled']:
            try:
                self.ocr_instances['paddleocr'] = paddleocr.PaddleOCR(
                    use_angle_cls=self.config['engines']['paddleocr']['use_angle_cls'],
                    lang=self.config['engines']['paddleocr']['lang'],
                    show_log=False
                )
                logger.info("âœ… PaddleOCR ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        if not self.ocr_instances:
            raise RuntimeError("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ OCR ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤")
    
    def process_image(self, image_path: Union[str, Path], 
                     compare_engines: bool = False) -> EnhancedOCRResult:
        """ì´ë¯¸ì§€ OCR ì²˜ë¦¬ (ë‹¤ì¤‘ ì—”ì§„)"""
        start_time = time.time()
        image_path = Path(image_path)
        
        # ìºì‹œ í™•ì¸
        cache_key = self._get_cache_key(image_path)
        if cache_key in self.cache and self.config['performance']['cache_results']:
            logger.info(f"ğŸ“‹ ìºì‹œì—ì„œ ê²°ê³¼ ë¡œë“œ: {image_path.name}")
            return self.cache[cache_key]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
        
        # ì „ì²˜ë¦¬
        preprocessing_applied = []
        if self.config['preprocessing']['enabled']:
            image, preprocessing_applied = self.preprocessor.enhance_ppt_image(image)
        
        # ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = self._calculate_image_quality(image)
        
        # ê° OCR ì—”ì§„ìœ¼ë¡œ ì²˜ë¦¬
        individual_results = []
        
        for engine_name in self.ocr_instances.keys():
            try:
                engine_start = time.time()
                result = self._process_with_engine(engine_name, image)
                engine_time = time.time() - engine_start
                
                individual_results.append(OCRResult(
                    engine=engine_name,
                    text=result['text'],
                    confidence=result['confidence'],
                    processing_time=engine_time,
                    bbox_count=result.get('bbox_count', 0),
                    metadata=result.get('metadata', {})
                ))
                
            except Exception as e:
                logger.warning(f"âš ï¸ {engine_name} OCR ì‹¤íŒ¨: {e}")
                individual_results.append(OCRResult(
                    engine=engine_name,
                    text="",
                    confidence=0.0,
                    processing_time=0.0,
                    bbox_count=0,
                    metadata={'error': str(e)}
                ))
        
        # ìµœì  ê²°ê³¼ ì„ íƒ
        best_result = self._select_best_result(individual_results)
        
        total_time = time.time() - start_time
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        enhanced_result = EnhancedOCRResult(
            final_text=best_result.text,
            confidence=best_result.confidence,
            processing_time=total_time,
            engines_used=[r.engine for r in individual_results if r.confidence > 0],
            best_engine=best_result.engine,
            individual_results=individual_results,
            preprocessing_applied=preprocessing_applied,
            image_quality_score=quality_score
        )
        
        # ìºì‹œ ì €ì¥
        if self.config['performance']['cache_results']:
            self.cache[cache_key] = enhanced_result
        
        return enhanced_result
    
    def _process_with_engine(self, engine_name: str, image: np.ndarray) -> Dict:
        """íŠ¹ì • OCR ì—”ì§„ìœ¼ë¡œ ì²˜ë¦¬"""
        if engine_name == 'easyocr':
            return self._process_easyocr(image)
        elif engine_name == 'tesseract':
            return self._process_tesseract(image)
        elif engine_name == 'paddleocr':
            return self._process_paddleocr(image)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—”ì§„: {engine_name}")
    
    def _process_easyocr(self, image: np.ndarray) -> Dict:
        """EasyOCR ì²˜ë¦¬"""
        results = self.ocr_instances['easyocr'].readtext(image)
        
        text_blocks = []
        confidences = []
        
        for detection in results:
            bbox, text, confidence = detection
            if confidence >= self.config['confidence']['min_threshold']:
                text_blocks.append(text.strip())
                confidences.append(confidence)
        
        full_text = ' '.join(text_blocks)
        avg_confidence = np.mean(confidences) if confidences else 0.0
        
        return {
            'text': full_text,
            'confidence': avg_confidence,
            'bbox_count': len(text_blocks),
            'metadata': {'engine': 'easyocr', 'raw_results': len(results)}
        }
    
    def _process_tesseract(self, image: np.ndarray) -> Dict:
        """Tesseract ì²˜ë¦¬"""
        # PIL Imageë¡œ ë³€í™˜
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # OCR ì‹¤í–‰
        config = self.config['engines']['tesseract']['config']
        text = pytesseract.image_to_string(pil_image, config=config, lang='kor+eng')
        
        # ì‹ ë¢°ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        data = pytesseract.image_to_data(pil_image, config=config, lang='kor+eng', output_type=pytesseract.Output.DICT)
        
        # ìœ íš¨í•œ í…ìŠ¤íŠ¸ ë¸”ë¡ì˜ ì‹ ë¢°ë„ ê³„ì‚°
        confidences = []
        valid_text_count = 0
        
        for i, conf in enumerate(data['conf']):
            if int(conf) > 0 and data['text'][i].strip():
                confidences.append(int(conf) / 100.0)  # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
                valid_text_count += 1
        
        avg_confidence = np.mean(confidences) if confidences else 0.0
        
        return {
            'text': text.strip(),
            'confidence': avg_confidence,
            'bbox_count': valid_text_count,
            'metadata': {'engine': 'tesseract', 'total_boxes': len(data['text'])}
        }
    
    def _process_paddleocr(self, image: np.ndarray) -> Dict:
        """PaddleOCR ì²˜ë¦¬"""
        results = self.ocr_instances['paddleocr'].ocr(image, cls=True)
        
        if not results or not results[0]:
            return {'text': '', 'confidence': 0.0, 'bbox_count': 0, 'metadata': {'engine': 'paddleocr'}}
        
        text_blocks = []
        confidences = []
        
        for detection in results[0]:
            if len(detection) >= 2:
                bbox, (text, confidence) = detection[0], detection[1]
                if confidence >= self.config['confidence']['min_threshold']:
                    text_blocks.append(text.strip())
                    confidences.append(confidence)
        
        full_text = ' '.join(text_blocks)
        avg_confidence = np.mean(confidences) if confidences else 0.0
        
        return {
            'text': full_text,
            'confidence': avg_confidence,
            'bbox_count': len(text_blocks),
            'metadata': {'engine': 'paddleocr', 'total_detections': len(results[0])}
        }
    
    def _select_best_result(self, results: List[OCRResult]) -> OCRResult:
        """ìµœì  OCR ê²°ê³¼ ì„ íƒ"""
        if not results:
            raise ValueError("OCR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ í•„í„°ë§
        valid_results = [r for r in results if r.confidence > 0 and r.text.strip()]
        
        if not valid_results:
            # ëª¨ë“  ì—”ì§„ì´ ì‹¤íŒ¨í•œ ê²½ìš°, ê°€ì¥ ì²˜ë¦¬ ì‹œê°„ì´ ì§§ì€ ê²ƒ ë°˜í™˜
            return min(results, key=lambda x: x.processing_time)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì‹ ë¢°ë„ + í…ìŠ¤íŠ¸ ê¸¸ì´ + ì—”ì§„ ìš°ì„ ìˆœìœ„)
        engine_priority = {'paddleocr': 3, 'easyocr': 2, 'tesseract': 1}
        
        best_result = None
        best_score = -1
        
        for result in valid_results:
            # ì ìˆ˜ ê³„ì‚°
            confidence_score = result.confidence
            length_score = min(len(result.text) / 100.0, 1.0)  # í…ìŠ¤íŠ¸ ê¸¸ì´ (ìµœëŒ€ 100ì ê¸°ì¤€)
            priority_score = engine_priority.get(result.engine, 1) / 3.0
            
            total_score = (confidence_score * 0.6 + 
                          length_score * 0.3 + 
                          priority_score * 0.1)
            
            if total_score > best_score:
                best_score = total_score
                best_result = result
        
        return best_result or results[0]
    
    def _calculate_image_quality(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-1)"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            
            # ì„ ëª…ë„ ì¸¡ì • (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_score = min(sharpness / 1000.0, 1.0)
            
            # ëŒ€ë¹„ ì¸¡ì •
            contrast = gray.std()
            contrast_score = min(contrast / 128.0, 1.0)
            
            # ë°ê¸° ë¶„í¬ ì¸¡ì •
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            brightness_distribution = np.std(hist)
            brightness_score = min(brightness_distribution / 1000.0, 1.0)
            
            # ì¢…í•© ì ìˆ˜
            quality_score = (sharpness_score * 0.5 + 
                           contrast_score * 0.3 + 
                           brightness_score * 0.2)
            
            return quality_score
            
        except Exception:
            return 0.5  # ê¸°ë³¸ê°’
    
    def _get_cache_key(self, image_path: Path) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        # íŒŒì¼ ë‚´ìš©ì˜ í•´ì‹œê°’ ì‚¬ìš©
        try:
            with open(image_path, 'rb') as f:
                file_content = f.read()
            return hashlib.md5(file_content).hexdigest()
        except:
            return str(image_path)

# ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í˜¸í™˜ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤
def process_image_enhanced(image_path: Union[str, Path], 
                          fallback_function: Optional[callable] = None) -> Dict[str, Any]:
    """
    ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í˜¸í™˜ë˜ëŠ” ê°•í™”ëœ OCR ì²˜ë¦¬ í•¨ìˆ˜
    
    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        fallback_function: ì‹¤íŒ¨ì‹œ ì‚¬ìš©í•  ê¸°ì¡´ OCR í•¨ìˆ˜
    
    Returns:
        ê¸°ì¡´ í˜•ì‹ê³¼ í˜¸í™˜ë˜ëŠ” ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # Enhanced OCR ì—”ì§„ ì‚¬ìš©
        ocr_engine = EnhancedOCREngine()
        result = ocr_engine.process_image(image_path)
        
        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return {
            'text': result.final_text,
            'text_blocks': [{'text': result.final_text, 'confidence': result.confidence}],
            'total_blocks': 1,
            'average_confidence': result.confidence,
            'processing_time': result.processing_time,
            'enhanced': True,
            'engines_used': result.engines_used,
            'best_engine': result.best_engine,
            'image_quality': result.image_quality_score,
            'preprocessing': result.preprocessing_applied
        }
        
    except Exception as e:
        logger.error(f"âŒ Enhanced OCR ì‹¤íŒ¨: {e}")
        
        # í´ë°± í•¨ìˆ˜ ì‚¬ìš©
        if fallback_function:
            logger.info("ğŸ”„ ê¸°ì¡´ OCR í´ë°± ì‚¬ìš©")
            try:
                fallback_result = fallback_function(image_path)
                if isinstance(fallback_result, dict):
                    fallback_result['enhanced'] = False
                    fallback_result['fallback_used'] = True
                    return fallback_result
            except Exception as fallback_error:
                logger.error(f"âŒ í´ë°± OCRë„ ì‹¤íŒ¨: {fallback_error}")
        
        # ìµœì¢… ì‹¤íŒ¨
        return {
            'text': '',
            'text_blocks': [],
            'total_blocks': 0,
            'average_confidence': 0.0,
            'processing_time': 0.0,
            'enhanced': False,
            'error': str(e)
        }

if __name__ == "__main__":
    # Enhanced OCR í…ŒìŠ¤íŠ¸
    try:
        ocr_engine = EnhancedOCREngine()
        print(f"âœ… Enhanced OCR ì—”ì§„ ì´ˆê¸°í™” ì„±ê³µ ({len(ocr_engine.ocr_instances)}ê°œ ì—”ì§„)")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ì§„ ì¶œë ¥
        for engine in ocr_engine.ocr_instances.keys():
            print(f"  ğŸ” {engine} ì‚¬ìš© ê°€ëŠ¥")
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì²˜ë¦¬
        test_image_path = Path("test_files/test.png")
        if test_image_path.exists():
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬: {test_image_path}")
            result = ocr_engine.process_image(test_image_path)
            print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {result.final_text[:100]}...")
            print(f"ğŸ¯ ì‹ ë¢°ë„: {result.confidence:.2f}")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
            print(f"ğŸ† ìµœì  ì—”ì§„: {result.best_engine}")
        
    except Exception as e:
        print(f"âŒ Enhanced OCR í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()